TabNet Logs:

Saving copy of script...
In this script only the Era dataset is used
Normalization used is StandardScaler
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 0
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 03:30:40
epoch 0  | loss: 1.68231 | val_0_rmse: 1.00455 | val_1_rmse: 0.98893 |  0:00:02s
epoch 1  | loss: 1.07703 | val_0_rmse: 1.0034  | val_1_rmse: 0.98878 |  0:00:03s
epoch 2  | loss: 0.96405 | val_0_rmse: 0.95461 | val_1_rmse: 0.93579 |  0:00:04s
epoch 3  | loss: 0.83011 | val_0_rmse: 0.85762 | val_1_rmse: 0.86629 |  0:00:04s
epoch 4  | loss: 0.67287 | val_0_rmse: 0.83497 | val_1_rmse: 0.84936 |  0:00:05s
epoch 5  | loss: 0.57511 | val_0_rmse: 0.7889  | val_1_rmse: 0.80477 |  0:00:06s
epoch 6  | loss: 0.54045 | val_0_rmse: 0.78848 | val_1_rmse: 0.80164 |  0:00:06s
epoch 7  | loss: 0.51219 | val_0_rmse: 0.74599 | val_1_rmse: 0.79739 |  0:00:07s
epoch 8  | loss: 0.48663 | val_0_rmse: 0.71713 | val_1_rmse: 0.78778 |  0:00:08s
epoch 9  | loss: 0.44952 | val_0_rmse: 0.72611 | val_1_rmse: 0.74746 |  0:00:08s
epoch 10 | loss: 0.44944 | val_0_rmse: 0.73166 | val_1_rmse: 0.74149 |  0:00:09s
epoch 11 | loss: 0.4441  | val_0_rmse: 0.72774 | val_1_rmse: 0.73822 |  0:00:10s
epoch 12 | loss: 0.43195 | val_0_rmse: 0.71559 | val_1_rmse: 0.73239 |  0:00:10s
epoch 13 | loss: 0.41361 | val_0_rmse: 0.73162 | val_1_rmse: 0.73633 |  0:00:11s
epoch 14 | loss: 0.41784 | val_0_rmse: 0.70045 | val_1_rmse: 0.71629 |  0:00:12s
epoch 15 | loss: 0.40295 | val_0_rmse: 0.67428 | val_1_rmse: 0.69356 |  0:00:12s
epoch 16 | loss: 0.38646 | val_0_rmse: 0.65818 | val_1_rmse: 0.68644 |  0:00:13s
epoch 17 | loss: 0.37845 | val_0_rmse: 0.67318 | val_1_rmse: 0.70219 |  0:00:14s
epoch 18 | loss: 0.36945 | val_0_rmse: 0.66608 | val_1_rmse: 0.68907 |  0:00:15s
epoch 19 | loss: 0.35401 | val_0_rmse: 0.64665 | val_1_rmse: 0.67497 |  0:00:15s
epoch 20 | loss: 0.33745 | val_0_rmse: 0.65298 | val_1_rmse: 0.67718 |  0:00:16s
epoch 21 | loss: 0.32722 | val_0_rmse: 0.65167 | val_1_rmse: 0.67423 |  0:00:17s
epoch 22 | loss: 0.31635 | val_0_rmse: 0.66139 | val_1_rmse: 0.68277 |  0:00:17s
epoch 23 | loss: 0.31514 | val_0_rmse: 0.62845 | val_1_rmse: 0.66208 |  0:00:18s
epoch 24 | loss: 0.29765 | val_0_rmse: 0.63762 | val_1_rmse: 0.67103 |  0:00:19s
epoch 25 | loss: 0.30147 | val_0_rmse: 0.65708 | val_1_rmse: 0.68405 |  0:00:19s
epoch 26 | loss: 0.29914 | val_0_rmse: 0.62984 | val_1_rmse: 0.66326 |  0:00:20s
epoch 27 | loss: 0.29685 | val_0_rmse: 0.68911 | val_1_rmse: 0.71337 |  0:00:21s
epoch 28 | loss: 0.29671 | val_0_rmse: 0.65998 | val_1_rmse: 0.68794 |  0:00:21s
epoch 29 | loss: 0.28769 | val_0_rmse: 0.60289 | val_1_rmse: 0.65003 |  0:00:22s
epoch 30 | loss: 0.27175 | val_0_rmse: 0.5947  | val_1_rmse: 0.63512 |  0:00:22s
epoch 31 | loss: 0.27327 | val_0_rmse: 0.59825 | val_1_rmse: 0.64101 |  0:00:23s
epoch 32 | loss: 0.25417 | val_0_rmse: 0.59713 | val_1_rmse: 0.64003 |  0:00:24s
epoch 33 | loss: 0.25194 | val_0_rmse: 0.60305 | val_1_rmse: 0.64789 |  0:00:24s
epoch 34 | loss: 0.24235 | val_0_rmse: 0.60119 | val_1_rmse: 0.63683 |  0:00:25s
epoch 35 | loss: 0.2396  | val_0_rmse: 0.60443 | val_1_rmse: 0.64236 |  0:00:26s
epoch 36 | loss: 0.23141 | val_0_rmse: 0.56535 | val_1_rmse: 0.60744 |  0:00:26s
epoch 37 | loss: 0.23153 | val_0_rmse: 0.58896 | val_1_rmse: 0.63387 |  0:00:27s
epoch 38 | loss: 0.22196 | val_0_rmse: 0.59104 | val_1_rmse: 0.62549 |  0:00:28s
epoch 39 | loss: 0.22223 | val_0_rmse: 0.56127 | val_1_rmse: 0.606   |  0:00:28s
epoch 40 | loss: 0.22286 | val_0_rmse: 0.55493 | val_1_rmse: 0.60181 |  0:00:29s
epoch 41 | loss: 0.20507 | val_0_rmse: 0.55085 | val_1_rmse: 0.59702 |  0:00:30s
epoch 42 | loss: 0.21427 | val_0_rmse: 0.55541 | val_1_rmse: 0.60032 |  0:00:31s
epoch 43 | loss: 0.21344 | val_0_rmse: 0.56085 | val_1_rmse: 0.60675 |  0:00:31s
epoch 44 | loss: 0.20873 | val_0_rmse: 0.54082 | val_1_rmse: 0.59548 |  0:00:32s
epoch 45 | loss: 0.20354 | val_0_rmse: 0.53447 | val_1_rmse: 0.59171 |  0:00:33s
epoch 46 | loss: 0.2122  | val_0_rmse: 0.53787 | val_1_rmse: 0.58989 |  0:00:33s
epoch 47 | loss: 0.19829 | val_0_rmse: 0.58101 | val_1_rmse: 0.61913 |  0:00:34s
epoch 48 | loss: 0.2033  | val_0_rmse: 0.52577 | val_1_rmse: 0.58932 |  0:00:35s
epoch 49 | loss: 0.19684 | val_0_rmse: 0.5132  | val_1_rmse: 0.56834 |  0:00:35s
epoch 50 | loss: 0.19983 | val_0_rmse: 0.51841 | val_1_rmse: 0.57283 |  0:00:36s
epoch 51 | loss: 0.18662 | val_0_rmse: 0.51296 | val_1_rmse: 0.56014 |  0:00:37s
epoch 52 | loss: 0.18168 | val_0_rmse: 0.49979 | val_1_rmse: 0.55974 |  0:00:38s
epoch 53 | loss: 0.17429 | val_0_rmse: 0.48554 | val_1_rmse: 0.54502 |  0:00:39s
epoch 54 | loss: 0.17573 | val_0_rmse: 0.48719 | val_1_rmse: 0.5441  |  0:00:39s
epoch 55 | loss: 0.17254 | val_0_rmse: 0.46968 | val_1_rmse: 0.53111 |  0:00:40s
epoch 56 | loss: 0.16902 | val_0_rmse: 0.46389 | val_1_rmse: 0.51834 |  0:00:41s
epoch 57 | loss: 0.1753  | val_0_rmse: 0.46459 | val_1_rmse: 0.5246  |  0:00:42s
epoch 58 | loss: 0.17073 | val_0_rmse: 0.48898 | val_1_rmse: 0.54472 |  0:00:42s
epoch 59 | loss: 0.16189 | val_0_rmse: 0.46854 | val_1_rmse: 0.52307 |  0:00:43s
epoch 60 | loss: 0.16672 | val_0_rmse: 0.44419 | val_1_rmse: 0.50729 |  0:00:44s
epoch 61 | loss: 0.15751 | val_0_rmse: 0.45202 | val_1_rmse: 0.5163  |  0:00:44s
epoch 62 | loss: 0.15094 | val_0_rmse: 0.43958 | val_1_rmse: 0.50995 |  0:00:45s
epoch 63 | loss: 0.14965 | val_0_rmse: 0.44629 | val_1_rmse: 0.51236 |  0:00:46s
epoch 64 | loss: 0.16427 | val_0_rmse: 0.47682 | val_1_rmse: 0.52454 |  0:00:47s
epoch 65 | loss: 0.16762 | val_0_rmse: 0.46149 | val_1_rmse: 0.52044 |  0:00:47s
epoch 66 | loss: 0.16483 | val_0_rmse: 0.44426 | val_1_rmse: 0.50801 |  0:00:48s
epoch 67 | loss: 0.16569 | val_0_rmse: 0.4238  | val_1_rmse: 0.49359 |  0:00:49s
epoch 68 | loss: 0.16116 | val_0_rmse: 0.42595 | val_1_rmse: 0.49477 |  0:00:50s
epoch 69 | loss: 0.1502  | val_0_rmse: 0.42346 | val_1_rmse: 0.49994 |  0:00:50s
epoch 70 | loss: 0.15424 | val_0_rmse: 0.40454 | val_1_rmse: 0.47607 |  0:00:51s
epoch 71 | loss: 0.14583 | val_0_rmse: 0.39949 | val_1_rmse: 0.47919 |  0:00:51s
epoch 72 | loss: 0.15137 | val_0_rmse: 0.41048 | val_1_rmse: 0.49659 |  0:00:52s
epoch 73 | loss: 0.15895 | val_0_rmse: 0.41768 | val_1_rmse: 0.49045 |  0:00:53s
epoch 74 | loss: 0.15816 | val_0_rmse: 0.41351 | val_1_rmse: 0.4773  |  0:00:53s
epoch 75 | loss: 0.16601 | val_0_rmse: 0.44102 | val_1_rmse: 0.50782 |  0:00:54s
epoch 76 | loss: 0.16957 | val_0_rmse: 0.39983 | val_1_rmse: 0.47789 |  0:00:55s
epoch 77 | loss: 0.17181 | val_0_rmse: 0.4063  | val_1_rmse: 0.49289 |  0:00:55s
epoch 78 | loss: 0.16201 | val_0_rmse: 0.42579 | val_1_rmse: 0.48928 |  0:00:56s
epoch 79 | loss: 0.17714 | val_0_rmse: 0.41316 | val_1_rmse: 0.49404 |  0:00:57s
epoch 80 | loss: 0.17512 | val_0_rmse: 0.41264 | val_1_rmse: 0.48761 |  0:00:57s
epoch 81 | loss: 0.17509 | val_0_rmse: 0.41374 | val_1_rmse: 0.48633 |  0:00:58s
epoch 82 | loss: 0.2018  | val_0_rmse: 0.43878 | val_1_rmse: 0.52522 |  0:00:59s
epoch 83 | loss: 0.20387 | val_0_rmse: 0.46241 | val_1_rmse: 0.52061 |  0:00:59s
epoch 84 | loss: 0.20224 | val_0_rmse: 0.473   | val_1_rmse: 0.52867 |  0:01:00s
epoch 85 | loss: 0.18699 | val_0_rmse: 0.41585 | val_1_rmse: 0.49235 |  0:01:01s
epoch 86 | loss: 0.1717  | val_0_rmse: 0.3892  | val_1_rmse: 1.64483 |  0:01:01s
epoch 87 | loss: 0.16344 | val_0_rmse: 0.39215 | val_1_rmse: 1.2982  |  0:01:02s
epoch 88 | loss: 0.15773 | val_0_rmse: 0.40179 | val_1_rmse: 0.47786 |  0:01:03s
epoch 89 | loss: 0.16626 | val_0_rmse: 0.43399 | val_1_rmse: 0.50544 |  0:01:03s
epoch 90 | loss: 0.16255 | val_0_rmse: 0.39725 | val_1_rmse: 0.46897 |  0:01:04s
epoch 91 | loss: 0.15249 | val_0_rmse: 0.36529 | val_1_rmse: 0.44735 |  0:01:05s
epoch 92 | loss: 0.14478 | val_0_rmse: 0.35219 | val_1_rmse: 0.45082 |  0:01:06s
epoch 93 | loss: 0.13957 | val_0_rmse: 0.35017 | val_1_rmse: 0.45257 |  0:01:06s
epoch 94 | loss: 0.14495 | val_0_rmse: 0.34292 | val_1_rmse: 0.43989 |  0:01:07s
epoch 95 | loss: 0.13874 | val_0_rmse: 0.35802 | val_1_rmse: 0.445   |  0:01:08s
epoch 96 | loss: 0.17082 | val_0_rmse: 0.39254 | val_1_rmse: 0.47011 |  0:01:08s
epoch 97 | loss: 0.18279 | val_0_rmse: 0.3999  | val_1_rmse: 0.48445 |  0:01:09s
epoch 98 | loss: 0.19506 | val_0_rmse: 0.4315  | val_1_rmse: 0.5193  |  0:01:09s
epoch 99 | loss: 0.17974 | val_0_rmse: 0.3893  | val_1_rmse: 0.47479 |  0:01:10s
epoch 100| loss: 0.16902 | val_0_rmse: 0.38623 | val_1_rmse: 0.47419 |  0:01:11s
epoch 101| loss: 0.15914 | val_0_rmse: 0.38747 | val_1_rmse: 0.47995 |  0:01:12s
epoch 102| loss: 0.1623  | val_0_rmse: 0.36658 | val_1_rmse: 0.46751 |  0:01:12s
epoch 103| loss: 0.15941 | val_0_rmse: 0.36869 | val_1_rmse: 0.45097 |  0:01:13s
epoch 104| loss: 0.15943 | val_0_rmse: 0.36001 | val_1_rmse: 0.44615 |  0:01:14s
epoch 105| loss: 0.14767 | val_0_rmse: 0.36199 | val_1_rmse: 0.45743 |  0:01:14s
epoch 106| loss: 0.14114 | val_0_rmse: 0.33866 | val_1_rmse: 0.44229 |  0:01:15s
epoch 107| loss: 0.14595 | val_0_rmse: 0.34523 | val_1_rmse: 0.43419 |  0:01:16s
epoch 108| loss: 0.15139 | val_0_rmse: 0.35059 | val_1_rmse: 0.43065 |  0:01:16s
epoch 109| loss: 0.14507 | val_0_rmse: 0.36464 | val_1_rmse: 0.44434 |  0:01:17s
epoch 110| loss: 0.14231 | val_0_rmse: 0.34169 | val_1_rmse: 0.42908 |  0:01:18s
epoch 111| loss: 0.13708 | val_0_rmse: 0.33484 | val_1_rmse: 0.42483 |  0:01:18s
epoch 112| loss: 0.13583 | val_0_rmse: 0.3273  | val_1_rmse: 0.42753 |  0:01:19s
epoch 113| loss: 0.13641 | val_0_rmse: 0.32366 | val_1_rmse: 0.42835 |  0:01:20s
epoch 114| loss: 0.12728 | val_0_rmse: 0.32463 | val_1_rmse: 0.42926 |  0:01:20s
epoch 115| loss: 0.125   | val_0_rmse: 0.3153  | val_1_rmse: 0.41894 |  0:01:21s
epoch 116| loss: 0.1218  | val_0_rmse: 0.31456 | val_1_rmse: 0.41583 |  0:01:22s
epoch 117| loss: 0.12036 | val_0_rmse: 0.31585 | val_1_rmse: 0.42699 |  0:01:22s
epoch 118| loss: 0.11696 | val_0_rmse: 0.31935 | val_1_rmse: 0.42869 |  0:01:23s
epoch 119| loss: 0.1232  | val_0_rmse: 0.30771 | val_1_rmse: 0.42626 |  0:01:24s
epoch 120| loss: 0.11973 | val_0_rmse: 0.30948 | val_1_rmse: 0.41927 |  0:01:24s
epoch 121| loss: 0.11245 | val_0_rmse: 0.30889 | val_1_rmse: 0.41705 |  0:01:25s
epoch 122| loss: 0.1126  | val_0_rmse: 0.31255 | val_1_rmse: 0.41555 |  0:01:26s
epoch 123| loss: 0.11519 | val_0_rmse: 0.3004  | val_1_rmse: 0.42141 |  0:01:26s
epoch 124| loss: 0.11681 | val_0_rmse: 0.29475 | val_1_rmse: 0.4253  |  0:01:27s
epoch 125| loss: 0.11306 | val_0_rmse: 0.29829 | val_1_rmse: 0.41899 |  0:01:28s
epoch 126| loss: 0.10423 | val_0_rmse: 0.29163 | val_1_rmse: 0.41155 |  0:01:28s
epoch 127| loss: 0.1102  | val_0_rmse: 0.29576 | val_1_rmse: 0.41689 |  0:01:29s
epoch 128| loss: 0.10642 | val_0_rmse: 0.29027 | val_1_rmse: 0.4104  |  0:01:30s
epoch 129| loss: 0.10222 | val_0_rmse: 0.28735 | val_1_rmse: 0.41479 |  0:01:31s
epoch 130| loss: 0.10375 | val_0_rmse: 0.29494 | val_1_rmse: 0.42332 |  0:01:32s
epoch 131| loss: 0.11061 | val_0_rmse: 0.29561 | val_1_rmse: 0.42145 |  0:01:32s
epoch 132| loss: 0.11333 | val_0_rmse: 0.2922  | val_1_rmse: 0.42249 |  0:01:33s
epoch 133| loss: 0.10267 | val_0_rmse: 0.28504 | val_1_rmse: 0.42553 |  0:01:33s
epoch 134| loss: 0.09843 | val_0_rmse: 0.28057 | val_1_rmse: 0.4179  |  0:01:34s
epoch 135| loss: 0.09814 | val_0_rmse: 0.28462 | val_1_rmse: 0.41982 |  0:01:35s
epoch 136| loss: 0.08997 | val_0_rmse: 0.26775 | val_1_rmse: 0.41587 |  0:01:35s
epoch 137| loss: 0.08945 | val_0_rmse: 0.26089 | val_1_rmse: 0.41433 |  0:01:36s
epoch 138| loss: 0.09111 | val_0_rmse: 0.26547 | val_1_rmse: 0.41685 |  0:01:37s
epoch 139| loss: 0.08763 | val_0_rmse: 0.25782 | val_1_rmse: 0.41417 |  0:01:38s
epoch 140| loss: 0.09803 | val_0_rmse: 0.27261 | val_1_rmse: 0.42283 |  0:01:39s
epoch 141| loss: 0.09404 | val_0_rmse: 0.2677  | val_1_rmse: 0.42365 |  0:01:39s
epoch 142| loss: 0.09325 | val_0_rmse: 0.26734 | val_1_rmse: 0.42362 |  0:01:40s
epoch 143| loss: 0.08867 | val_0_rmse: 0.26751 | val_1_rmse: 0.42163 |  0:01:41s
epoch 144| loss: 0.0898  | val_0_rmse: 0.27162 | val_1_rmse: 0.43478 |  0:01:41s
epoch 145| loss: 0.08964 | val_0_rmse: 0.28007 | val_1_rmse: 0.42789 |  0:01:42s
epoch 146| loss: 0.10483 | val_0_rmse: 0.32729 | val_1_rmse: 0.45106 |  0:01:43s
epoch 147| loss: 0.10469 | val_0_rmse: 0.28464 | val_1_rmse: 0.41709 |  0:01:43s
epoch 148| loss: 0.09987 | val_0_rmse: 0.27039 | val_1_rmse: 0.4024  |  0:01:44s
epoch 149| loss: 0.09323 | val_0_rmse: 0.27706 | val_1_rmse: 0.41069 |  0:01:45s
Stop training because you reached max_epochs = 150 with best_epoch = 148 and best_val_1_rmse = 0.4024
Best weights from best epoch are automatically used!
ended training at: 03:32:25
Feature importance:
Mean squared error is of 2704686797.897267
Mean absolute error:33703.569438651226
MAPE:0.29079626640202005
R2 score:0.8524392884050752
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 1
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 03:32:26
epoch 0  | loss: 2.23931 | val_0_rmse: 0.99407 | val_1_rmse: 1.01333 |  0:00:00s
epoch 1  | loss: 1.11538 | val_0_rmse: 0.99527 | val_1_rmse: 1.01588 |  0:00:01s
epoch 2  | loss: 0.9641  | val_0_rmse: 0.92733 | val_1_rmse: 0.93717 |  0:00:01s
epoch 3  | loss: 0.83554 | val_0_rmse: 0.85144 | val_1_rmse: 0.85197 |  0:00:02s
epoch 4  | loss: 0.73216 | val_0_rmse: 0.90366 | val_1_rmse: 0.89236 |  0:00:03s
epoch 5  | loss: 0.63545 | val_0_rmse: 0.80852 | val_1_rmse: 0.8207  |  0:00:03s
epoch 6  | loss: 0.61013 | val_0_rmse: 0.79507 | val_1_rmse: 0.81426 |  0:00:04s
epoch 7  | loss: 0.55993 | val_0_rmse: 0.8052  | val_1_rmse: 0.82823 |  0:00:05s
epoch 8  | loss: 0.52097 | val_0_rmse: 0.78716 | val_1_rmse: 0.80629 |  0:00:05s
epoch 9  | loss: 0.47666 | val_0_rmse: 0.75372 | val_1_rmse: 0.78034 |  0:00:06s
epoch 10 | loss: 0.42933 | val_0_rmse: 0.7616  | val_1_rmse: 0.78494 |  0:00:07s
epoch 11 | loss: 0.40794 | val_0_rmse: 0.70594 | val_1_rmse: 0.7386  |  0:00:07s
epoch 12 | loss: 0.37833 | val_0_rmse: 0.69704 | val_1_rmse: 0.72526 |  0:00:08s
epoch 13 | loss: 0.35037 | val_0_rmse: 0.67563 | val_1_rmse: 0.69869 |  0:00:09s
epoch 14 | loss: 0.33007 | val_0_rmse: 0.66716 | val_1_rmse: 0.68813 |  0:00:09s
epoch 15 | loss: 0.31353 | val_0_rmse: 0.65534 | val_1_rmse: 0.67727 |  0:00:10s
epoch 16 | loss: 0.30218 | val_0_rmse: 0.66081 | val_1_rmse: 0.68488 |  0:00:11s
epoch 17 | loss: 0.29021 | val_0_rmse: 0.64715 | val_1_rmse: 0.6686  |  0:00:11s
epoch 18 | loss: 0.27698 | val_0_rmse: 0.66626 | val_1_rmse: 0.68758 |  0:00:12s
epoch 19 | loss: 0.2731  | val_0_rmse: 0.64825 | val_1_rmse: 0.66692 |  0:00:13s
epoch 20 | loss: 0.26123 | val_0_rmse: 0.64821 | val_1_rmse: 0.66914 |  0:00:13s
epoch 21 | loss: 0.24809 | val_0_rmse: 0.63576 | val_1_rmse: 0.65842 |  0:00:14s
epoch 22 | loss: 0.24846 | val_0_rmse: 0.62977 | val_1_rmse: 0.65067 |  0:00:15s
epoch 23 | loss: 0.23684 | val_0_rmse: 0.64329 | val_1_rmse: 0.66395 |  0:00:15s
epoch 24 | loss: 0.2345  | val_0_rmse: 0.62844 | val_1_rmse: 0.64835 |  0:00:16s
epoch 25 | loss: 0.21958 | val_0_rmse: 0.63852 | val_1_rmse: 0.65718 |  0:00:17s
epoch 26 | loss: 0.22128 | val_0_rmse: 0.6265  | val_1_rmse: 0.65699 |  0:00:17s
epoch 27 | loss: 0.21791 | val_0_rmse: 0.63442 | val_1_rmse: 0.65051 |  0:00:18s
epoch 28 | loss: 0.20437 | val_0_rmse: 0.62399 | val_1_rmse: 0.64612 |  0:00:19s
epoch 29 | loss: 0.19888 | val_0_rmse: 0.58695 | val_1_rmse: 0.60837 |  0:00:19s
epoch 30 | loss: 0.18539 | val_0_rmse: 0.62673 | val_1_rmse: 0.6448  |  0:00:20s
epoch 31 | loss: 0.18645 | val_0_rmse: 0.5987  | val_1_rmse: 0.61917 |  0:00:21s
epoch 32 | loss: 0.18465 | val_0_rmse: 0.58303 | val_1_rmse: 0.604   |  0:00:21s
epoch 33 | loss: 0.17774 | val_0_rmse: 0.5914  | val_1_rmse: 0.61442 |  0:00:22s
epoch 34 | loss: 0.16951 | val_0_rmse: 0.58284 | val_1_rmse: 0.60936 |  0:00:23s
epoch 35 | loss: 0.17594 | val_0_rmse: 0.56085 | val_1_rmse: 0.58467 |  0:00:23s
epoch 36 | loss: 0.17521 | val_0_rmse: 0.55543 | val_1_rmse: 0.58963 |  0:00:24s
epoch 37 | loss: 0.16703 | val_0_rmse: 0.57161 | val_1_rmse: 0.60139 |  0:00:24s
epoch 38 | loss: 0.16739 | val_0_rmse: 0.55257 | val_1_rmse: 0.59128 |  0:00:25s
epoch 39 | loss: 0.16519 | val_0_rmse: 0.53644 | val_1_rmse: 0.58201 |  0:00:26s
epoch 40 | loss: 0.16238 | val_0_rmse: 0.57527 | val_1_rmse: 0.60483 |  0:00:26s
epoch 41 | loss: 0.16153 | val_0_rmse: 0.52707 | val_1_rmse: 0.56841 |  0:00:27s
epoch 42 | loss: 0.15397 | val_0_rmse: 0.54772 | val_1_rmse: 0.58057 |  0:00:28s
epoch 43 | loss: 0.16097 | val_0_rmse: 0.52727 | val_1_rmse: 0.57394 |  0:00:28s
epoch 44 | loss: 0.15048 | val_0_rmse: 0.50844 | val_1_rmse: 0.55418 |  0:00:29s
epoch 45 | loss: 0.15507 | val_0_rmse: 0.5002  | val_1_rmse: 0.53948 |  0:00:29s
epoch 46 | loss: 0.14278 | val_0_rmse: 0.50098 | val_1_rmse: 0.54848 |  0:00:30s
epoch 47 | loss: 0.14027 | val_0_rmse: 0.49432 | val_1_rmse: 0.54442 |  0:00:31s
epoch 48 | loss: 0.13764 | val_0_rmse: 0.51172 | val_1_rmse: 0.55697 |  0:00:31s
epoch 49 | loss: 0.13861 | val_0_rmse: 0.48429 | val_1_rmse: 0.54073 |  0:00:32s
epoch 50 | loss: 0.13532 | val_0_rmse: 0.47937 | val_1_rmse: 0.53347 |  0:00:33s
epoch 51 | loss: 0.1349  | val_0_rmse: 0.46754 | val_1_rmse: 0.52631 |  0:00:33s
epoch 52 | loss: 0.13726 | val_0_rmse: 0.46052 | val_1_rmse: 0.52344 |  0:00:34s
epoch 53 | loss: 0.13008 | val_0_rmse: 0.45464 | val_1_rmse: 0.51686 |  0:00:35s
epoch 54 | loss: 0.13002 | val_0_rmse: 0.45753 | val_1_rmse: 0.51368 |  0:00:35s
epoch 55 | loss: 0.12861 | val_0_rmse: 0.44747 | val_1_rmse: 0.51956 |  0:00:36s
epoch 56 | loss: 0.13049 | val_0_rmse: 0.44025 | val_1_rmse: 0.50289 |  0:00:36s
epoch 57 | loss: 0.1233  | val_0_rmse: 0.43639 | val_1_rmse: 0.50637 |  0:00:37s
epoch 58 | loss: 0.12254 | val_0_rmse: 0.47083 | val_1_rmse: 0.52917 |  0:00:38s
epoch 59 | loss: 0.12005 | val_0_rmse: 0.40846 | val_1_rmse: 0.48147 |  0:00:38s
epoch 60 | loss: 0.11142 | val_0_rmse: 0.40741 | val_1_rmse: 0.48184 |  0:00:39s
epoch 61 | loss: 0.10636 | val_0_rmse: 0.44308 | val_1_rmse: 0.50207 |  0:00:40s
epoch 62 | loss: 0.11381 | val_0_rmse: 0.39553 | val_1_rmse: 0.46785 |  0:00:40s
epoch 63 | loss: 0.10903 | val_0_rmse: 0.39022 | val_1_rmse: 0.46895 |  0:00:41s
epoch 64 | loss: 0.10943 | val_0_rmse: 0.43505 | val_1_rmse: 0.4977  |  0:00:41s
epoch 65 | loss: 0.10706 | val_0_rmse: 0.38589 | val_1_rmse: 0.45607 |  0:00:42s
epoch 66 | loss: 0.10215 | val_0_rmse: 0.39187 | val_1_rmse: 0.45839 |  0:00:43s
epoch 67 | loss: 0.10218 | val_0_rmse: 0.37124 | val_1_rmse: 0.44976 |  0:00:43s
epoch 68 | loss: 0.10256 | val_0_rmse: 0.36118 | val_1_rmse: 0.4404  |  0:00:44s
epoch 69 | loss: 0.10622 | val_0_rmse: 0.378   | val_1_rmse: 0.44045 |  0:00:45s
epoch 70 | loss: 0.10345 | val_0_rmse: 0.35653 | val_1_rmse: 0.43899 |  0:00:45s
epoch 71 | loss: 0.09917 | val_0_rmse: 0.3479  | val_1_rmse: 0.43486 |  0:00:46s
epoch 72 | loss: 0.09538 | val_0_rmse: 0.35047 | val_1_rmse: 0.43308 |  0:00:47s
epoch 73 | loss: 0.09908 | val_0_rmse: 0.33095 | val_1_rmse: 0.43308 |  0:00:47s
epoch 74 | loss: 0.09027 | val_0_rmse: 0.33698 | val_1_rmse: 0.44066 |  0:00:48s
epoch 75 | loss: 0.09418 | val_0_rmse: 0.34087 | val_1_rmse: 0.4347  |  0:00:49s
epoch 76 | loss: 0.08875 | val_0_rmse: 0.31645 | val_1_rmse: 0.43061 |  0:00:49s
epoch 77 | loss: 0.0945  | val_0_rmse: 0.31786 | val_1_rmse: 0.42588 |  0:00:50s
epoch 78 | loss: 0.09602 | val_0_rmse: 0.31146 | val_1_rmse: 0.41837 |  0:00:50s
epoch 79 | loss: 0.08559 | val_0_rmse: 0.31399 | val_1_rmse: 0.41895 |  0:00:51s
epoch 80 | loss: 0.08637 | val_0_rmse: 0.31437 | val_1_rmse: 0.42073 |  0:00:52s
epoch 81 | loss: 0.09008 | val_0_rmse: 0.29329 | val_1_rmse: 0.41479 |  0:00:52s
epoch 82 | loss: 0.08942 | val_0_rmse: 0.29735 | val_1_rmse: 0.41282 |  0:00:53s
epoch 83 | loss: 0.08752 | val_0_rmse: 0.28025 | val_1_rmse: 0.40311 |  0:00:54s
epoch 84 | loss: 0.08889 | val_0_rmse: 0.28905 | val_1_rmse: 0.41416 |  0:00:54s
epoch 85 | loss: 0.09309 | val_0_rmse: 0.28858 | val_1_rmse: 0.40809 |  0:00:55s
epoch 86 | loss: 0.08496 | val_0_rmse: 0.28148 | val_1_rmse: 0.42146 |  0:00:55s
epoch 87 | loss: 0.08625 | val_0_rmse: 0.30334 | val_1_rmse: 0.41361 |  0:00:56s
epoch 88 | loss: 0.07885 | val_0_rmse: 0.26784 | val_1_rmse: 0.39584 |  0:00:57s
epoch 89 | loss: 0.07712 | val_0_rmse: 0.26743 | val_1_rmse: 0.4032  |  0:00:57s
epoch 90 | loss: 0.07837 | val_0_rmse: 0.27055 | val_1_rmse: 0.39327 |  0:00:58s
epoch 91 | loss: 0.07641 | val_0_rmse: 0.25822 | val_1_rmse: 0.39634 |  0:00:59s
epoch 92 | loss: 0.07872 | val_0_rmse: 0.25545 | val_1_rmse: 0.39895 |  0:00:59s
epoch 93 | loss: 0.07452 | val_0_rmse: 0.24967 | val_1_rmse: 0.38844 |  0:01:00s
epoch 94 | loss: 0.07278 | val_0_rmse: 0.2454  | val_1_rmse: 0.39404 |  0:01:01s
epoch 95 | loss: 0.0733  | val_0_rmse: 0.24312 | val_1_rmse: 0.40003 |  0:01:01s
epoch 96 | loss: 0.07116 | val_0_rmse: 0.24925 | val_1_rmse: 0.39059 |  0:01:02s
epoch 97 | loss: 0.07019 | val_0_rmse: 0.23568 | val_1_rmse: 0.38995 |  0:01:02s
epoch 98 | loss: 0.07188 | val_0_rmse: 0.22957 | val_1_rmse: 0.38029 |  0:01:03s
epoch 99 | loss: 0.07104 | val_0_rmse: 0.2251  | val_1_rmse: 0.38087 |  0:01:04s
epoch 100| loss: 0.07531 | val_0_rmse: 0.23418 | val_1_rmse: 0.38438 |  0:01:04s
epoch 101| loss: 0.07419 | val_0_rmse: 0.23035 | val_1_rmse: 0.38794 |  0:01:05s
epoch 102| loss: 0.07253 | val_0_rmse: 0.23355 | val_1_rmse: 0.39674 |  0:01:06s
epoch 103| loss: 0.0701  | val_0_rmse: 0.22841 | val_1_rmse: 0.38382 |  0:01:06s
epoch 104| loss: 0.07473 | val_0_rmse: 0.22877 | val_1_rmse: 0.39533 |  0:01:07s
epoch 105| loss: 0.07536 | val_0_rmse: 0.22945 | val_1_rmse: 0.39581 |  0:01:08s
epoch 106| loss: 0.07307 | val_0_rmse: 0.22814 | val_1_rmse: 0.39232 |  0:01:08s
epoch 107| loss: 0.07119 | val_0_rmse: 0.22639 | val_1_rmse: 0.3844  |  0:01:09s
epoch 108| loss: 0.07352 | val_0_rmse: 0.22206 | val_1_rmse: 0.37777 |  0:01:09s
epoch 109| loss: 0.07364 | val_0_rmse: 0.23713 | val_1_rmse: 0.38644 |  0:01:10s
epoch 110| loss: 0.07358 | val_0_rmse: 0.24147 | val_1_rmse: 0.38412 |  0:01:11s
epoch 111| loss: 0.07155 | val_0_rmse: 0.22905 | val_1_rmse: 0.39874 |  0:01:11s
epoch 112| loss: 0.07875 | val_0_rmse: 0.23498 | val_1_rmse: 0.41163 |  0:01:12s
epoch 113| loss: 0.07899 | val_0_rmse: 0.23847 | val_1_rmse: 0.40661 |  0:01:13s
epoch 114| loss: 0.08221 | val_0_rmse: 0.24387 | val_1_rmse: 0.41819 |  0:01:13s
epoch 115| loss: 0.07878 | val_0_rmse: 0.25082 | val_1_rmse: 0.41933 |  0:01:14s
epoch 116| loss: 0.07906 | val_0_rmse: 0.23515 | val_1_rmse: 0.39696 |  0:01:14s
epoch 117| loss: 0.07666 | val_0_rmse: 0.26564 | val_1_rmse: 0.40887 |  0:01:15s
epoch 118| loss: 0.07595 | val_0_rmse: 0.24964 | val_1_rmse: 0.39382 |  0:01:16s
epoch 119| loss: 0.07892 | val_0_rmse: 0.27823 | val_1_rmse: 0.42754 |  0:01:16s
epoch 120| loss: 0.07474 | val_0_rmse: 0.49408 | val_1_rmse: 0.56085 |  0:01:17s
epoch 121| loss: 0.06512 | val_0_rmse: 0.36702 | val_1_rmse: 0.47295 |  0:01:18s
epoch 122| loss: 0.06783 | val_0_rmse: 0.23761 | val_1_rmse: 0.38565 |  0:01:18s
epoch 123| loss: 0.07352 | val_0_rmse: 0.22576 | val_1_rmse: 0.39983 |  0:01:19s
epoch 124| loss: 0.06936 | val_0_rmse: 0.22623 | val_1_rmse: 0.38704 |  0:01:19s
epoch 125| loss: 0.06527 | val_0_rmse: 0.21478 | val_1_rmse: 0.38683 |  0:01:20s
epoch 126| loss: 0.06729 | val_0_rmse: 0.22023 | val_1_rmse: 0.38373 |  0:01:21s
epoch 127| loss: 0.06755 | val_0_rmse: 0.21928 | val_1_rmse: 0.37596 |  0:01:21s
epoch 128| loss: 0.06709 | val_0_rmse: 0.20588 | val_1_rmse: 0.37813 |  0:01:22s
epoch 129| loss: 0.06118 | val_0_rmse: 0.21338 | val_1_rmse: 0.37937 |  0:01:23s
epoch 130| loss: 0.06242 | val_0_rmse: 0.20463 | val_1_rmse: 0.38109 |  0:01:23s
epoch 131| loss: 0.05986 | val_0_rmse: 0.21862 | val_1_rmse: 0.37428 |  0:01:24s
epoch 132| loss: 0.06629 | val_0_rmse: 0.20593 | val_1_rmse: 0.37374 |  0:01:25s
epoch 133| loss: 0.06309 | val_0_rmse: 0.20139 | val_1_rmse: 0.37804 |  0:01:25s
epoch 134| loss: 0.06101 | val_0_rmse: 0.20339 | val_1_rmse: 0.38144 |  0:01:26s
epoch 135| loss: 0.06542 | val_0_rmse: 0.23862 | val_1_rmse: 0.39269 |  0:01:27s
epoch 136| loss: 0.06441 | val_0_rmse: 0.20319 | val_1_rmse: 0.38878 |  0:01:27s
epoch 137| loss: 0.06572 | val_0_rmse: 0.2398  | val_1_rmse: 0.4212  |  0:01:28s
epoch 138| loss: 0.06801 | val_0_rmse: 0.209   | val_1_rmse: 0.38582 |  0:01:29s
epoch 139| loss: 0.06248 | val_0_rmse: 0.20356 | val_1_rmse: 0.39194 |  0:01:29s
epoch 140| loss: 0.05625 | val_0_rmse: 0.20131 | val_1_rmse: 0.38928 |  0:01:30s
epoch 141| loss: 0.06063 | val_0_rmse: 0.21601 | val_1_rmse: 0.39636 |  0:01:31s
epoch 142| loss: 0.06399 | val_0_rmse: 0.22106 | val_1_rmse: 0.40551 |  0:01:31s
epoch 143| loss: 0.06314 | val_0_rmse: 0.20987 | val_1_rmse: 0.40758 |  0:01:32s
epoch 144| loss: 0.0622  | val_0_rmse: 0.20894 | val_1_rmse: 0.40211 |  0:01:33s
epoch 145| loss: 0.05928 | val_0_rmse: 0.20561 | val_1_rmse: 0.38555 |  0:01:34s
epoch 146| loss: 0.05914 | val_0_rmse: 0.19793 | val_1_rmse: 0.3895  |  0:01:34s
epoch 147| loss: 0.06008 | val_0_rmse: 0.1975  | val_1_rmse: 0.39018 |  0:01:35s
epoch 148| loss: 0.05729 | val_0_rmse: 0.2031  | val_1_rmse: 0.3891  |  0:01:36s
epoch 149| loss: 0.06078 | val_0_rmse: 0.21101 | val_1_rmse: 0.40418 |  0:01:36s
Stop training because you reached max_epochs = 150 with best_epoch = 132 and best_val_1_rmse = 0.37374
Best weights from best epoch are automatically used!
ended training at: 03:34:03
Feature importance:
Mean squared error is of 2273738495.8159075
Mean absolute error:28510.278869335623
MAPE:0.23883098475555184
R2 score:0.87824054948357
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 2
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 03:34:03
epoch 0  | loss: 1.90554 | val_0_rmse: 0.99643 | val_1_rmse: 1.02653 |  0:00:00s
epoch 1  | loss: 1.12492 | val_0_rmse: 0.99135 | val_1_rmse: 1.02534 |  0:00:01s
epoch 2  | loss: 0.97311 | val_0_rmse: 0.9278  | val_1_rmse: 0.94386 |  0:00:01s
epoch 3  | loss: 0.88612 | val_0_rmse: 0.91153 | val_1_rmse: 0.92681 |  0:00:02s
epoch 4  | loss: 0.8257  | val_0_rmse: 0.93669 | val_1_rmse: 0.94265 |  0:00:03s
epoch 5  | loss: 0.74742 | val_0_rmse: 0.87229 | val_1_rmse: 0.89559 |  0:00:03s
epoch 6  | loss: 0.68767 | val_0_rmse: 0.82688 | val_1_rmse: 0.84048 |  0:00:04s
epoch 7  | loss: 0.66096 | val_0_rmse: 0.86066 | val_1_rmse: 0.88155 |  0:00:05s
epoch 8  | loss: 0.63893 | val_0_rmse: 0.86598 | val_1_rmse: 0.88185 |  0:00:05s
epoch 9  | loss: 0.59419 | val_0_rmse: 0.79162 | val_1_rmse: 0.80648 |  0:00:06s
epoch 10 | loss: 0.55129 | val_0_rmse: 0.79204 | val_1_rmse: 0.81374 |  0:00:07s
epoch 11 | loss: 0.52627 | val_0_rmse: 0.76174 | val_1_rmse: 0.77822 |  0:00:07s
epoch 12 | loss: 0.49469 | val_0_rmse: 0.76109 | val_1_rmse: 0.77703 |  0:00:08s
epoch 13 | loss: 0.45966 | val_0_rmse: 0.73183 | val_1_rmse: 0.74437 |  0:00:08s
epoch 14 | loss: 0.48434 | val_0_rmse: 0.72747 | val_1_rmse: 0.74476 |  0:00:09s
epoch 15 | loss: 0.4655  | val_0_rmse: 0.77575 | val_1_rmse: 0.796   |  0:00:10s
epoch 16 | loss: 0.44187 | val_0_rmse: 0.75754 | val_1_rmse: 0.76619 |  0:00:10s
epoch 17 | loss: 0.41902 | val_0_rmse: 0.77742 | val_1_rmse: 0.78426 |  0:00:11s
epoch 18 | loss: 0.38695 | val_0_rmse: 0.71557 | val_1_rmse: 0.7196  |  0:00:12s
epoch 19 | loss: 0.36078 | val_0_rmse: 0.66802 | val_1_rmse: 0.66557 |  0:00:12s
epoch 20 | loss: 0.34852 | val_0_rmse: 0.6538  | val_1_rmse: 0.65593 |  0:00:13s
epoch 21 | loss: 0.33577 | val_0_rmse: 0.63816 | val_1_rmse: 0.63593 |  0:00:14s
epoch 22 | loss: 0.32007 | val_0_rmse: 0.65196 | val_1_rmse: 0.65336 |  0:00:14s
epoch 23 | loss: 0.30026 | val_0_rmse: 0.65246 | val_1_rmse: 0.66048 |  0:00:15s
epoch 24 | loss: 0.3018  | val_0_rmse: 0.65663 | val_1_rmse: 0.66414 |  0:00:15s
epoch 25 | loss: 0.29362 | val_0_rmse: 0.65051 | val_1_rmse: 0.65546 |  0:00:16s
epoch 26 | loss: 0.29415 | val_0_rmse: 0.64416 | val_1_rmse: 0.64898 |  0:00:17s
epoch 27 | loss: 0.27945 | val_0_rmse: 0.62021 | val_1_rmse: 0.62907 |  0:00:17s
epoch 28 | loss: 0.27145 | val_0_rmse: 0.61822 | val_1_rmse: 0.62772 |  0:00:18s
epoch 29 | loss: 0.27369 | val_0_rmse: 0.61125 | val_1_rmse: 0.61522 |  0:00:19s
epoch 30 | loss: 0.2678  | val_0_rmse: 0.60645 | val_1_rmse: 0.6083  |  0:00:19s
epoch 31 | loss: 0.27058 | val_0_rmse: 0.60931 | val_1_rmse: 0.61611 |  0:00:20s
epoch 32 | loss: 0.25579 | val_0_rmse: 0.5944  | val_1_rmse: 0.60426 |  0:00:21s
epoch 33 | loss: 0.24356 | val_0_rmse: 0.58679 | val_1_rmse: 0.59856 |  0:00:21s
epoch 34 | loss: 0.24378 | val_0_rmse: 0.59432 | val_1_rmse: 0.60588 |  0:00:22s
epoch 35 | loss: 0.23795 | val_0_rmse: 0.5888  | val_1_rmse: 0.60117 |  0:00:23s
epoch 36 | loss: 0.22925 | val_0_rmse: 0.57916 | val_1_rmse: 0.59492 |  0:00:23s
epoch 37 | loss: 0.21623 | val_0_rmse: 0.56962 | val_1_rmse: 0.58607 |  0:00:24s
epoch 38 | loss: 0.21465 | val_0_rmse: 0.58436 | val_1_rmse: 0.59409 |  0:00:24s
epoch 39 | loss: 0.21746 | val_0_rmse: 0.56802 | val_1_rmse: 0.57774 |  0:00:25s
epoch 40 | loss: 0.21174 | val_0_rmse: 0.56025 | val_1_rmse: 0.5807  |  0:00:26s
epoch 41 | loss: 0.21384 | val_0_rmse: 0.55633 | val_1_rmse: 0.57203 |  0:00:26s
epoch 42 | loss: 0.20441 | val_0_rmse: 0.54509 | val_1_rmse: 0.55979 |  0:00:27s
epoch 43 | loss: 0.20897 | val_0_rmse: 0.55218 | val_1_rmse: 0.56559 |  0:00:28s
epoch 44 | loss: 0.1989  | val_0_rmse: 0.5511  | val_1_rmse: 0.56432 |  0:00:28s
epoch 45 | loss: 0.20344 | val_0_rmse: 0.53689 | val_1_rmse: 0.55781 |  0:00:29s
epoch 46 | loss: 0.19074 | val_0_rmse: 0.52951 | val_1_rmse: 0.5521  |  0:00:30s
epoch 47 | loss: 0.19798 | val_0_rmse: 0.52398 | val_1_rmse: 0.54963 |  0:00:30s
epoch 48 | loss: 0.18649 | val_0_rmse: 0.52226 | val_1_rmse: 0.54516 |  0:00:31s
epoch 49 | loss: 0.18835 | val_0_rmse: 0.52507 | val_1_rmse: 0.54922 |  0:00:32s
epoch 50 | loss: 0.18339 | val_0_rmse: 0.51002 | val_1_rmse: 0.54234 |  0:00:32s
epoch 51 | loss: 0.17706 | val_0_rmse: 0.53594 | val_1_rmse: 0.55871 |  0:00:33s
epoch 52 | loss: 0.17445 | val_0_rmse: 0.51867 | val_1_rmse: 0.54856 |  0:00:33s
epoch 53 | loss: 0.17264 | val_0_rmse: 0.50197 | val_1_rmse: 0.53564 |  0:00:34s
epoch 54 | loss: 0.16989 | val_0_rmse: 0.50077 | val_1_rmse: 0.54211 |  0:00:35s
epoch 55 | loss: 0.1665  | val_0_rmse: 0.49774 | val_1_rmse: 0.52868 |  0:00:35s
epoch 56 | loss: 0.15976 | val_0_rmse: 0.47841 | val_1_rmse: 0.51801 |  0:00:36s
epoch 57 | loss: 0.15595 | val_0_rmse: 0.4758  | val_1_rmse: 0.51908 |  0:00:37s
epoch 58 | loss: 0.16396 | val_0_rmse: 0.48206 | val_1_rmse: 0.53211 |  0:00:37s
epoch 59 | loss: 0.1553  | val_0_rmse: 0.45905 | val_1_rmse: 0.51202 |  0:00:38s
epoch 60 | loss: 0.14864 | val_0_rmse: 0.45659 | val_1_rmse: 0.50853 |  0:00:39s
epoch 61 | loss: 0.1608  | val_0_rmse: 0.4671  | val_1_rmse: 0.52702 |  0:00:39s
epoch 62 | loss: 0.16294 | val_0_rmse: 0.45565 | val_1_rmse: 0.51604 |  0:00:40s
epoch 63 | loss: 0.15996 | val_0_rmse: 0.44541 | val_1_rmse: 0.50241 |  0:00:40s
epoch 64 | loss: 0.15413 | val_0_rmse: 0.45175 | val_1_rmse: 0.51055 |  0:00:41s
epoch 65 | loss: 0.15125 | val_0_rmse: 0.42828 | val_1_rmse: 0.49747 |  0:00:42s
epoch 66 | loss: 0.14616 | val_0_rmse: 0.42836 | val_1_rmse: 0.49231 |  0:00:42s
epoch 67 | loss: 0.14253 | val_0_rmse: 0.42822 | val_1_rmse: 0.49444 |  0:00:43s
epoch 68 | loss: 0.14862 | val_0_rmse: 0.44853 | val_1_rmse: 0.51819 |  0:00:44s
epoch 69 | loss: 0.15009 | val_0_rmse: 0.44062 | val_1_rmse: 0.51662 |  0:00:44s
epoch 70 | loss: 0.15112 | val_0_rmse: 0.41478 | val_1_rmse: 0.50199 |  0:00:45s
epoch 71 | loss: 0.14208 | val_0_rmse: 0.41885 | val_1_rmse: 0.49721 |  0:00:46s
epoch 72 | loss: 0.13747 | val_0_rmse: 0.40467 | val_1_rmse: 0.49403 |  0:00:46s
epoch 73 | loss: 0.13816 | val_0_rmse: 0.3969  | val_1_rmse: 0.48656 |  0:00:47s
epoch 74 | loss: 0.13462 | val_0_rmse: 0.39321 | val_1_rmse: 0.49243 |  0:00:47s
epoch 75 | loss: 0.12668 | val_0_rmse: 0.39086 | val_1_rmse: 0.48952 |  0:00:48s
epoch 76 | loss: 0.1309  | val_0_rmse: 0.39834 | val_1_rmse: 0.49274 |  0:00:49s
epoch 77 | loss: 0.13543 | val_0_rmse: 0.38271 | val_1_rmse: 0.48805 |  0:00:49s
epoch 78 | loss: 0.148   | val_0_rmse: 0.3915  | val_1_rmse: 0.49107 |  0:00:50s
epoch 79 | loss: 0.14412 | val_0_rmse: 0.41391 | val_1_rmse: 0.50318 |  0:00:51s
epoch 80 | loss: 0.14324 | val_0_rmse: 0.37283 | val_1_rmse: 0.46841 |  0:00:51s
epoch 81 | loss: 0.1352  | val_0_rmse: 0.3558  | val_1_rmse: 0.46807 |  0:00:52s
epoch 82 | loss: 0.12804 | val_0_rmse: 0.35706 | val_1_rmse: 0.46442 |  0:00:53s
epoch 83 | loss: 0.13159 | val_0_rmse: 0.35225 | val_1_rmse: 0.46108 |  0:00:53s
epoch 84 | loss: 0.12553 | val_0_rmse: 0.3621  | val_1_rmse: 0.46861 |  0:00:54s
epoch 85 | loss: 0.12423 | val_0_rmse: 0.34324 | val_1_rmse: 0.45876 |  0:00:54s
epoch 86 | loss: 0.12386 | val_0_rmse: 0.34441 | val_1_rmse: 0.46118 |  0:00:55s
epoch 87 | loss: 0.12599 | val_0_rmse: 0.35745 | val_1_rmse: 0.46318 |  0:00:56s
epoch 88 | loss: 0.12519 | val_0_rmse: 0.33727 | val_1_rmse: 0.45225 |  0:00:56s
epoch 89 | loss: 0.12874 | val_0_rmse: 0.33115 | val_1_rmse: 0.45266 |  0:00:57s
epoch 90 | loss: 0.12366 | val_0_rmse: 0.33407 | val_1_rmse: 0.44674 |  0:00:58s
epoch 91 | loss: 0.12369 | val_0_rmse: 0.32567 | val_1_rmse: 0.43987 |  0:00:58s
epoch 92 | loss: 0.1175  | val_0_rmse: 0.31237 | val_1_rmse: 0.43718 |  0:00:59s
epoch 93 | loss: 0.11588 | val_0_rmse: 0.32369 | val_1_rmse: 0.45129 |  0:01:00s
epoch 94 | loss: 0.12242 | val_0_rmse: 0.33457 | val_1_rmse: 0.44775 |  0:01:00s
epoch 95 | loss: 0.11796 | val_0_rmse: 0.31059 | val_1_rmse: 0.42774 |  0:01:01s
epoch 96 | loss: 0.11527 | val_0_rmse: 0.30672 | val_1_rmse: 0.43882 |  0:01:01s
epoch 97 | loss: 0.11652 | val_0_rmse: 0.31963 | val_1_rmse: 0.43866 |  0:01:02s
epoch 98 | loss: 0.12149 | val_0_rmse: 0.3057  | val_1_rmse: 0.42189 |  0:01:03s
epoch 99 | loss: 0.11727 | val_0_rmse: 0.32253 | val_1_rmse: 0.4402  |  0:01:03s
epoch 100| loss: 0.12399 | val_0_rmse: 0.3107  | val_1_rmse: 0.42508 |  0:01:04s
epoch 101| loss: 0.11627 | val_0_rmse: 0.30899 | val_1_rmse: 0.43144 |  0:01:05s
epoch 102| loss: 0.11072 | val_0_rmse: 0.30491 | val_1_rmse: 0.43268 |  0:01:05s
epoch 103| loss: 0.10893 | val_0_rmse: 0.29301 | val_1_rmse: 0.43344 |  0:01:06s
epoch 104| loss: 0.1122  | val_0_rmse: 0.30976 | val_1_rmse: 0.43275 |  0:01:07s
epoch 105| loss: 0.10198 | val_0_rmse: 0.27927 | val_1_rmse: 0.41747 |  0:01:07s
epoch 106| loss: 0.10666 | val_0_rmse: 0.27912 | val_1_rmse: 0.4122  |  0:01:08s
epoch 107| loss: 0.10212 | val_0_rmse: 0.27155 | val_1_rmse: 0.41149 |  0:01:08s
epoch 108| loss: 0.09547 | val_0_rmse: 0.26632 | val_1_rmse: 0.40863 |  0:01:09s
epoch 109| loss: 0.09672 | val_0_rmse: 0.27846 | val_1_rmse: 0.42438 |  0:01:10s
epoch 110| loss: 0.10753 | val_0_rmse: 0.26898 | val_1_rmse: 0.40944 |  0:01:10s
epoch 111| loss: 0.10062 | val_0_rmse: 0.28612 | val_1_rmse: 0.41887 |  0:01:11s
epoch 112| loss: 0.10243 | val_0_rmse: 0.26599 | val_1_rmse: 0.40693 |  0:01:12s
epoch 113| loss: 0.09502 | val_0_rmse: 0.26892 | val_1_rmse: 0.4084  |  0:01:12s
epoch 114| loss: 0.09093 | val_0_rmse: 0.26412 | val_1_rmse: 0.40751 |  0:01:13s
epoch 115| loss: 0.08927 | val_0_rmse: 0.25637 | val_1_rmse: 0.39885 |  0:01:14s
epoch 116| loss: 0.09614 | val_0_rmse: 0.25995 | val_1_rmse: 0.40328 |  0:01:14s
epoch 117| loss: 0.0939  | val_0_rmse: 0.27025 | val_1_rmse: 0.41244 |  0:01:15s
epoch 118| loss: 0.09884 | val_0_rmse: 0.25626 | val_1_rmse: 0.39748 |  0:01:16s
epoch 119| loss: 0.08842 | val_0_rmse: 0.25904 | val_1_rmse: 0.39984 |  0:01:16s
epoch 120| loss: 0.08949 | val_0_rmse: 0.2485  | val_1_rmse: 0.39769 |  0:01:17s
epoch 121| loss: 0.08483 | val_0_rmse: 0.24555 | val_1_rmse: 0.39787 |  0:01:17s
epoch 122| loss: 0.08274 | val_0_rmse: 0.26351 | val_1_rmse: 0.40709 |  0:01:18s
epoch 123| loss: 0.08845 | val_0_rmse: 0.2436  | val_1_rmse: 0.39962 |  0:01:19s
epoch 124| loss: 0.08446 | val_0_rmse: 0.25382 | val_1_rmse: 0.42234 |  0:01:19s
epoch 125| loss: 0.08134 | val_0_rmse: 0.25825 | val_1_rmse: 0.41858 |  0:01:20s
epoch 126| loss: 0.08554 | val_0_rmse: 0.23795 | val_1_rmse: 0.4015  |  0:01:21s
epoch 127| loss: 0.08067 | val_0_rmse: 0.24703 | val_1_rmse: 0.40583 |  0:01:21s
epoch 128| loss: 0.07885 | val_0_rmse: 0.23672 | val_1_rmse: 0.40115 |  0:01:22s
epoch 129| loss: 0.07803 | val_0_rmse: 0.24852 | val_1_rmse: 0.40616 |  0:01:23s
epoch 130| loss: 0.07965 | val_0_rmse: 0.23722 | val_1_rmse: 0.3995  |  0:01:23s
epoch 131| loss: 0.08264 | val_0_rmse: 0.24304 | val_1_rmse: 0.3966  |  0:01:24s
epoch 132| loss: 0.07495 | val_0_rmse: 0.23827 | val_1_rmse: 0.39572 |  0:01:25s
epoch 133| loss: 0.07887 | val_0_rmse: 0.2375  | val_1_rmse: 0.38979 |  0:01:25s
epoch 134| loss: 0.08117 | val_0_rmse: 0.27689 | val_1_rmse: 0.41375 |  0:01:26s
epoch 135| loss: 0.08447 | val_0_rmse: 0.24332 | val_1_rmse: 0.40021 |  0:01:26s
epoch 136| loss: 0.08076 | val_0_rmse: 0.24158 | val_1_rmse: 0.40249 |  0:01:27s
epoch 137| loss: 0.07316 | val_0_rmse: 0.23617 | val_1_rmse: 0.39757 |  0:01:28s
epoch 138| loss: 0.08026 | val_0_rmse: 0.24167 | val_1_rmse: 0.3947  |  0:01:28s
epoch 139| loss: 0.07251 | val_0_rmse: 0.23724 | val_1_rmse: 0.39812 |  0:01:29s
epoch 140| loss: 0.07695 | val_0_rmse: 0.23595 | val_1_rmse: 0.40127 |  0:01:30s
epoch 141| loss: 0.07103 | val_0_rmse: 0.23003 | val_1_rmse: 0.39793 |  0:01:30s
epoch 142| loss: 0.07358 | val_0_rmse: 0.24177 | val_1_rmse: 0.4056  |  0:01:31s
epoch 143| loss: 0.0755  | val_0_rmse: 0.23433 | val_1_rmse: 0.39958 |  0:01:32s
epoch 144| loss: 0.07708 | val_0_rmse: 0.24231 | val_1_rmse: 0.39694 |  0:01:32s
epoch 145| loss: 0.0769  | val_0_rmse: 0.23698 | val_1_rmse: 0.39153 |  0:01:33s
epoch 146| loss: 0.07596 | val_0_rmse: 0.22948 | val_1_rmse: 0.39848 |  0:01:33s
epoch 147| loss: 0.07643 | val_0_rmse: 0.2275  | val_1_rmse: 0.40913 |  0:01:34s
epoch 148| loss: 0.07271 | val_0_rmse: 0.25013 | val_1_rmse: 0.4627  |  0:01:35s
epoch 149| loss: 0.07094 | val_0_rmse: 0.23332 | val_1_rmse: 0.4105  |  0:01:35s
Stop training because you reached max_epochs = 150 with best_epoch = 133 and best_val_1_rmse = 0.38979
Best weights from best epoch are automatically used!
ended training at: 03:35:39
Feature importance:
Mean squared error is of 2777034715.399909
Mean absolute error:32573.99911572344
MAPE:0.3017796452553466
R2 score:0.8552061644305781
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 3
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 03:35:39
epoch 0  | loss: 1.95088 | val_0_rmse: 0.99789 | val_1_rmse: 1.0135  |  0:00:00s
epoch 1  | loss: 1.10676 | val_0_rmse: 1.00117 | val_1_rmse: 1.01736 |  0:00:01s
epoch 2  | loss: 0.92155 | val_0_rmse: 0.94566 | val_1_rmse: 0.9589  |  0:00:01s
epoch 3  | loss: 0.79116 | val_0_rmse: 0.9244  | val_1_rmse: 0.91724 |  0:00:02s
epoch 4  | loss: 0.66939 | val_0_rmse: 0.82443 | val_1_rmse: 0.84844 |  0:00:03s
epoch 5  | loss: 0.57268 | val_0_rmse: 0.78933 | val_1_rmse: 0.81539 |  0:00:03s
epoch 6  | loss: 0.53388 | val_0_rmse: 0.7762  | val_1_rmse: 0.80441 |  0:00:04s
epoch 7  | loss: 0.48605 | val_0_rmse: 0.75322 | val_1_rmse: 0.77456 |  0:00:05s
epoch 8  | loss: 0.46371 | val_0_rmse: 0.74389 | val_1_rmse: 0.7705  |  0:00:05s
epoch 9  | loss: 0.44846 | val_0_rmse: 0.73038 | val_1_rmse: 0.76238 |  0:00:06s
epoch 10 | loss: 0.41509 | val_0_rmse: 0.72919 | val_1_rmse: 0.7607  |  0:00:07s
epoch 11 | loss: 0.4077  | val_0_rmse: 0.70583 | val_1_rmse: 0.73592 |  0:00:07s
epoch 12 | loss: 0.39264 | val_0_rmse: 0.69216 | val_1_rmse: 0.71174 |  0:00:08s
epoch 13 | loss: 0.36368 | val_0_rmse: 0.68522 | val_1_rmse: 0.71007 |  0:00:08s
epoch 14 | loss: 0.33959 | val_0_rmse: 0.68045 | val_1_rmse: 0.70513 |  0:00:09s
epoch 15 | loss: 0.33079 | val_0_rmse: 0.66909 | val_1_rmse: 0.69238 |  0:00:10s
epoch 16 | loss: 0.32872 | val_0_rmse: 0.67978 | val_1_rmse: 0.70423 |  0:00:10s
epoch 17 | loss: 0.31963 | val_0_rmse: 0.67    | val_1_rmse: 0.69127 |  0:00:11s
epoch 18 | loss: 0.29756 | val_0_rmse: 0.6625  | val_1_rmse: 0.68524 |  0:00:12s
epoch 19 | loss: 0.28785 | val_0_rmse: 0.63783 | val_1_rmse: 0.65974 |  0:00:12s
epoch 20 | loss: 0.28258 | val_0_rmse: 0.64299 | val_1_rmse: 0.66998 |  0:00:13s
epoch 21 | loss: 0.26508 | val_0_rmse: 0.64403 | val_1_rmse: 0.67226 |  0:00:14s
epoch 22 | loss: 0.26716 | val_0_rmse: 0.66929 | val_1_rmse: 0.70049 |  0:00:14s
epoch 23 | loss: 0.25207 | val_0_rmse: 0.63956 | val_1_rmse: 0.67069 |  0:00:15s
epoch 24 | loss: 0.24972 | val_0_rmse: 0.63617 | val_1_rmse: 0.66874 |  0:00:16s
epoch 25 | loss: 0.24562 | val_0_rmse: 0.62343 | val_1_rmse: 0.66113 |  0:00:16s
epoch 26 | loss: 0.24296 | val_0_rmse: 0.62646 | val_1_rmse: 0.66479 |  0:00:17s
epoch 27 | loss: 0.23254 | val_0_rmse: 0.61202 | val_1_rmse: 0.64973 |  0:00:17s
epoch 28 | loss: 0.22981 | val_0_rmse: 0.62777 | val_1_rmse: 0.66205 |  0:00:18s
epoch 29 | loss: 0.22709 | val_0_rmse: 0.58125 | val_1_rmse: 0.61562 |  0:00:19s
epoch 30 | loss: 0.22761 | val_0_rmse: 0.58899 | val_1_rmse: 0.62804 |  0:00:19s
epoch 31 | loss: 0.21988 | val_0_rmse: 0.61411 | val_1_rmse: 0.63946 |  0:00:20s
epoch 32 | loss: 0.22393 | val_0_rmse: 0.60403 | val_1_rmse: 0.62986 |  0:00:21s
epoch 33 | loss: 0.21925 | val_0_rmse: 0.60727 | val_1_rmse: 0.63983 |  0:00:21s
epoch 34 | loss: 0.20908 | val_0_rmse: 0.56946 | val_1_rmse: 0.60696 |  0:00:22s
epoch 35 | loss: 0.20373 | val_0_rmse: 0.5494  | val_1_rmse: 0.58618 |  0:00:23s
epoch 36 | loss: 0.20413 | val_0_rmse: 0.57938 | val_1_rmse: 0.61397 |  0:00:23s
epoch 37 | loss: 0.19472 | val_0_rmse: 0.54587 | val_1_rmse: 0.58692 |  0:00:24s
epoch 38 | loss: 0.19896 | val_0_rmse: 0.5437  | val_1_rmse: 0.58062 |  0:00:24s
epoch 39 | loss: 0.19495 | val_0_rmse: 0.54732 | val_1_rmse: 0.58489 |  0:00:25s
epoch 40 | loss: 0.19221 | val_0_rmse: 0.52093 | val_1_rmse: 0.56997 |  0:00:26s
epoch 41 | loss: 0.18946 | val_0_rmse: 0.54437 | val_1_rmse: 0.57751 |  0:00:26s
epoch 42 | loss: 0.17894 | val_0_rmse: 0.51099 | val_1_rmse: 0.55802 |  0:00:27s
epoch 43 | loss: 0.17457 | val_0_rmse: 0.51559 | val_1_rmse: 0.56054 |  0:00:28s
epoch 44 | loss: 0.17435 | val_0_rmse: 0.51656 | val_1_rmse: 0.56567 |  0:00:28s
epoch 45 | loss: 0.17371 | val_0_rmse: 0.51592 | val_1_rmse: 0.55915 |  0:00:29s
epoch 46 | loss: 0.17149 | val_0_rmse: 0.51363 | val_1_rmse: 0.56169 |  0:00:30s
epoch 47 | loss: 0.16255 | val_0_rmse: 0.50913 | val_1_rmse: 0.55419 |  0:00:30s
epoch 48 | loss: 0.15615 | val_0_rmse: 0.5073  | val_1_rmse: 0.54809 |  0:00:31s
epoch 49 | loss: 0.1546  | val_0_rmse: 0.50508 | val_1_rmse: 0.55476 |  0:00:32s
epoch 50 | loss: 0.15709 | val_0_rmse: 0.49826 | val_1_rmse: 0.54124 |  0:00:32s
epoch 51 | loss: 0.15147 | val_0_rmse: 0.48414 | val_1_rmse: 0.52849 |  0:00:33s
epoch 52 | loss: 0.14975 | val_0_rmse: 0.48051 | val_1_rmse: 0.52182 |  0:00:33s
epoch 53 | loss: 0.14253 | val_0_rmse: 0.48309 | val_1_rmse: 0.5272  |  0:00:34s
epoch 54 | loss: 0.14427 | val_0_rmse: 0.46848 | val_1_rmse: 0.51901 |  0:00:35s
epoch 55 | loss: 0.14392 | val_0_rmse: 0.47108 | val_1_rmse: 0.52317 |  0:00:35s
epoch 56 | loss: 0.14834 | val_0_rmse: 0.47806 | val_1_rmse: 0.5253  |  0:00:36s
epoch 57 | loss: 0.14167 | val_0_rmse: 0.46521 | val_1_rmse: 0.51564 |  0:00:37s
epoch 58 | loss: 0.14517 | val_0_rmse: 0.45127 | val_1_rmse: 0.50876 |  0:00:37s
epoch 59 | loss: 0.13865 | val_0_rmse: 0.4493  | val_1_rmse: 0.50508 |  0:00:38s
epoch 60 | loss: 0.13745 | val_0_rmse: 0.44799 | val_1_rmse: 0.50639 |  0:00:39s
epoch 61 | loss: 0.13705 | val_0_rmse: 0.46282 | val_1_rmse: 0.5213  |  0:00:39s
epoch 62 | loss: 0.13819 | val_0_rmse: 0.44318 | val_1_rmse: 0.50348 |  0:00:40s
epoch 63 | loss: 0.13974 | val_0_rmse: 0.4521  | val_1_rmse: 0.50364 |  0:00:41s
epoch 64 | loss: 0.13789 | val_0_rmse: 0.41946 | val_1_rmse: 0.48583 |  0:00:41s
epoch 65 | loss: 0.12922 | val_0_rmse: 0.4241  | val_1_rmse: 0.48771 |  0:00:42s
epoch 66 | loss: 0.13972 | val_0_rmse: 0.40327 | val_1_rmse: 0.47685 |  0:00:42s
epoch 67 | loss: 0.13194 | val_0_rmse: 0.39832 | val_1_rmse: 0.47504 |  0:00:43s
epoch 68 | loss: 0.13358 | val_0_rmse: 0.39762 | val_1_rmse: 0.46801 |  0:00:44s
epoch 69 | loss: 0.13566 | val_0_rmse: 0.4023  | val_1_rmse: 0.48542 |  0:00:44s
epoch 70 | loss: 0.12664 | val_0_rmse: 0.3953  | val_1_rmse: 0.47159 |  0:00:45s
epoch 71 | loss: 0.12257 | val_0_rmse: 0.37781 | val_1_rmse: 0.4552  |  0:00:46s
epoch 72 | loss: 0.12212 | val_0_rmse: 0.37457 | val_1_rmse: 0.44875 |  0:00:46s
epoch 73 | loss: 0.1205  | val_0_rmse: 0.3631  | val_1_rmse: 0.44611 |  0:00:47s
epoch 74 | loss: 0.1156  | val_0_rmse: 0.35671 | val_1_rmse: 0.44916 |  0:00:48s
epoch 75 | loss: 0.12097 | val_0_rmse: 0.36284 | val_1_rmse: 0.45034 |  0:00:48s
epoch 76 | loss: 0.11974 | val_0_rmse: 0.35729 | val_1_rmse: 0.45173 |  0:00:49s
epoch 77 | loss: 0.11967 | val_0_rmse: 0.35609 | val_1_rmse: 0.44537 |  0:00:49s
epoch 78 | loss: 0.1131  | val_0_rmse: 0.34993 | val_1_rmse: 0.44303 |  0:00:50s
epoch 79 | loss: 0.11354 | val_0_rmse: 0.33836 | val_1_rmse: 0.42589 |  0:00:51s
epoch 80 | loss: 0.12473 | val_0_rmse: 0.37812 | val_1_rmse: 0.46565 |  0:00:51s
epoch 81 | loss: 0.12734 | val_0_rmse: 0.3429  | val_1_rmse: 0.44607 |  0:00:52s
epoch 82 | loss: 0.12219 | val_0_rmse: 0.33725 | val_1_rmse: 0.43513 |  0:00:53s
epoch 83 | loss: 0.11648 | val_0_rmse: 0.3309  | val_1_rmse: 0.43094 |  0:00:53s
epoch 84 | loss: 0.11417 | val_0_rmse: 0.32101 | val_1_rmse: 0.42773 |  0:00:54s
epoch 85 | loss: 0.10908 | val_0_rmse: 0.39024 | val_1_rmse: 0.42409 |  0:00:55s
epoch 86 | loss: 0.11345 | val_0_rmse: 0.34178 | val_1_rmse: 0.43516 |  0:00:55s
epoch 87 | loss: 0.11313 | val_0_rmse: 0.33154 | val_1_rmse: 0.4171  |  0:00:56s
epoch 88 | loss: 0.11374 | val_0_rmse: 0.31844 | val_1_rmse: 0.42696 |  0:00:57s
epoch 89 | loss: 0.11247 | val_0_rmse: 0.31534 | val_1_rmse: 0.42112 |  0:00:57s
epoch 90 | loss: 0.10973 | val_0_rmse: 0.32779 | val_1_rmse: 0.4193  |  0:00:58s
epoch 91 | loss: 0.11022 | val_0_rmse: 0.30691 | val_1_rmse: 0.42373 |  0:00:58s
epoch 92 | loss: 0.10327 | val_0_rmse: 0.30151 | val_1_rmse: 0.41472 |  0:00:59s
epoch 93 | loss: 0.10715 | val_0_rmse: 0.30085 | val_1_rmse: 0.42368 |  0:01:00s
epoch 94 | loss: 0.10036 | val_0_rmse: 0.29456 | val_1_rmse: 0.40682 |  0:01:00s
epoch 95 | loss: 0.10201 | val_0_rmse: 0.30145 | val_1_rmse: 0.41188 |  0:01:01s
epoch 96 | loss: 0.10187 | val_0_rmse: 0.28541 | val_1_rmse: 0.40279 |  0:01:02s
epoch 97 | loss: 0.09885 | val_0_rmse: 0.29047 | val_1_rmse: 0.411   |  0:01:02s
epoch 98 | loss: 0.09592 | val_0_rmse: 0.27956 | val_1_rmse: 0.40182 |  0:01:03s
epoch 99 | loss: 0.10097 | val_0_rmse: 0.28704 | val_1_rmse: 0.40467 |  0:01:04s
epoch 100| loss: 0.10976 | val_0_rmse: 0.29822 | val_1_rmse: 0.41011 |  0:01:04s
epoch 101| loss: 0.10734 | val_0_rmse: 0.28696 | val_1_rmse: 0.40395 |  0:01:05s
epoch 102| loss: 0.10131 | val_0_rmse: 0.2951  | val_1_rmse: 0.40351 |  0:01:05s
epoch 103| loss: 0.10591 | val_0_rmse: 0.28551 | val_1_rmse: 0.41235 |  0:01:06s
epoch 104| loss: 0.10128 | val_0_rmse: 0.277   | val_1_rmse: 0.39505 |  0:01:07s
epoch 105| loss: 0.09469 | val_0_rmse: 0.28558 | val_1_rmse: 0.41231 |  0:01:07s
epoch 106| loss: 0.10107 | val_0_rmse: 0.2801  | val_1_rmse: 0.41631 |  0:01:08s
epoch 107| loss: 0.10687 | val_0_rmse: 0.29962 | val_1_rmse: 0.42622 |  0:01:09s
epoch 108| loss: 0.11353 | val_0_rmse: 0.30569 | val_1_rmse: 0.42629 |  0:01:09s
epoch 109| loss: 0.10302 | val_0_rmse: 0.29621 | val_1_rmse: 0.41657 |  0:01:10s
epoch 110| loss: 0.1088  | val_0_rmse: 0.2873  | val_1_rmse: 0.41642 |  0:01:11s
epoch 111| loss: 0.10383 | val_0_rmse: 0.28876 | val_1_rmse: 0.4147  |  0:01:11s
epoch 112| loss: 0.10504 | val_0_rmse: 0.27987 | val_1_rmse: 0.40125 |  0:01:12s
epoch 113| loss: 0.09946 | val_0_rmse: 0.27804 | val_1_rmse: 0.41865 |  0:01:12s
epoch 114| loss: 0.09425 | val_0_rmse: 0.26809 | val_1_rmse: 0.40166 |  0:01:13s
epoch 115| loss: 0.09783 | val_0_rmse: 0.28626 | val_1_rmse: 0.4074  |  0:01:14s
epoch 116| loss: 0.10344 | val_0_rmse: 0.28665 | val_1_rmse: 0.40912 |  0:01:14s
epoch 117| loss: 0.10666 | val_0_rmse: 0.30462 | val_1_rmse: 0.42927 |  0:01:15s
epoch 118| loss: 0.10175 | val_0_rmse: 0.3058  | val_1_rmse: 0.41064 |  0:01:16s
epoch 119| loss: 0.11779 | val_0_rmse: 0.3329  | val_1_rmse: 0.43352 |  0:01:16s
epoch 120| loss: 0.11532 | val_0_rmse: 0.29481 | val_1_rmse: 0.40213 |  0:01:17s
epoch 121| loss: 0.10502 | val_0_rmse: 0.29499 | val_1_rmse: 0.40327 |  0:01:18s
epoch 122| loss: 0.10635 | val_0_rmse: 0.28781 | val_1_rmse: 0.40462 |  0:01:18s
epoch 123| loss: 0.10201 | val_0_rmse: 0.28554 | val_1_rmse: 0.40137 |  0:01:19s
epoch 124| loss: 0.10203 | val_0_rmse: 0.28332 | val_1_rmse: 0.399   |  0:01:19s
epoch 125| loss: 0.09981 | val_0_rmse: 0.28724 | val_1_rmse: 0.4073  |  0:01:20s
epoch 126| loss: 0.11149 | val_0_rmse: 0.30065 | val_1_rmse: 0.42332 |  0:01:21s
epoch 127| loss: 0.11498 | val_0_rmse: 0.32296 | val_1_rmse: 0.43832 |  0:01:21s
epoch 128| loss: 0.11626 | val_0_rmse: 0.29473 | val_1_rmse: 0.43194 |  0:01:22s
epoch 129| loss: 0.1058  | val_0_rmse: 0.28298 | val_1_rmse: 0.42158 |  0:01:23s
epoch 130| loss: 0.10446 | val_0_rmse: 0.28489 | val_1_rmse: 0.42071 |  0:01:23s
epoch 131| loss: 0.09968 | val_0_rmse: 0.29297 | val_1_rmse: 0.42021 |  0:01:24s
epoch 132| loss: 0.10588 | val_0_rmse: 0.28923 | val_1_rmse: 0.42446 |  0:01:25s
epoch 133| loss: 0.104   | val_0_rmse: 0.29247 | val_1_rmse: 0.427   |  0:01:25s
epoch 134| loss: 0.09737 | val_0_rmse: 0.28613 | val_1_rmse: 0.42514 |  0:01:26s

Early stopping occured at epoch 134 with best_epoch = 104 and best_val_1_rmse = 0.39505
Best weights from best epoch are automatically used!
ended training at: 03:37:06
Feature importance:
Mean squared error is of 3591215075.4832044
Mean absolute error:37066.26983522007
MAPE:0.2820280699980849
R2 score:0.8104769580071376
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 4
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 03:37:06
epoch 0  | loss: 1.72884 | val_0_rmse: 1.0037  | val_1_rmse: 1.00502 |  0:00:00s
epoch 1  | loss: 1.06763 | val_0_rmse: 0.97271 | val_1_rmse: 0.97557 |  0:00:01s
epoch 2  | loss: 0.95955 | val_0_rmse: 0.88784 | val_1_rmse: 0.89206 |  0:00:01s
epoch 3  | loss: 0.8232  | val_0_rmse: 0.85221 | val_1_rmse: 0.86822 |  0:00:02s
epoch 4  | loss: 0.68179 | val_0_rmse: 0.80391 | val_1_rmse: 0.82013 |  0:00:03s
epoch 5  | loss: 0.64494 | val_0_rmse: 0.8187  | val_1_rmse: 0.81586 |  0:00:03s
epoch 6  | loss: 0.56461 | val_0_rmse: 0.76744 | val_1_rmse: 0.76255 |  0:00:04s
epoch 7  | loss: 0.50319 | val_0_rmse: 0.76471 | val_1_rmse: 0.75688 |  0:00:05s
epoch 8  | loss: 0.45006 | val_0_rmse: 0.74034 | val_1_rmse: 0.73441 |  0:00:05s
epoch 9  | loss: 0.42429 | val_0_rmse: 0.704   | val_1_rmse: 0.70445 |  0:00:06s
epoch 10 | loss: 0.40493 | val_0_rmse: 0.68713 | val_1_rmse: 0.69113 |  0:00:07s
epoch 11 | loss: 0.38537 | val_0_rmse: 0.68973 | val_1_rmse: 0.69443 |  0:00:07s
epoch 12 | loss: 0.3649  | val_0_rmse: 0.67205 | val_1_rmse: 0.67436 |  0:00:08s
epoch 13 | loss: 0.33512 | val_0_rmse: 0.6641  | val_1_rmse: 0.66754 |  0:00:09s
epoch 14 | loss: 0.32349 | val_0_rmse: 0.66149 | val_1_rmse: 0.66611 |  0:00:09s
epoch 15 | loss: 0.30822 | val_0_rmse: 0.67397 | val_1_rmse: 0.67494 |  0:00:10s
epoch 16 | loss: 0.28884 | val_0_rmse: 0.66525 | val_1_rmse: 0.66694 |  0:00:10s
epoch 17 | loss: 0.27722 | val_0_rmse: 0.65856 | val_1_rmse: 0.66641 |  0:00:11s
epoch 18 | loss: 0.26465 | val_0_rmse: 0.65082 | val_1_rmse: 0.65737 |  0:00:12s
epoch 19 | loss: 0.25322 | val_0_rmse: 0.63701 | val_1_rmse: 0.64399 |  0:00:12s
epoch 20 | loss: 0.24011 | val_0_rmse: 0.63293 | val_1_rmse: 0.64323 |  0:00:13s
epoch 21 | loss: 0.23836 | val_0_rmse: 0.63834 | val_1_rmse: 0.64515 |  0:00:14s
epoch 22 | loss: 0.23185 | val_0_rmse: 0.63724 | val_1_rmse: 0.64356 |  0:00:14s
epoch 23 | loss: 0.21834 | val_0_rmse: 0.62371 | val_1_rmse: 0.6342  |  0:00:15s
epoch 24 | loss: 0.2115  | val_0_rmse: 0.61994 | val_1_rmse: 0.63121 |  0:00:16s
epoch 25 | loss: 0.20553 | val_0_rmse: 0.61933 | val_1_rmse: 0.62818 |  0:00:16s
epoch 26 | loss: 0.20819 | val_0_rmse: 0.61401 | val_1_rmse: 0.6233  |  0:00:17s
epoch 27 | loss: 0.19714 | val_0_rmse: 0.60579 | val_1_rmse: 0.60993 |  0:00:18s
epoch 28 | loss: 0.19618 | val_0_rmse: 0.59751 | val_1_rmse: 0.60978 |  0:00:18s
epoch 29 | loss: 0.19728 | val_0_rmse: 0.58636 | val_1_rmse: 0.59967 |  0:00:19s
epoch 30 | loss: 0.1839  | val_0_rmse: 0.59219 | val_1_rmse: 0.60366 |  0:00:19s
epoch 31 | loss: 0.17782 | val_0_rmse: 0.57425 | val_1_rmse: 0.58614 |  0:00:20s
epoch 32 | loss: 0.18946 | val_0_rmse: 0.57723 | val_1_rmse: 0.59342 |  0:00:21s
epoch 33 | loss: 0.17638 | val_0_rmse: 0.56685 | val_1_rmse: 0.57847 |  0:00:21s
epoch 34 | loss: 0.1722  | val_0_rmse: 0.5663  | val_1_rmse: 0.57712 |  0:00:22s
epoch 35 | loss: 0.17726 | val_0_rmse: 0.58295 | val_1_rmse: 0.59379 |  0:00:23s
epoch 36 | loss: 0.1881  | val_0_rmse: 0.56859 | val_1_rmse: 0.57256 |  0:00:23s
epoch 37 | loss: 0.18702 | val_0_rmse: 0.54841 | val_1_rmse: 0.55635 |  0:00:24s
epoch 38 | loss: 0.18048 | val_0_rmse: 0.5641  | val_1_rmse: 0.57094 |  0:00:25s
epoch 39 | loss: 0.18469 | val_0_rmse: 0.5532  | val_1_rmse: 0.5633  |  0:00:25s
epoch 40 | loss: 0.16956 | val_0_rmse: 0.53917 | val_1_rmse: 0.54176 |  0:00:26s
epoch 41 | loss: 0.16869 | val_0_rmse: 0.53006 | val_1_rmse: 0.53336 |  0:00:27s
epoch 42 | loss: 0.16298 | val_0_rmse: 0.52818 | val_1_rmse: 0.53719 |  0:00:27s
epoch 43 | loss: 0.16175 | val_0_rmse: 0.51514 | val_1_rmse: 0.52807 |  0:00:28s
epoch 44 | loss: 0.16076 | val_0_rmse: 0.51609 | val_1_rmse: 0.52301 |  0:00:28s
epoch 45 | loss: 0.15583 | val_0_rmse: 0.4957  | val_1_rmse: 0.50288 |  0:00:29s
epoch 46 | loss: 0.14604 | val_0_rmse: 0.49626 | val_1_rmse: 0.50575 |  0:00:30s
epoch 47 | loss: 0.13923 | val_0_rmse: 0.49116 | val_1_rmse: 0.50662 |  0:00:30s
epoch 48 | loss: 0.1387  | val_0_rmse: 0.48449 | val_1_rmse: 0.50591 |  0:00:31s
epoch 49 | loss: 0.1369  | val_0_rmse: 0.48366 | val_1_rmse: 0.50425 |  0:00:32s
epoch 50 | loss: 0.13156 | val_0_rmse: 0.48283 | val_1_rmse: 0.50016 |  0:00:32s
epoch 51 | loss: 0.13325 | val_0_rmse: 0.46491 | val_1_rmse: 0.49483 |  0:00:33s
epoch 52 | loss: 0.13561 | val_0_rmse: 0.46916 | val_1_rmse: 0.50047 |  0:00:34s
epoch 53 | loss: 0.13274 | val_0_rmse: 0.45284 | val_1_rmse: 0.48413 |  0:00:34s
epoch 54 | loss: 0.12879 | val_0_rmse: 0.45428 | val_1_rmse: 0.48035 |  0:00:35s
epoch 55 | loss: 0.15612 | val_0_rmse: 0.47437 | val_1_rmse: 0.4959  |  0:00:36s
epoch 56 | loss: 0.17281 | val_0_rmse: 0.49394 | val_1_rmse: 0.51557 |  0:00:36s
epoch 57 | loss: 0.16176 | val_0_rmse: 0.46749 | val_1_rmse: 0.50048 |  0:00:37s
epoch 58 | loss: 0.15127 | val_0_rmse: 0.44717 | val_1_rmse: 0.47314 |  0:00:37s
epoch 59 | loss: 0.14059 | val_0_rmse: 0.44062 | val_1_rmse: 0.46869 |  0:00:38s
epoch 60 | loss: 0.13054 | val_0_rmse: 0.42692 | val_1_rmse: 0.45281 |  0:00:39s
epoch 61 | loss: 0.1312  | val_0_rmse: 0.41067 | val_1_rmse: 0.44522 |  0:00:39s
epoch 62 | loss: 0.13174 | val_0_rmse: 0.41784 | val_1_rmse: 0.44692 |  0:00:40s
epoch 63 | loss: 0.12835 | val_0_rmse: 0.40567 | val_1_rmse: 0.45132 |  0:00:41s
epoch 64 | loss: 0.1265  | val_0_rmse: 0.42712 | val_1_rmse: 0.47188 |  0:00:41s
epoch 65 | loss: 0.12611 | val_0_rmse: 0.40555 | val_1_rmse: 0.46027 |  0:00:42s
epoch 66 | loss: 0.12778 | val_0_rmse: 0.40159 | val_1_rmse: 0.45932 |  0:00:43s
epoch 67 | loss: 0.1249  | val_0_rmse: 0.38826 | val_1_rmse: 0.44657 |  0:00:43s
epoch 68 | loss: 0.12312 | val_0_rmse: 0.38483 | val_1_rmse: 0.44404 |  0:00:44s
epoch 69 | loss: 0.11861 | val_0_rmse: 0.37758 | val_1_rmse: 0.43353 |  0:00:45s
epoch 70 | loss: 0.11522 | val_0_rmse: 0.36697 | val_1_rmse: 0.42542 |  0:00:45s
epoch 71 | loss: 0.12377 | val_0_rmse: 0.3669  | val_1_rmse: 0.42045 |  0:00:46s
epoch 72 | loss: 0.10822 | val_0_rmse: 0.36143 | val_1_rmse: 0.42306 |  0:00:46s
epoch 73 | loss: 0.1145  | val_0_rmse: 0.34966 | val_1_rmse: 0.40935 |  0:00:47s
epoch 74 | loss: 0.10126 | val_0_rmse: 0.34617 | val_1_rmse: 0.41586 |  0:00:48s
epoch 75 | loss: 0.10586 | val_0_rmse: 0.33894 | val_1_rmse: 0.40298 |  0:00:48s
epoch 76 | loss: 0.10724 | val_0_rmse: 0.33289 | val_1_rmse: 0.40492 |  0:00:49s
epoch 77 | loss: 0.09839 | val_0_rmse: 0.32106 | val_1_rmse: 0.39597 |  0:00:50s
epoch 78 | loss: 0.10004 | val_0_rmse: 0.3169  | val_1_rmse: 0.39345 |  0:00:50s
epoch 79 | loss: 0.09873 | val_0_rmse: 0.31523 | val_1_rmse: 0.40042 |  0:00:51s
epoch 80 | loss: 0.09626 | val_0_rmse: 0.33323 | val_1_rmse: 0.4236  |  0:00:52s
epoch 81 | loss: 0.09759 | val_0_rmse: 0.30393 | val_1_rmse: 0.40173 |  0:00:52s
epoch 82 | loss: 0.09399 | val_0_rmse: 0.30018 | val_1_rmse: 0.39145 |  0:00:53s
epoch 83 | loss: 0.09343 | val_0_rmse: 0.30488 | val_1_rmse: 0.39538 |  0:00:54s
epoch 84 | loss: 0.09171 | val_0_rmse: 0.29141 | val_1_rmse: 0.39188 |  0:00:54s
epoch 85 | loss: 0.09187 | val_0_rmse: 0.28649 | val_1_rmse: 0.38096 |  0:00:55s
epoch 86 | loss: 0.0861  | val_0_rmse: 0.28146 | val_1_rmse: 0.37319 |  0:00:55s
epoch 87 | loss: 0.0873  | val_0_rmse: 0.28114 | val_1_rmse: 0.3816  |  0:00:56s
epoch 88 | loss: 0.08852 | val_0_rmse: 0.2945  | val_1_rmse: 0.39771 |  0:00:57s
epoch 89 | loss: 0.08734 | val_0_rmse: 0.27385 | val_1_rmse: 0.38326 |  0:00:57s
epoch 90 | loss: 0.08756 | val_0_rmse: 0.27286 | val_1_rmse: 0.37995 |  0:00:58s
epoch 91 | loss: 0.0894  | val_0_rmse: 0.2774  | val_1_rmse: 0.38048 |  0:00:59s
epoch 92 | loss: 0.08798 | val_0_rmse: 0.26773 | val_1_rmse: 0.37276 |  0:00:59s
epoch 93 | loss: 0.0908  | val_0_rmse: 0.26539 | val_1_rmse: 0.37935 |  0:01:00s
epoch 94 | loss: 0.08828 | val_0_rmse: 0.27164 | val_1_rmse: 0.38662 |  0:01:01s
epoch 95 | loss: 0.08762 | val_0_rmse: 0.28515 | val_1_rmse: 0.39128 |  0:01:01s
epoch 96 | loss: 0.09096 | val_0_rmse: 0.26226 | val_1_rmse: 0.38217 |  0:01:02s
epoch 97 | loss: 0.08147 | val_0_rmse: 0.25455 | val_1_rmse: 0.38408 |  0:01:03s
epoch 98 | loss: 0.08129 | val_0_rmse: 0.26097 | val_1_rmse: 0.38041 |  0:01:03s
epoch 99 | loss: 0.08064 | val_0_rmse: 0.25982 | val_1_rmse: 0.37603 |  0:01:04s
epoch 100| loss: 0.07493 | val_0_rmse: 0.2438  | val_1_rmse: 0.38105 |  0:01:05s
epoch 101| loss: 0.0808  | val_0_rmse: 0.24595 | val_1_rmse: 0.38567 |  0:01:05s
epoch 102| loss: 0.07974 | val_0_rmse: 0.25579 | val_1_rmse: 0.38552 |  0:01:06s
epoch 103| loss: 0.09379 | val_0_rmse: 0.29601 | val_1_rmse: 0.41648 |  0:01:07s
epoch 104| loss: 0.11195 | val_0_rmse: 0.31004 | val_1_rmse: 0.42117 |  0:01:07s
epoch 105| loss: 0.1047  | val_0_rmse: 0.28629 | val_1_rmse: 0.39205 |  0:01:08s
epoch 106| loss: 0.1021  | val_0_rmse: 0.27186 | val_1_rmse: 0.38359 |  0:01:09s
epoch 107| loss: 0.09974 | val_0_rmse: 0.27284 | val_1_rmse: 0.3963  |  0:01:09s
epoch 108| loss: 0.09187 | val_0_rmse: 0.26569 | val_1_rmse: 0.40241 |  0:01:10s
epoch 109| loss: 0.08754 | val_0_rmse: 0.25327 | val_1_rmse: 0.39145 |  0:01:11s
epoch 110| loss: 0.08309 | val_0_rmse: 0.26021 | val_1_rmse: 0.3897  |  0:01:11s
epoch 111| loss: 0.0796  | val_0_rmse: 0.24891 | val_1_rmse: 0.38784 |  0:01:12s
epoch 112| loss: 0.08231 | val_0_rmse: 0.26294 | val_1_rmse: 0.39484 |  0:01:13s
epoch 113| loss: 0.08639 | val_0_rmse: 0.23992 | val_1_rmse: 0.38928 |  0:01:13s
epoch 114| loss: 0.07779 | val_0_rmse: 0.23822 | val_1_rmse: 0.38685 |  0:01:14s
epoch 115| loss: 0.07736 | val_0_rmse: 0.25035 | val_1_rmse: 0.3991  |  0:01:14s
epoch 116| loss: 0.07636 | val_0_rmse: 0.23581 | val_1_rmse: 0.38621 |  0:01:15s
epoch 117| loss: 0.0741  | val_0_rmse: 0.23475 | val_1_rmse: 0.38031 |  0:01:16s
epoch 118| loss: 0.07699 | val_0_rmse: 0.24496 | val_1_rmse: 0.39711 |  0:01:16s
epoch 119| loss: 0.08142 | val_0_rmse: 0.24144 | val_1_rmse: 0.38914 |  0:01:17s
epoch 120| loss: 0.07164 | val_0_rmse: 0.24148 | val_1_rmse: 0.39131 |  0:01:18s
epoch 121| loss: 0.07483 | val_0_rmse: 0.23079 | val_1_rmse: 0.38543 |  0:01:18s
epoch 122| loss: 0.0674  | val_0_rmse: 0.23616 | val_1_rmse: 0.3886  |  0:01:19s

Early stopping occured at epoch 122 with best_epoch = 92 and best_val_1_rmse = 0.37276
Best weights from best epoch are automatically used!
ended training at: 03:38:26
Feature importance:
Mean squared error is of 2675791916.3454585
Mean absolute error:34093.70489720285
MAPE:0.3284440672991449
R2 score:0.8604745997735013
------------------------------------------------------------------
