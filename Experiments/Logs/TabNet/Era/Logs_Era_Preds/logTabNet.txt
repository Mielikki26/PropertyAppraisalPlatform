TabNet Logs:

Saving copy of script...
In this script only the Era dataset is used
Normalization used is StandardScaler
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 0
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 15:52:42
epoch 0  | loss: 1.6728  | val_0_rmse: 0.98608 | val_1_rmse: 0.99248 |  0:00:04s
epoch 1  | loss: 1.04361 | val_0_rmse: 0.97321 | val_1_rmse: 0.98211 |  0:00:05s
epoch 2  | loss: 0.8894  | val_0_rmse: 0.84391 | val_1_rmse: 0.8615  |  0:00:05s
epoch 3  | loss: 0.71903 | val_0_rmse: 0.84367 | val_1_rmse: 0.84591 |  0:00:06s
epoch 4  | loss: 0.63995 | val_0_rmse: 0.80315 | val_1_rmse: 0.80878 |  0:00:06s
epoch 5  | loss: 0.59033 | val_0_rmse: 0.765   | val_1_rmse: 0.78453 |  0:00:07s
epoch 6  | loss: 0.54862 | val_0_rmse: 0.74169 | val_1_rmse: 0.75349 |  0:00:08s
epoch 7  | loss: 0.51393 | val_0_rmse: 0.72514 | val_1_rmse: 0.7456  |  0:00:08s
epoch 8  | loss: 0.50436 | val_0_rmse: 0.70664 | val_1_rmse: 0.72785 |  0:00:09s
epoch 9  | loss: 0.46578 | val_0_rmse: 0.7092  | val_1_rmse: 0.73707 |  0:00:10s
epoch 10 | loss: 0.45579 | val_0_rmse: 0.71214 | val_1_rmse: 0.73772 |  0:00:10s
epoch 11 | loss: 0.43322 | val_0_rmse: 0.72858 | val_1_rmse: 0.7433  |  0:00:11s
epoch 12 | loss: 0.41287 | val_0_rmse: 0.69435 | val_1_rmse: 0.71349 |  0:00:11s
epoch 13 | loss: 0.39857 | val_0_rmse: 0.69343 | val_1_rmse: 0.71201 |  0:00:12s
epoch 14 | loss: 0.37974 | val_0_rmse: 0.66275 | val_1_rmse: 0.68323 |  0:00:13s
epoch 15 | loss: 0.35913 | val_0_rmse: 0.66827 | val_1_rmse: 0.69143 |  0:00:13s
epoch 16 | loss: 0.34584 | val_0_rmse: 0.66494 | val_1_rmse: 0.68827 |  0:00:14s
epoch 17 | loss: 0.32753 | val_0_rmse: 0.64226 | val_1_rmse: 0.66594 |  0:00:15s
epoch 18 | loss: 0.32175 | val_0_rmse: 0.64624 | val_1_rmse: 0.66683 |  0:00:15s
epoch 19 | loss: 0.31433 | val_0_rmse: 0.63274 | val_1_rmse: 0.65753 |  0:00:16s
epoch 20 | loss: 0.30141 | val_0_rmse: 0.63671 | val_1_rmse: 0.65972 |  0:00:16s
epoch 21 | loss: 0.29713 | val_0_rmse: 0.62878 | val_1_rmse: 0.65012 |  0:00:17s
epoch 22 | loss: 0.2885  | val_0_rmse: 0.60947 | val_1_rmse: 0.63151 |  0:00:18s
epoch 23 | loss: 0.27953 | val_0_rmse: 0.61091 | val_1_rmse: 0.63903 |  0:00:18s
epoch 24 | loss: 0.27026 | val_0_rmse: 0.61548 | val_1_rmse: 0.64301 |  0:00:19s
epoch 25 | loss: 0.26689 | val_0_rmse: 0.61524 | val_1_rmse: 0.64528 |  0:00:20s
epoch 26 | loss: 0.26057 | val_0_rmse: 0.60606 | val_1_rmse: 0.63471 |  0:00:20s
epoch 27 | loss: 0.27425 | val_0_rmse: 0.59574 | val_1_rmse: 0.62619 |  0:00:21s
epoch 28 | loss: 0.26826 | val_0_rmse: 0.58602 | val_1_rmse: 0.61279 |  0:00:21s
epoch 29 | loss: 0.25626 | val_0_rmse: 0.57048 | val_1_rmse: 0.60333 |  0:00:22s
epoch 30 | loss: 0.25473 | val_0_rmse: 0.56627 | val_1_rmse: 0.59697 |  0:00:23s
epoch 31 | loss: 0.2484  | val_0_rmse: 0.55114 | val_1_rmse: 0.59474 |  0:00:23s
epoch 32 | loss: 0.23573 | val_0_rmse: 0.55181 | val_1_rmse: 0.59625 |  0:00:24s
epoch 33 | loss: 0.22806 | val_0_rmse: 0.53951 | val_1_rmse: 0.58366 |  0:00:25s
epoch 34 | loss: 0.22524 | val_0_rmse: 0.54209 | val_1_rmse: 0.57607 |  0:00:25s
epoch 35 | loss: 0.22128 | val_0_rmse: 0.54302 | val_1_rmse: 0.58472 |  0:00:26s
epoch 36 | loss: 0.20737 | val_0_rmse: 0.5336  | val_1_rmse: 0.57381 |  0:00:26s
epoch 37 | loss: 0.20213 | val_0_rmse: 0.53294 | val_1_rmse: 0.58139 |  0:00:27s
epoch 38 | loss: 0.20065 | val_0_rmse: 0.53636 | val_1_rmse: 0.57818 |  0:00:28s
epoch 39 | loss: 0.19069 | val_0_rmse: 0.52973 | val_1_rmse: 0.58165 |  0:00:28s
epoch 40 | loss: 0.18711 | val_0_rmse: 0.52525 | val_1_rmse: 0.58146 |  0:00:29s
epoch 41 | loss: 0.17618 | val_0_rmse: 0.51703 | val_1_rmse: 0.5715  |  0:00:30s
epoch 42 | loss: 0.18114 | val_0_rmse: 0.51086 | val_1_rmse: 0.57164 |  0:00:30s
epoch 43 | loss: 0.17764 | val_0_rmse: 0.5127  | val_1_rmse: 0.56589 |  0:00:31s
epoch 44 | loss: 0.17411 | val_0_rmse: 0.51637 | val_1_rmse: 0.57429 |  0:00:31s
epoch 45 | loss: 0.1697  | val_0_rmse: 0.50986 | val_1_rmse: 0.5675  |  0:00:32s
epoch 46 | loss: 0.17028 | val_0_rmse: 0.49474 | val_1_rmse: 0.55185 |  0:00:33s
epoch 47 | loss: 0.17155 | val_0_rmse: 0.49379 | val_1_rmse: 0.55056 |  0:00:33s
epoch 48 | loss: 0.1662  | val_0_rmse: 0.4882  | val_1_rmse: 0.54051 |  0:00:34s
epoch 49 | loss: 0.16064 | val_0_rmse: 0.49775 | val_1_rmse: 0.55524 |  0:00:35s
epoch 50 | loss: 0.16124 | val_0_rmse: 0.48907 | val_1_rmse: 0.55058 |  0:00:35s
epoch 51 | loss: 0.15802 | val_0_rmse: 0.47515 | val_1_rmse: 0.53555 |  0:00:36s
epoch 52 | loss: 0.17375 | val_0_rmse: 0.4905  | val_1_rmse: 0.55196 |  0:00:36s
epoch 53 | loss: 0.17729 | val_0_rmse: 0.49239 | val_1_rmse: 0.55288 |  0:00:37s
epoch 54 | loss: 0.16574 | val_0_rmse: 0.49694 | val_1_rmse: 0.55356 |  0:00:38s
epoch 55 | loss: 0.16328 | val_0_rmse: 0.4569  | val_1_rmse: 0.52956 |  0:00:38s
epoch 56 | loss: 0.15819 | val_0_rmse: 0.46573 | val_1_rmse: 0.53054 |  0:00:39s
epoch 57 | loss: 0.14968 | val_0_rmse: 0.45103 | val_1_rmse: 0.52164 |  0:00:39s
epoch 58 | loss: 0.14142 | val_0_rmse: 0.46572 | val_1_rmse: 0.52566 |  0:00:40s
epoch 59 | loss: 0.14793 | val_0_rmse: 0.43762 | val_1_rmse: 0.51028 |  0:00:41s
epoch 60 | loss: 0.13922 | val_0_rmse: 0.41705 | val_1_rmse: 0.49715 |  0:00:41s
epoch 61 | loss: 0.14131 | val_0_rmse: 0.42847 | val_1_rmse: 0.50274 |  0:00:42s
epoch 62 | loss: 0.14284 | val_0_rmse: 0.43623 | val_1_rmse: 0.50349 |  0:00:43s
epoch 63 | loss: 0.13194 | val_0_rmse: 0.40606 | val_1_rmse: 0.48645 |  0:00:43s
epoch 64 | loss: 0.12861 | val_0_rmse: 0.41432 | val_1_rmse: 0.4946  |  0:00:44s
epoch 65 | loss: 0.12623 | val_0_rmse: 0.39849 | val_1_rmse: 0.48224 |  0:00:44s
epoch 66 | loss: 0.12804 | val_0_rmse: 0.40275 | val_1_rmse: 0.49445 |  0:00:45s
epoch 67 | loss: 0.13513 | val_0_rmse: 0.40907 | val_1_rmse: 0.48595 |  0:00:46s
epoch 68 | loss: 0.13671 | val_0_rmse: 0.39488 | val_1_rmse: 0.48245 |  0:00:46s
epoch 69 | loss: 0.13485 | val_0_rmse: 0.40541 | val_1_rmse: 0.49043 |  0:00:47s
epoch 70 | loss: 0.13116 | val_0_rmse: 0.38981 | val_1_rmse: 0.48175 |  0:00:48s
epoch 71 | loss: 0.12883 | val_0_rmse: 0.38772 | val_1_rmse: 0.47873 |  0:00:48s
epoch 72 | loss: 0.13186 | val_0_rmse: 0.38173 | val_1_rmse: 0.47113 |  0:00:49s
epoch 73 | loss: 0.12638 | val_0_rmse: 0.37561 | val_1_rmse: 0.48171 |  0:00:49s
epoch 74 | loss: 0.12091 | val_0_rmse: 0.36166 | val_1_rmse: 0.4612  |  0:00:50s
epoch 75 | loss: 0.11583 | val_0_rmse: 0.38002 | val_1_rmse: 0.47458 |  0:00:51s
epoch 76 | loss: 0.14891 | val_0_rmse: 0.40981 | val_1_rmse: 0.49118 |  0:00:51s
epoch 77 | loss: 0.14719 | val_0_rmse: 0.38716 | val_1_rmse: 0.47386 |  0:00:52s
epoch 78 | loss: 0.13567 | val_0_rmse: 0.36704 | val_1_rmse: 0.46739 |  0:00:53s
epoch 79 | loss: 0.12854 | val_0_rmse: 0.38103 | val_1_rmse: 0.48445 |  0:00:53s
epoch 80 | loss: 0.14231 | val_0_rmse: 0.3804  | val_1_rmse: 0.48014 |  0:00:54s
epoch 81 | loss: 0.14232 | val_0_rmse: 0.37625 | val_1_rmse: 0.47574 |  0:00:54s
epoch 82 | loss: 0.13413 | val_0_rmse: 0.3635  | val_1_rmse: 0.45331 |  0:00:55s
epoch 83 | loss: 0.1475  | val_0_rmse: 0.43285 | val_1_rmse: 0.51151 |  0:00:56s
epoch 84 | loss: 0.16313 | val_0_rmse: 0.38637 | val_1_rmse: 0.48127 |  0:00:56s
epoch 85 | loss: 0.15252 | val_0_rmse: 0.35718 | val_1_rmse: 0.46383 |  0:00:57s
epoch 86 | loss: 0.13732 | val_0_rmse: 0.34778 | val_1_rmse: 0.46108 |  0:00:58s
epoch 87 | loss: 0.12895 | val_0_rmse: 0.33724 | val_1_rmse: 0.44972 |  0:00:58s
epoch 88 | loss: 0.13026 | val_0_rmse: 0.33744 | val_1_rmse: 0.43808 |  0:00:59s
epoch 89 | loss: 0.12641 | val_0_rmse: 0.34639 | val_1_rmse: 0.43546 |  0:00:59s
epoch 90 | loss: 0.13465 | val_0_rmse: 0.34124 | val_1_rmse: 0.43684 |  0:01:00s
epoch 91 | loss: 0.13175 | val_0_rmse: 0.33855 | val_1_rmse: 0.43286 |  0:01:01s
epoch 92 | loss: 0.12001 | val_0_rmse: 0.32238 | val_1_rmse: 0.4316  |  0:01:01s
epoch 93 | loss: 0.11289 | val_0_rmse: 0.31801 | val_1_rmse: 0.42928 |  0:01:02s
epoch 94 | loss: 0.11329 | val_0_rmse: 0.31033 | val_1_rmse: 0.42477 |  0:01:03s
epoch 95 | loss: 0.10936 | val_0_rmse: 0.30832 | val_1_rmse: 0.42629 |  0:01:03s
epoch 96 | loss: 0.1075  | val_0_rmse: 0.31431 | val_1_rmse: 0.42498 |  0:01:04s
epoch 97 | loss: 0.10584 | val_0_rmse: 0.29814 | val_1_rmse: 0.4199  |  0:01:04s
epoch 98 | loss: 0.11079 | val_0_rmse: 0.30699 | val_1_rmse: 0.42411 |  0:01:05s
epoch 99 | loss: 0.1124  | val_0_rmse: 0.31779 | val_1_rmse: 0.43165 |  0:01:06s
epoch 100| loss: 0.11348 | val_0_rmse: 0.3259  | val_1_rmse: 0.44187 |  0:01:06s
epoch 101| loss: 0.11185 | val_0_rmse: 0.30167 | val_1_rmse: 0.42514 |  0:01:07s
epoch 102| loss: 0.10739 | val_0_rmse: 0.29409 | val_1_rmse: 0.42259 |  0:01:07s
epoch 103| loss: 0.1021  | val_0_rmse: 0.28478 | val_1_rmse: 0.41809 |  0:01:08s
epoch 104| loss: 0.0979  | val_0_rmse: 0.28169 | val_1_rmse: 0.41783 |  0:01:09s
epoch 105| loss: 0.09573 | val_0_rmse: 0.2809  | val_1_rmse: 0.41063 |  0:01:09s
epoch 106| loss: 0.09596 | val_0_rmse: 0.27143 | val_1_rmse: 0.41289 |  0:01:10s
epoch 107| loss: 0.10657 | val_0_rmse: 0.32612 | val_1_rmse: 0.43383 |  0:01:11s
epoch 108| loss: 0.12259 | val_0_rmse: 0.30772 | val_1_rmse: 0.42609 |  0:01:11s
epoch 109| loss: 0.11387 | val_0_rmse: 0.29937 | val_1_rmse: 0.42641 |  0:01:12s
epoch 110| loss: 0.11064 | val_0_rmse: 0.29619 | val_1_rmse: 0.42562 |  0:01:12s
epoch 111| loss: 0.10181 | val_0_rmse: 0.28957 | val_1_rmse: 0.42166 |  0:01:13s
epoch 112| loss: 0.10409 | val_0_rmse: 0.28229 | val_1_rmse: 0.42146 |  0:01:14s
epoch 113| loss: 0.10214 | val_0_rmse: 0.27835 | val_1_rmse: 0.41164 |  0:01:14s
epoch 114| loss: 0.09909 | val_0_rmse: 0.2801  | val_1_rmse: 0.42184 |  0:01:15s
epoch 115| loss: 0.09731 | val_0_rmse: 0.28149 | val_1_rmse: 0.42952 |  0:01:16s
epoch 116| loss: 0.09715 | val_0_rmse: 0.28223 | val_1_rmse: 0.42373 |  0:01:16s
epoch 117| loss: 0.09507 | val_0_rmse: 0.27313 | val_1_rmse: 0.41892 |  0:01:17s
epoch 118| loss: 0.09208 | val_0_rmse: 0.27255 | val_1_rmse: 0.42506 |  0:01:17s
epoch 119| loss: 0.09    | val_0_rmse: 0.26775 | val_1_rmse: 0.41961 |  0:01:18s
epoch 120| loss: 0.08178 | val_0_rmse: 0.2695  | val_1_rmse: 0.41892 |  0:01:19s
epoch 121| loss: 0.08447 | val_0_rmse: 0.26382 | val_1_rmse: 0.42556 |  0:01:19s
epoch 122| loss: 0.08269 | val_0_rmse: 0.25707 | val_1_rmse: 0.40756 |  0:01:20s
epoch 123| loss: 0.08035 | val_0_rmse: 0.25596 | val_1_rmse: 0.40561 |  0:01:21s
epoch 124| loss: 0.08075 | val_0_rmse: 0.27709 | val_1_rmse: 0.43283 |  0:01:21s
epoch 125| loss: 0.08069 | val_0_rmse: 0.25828 | val_1_rmse: 0.4141  |  0:01:22s
epoch 126| loss: 0.07787 | val_0_rmse: 0.25242 | val_1_rmse: 0.40547 |  0:01:22s
epoch 127| loss: 0.08224 | val_0_rmse: 0.261   | val_1_rmse: 0.41358 |  0:01:23s
epoch 128| loss: 0.07803 | val_0_rmse: 0.26064 | val_1_rmse: 0.41615 |  0:01:24s
epoch 129| loss: 0.07764 | val_0_rmse: 0.25475 | val_1_rmse: 0.41571 |  0:01:24s
epoch 130| loss: 0.08144 | val_0_rmse: 0.25097 | val_1_rmse: 0.41979 |  0:01:25s
epoch 131| loss: 0.08229 | val_0_rmse: 0.25845 | val_1_rmse: 0.41747 |  0:01:25s
epoch 132| loss: 0.08269 | val_0_rmse: 0.25755 | val_1_rmse: 0.406   |  0:01:26s
epoch 133| loss: 0.08456 | val_0_rmse: 0.2624  | val_1_rmse: 0.41027 |  0:01:27s
epoch 134| loss: 0.08171 | val_0_rmse: 0.26874 | val_1_rmse: 0.41827 |  0:01:27s
epoch 135| loss: 0.0775  | val_0_rmse: 0.25154 | val_1_rmse: 0.41539 |  0:01:28s
epoch 136| loss: 0.07414 | val_0_rmse: 0.2584  | val_1_rmse: 0.42227 |  0:01:29s
epoch 137| loss: 0.07151 | val_0_rmse: 0.25362 | val_1_rmse: 0.41016 |  0:01:29s
epoch 138| loss: 0.07512 | val_0_rmse: 0.27016 | val_1_rmse: 0.41476 |  0:01:30s
epoch 139| loss: 0.07772 | val_0_rmse: 0.25425 | val_1_rmse: 0.42183 |  0:01:30s
epoch 140| loss: 0.07541 | val_0_rmse: 0.26522 | val_1_rmse: 0.42677 |  0:01:31s
epoch 141| loss: 0.07774 | val_0_rmse: 0.25167 | val_1_rmse: 0.41424 |  0:01:32s
epoch 142| loss: 0.07435 | val_0_rmse: 0.25789 | val_1_rmse: 0.41242 |  0:01:32s
epoch 143| loss: 0.07105 | val_0_rmse: 0.26466 | val_1_rmse: 0.41382 |  0:01:33s
epoch 144| loss: 0.07419 | val_0_rmse: 0.2524  | val_1_rmse: 0.40999 |  0:01:34s
epoch 145| loss: 0.07213 | val_0_rmse: 0.2607  | val_1_rmse: 0.40162 |  0:01:34s
epoch 146| loss: 0.06922 | val_0_rmse: 0.26131 | val_1_rmse: 0.41415 |  0:01:35s
epoch 147| loss: 0.07351 | val_0_rmse: 0.2472  | val_1_rmse: 0.40583 |  0:01:35s
epoch 148| loss: 0.06966 | val_0_rmse: 0.25733 | val_1_rmse: 0.42775 |  0:01:36s
epoch 149| loss: 0.06962 | val_0_rmse: 0.24261 | val_1_rmse: 0.41464 |  0:01:37s
Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_val_1_rmse = 0.40162
Best weights from best epoch are automatically used!
ended training at: 15:54:20
Feature importance:
Mean squared error is of 4164778308.8607974
Mean absolute error:35339.199975807525
MAPE:0.26667159271724405
R2 score:0.8022460721429582
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 1
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 15:54:21
epoch 0  | loss: 1.77069 | val_0_rmse: 0.98994 | val_1_rmse: 1.01459 |  0:00:00s
epoch 1  | loss: 1.10593 | val_0_rmse: 0.99056 | val_1_rmse: 1.01615 |  0:00:01s
epoch 2  | loss: 0.95704 | val_0_rmse: 0.95473 | val_1_rmse: 0.97806 |  0:00:01s
epoch 3  | loss: 0.84997 | val_0_rmse: 0.8767  | val_1_rmse: 0.89497 |  0:00:02s
epoch 4  | loss: 0.70469 | val_0_rmse: 0.84481 | val_1_rmse: 0.86295 |  0:00:03s
epoch 5  | loss: 0.64801 | val_0_rmse: 0.81575 | val_1_rmse: 0.83264 |  0:00:03s
epoch 6  | loss: 0.58878 | val_0_rmse: 0.77345 | val_1_rmse: 0.7897  |  0:00:04s
epoch 7  | loss: 0.53554 | val_0_rmse: 0.77672 | val_1_rmse: 0.77857 |  0:00:04s
epoch 8  | loss: 0.49471 | val_0_rmse: 0.75168 | val_1_rmse: 0.76193 |  0:00:05s
epoch 9  | loss: 0.43887 | val_0_rmse: 0.72198 | val_1_rmse: 0.72896 |  0:00:06s
epoch 10 | loss: 0.40613 | val_0_rmse: 0.70649 | val_1_rmse: 0.70764 |  0:00:06s
epoch 11 | loss: 0.37665 | val_0_rmse: 0.71196 | val_1_rmse: 0.71147 |  0:00:07s
epoch 12 | loss: 0.35934 | val_0_rmse: 0.67926 | val_1_rmse: 0.6817  |  0:00:08s
epoch 13 | loss: 0.34306 | val_0_rmse: 0.67361 | val_1_rmse: 0.67446 |  0:00:08s
epoch 14 | loss: 0.3234  | val_0_rmse: 0.65098 | val_1_rmse: 0.65647 |  0:00:09s
epoch 15 | loss: 0.30002 | val_0_rmse: 0.64625 | val_1_rmse: 0.65278 |  0:00:09s
epoch 16 | loss: 0.28584 | val_0_rmse: 0.64375 | val_1_rmse: 0.64797 |  0:00:10s
epoch 17 | loss: 0.28483 | val_0_rmse: 0.63031 | val_1_rmse: 0.63543 |  0:00:11s
epoch 18 | loss: 0.27703 | val_0_rmse: 0.62936 | val_1_rmse: 0.63396 |  0:00:11s
epoch 19 | loss: 0.25741 | val_0_rmse: 0.63157 | val_1_rmse: 0.63307 |  0:00:12s
epoch 20 | loss: 0.25369 | val_0_rmse: 0.6198  | val_1_rmse: 0.61935 |  0:00:13s
epoch 21 | loss: 0.23964 | val_0_rmse: 0.62774 | val_1_rmse: 0.63168 |  0:00:13s
epoch 22 | loss: 0.24106 | val_0_rmse: 0.62077 | val_1_rmse: 0.62748 |  0:00:14s
epoch 23 | loss: 0.2422  | val_0_rmse: 0.61075 | val_1_rmse: 0.6199  |  0:00:14s
epoch 24 | loss: 0.23157 | val_0_rmse: 0.61848 | val_1_rmse: 0.62223 |  0:00:15s
epoch 25 | loss: 0.23078 | val_0_rmse: 0.60808 | val_1_rmse: 0.61242 |  0:00:16s
epoch 26 | loss: 0.2244  | val_0_rmse: 0.60671 | val_1_rmse: 0.61071 |  0:00:16s
epoch 27 | loss: 0.21473 | val_0_rmse: 0.59821 | val_1_rmse: 0.60562 |  0:00:17s
epoch 28 | loss: 0.21535 | val_0_rmse: 0.61153 | val_1_rmse: 0.61838 |  0:00:18s
epoch 29 | loss: 0.20677 | val_0_rmse: 0.57978 | val_1_rmse: 0.58903 |  0:00:18s
epoch 30 | loss: 0.19555 | val_0_rmse: 0.5713  | val_1_rmse: 0.58008 |  0:00:19s
epoch 31 | loss: 0.18673 | val_0_rmse: 0.5571  | val_1_rmse: 0.56962 |  0:00:19s
epoch 32 | loss: 0.18247 | val_0_rmse: 0.55486 | val_1_rmse: 0.56669 |  0:00:20s
epoch 33 | loss: 0.18339 | val_0_rmse: 0.56838 | val_1_rmse: 0.57979 |  0:00:21s
epoch 34 | loss: 0.17394 | val_0_rmse: 0.56818 | val_1_rmse: 0.58176 |  0:00:21s
epoch 35 | loss: 0.16914 | val_0_rmse: 0.56748 | val_1_rmse: 0.58119 |  0:00:22s
epoch 36 | loss: 0.1717  | val_0_rmse: 0.54533 | val_1_rmse: 0.56718 |  0:00:22s
epoch 37 | loss: 0.1732  | val_0_rmse: 0.53631 | val_1_rmse: 0.56453 |  0:00:23s
epoch 38 | loss: 0.16088 | val_0_rmse: 0.53703 | val_1_rmse: 0.55873 |  0:00:24s
epoch 39 | loss: 0.15189 | val_0_rmse: 0.52209 | val_1_rmse: 0.55129 |  0:00:24s
epoch 40 | loss: 0.15688 | val_0_rmse: 0.52221 | val_1_rmse: 0.55491 |  0:00:25s
epoch 41 | loss: 0.14433 | val_0_rmse: 0.54209 | val_1_rmse: 0.56707 |  0:00:26s
epoch 42 | loss: 0.1581  | val_0_rmse: 0.5389  | val_1_rmse: 0.56978 |  0:00:26s
epoch 43 | loss: 0.14475 | val_0_rmse: 0.51573 | val_1_rmse: 0.54149 |  0:00:27s
epoch 44 | loss: 0.14593 | val_0_rmse: 0.49794 | val_1_rmse: 0.53495 |  0:00:27s
epoch 45 | loss: 0.14604 | val_0_rmse: 0.4925  | val_1_rmse: 0.53121 |  0:00:28s
epoch 46 | loss: 0.14443 | val_0_rmse: 0.49544 | val_1_rmse: 0.52962 |  0:00:29s
epoch 47 | loss: 0.13688 | val_0_rmse: 0.47562 | val_1_rmse: 0.51672 |  0:00:29s
epoch 48 | loss: 0.12643 | val_0_rmse: 0.47548 | val_1_rmse: 0.52318 |  0:00:30s
epoch 49 | loss: 0.13155 | val_0_rmse: 0.4718  | val_1_rmse: 0.51386 |  0:00:31s
epoch 50 | loss: 0.12672 | val_0_rmse: 0.45456 | val_1_rmse: 0.50711 |  0:00:31s
epoch 51 | loss: 0.12786 | val_0_rmse: 0.45239 | val_1_rmse: 0.50315 |  0:00:32s
epoch 52 | loss: 0.1275  | val_0_rmse: 0.43093 | val_1_rmse: 0.49498 |  0:00:32s
epoch 53 | loss: 0.12223 | val_0_rmse: 0.43278 | val_1_rmse: 0.4986  |  0:00:33s
epoch 54 | loss: 0.12129 | val_0_rmse: 0.44072 | val_1_rmse: 0.50334 |  0:00:34s
epoch 55 | loss: 0.11142 | val_0_rmse: 0.41936 | val_1_rmse: 0.49162 |  0:00:34s
epoch 56 | loss: 0.11387 | val_0_rmse: 0.41072 | val_1_rmse: 0.47944 |  0:00:35s
epoch 57 | loss: 0.10773 | val_0_rmse: 0.4033  | val_1_rmse: 0.48099 |  0:00:36s
epoch 58 | loss: 0.11046 | val_0_rmse: 0.40125 | val_1_rmse: 0.47782 |  0:00:36s
epoch 59 | loss: 0.10331 | val_0_rmse: 0.40604 | val_1_rmse: 0.48344 |  0:00:37s
epoch 60 | loss: 0.10032 | val_0_rmse: 0.39505 | val_1_rmse: 0.47591 |  0:00:37s
epoch 61 | loss: 0.10169 | val_0_rmse: 0.3853  | val_1_rmse: 0.47562 |  0:00:38s
epoch 62 | loss: 0.10656 | val_0_rmse: 0.38655 | val_1_rmse: 0.47192 |  0:00:39s
epoch 63 | loss: 0.10176 | val_0_rmse: 0.39662 | val_1_rmse: 0.48156 |  0:00:39s
epoch 64 | loss: 0.10247 | val_0_rmse: 0.37057 | val_1_rmse: 0.45906 |  0:00:40s
epoch 65 | loss: 0.10744 | val_0_rmse: 0.36216 | val_1_rmse: 0.44977 |  0:00:41s
epoch 66 | loss: 0.09821 | val_0_rmse: 0.36606 | val_1_rmse: 0.45335 |  0:00:41s
epoch 67 | loss: 0.09897 | val_0_rmse: 0.34893 | val_1_rmse: 0.43972 |  0:00:42s
epoch 68 | loss: 0.0885  | val_0_rmse: 0.35197 | val_1_rmse: 0.44458 |  0:00:42s
epoch 69 | loss: 0.09129 | val_0_rmse: 0.3435  | val_1_rmse: 0.44286 |  0:00:43s
epoch 70 | loss: 0.08944 | val_0_rmse: 0.34925 | val_1_rmse: 0.43478 |  0:00:44s
epoch 71 | loss: 0.09244 | val_0_rmse: 0.32634 | val_1_rmse: 0.4342  |  0:00:44s
epoch 72 | loss: 0.08877 | val_0_rmse: 0.33045 | val_1_rmse: 0.43223 |  0:00:45s
epoch 73 | loss: 0.08373 | val_0_rmse: 0.3411  | val_1_rmse: 0.43196 |  0:00:46s
epoch 74 | loss: 0.09107 | val_0_rmse: 0.33422 | val_1_rmse: 0.43974 |  0:00:46s
epoch 75 | loss: 0.08746 | val_0_rmse: 0.31047 | val_1_rmse: 0.41821 |  0:00:47s
epoch 76 | loss: 0.08387 | val_0_rmse: 0.31084 | val_1_rmse: 0.40739 |  0:00:47s
epoch 77 | loss: 0.08054 | val_0_rmse: 0.29606 | val_1_rmse: 0.4065  |  0:00:48s
epoch 78 | loss: 0.08108 | val_0_rmse: 0.30083 | val_1_rmse: 0.40329 |  0:00:49s
epoch 79 | loss: 0.08374 | val_0_rmse: 0.29617 | val_1_rmse: 0.41882 |  0:00:49s
epoch 80 | loss: 0.08291 | val_0_rmse: 0.28741 | val_1_rmse: 0.39642 |  0:00:50s
epoch 81 | loss: 0.08331 | val_0_rmse: 0.30171 | val_1_rmse: 0.40283 |  0:00:51s
epoch 82 | loss: 0.0857  | val_0_rmse: 0.28629 | val_1_rmse: 0.39471 |  0:00:51s
epoch 83 | loss: 0.08496 | val_0_rmse: 0.26761 | val_1_rmse: 0.40125 |  0:00:52s
epoch 84 | loss: 0.08139 | val_0_rmse: 0.2752  | val_1_rmse: 0.39989 |  0:00:52s
epoch 85 | loss: 0.07997 | val_0_rmse: 0.27466 | val_1_rmse: 0.38779 |  0:00:53s
epoch 86 | loss: 0.07603 | val_0_rmse: 0.26241 | val_1_rmse: 0.40107 |  0:00:54s
epoch 87 | loss: 0.08211 | val_0_rmse: 0.26418 | val_1_rmse: 0.39525 |  0:00:54s
epoch 88 | loss: 0.07718 | val_0_rmse: 0.26083 | val_1_rmse: 0.39082 |  0:00:55s
epoch 89 | loss: 0.07864 | val_0_rmse: 0.25401 | val_1_rmse: 0.38069 |  0:00:55s
epoch 90 | loss: 0.07365 | val_0_rmse: 0.24551 | val_1_rmse: 0.37369 |  0:00:56s
epoch 91 | loss: 0.07372 | val_0_rmse: 0.24317 | val_1_rmse: 0.37774 |  0:00:57s
epoch 92 | loss: 0.07127 | val_0_rmse: 0.24476 | val_1_rmse: 0.37944 |  0:00:57s
epoch 93 | loss: 0.07468 | val_0_rmse: 0.24464 | val_1_rmse: 0.37221 |  0:00:58s
epoch 94 | loss: 0.07548 | val_0_rmse: 0.24719 | val_1_rmse: 0.38269 |  0:00:59s
epoch 95 | loss: 0.07505 | val_0_rmse: 0.23772 | val_1_rmse: 0.36979 |  0:00:59s
epoch 96 | loss: 0.07125 | val_0_rmse: 0.24378 | val_1_rmse: 0.37298 |  0:01:00s
epoch 97 | loss: 0.07684 | val_0_rmse: 0.24925 | val_1_rmse: 0.37956 |  0:01:00s
epoch 98 | loss: 0.07749 | val_0_rmse: 0.25501 | val_1_rmse: 0.38464 |  0:01:01s
epoch 99 | loss: 0.07778 | val_0_rmse: 0.23968 | val_1_rmse: 0.37487 |  0:01:02s
epoch 100| loss: 0.07087 | val_0_rmse: 0.24052 | val_1_rmse: 0.36795 |  0:01:02s
epoch 101| loss: 0.07433 | val_0_rmse: 0.23108 | val_1_rmse: 0.36983 |  0:01:03s
epoch 102| loss: 0.07112 | val_0_rmse: 0.22413 | val_1_rmse: 0.36518 |  0:01:04s
epoch 103| loss: 0.07255 | val_0_rmse: 0.23198 | val_1_rmse: 0.38051 |  0:01:04s
epoch 104| loss: 0.07118 | val_0_rmse: 0.22935 | val_1_rmse: 0.37308 |  0:01:05s
epoch 105| loss: 0.07104 | val_0_rmse: 0.23858 | val_1_rmse: 0.37529 |  0:01:05s
epoch 106| loss: 0.06549 | val_0_rmse: 0.2277  | val_1_rmse: 0.37475 |  0:01:06s
epoch 107| loss: 0.07455 | val_0_rmse: 0.22891 | val_1_rmse: 0.39283 |  0:01:07s
epoch 108| loss: 0.07735 | val_0_rmse: 0.23639 | val_1_rmse: 0.38785 |  0:01:07s
epoch 109| loss: 0.07749 | val_0_rmse: 0.24378 | val_1_rmse: 0.40107 |  0:01:08s
epoch 110| loss: 0.07683 | val_0_rmse: 0.23064 | val_1_rmse: 0.38191 |  0:01:08s
epoch 111| loss: 0.0721  | val_0_rmse: 0.22884 | val_1_rmse: 0.39757 |  0:01:09s
epoch 112| loss: 0.07366 | val_0_rmse: 0.22018 | val_1_rmse: 0.3957  |  0:01:10s
epoch 113| loss: 0.06907 | val_0_rmse: 0.21952 | val_1_rmse: 0.39101 |  0:01:10s
epoch 114| loss: 0.06661 | val_0_rmse: 0.21634 | val_1_rmse: 0.3895  |  0:01:11s
epoch 115| loss: 0.06371 | val_0_rmse: 0.21752 | val_1_rmse: 0.39429 |  0:01:12s
epoch 116| loss: 0.06656 | val_0_rmse: 0.21279 | val_1_rmse: 0.39948 |  0:01:12s
epoch 117| loss: 0.06823 | val_0_rmse: 0.21061 | val_1_rmse: 0.38864 |  0:01:13s
epoch 118| loss: 0.06677 | val_0_rmse: 0.2173  | val_1_rmse: 0.37938 |  0:01:13s
epoch 119| loss: 0.06664 | val_0_rmse: 0.22899 | val_1_rmse: 0.38864 |  0:01:14s
epoch 120| loss: 0.06884 | val_0_rmse: 0.2143  | val_1_rmse: 0.38107 |  0:01:15s
epoch 121| loss: 0.06914 | val_0_rmse: 0.22493 | val_1_rmse: 0.40246 |  0:01:15s
epoch 122| loss: 0.06931 | val_0_rmse: 0.22299 | val_1_rmse: 0.38283 |  0:01:16s
epoch 123| loss: 0.06819 | val_0_rmse: 0.21785 | val_1_rmse: 0.39251 |  0:01:16s
epoch 124| loss: 0.06294 | val_0_rmse: 0.25994 | val_1_rmse: 0.41736 |  0:01:17s
epoch 125| loss: 0.06285 | val_0_rmse: 0.21282 | val_1_rmse: 0.39075 |  0:01:18s
epoch 126| loss: 0.05809 | val_0_rmse: 0.21229 | val_1_rmse: 0.4015  |  0:01:18s
epoch 127| loss: 0.05881 | val_0_rmse: 0.20155 | val_1_rmse: 0.39424 |  0:01:19s
epoch 128| loss: 0.06239 | val_0_rmse: 0.21294 | val_1_rmse: 0.40246 |  0:01:20s
epoch 129| loss: 0.06313 | val_0_rmse: 0.21471 | val_1_rmse: 0.4153  |  0:01:20s
epoch 130| loss: 0.06444 | val_0_rmse: 0.21368 | val_1_rmse: 0.40934 |  0:01:21s
epoch 131| loss: 0.0658  | val_0_rmse: 0.21606 | val_1_rmse: 0.41481 |  0:01:21s
epoch 132| loss: 0.06096 | val_0_rmse: 0.21596 | val_1_rmse: 0.403   |  0:01:22s

Early stopping occured at epoch 132 with best_epoch = 102 and best_val_1_rmse = 0.36518
Best weights from best epoch are automatically used!
ended training at: 15:55:43
Feature importance:
Mean squared error is of 3107505555.9321423
Mean absolute error:33236.01198987253
MAPE:0.2816237504523134
R2 score:0.8418427479342057
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 2
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 15:55:44
epoch 0  | loss: 1.65305 | val_0_rmse: 0.99841 | val_1_rmse: 0.96702 |  0:00:00s
epoch 1  | loss: 1.06983 | val_0_rmse: 0.99729 | val_1_rmse: 0.96607 |  0:00:01s
epoch 2  | loss: 0.96228 | val_0_rmse: 0.96725 | val_1_rmse: 0.93947 |  0:00:01s
epoch 3  | loss: 0.81312 | val_0_rmse: 0.88848 | val_1_rmse: 0.87964 |  0:00:02s
epoch 4  | loss: 0.71348 | val_0_rmse: 0.8818  | val_1_rmse: 0.88872 |  0:00:03s
epoch 5  | loss: 0.68165 | val_0_rmse: 0.82406 | val_1_rmse: 0.81594 |  0:00:03s
epoch 6  | loss: 0.65185 | val_0_rmse: 0.82278 | val_1_rmse: 0.82511 |  0:00:04s
epoch 7  | loss: 0.59603 | val_0_rmse: 0.78316 | val_1_rmse: 0.7861  |  0:00:05s
epoch 8  | loss: 0.54889 | val_0_rmse: 0.73635 | val_1_rmse: 0.72757 |  0:00:05s
epoch 9  | loss: 0.5243  | val_0_rmse: 0.72413 | val_1_rmse: 0.71646 |  0:00:06s
epoch 10 | loss: 0.49886 | val_0_rmse: 0.71658 | val_1_rmse: 0.71071 |  0:00:06s
epoch 11 | loss: 0.46312 | val_0_rmse: 0.70929 | val_1_rmse: 0.70115 |  0:00:07s
epoch 12 | loss: 0.43638 | val_0_rmse: 0.73438 | val_1_rmse: 0.72544 |  0:00:08s
epoch 13 | loss: 0.42418 | val_0_rmse: 0.716   | val_1_rmse: 0.70169 |  0:00:08s
epoch 14 | loss: 0.41361 | val_0_rmse: 0.69603 | val_1_rmse: 0.6745  |  0:00:09s
epoch 15 | loss: 0.39123 | val_0_rmse: 0.68536 | val_1_rmse: 0.66951 |  0:00:10s
epoch 16 | loss: 0.36584 | val_0_rmse: 0.67833 | val_1_rmse: 0.66372 |  0:00:10s
epoch 17 | loss: 0.34419 | val_0_rmse: 0.6667  | val_1_rmse: 0.65412 |  0:00:11s
epoch 18 | loss: 0.33223 | val_0_rmse: 0.65485 | val_1_rmse: 0.64625 |  0:00:11s
epoch 19 | loss: 0.32819 | val_0_rmse: 0.6597  | val_1_rmse: 0.65106 |  0:00:12s
epoch 20 | loss: 0.32625 | val_0_rmse: 0.65631 | val_1_rmse: 0.64958 |  0:00:13s
epoch 21 | loss: 0.30507 | val_0_rmse: 0.63858 | val_1_rmse: 0.63028 |  0:00:13s
epoch 22 | loss: 0.2967  | val_0_rmse: 0.64472 | val_1_rmse: 0.6321  |  0:00:14s
epoch 23 | loss: 0.29244 | val_0_rmse: 0.63997 | val_1_rmse: 0.62797 |  0:00:14s
epoch 24 | loss: 0.27983 | val_0_rmse: 0.6297  | val_1_rmse: 0.62068 |  0:00:15s
epoch 25 | loss: 0.27811 | val_0_rmse: 0.63197 | val_1_rmse: 0.62539 |  0:00:16s
epoch 26 | loss: 0.26856 | val_0_rmse: 0.64296 | val_1_rmse: 0.62804 |  0:00:16s
epoch 27 | loss: 0.26652 | val_0_rmse: 0.64865 | val_1_rmse: 0.63351 |  0:00:17s
epoch 28 | loss: 0.25879 | val_0_rmse: 0.60759 | val_1_rmse: 0.60471 |  0:00:18s
epoch 29 | loss: 0.24613 | val_0_rmse: 0.60617 | val_1_rmse: 0.60634 |  0:00:18s
epoch 30 | loss: 0.24926 | val_0_rmse: 0.60173 | val_1_rmse: 0.60236 |  0:00:19s
epoch 31 | loss: 0.25251 | val_0_rmse: 0.60327 | val_1_rmse: 0.59799 |  0:00:19s
epoch 32 | loss: 0.24876 | val_0_rmse: 0.60765 | val_1_rmse: 0.59326 |  0:00:20s
epoch 33 | loss: 0.23694 | val_0_rmse: 0.60939 | val_1_rmse: 0.59219 |  0:00:21s
epoch 34 | loss: 0.22845 | val_0_rmse: 0.59575 | val_1_rmse: 0.58083 |  0:00:21s
epoch 35 | loss: 0.22647 | val_0_rmse: 0.57299 | val_1_rmse: 0.5715  |  0:00:22s
epoch 36 | loss: 0.22545 | val_0_rmse: 0.57074 | val_1_rmse: 0.58501 |  0:00:23s
epoch 37 | loss: 0.21217 | val_0_rmse: 0.57043 | val_1_rmse: 0.58397 |  0:00:23s
epoch 38 | loss: 0.20572 | val_0_rmse: 0.54665 | val_1_rmse: 0.5506  |  0:00:24s
epoch 39 | loss: 0.19739 | val_0_rmse: 0.54558 | val_1_rmse: 0.55175 |  0:00:24s
epoch 40 | loss: 0.19659 | val_0_rmse: 0.54587 | val_1_rmse: 0.54379 |  0:00:25s
epoch 41 | loss: 0.19106 | val_0_rmse: 0.54011 | val_1_rmse: 0.53322 |  0:00:26s
epoch 42 | loss: 0.19321 | val_0_rmse: 0.53382 | val_1_rmse: 0.52987 |  0:00:26s
epoch 43 | loss: 0.17699 | val_0_rmse: 0.52119 | val_1_rmse: 0.52714 |  0:00:27s
epoch 44 | loss: 0.18941 | val_0_rmse: 0.5263  | val_1_rmse: 0.52141 |  0:00:28s
epoch 45 | loss: 0.17997 | val_0_rmse: 0.52613 | val_1_rmse: 0.52492 |  0:00:28s
epoch 46 | loss: 0.17629 | val_0_rmse: 0.50959 | val_1_rmse: 0.51023 |  0:00:29s
epoch 47 | loss: 0.17389 | val_0_rmse: 0.50596 | val_1_rmse: 0.50725 |  0:00:29s
epoch 48 | loss: 0.17179 | val_0_rmse: 0.48538 | val_1_rmse: 0.49948 |  0:00:30s
epoch 49 | loss: 0.16457 | val_0_rmse: 0.48059 | val_1_rmse: 0.48644 |  0:00:31s
epoch 50 | loss: 0.16159 | val_0_rmse: 0.47677 | val_1_rmse: 0.48467 |  0:00:31s
epoch 51 | loss: 0.15909 | val_0_rmse: 0.48786 | val_1_rmse: 0.49329 |  0:00:32s
epoch 52 | loss: 0.15545 | val_0_rmse: 0.47337 | val_1_rmse: 0.48848 |  0:00:32s
epoch 53 | loss: 0.15236 | val_0_rmse: 0.46085 | val_1_rmse: 0.48405 |  0:00:33s
epoch 54 | loss: 0.15118 | val_0_rmse: 0.47199 | val_1_rmse: 0.48312 |  0:00:34s
epoch 55 | loss: 0.14776 | val_0_rmse: 0.46603 | val_1_rmse: 0.48174 |  0:00:34s
epoch 56 | loss: 0.14988 | val_0_rmse: 0.45191 | val_1_rmse: 0.47391 |  0:00:35s
epoch 57 | loss: 0.13971 | val_0_rmse: 0.4461  | val_1_rmse: 0.47149 |  0:00:36s
epoch 58 | loss: 0.14284 | val_0_rmse: 0.43532 | val_1_rmse: 0.46449 |  0:00:36s
epoch 59 | loss: 0.13703 | val_0_rmse: 0.43884 | val_1_rmse: 0.45852 |  0:00:37s
epoch 60 | loss: 0.13545 | val_0_rmse: 0.46007 | val_1_rmse: 0.47755 |  0:00:37s
epoch 61 | loss: 0.15684 | val_0_rmse: 0.43887 | val_1_rmse: 0.46202 |  0:00:38s
epoch 62 | loss: 0.14111 | val_0_rmse: 0.41594 | val_1_rmse: 0.45079 |  0:00:39s
epoch 63 | loss: 0.14926 | val_0_rmse: 0.41123 | val_1_rmse: 0.45743 |  0:00:39s
epoch 64 | loss: 0.13329 | val_0_rmse: 0.4021  | val_1_rmse: 0.44379 |  0:00:40s
epoch 65 | loss: 0.13273 | val_0_rmse: 0.40084 | val_1_rmse: 0.4473  |  0:00:41s
epoch 66 | loss: 0.13188 | val_0_rmse: 0.38887 | val_1_rmse: 0.44982 |  0:00:41s
epoch 67 | loss: 0.12583 | val_0_rmse: 0.38794 | val_1_rmse: 0.44321 |  0:00:42s
epoch 68 | loss: 0.1238  | val_0_rmse: 0.37174 | val_1_rmse: 0.43801 |  0:00:42s
epoch 69 | loss: 0.11867 | val_0_rmse: 0.37976 | val_1_rmse: 0.43804 |  0:00:43s
epoch 70 | loss: 0.12547 | val_0_rmse: 0.36818 | val_1_rmse: 0.432   |  0:00:44s
epoch 71 | loss: 0.11928 | val_0_rmse: 0.3675  | val_1_rmse: 0.43219 |  0:00:44s
epoch 72 | loss: 0.11333 | val_0_rmse: 0.3575  | val_1_rmse: 0.42535 |  0:00:45s
epoch 73 | loss: 0.11822 | val_0_rmse: 0.37117 | val_1_rmse: 0.43017 |  0:00:46s
epoch 74 | loss: 0.12348 | val_0_rmse: 0.36759 | val_1_rmse: 0.43473 |  0:00:46s
epoch 75 | loss: 0.11831 | val_0_rmse: 0.36668 | val_1_rmse: 0.4306  |  0:00:47s
epoch 76 | loss: 0.12147 | val_0_rmse: 0.36361 | val_1_rmse: 0.42732 |  0:00:47s
epoch 77 | loss: 0.11399 | val_0_rmse: 0.34311 | val_1_rmse: 0.41383 |  0:00:48s
epoch 78 | loss: 0.11352 | val_0_rmse: 0.35633 | val_1_rmse: 0.42298 |  0:00:49s
epoch 79 | loss: 0.11527 | val_0_rmse: 0.33285 | val_1_rmse: 0.41207 |  0:00:49s
epoch 80 | loss: 0.11763 | val_0_rmse: 0.34128 | val_1_rmse: 0.41478 |  0:00:50s
epoch 81 | loss: 0.11708 | val_0_rmse: 0.34129 | val_1_rmse: 0.42333 |  0:00:50s
epoch 82 | loss: 0.11536 | val_0_rmse: 0.36387 | val_1_rmse: 0.44214 |  0:00:51s
epoch 83 | loss: 0.11957 | val_0_rmse: 0.33272 | val_1_rmse: 0.4207  |  0:00:52s
epoch 84 | loss: 0.10928 | val_0_rmse: 0.31807 | val_1_rmse: 0.42242 |  0:00:52s
epoch 85 | loss: 0.11207 | val_0_rmse: 0.31629 | val_1_rmse: 0.41604 |  0:00:53s
epoch 86 | loss: 0.10352 | val_0_rmse: 0.31432 | val_1_rmse: 0.40829 |  0:00:54s
epoch 87 | loss: 0.11595 | val_0_rmse: 0.33352 | val_1_rmse: 0.43028 |  0:00:54s
epoch 88 | loss: 0.12026 | val_0_rmse: 0.34241 | val_1_rmse: 0.41351 |  0:00:55s
epoch 89 | loss: 0.11763 | val_0_rmse: 0.31749 | val_1_rmse: 0.39449 |  0:00:55s
epoch 90 | loss: 0.11975 | val_0_rmse: 0.31649 | val_1_rmse: 0.40763 |  0:00:56s
epoch 91 | loss: 0.11149 | val_0_rmse: 0.31847 | val_1_rmse: 0.40421 |  0:00:57s
epoch 92 | loss: 0.10792 | val_0_rmse: 0.30649 | val_1_rmse: 0.40964 |  0:00:57s
epoch 93 | loss: 0.10755 | val_0_rmse: 0.29075 | val_1_rmse: 0.39354 |  0:00:58s
epoch 94 | loss: 0.10739 | val_0_rmse: 0.30385 | val_1_rmse: 0.4025  |  0:00:59s
epoch 95 | loss: 0.1115  | val_0_rmse: 0.3012  | val_1_rmse: 0.40426 |  0:00:59s
epoch 96 | loss: 0.10781 | val_0_rmse: 0.29462 | val_1_rmse: 0.40048 |  0:01:00s
epoch 97 | loss: 0.10528 | val_0_rmse: 0.30309 | val_1_rmse: 0.41456 |  0:01:00s
epoch 98 | loss: 0.10742 | val_0_rmse: 0.28922 | val_1_rmse: 0.3992  |  0:01:01s
epoch 99 | loss: 0.09862 | val_0_rmse: 0.28881 | val_1_rmse: 0.40186 |  0:01:02s
epoch 100| loss: 0.09152 | val_0_rmse: 0.28962 | val_1_rmse: 0.41296 |  0:01:02s
epoch 101| loss: 0.10021 | val_0_rmse: 0.28311 | val_1_rmse: 0.41313 |  0:01:03s
epoch 102| loss: 0.10055 | val_0_rmse: 0.27818 | val_1_rmse: 0.40485 |  0:01:03s
epoch 103| loss: 0.10177 | val_0_rmse: 0.303   | val_1_rmse: 0.40779 |  0:01:04s
epoch 104| loss: 0.0984  | val_0_rmse: 0.27374 | val_1_rmse: 0.39835 |  0:01:05s
epoch 105| loss: 0.09701 | val_0_rmse: 0.27749 | val_1_rmse: 0.39757 |  0:01:05s
epoch 106| loss: 0.10248 | val_0_rmse: 0.27199 | val_1_rmse: 0.39595 |  0:01:06s
epoch 107| loss: 0.09556 | val_0_rmse: 0.27428 | val_1_rmse: 0.39412 |  0:01:07s
epoch 108| loss: 0.09048 | val_0_rmse: 0.27534 | val_1_rmse: 0.39377 |  0:01:07s
epoch 109| loss: 0.09402 | val_0_rmse: 0.25454 | val_1_rmse: 0.38693 |  0:01:08s
epoch 110| loss: 0.09157 | val_0_rmse: 0.26564 | val_1_rmse: 0.38818 |  0:01:08s
epoch 111| loss: 0.08781 | val_0_rmse: 0.26026 | val_1_rmse: 0.39203 |  0:01:09s
epoch 112| loss: 0.09112 | val_0_rmse: 0.26387 | val_1_rmse: 0.39608 |  0:01:10s
epoch 113| loss: 0.09164 | val_0_rmse: 0.25931 | val_1_rmse: 0.3963  |  0:01:10s
epoch 114| loss: 0.0903  | val_0_rmse: 0.26384 | val_1_rmse: 0.39816 |  0:01:11s
epoch 115| loss: 0.09096 | val_0_rmse: 0.26598 | val_1_rmse: 0.38657 |  0:01:11s
epoch 116| loss: 0.09077 | val_0_rmse: 0.28117 | val_1_rmse: 0.40401 |  0:01:12s
epoch 117| loss: 0.08975 | val_0_rmse: 0.25943 | val_1_rmse: 0.39423 |  0:01:13s
epoch 118| loss: 0.08832 | val_0_rmse: 0.26634 | val_1_rmse: 0.39829 |  0:01:13s
epoch 119| loss: 0.08962 | val_0_rmse: 0.25192 | val_1_rmse: 0.39023 |  0:01:14s
epoch 120| loss: 0.0866  | val_0_rmse: 0.25489 | val_1_rmse: 0.39248 |  0:01:15s
epoch 121| loss: 0.09442 | val_0_rmse: 0.2647  | val_1_rmse: 0.38702 |  0:01:15s
epoch 122| loss: 0.08409 | val_0_rmse: 0.27168 | val_1_rmse: 0.39849 |  0:01:16s
epoch 123| loss: 0.08317 | val_0_rmse: 0.25241 | val_1_rmse: 0.37813 |  0:01:16s
epoch 124| loss: 0.08555 | val_0_rmse: 0.24359 | val_1_rmse: 0.37824 |  0:01:17s
epoch 125| loss: 0.07767 | val_0_rmse: 0.24661 | val_1_rmse: 0.37952 |  0:01:18s
epoch 126| loss: 0.07548 | val_0_rmse: 0.24041 | val_1_rmse: 0.38491 |  0:01:18s
epoch 127| loss: 0.07621 | val_0_rmse: 0.244   | val_1_rmse: 0.38326 |  0:01:19s
epoch 128| loss: 0.07448 | val_0_rmse: 0.23712 | val_1_rmse: 0.37397 |  0:01:20s
epoch 129| loss: 0.0761  | val_0_rmse: 0.2388  | val_1_rmse: 0.38718 |  0:01:20s
epoch 130| loss: 0.07754 | val_0_rmse: 0.25845 | val_1_rmse: 0.39964 |  0:01:21s
epoch 131| loss: 0.08004 | val_0_rmse: 0.23768 | val_1_rmse: 0.37748 |  0:01:21s
epoch 132| loss: 0.07862 | val_0_rmse: 0.24899 | val_1_rmse: 0.3895  |  0:01:22s
epoch 133| loss: 0.07863 | val_0_rmse: 0.24897 | val_1_rmse: 0.38488 |  0:01:23s
epoch 134| loss: 0.07759 | val_0_rmse: 0.25123 | val_1_rmse: 0.39243 |  0:01:23s
epoch 135| loss: 0.07474 | val_0_rmse: 0.2458  | val_1_rmse: 0.38957 |  0:01:24s
epoch 136| loss: 0.07595 | val_0_rmse: 0.23334 | val_1_rmse: 0.38794 |  0:01:24s
epoch 137| loss: 0.07446 | val_0_rmse: 0.24057 | val_1_rmse: 0.38729 |  0:01:25s
epoch 138| loss: 0.07463 | val_0_rmse: 0.2396  | val_1_rmse: 0.38211 |  0:01:26s
epoch 139| loss: 0.07539 | val_0_rmse: 0.23955 | val_1_rmse: 0.37979 |  0:01:26s
epoch 140| loss: 0.07349 | val_0_rmse: 0.23795 | val_1_rmse: 0.38037 |  0:01:27s
epoch 141| loss: 0.07505 | val_0_rmse: 0.24569 | val_1_rmse: 0.37936 |  0:01:28s
epoch 142| loss: 0.06932 | val_0_rmse: 0.23461 | val_1_rmse: 0.37308 |  0:01:28s
epoch 143| loss: 0.06849 | val_0_rmse: 0.22919 | val_1_rmse: 0.38001 |  0:01:29s
epoch 144| loss: 0.06898 | val_0_rmse: 0.22555 | val_1_rmse: 0.37687 |  0:01:29s
epoch 145| loss: 0.06912 | val_0_rmse: 0.2228  | val_1_rmse: 0.3809  |  0:01:30s
epoch 146| loss: 0.06872 | val_0_rmse: 0.2312  | val_1_rmse: 0.38466 |  0:01:31s
epoch 147| loss: 0.06865 | val_0_rmse: 0.22893 | val_1_rmse: 0.37824 |  0:01:31s
epoch 148| loss: 0.06671 | val_0_rmse: 0.23043 | val_1_rmse: 0.37871 |  0:01:32s
epoch 149| loss: 0.0651  | val_0_rmse: 0.22875 | val_1_rmse: 0.37735 |  0:01:32s
Stop training because you reached max_epochs = 150 with best_epoch = 142 and best_val_1_rmse = 0.37308
Best weights from best epoch are automatically used!
ended training at: 15:57:17
Feature importance:
Mean squared error is of 3467604638.7810445
Mean absolute error:34253.015803315204
MAPE:0.30110227443587007
R2 score:0.8261695519651981
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 3
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 15:57:17
epoch 0  | loss: 1.82721 | val_0_rmse: 1.0021  | val_1_rmse: 1.00131 |  0:00:00s
epoch 1  | loss: 1.12737 | val_0_rmse: 1.00206 | val_1_rmse: 1.00148 |  0:00:01s
epoch 2  | loss: 0.98294 | val_0_rmse: 0.92265 | val_1_rmse: 0.91216 |  0:00:01s
epoch 3  | loss: 0.82399 | val_0_rmse: 0.96183 | val_1_rmse: 0.91423 |  0:00:02s
epoch 4  | loss: 0.66698 | val_0_rmse: 0.87877 | val_1_rmse: 0.86094 |  0:00:03s
epoch 5  | loss: 0.57475 | val_0_rmse: 0.81869 | val_1_rmse: 0.79587 |  0:00:03s
epoch 6  | loss: 0.53929 | val_0_rmse: 0.79143 | val_1_rmse: 0.77478 |  0:00:04s
epoch 7  | loss: 0.51502 | val_0_rmse: 0.79401 | val_1_rmse: 0.7735  |  0:00:04s
epoch 8  | loss: 0.50883 | val_0_rmse: 0.7637  | val_1_rmse: 0.75336 |  0:00:05s
epoch 9  | loss: 0.48785 | val_0_rmse: 0.71251 | val_1_rmse: 0.70256 |  0:00:06s
epoch 10 | loss: 0.45423 | val_0_rmse: 0.74387 | val_1_rmse: 0.72699 |  0:00:06s
epoch 11 | loss: 0.44203 | val_0_rmse: 0.70488 | val_1_rmse: 0.69995 |  0:00:07s
epoch 12 | loss: 0.40166 | val_0_rmse: 0.69811 | val_1_rmse: 0.68949 |  0:00:08s
epoch 13 | loss: 0.39027 | val_0_rmse: 0.7136  | val_1_rmse: 0.70409 |  0:00:08s
epoch 14 | loss: 0.37396 | val_0_rmse: 0.7147  | val_1_rmse: 0.703   |  0:00:09s
epoch 15 | loss: 0.36515 | val_0_rmse: 0.68005 | val_1_rmse: 0.67195 |  0:00:09s
epoch 16 | loss: 0.35876 | val_0_rmse: 0.66988 | val_1_rmse: 0.6606  |  0:00:10s
epoch 17 | loss: 0.34446 | val_0_rmse: 0.69019 | val_1_rmse: 0.68528 |  0:00:11s
epoch 18 | loss: 0.33855 | val_0_rmse: 0.66817 | val_1_rmse: 0.66015 |  0:00:11s
epoch 19 | loss: 0.31921 | val_0_rmse: 0.63632 | val_1_rmse: 0.63545 |  0:00:12s
epoch 20 | loss: 0.30391 | val_0_rmse: 0.63598 | val_1_rmse: 0.63032 |  0:00:13s
epoch 21 | loss: 0.28977 | val_0_rmse: 0.62355 | val_1_rmse: 0.61559 |  0:00:13s
epoch 22 | loss: 0.27928 | val_0_rmse: 0.61848 | val_1_rmse: 0.60987 |  0:00:14s
epoch 23 | loss: 0.26852 | val_0_rmse: 0.62136 | val_1_rmse: 0.61053 |  0:00:14s
epoch 24 | loss: 0.26023 | val_0_rmse: 0.608   | val_1_rmse: 0.59704 |  0:00:15s
epoch 25 | loss: 0.24854 | val_0_rmse: 0.60293 | val_1_rmse: 0.59006 |  0:00:16s
epoch 26 | loss: 0.24955 | val_0_rmse: 0.59717 | val_1_rmse: 0.59073 |  0:00:16s
epoch 27 | loss: 0.24731 | val_0_rmse: 0.59947 | val_1_rmse: 0.59004 |  0:00:17s
epoch 28 | loss: 0.25538 | val_0_rmse: 0.59287 | val_1_rmse: 0.59251 |  0:00:18s
epoch 29 | loss: 0.24311 | val_0_rmse: 0.59128 | val_1_rmse: 0.5932  |  0:00:18s
epoch 30 | loss: 0.22979 | val_0_rmse: 0.58449 | val_1_rmse: 0.58385 |  0:00:19s
epoch 31 | loss: 0.22863 | val_0_rmse: 0.57747 | val_1_rmse: 0.58536 |  0:00:19s
epoch 32 | loss: 0.22154 | val_0_rmse: 0.57448 | val_1_rmse: 0.58024 |  0:00:20s
epoch 33 | loss: 0.22228 | val_0_rmse: 0.57829 | val_1_rmse: 0.58307 |  0:00:21s
epoch 34 | loss: 0.21459 | val_0_rmse: 0.56923 | val_1_rmse: 0.5775  |  0:00:21s
epoch 35 | loss: 0.21003 | val_0_rmse: 0.56777 | val_1_rmse: 0.57552 |  0:00:22s
epoch 36 | loss: 0.20484 | val_0_rmse: 0.56164 | val_1_rmse: 0.57742 |  0:00:23s
epoch 37 | loss: 0.20928 | val_0_rmse: 0.55392 | val_1_rmse: 0.5718  |  0:00:23s
epoch 38 | loss: 0.19336 | val_0_rmse: 0.55705 | val_1_rmse: 0.57623 |  0:00:24s
epoch 39 | loss: 0.19714 | val_0_rmse: 0.57444 | val_1_rmse: 0.58688 |  0:00:24s
epoch 40 | loss: 0.19015 | val_0_rmse: 0.57223 | val_1_rmse: 0.59266 |  0:00:25s
epoch 41 | loss: 0.18309 | val_0_rmse: 0.56278 | val_1_rmse: 0.57597 |  0:00:26s
epoch 42 | loss: 0.18203 | val_0_rmse: 0.55223 | val_1_rmse: 0.57251 |  0:00:26s
epoch 43 | loss: 0.18241 | val_0_rmse: 0.5414  | val_1_rmse: 0.55777 |  0:00:27s
epoch 44 | loss: 0.17523 | val_0_rmse: 0.5263  | val_1_rmse: 0.55168 |  0:00:28s
epoch 45 | loss: 0.17637 | val_0_rmse: 0.52679 | val_1_rmse: 0.56185 |  0:00:28s
epoch 46 | loss: 0.17105 | val_0_rmse: 0.51682 | val_1_rmse: 0.54224 |  0:00:29s
epoch 47 | loss: 0.16765 | val_0_rmse: 0.51358 | val_1_rmse: 0.55032 |  0:00:29s
epoch 48 | loss: 0.16694 | val_0_rmse: 0.51319 | val_1_rmse: 0.55044 |  0:00:30s
epoch 49 | loss: 0.16111 | val_0_rmse: 0.49669 | val_1_rmse: 0.53204 |  0:00:31s
epoch 50 | loss: 0.1591  | val_0_rmse: 0.48322 | val_1_rmse: 0.52688 |  0:00:31s
epoch 51 | loss: 0.15736 | val_0_rmse: 0.4959  | val_1_rmse: 0.53776 |  0:00:32s
epoch 52 | loss: 0.16375 | val_0_rmse: 0.53161 | val_1_rmse: 0.56664 |  0:00:33s
epoch 53 | loss: 0.16117 | val_0_rmse: 0.50367 | val_1_rmse: 0.55936 |  0:00:33s
epoch 54 | loss: 0.15819 | val_0_rmse: 0.50002 | val_1_rmse: 0.54155 |  0:00:34s
epoch 55 | loss: 0.15734 | val_0_rmse: 0.49434 | val_1_rmse: 0.54068 |  0:00:34s
epoch 56 | loss: 0.15683 | val_0_rmse: 0.48232 | val_1_rmse: 0.52327 |  0:00:35s
epoch 57 | loss: 0.15083 | val_0_rmse: 0.46381 | val_1_rmse: 0.52047 |  0:00:36s
epoch 58 | loss: 0.15672 | val_0_rmse: 0.45511 | val_1_rmse: 0.5177  |  0:00:36s
epoch 59 | loss: 0.1483  | val_0_rmse: 0.44843 | val_1_rmse: 0.50625 |  0:00:37s
epoch 60 | loss: 0.14435 | val_0_rmse: 0.44914 | val_1_rmse: 0.50695 |  0:00:38s
epoch 61 | loss: 0.14974 | val_0_rmse: 0.4617  | val_1_rmse: 0.51996 |  0:00:38s
epoch 62 | loss: 0.14568 | val_0_rmse: 0.44252 | val_1_rmse: 0.49367 |  0:00:39s
epoch 63 | loss: 0.13371 | val_0_rmse: 0.43062 | val_1_rmse: 0.49131 |  0:00:39s
epoch 64 | loss: 0.12954 | val_0_rmse: 0.40932 | val_1_rmse: 0.48035 |  0:00:40s
epoch 65 | loss: 0.12943 | val_0_rmse: 0.42293 | val_1_rmse: 0.48778 |  0:00:41s
epoch 66 | loss: 0.13114 | val_0_rmse: 0.41745 | val_1_rmse: 0.47981 |  0:00:41s
epoch 67 | loss: 0.12638 | val_0_rmse: 0.40013 | val_1_rmse: 0.47821 |  0:00:42s
epoch 68 | loss: 0.12209 | val_0_rmse: 0.40677 | val_1_rmse: 0.49034 |  0:00:43s
epoch 69 | loss: 0.12456 | val_0_rmse: 0.39309 | val_1_rmse: 0.48117 |  0:00:43s
epoch 70 | loss: 0.12682 | val_0_rmse: 0.39618 | val_1_rmse: 0.47789 |  0:00:44s
epoch 71 | loss: 0.12186 | val_0_rmse: 0.3976  | val_1_rmse: 0.47994 |  0:00:44s
epoch 72 | loss: 0.11512 | val_0_rmse: 0.37419 | val_1_rmse: 0.47727 |  0:00:45s
epoch 73 | loss: 0.12143 | val_0_rmse: 0.36999 | val_1_rmse: 0.4775  |  0:00:46s
epoch 74 | loss: 0.11609 | val_0_rmse: 0.3776  | val_1_rmse: 0.4765  |  0:00:46s
epoch 75 | loss: 0.11369 | val_0_rmse: 0.37523 | val_1_rmse: 0.47006 |  0:00:47s
epoch 76 | loss: 0.11305 | val_0_rmse: 0.36157 | val_1_rmse: 0.46388 |  0:00:48s
epoch 77 | loss: 0.11151 | val_0_rmse: 0.35737 | val_1_rmse: 0.46303 |  0:00:48s
epoch 78 | loss: 0.11275 | val_0_rmse: 0.36044 | val_1_rmse: 0.46732 |  0:00:49s
epoch 79 | loss: 0.11027 | val_0_rmse: 0.35042 | val_1_rmse: 0.46542 |  0:00:49s
epoch 80 | loss: 0.11643 | val_0_rmse: 0.34235 | val_1_rmse: 0.45204 |  0:00:50s
epoch 81 | loss: 0.11271 | val_0_rmse: 0.33885 | val_1_rmse: 0.45663 |  0:00:51s
epoch 82 | loss: 0.11231 | val_0_rmse: 0.3496  | val_1_rmse: 0.46245 |  0:00:51s
epoch 83 | loss: 0.10942 | val_0_rmse: 0.31987 | val_1_rmse: 0.44352 |  0:00:52s
epoch 84 | loss: 0.1041  | val_0_rmse: 0.32552 | val_1_rmse: 0.44444 |  0:00:52s
epoch 85 | loss: 0.10264 | val_0_rmse: 0.31073 | val_1_rmse: 0.43704 |  0:00:53s
epoch 86 | loss: 0.1024  | val_0_rmse: 0.31698 | val_1_rmse: 0.43889 |  0:00:54s
epoch 87 | loss: 0.10012 | val_0_rmse: 0.31714 | val_1_rmse: 0.43674 |  0:00:54s
epoch 88 | loss: 0.09846 | val_0_rmse: 0.30767 | val_1_rmse: 0.43866 |  0:00:55s
epoch 89 | loss: 0.09711 | val_0_rmse: 0.32763 | val_1_rmse: 0.45533 |  0:00:56s
epoch 90 | loss: 0.09979 | val_0_rmse: 0.32596 | val_1_rmse: 0.44616 |  0:00:56s
epoch 91 | loss: 0.10852 | val_0_rmse: 0.32669 | val_1_rmse: 0.4434  |  0:00:57s
epoch 92 | loss: 0.10541 | val_0_rmse: 0.40395 | val_1_rmse: 0.53061 |  0:00:57s
epoch 93 | loss: 0.10658 | val_0_rmse: 0.29934 | val_1_rmse: 0.4375  |  0:00:58s
epoch 94 | loss: 0.09832 | val_0_rmse: 0.2949  | val_1_rmse: 0.4328  |  0:00:59s
epoch 95 | loss: 0.09695 | val_0_rmse: 0.30354 | val_1_rmse: 0.45217 |  0:00:59s
epoch 96 | loss: 0.11273 | val_0_rmse: 0.31386 | val_1_rmse: 0.45345 |  0:01:00s
epoch 97 | loss: 0.10831 | val_0_rmse: 0.31514 | val_1_rmse: 0.45038 |  0:01:01s
epoch 98 | loss: 0.10511 | val_0_rmse: 0.30005 | val_1_rmse: 0.43831 |  0:01:01s
epoch 99 | loss: 0.10472 | val_0_rmse: 0.2901  | val_1_rmse: 0.43418 |  0:01:02s
epoch 100| loss: 0.10194 | val_0_rmse: 0.28219 | val_1_rmse: 0.43144 |  0:01:02s
epoch 101| loss: 0.09471 | val_0_rmse: 0.27943 | val_1_rmse: 0.42953 |  0:01:03s
epoch 102| loss: 0.09301 | val_0_rmse: 0.26827 | val_1_rmse: 0.42519 |  0:01:04s
epoch 103| loss: 0.09565 | val_0_rmse: 0.27729 | val_1_rmse: 0.42113 |  0:01:04s
epoch 104| loss: 0.08738 | val_0_rmse: 0.26173 | val_1_rmse: 0.42072 |  0:01:05s
epoch 105| loss: 0.08791 | val_0_rmse: 0.28022 | val_1_rmse: 0.42829 |  0:01:06s
epoch 106| loss: 0.0848  | val_0_rmse: 0.25845 | val_1_rmse: 0.41648 |  0:01:06s
epoch 107| loss: 0.09031 | val_0_rmse: 0.25333 | val_1_rmse: 0.41478 |  0:01:07s
epoch 108| loss: 0.08351 | val_0_rmse: 0.25583 | val_1_rmse: 0.41784 |  0:01:07s
epoch 109| loss: 0.08244 | val_0_rmse: 0.2634  | val_1_rmse: 0.41613 |  0:01:08s
epoch 110| loss: 0.08705 | val_0_rmse: 0.28929 | val_1_rmse: 0.42801 |  0:01:09s
epoch 111| loss: 0.08397 | val_0_rmse: 0.25602 | val_1_rmse: 0.41761 |  0:01:09s
epoch 112| loss: 0.08255 | val_0_rmse: 0.25184 | val_1_rmse: 0.41901 |  0:01:10s
epoch 113| loss: 0.08483 | val_0_rmse: 0.25412 | val_1_rmse: 0.41833 |  0:01:11s
epoch 114| loss: 0.08712 | val_0_rmse: 0.26132 | val_1_rmse: 0.41823 |  0:01:11s
epoch 115| loss: 0.08566 | val_0_rmse: 0.25911 | val_1_rmse: 0.4127  |  0:01:12s
epoch 116| loss: 0.08338 | val_0_rmse: 0.25534 | val_1_rmse: 0.41542 |  0:01:12s
epoch 117| loss: 0.0839  | val_0_rmse: 0.26226 | val_1_rmse: 0.41311 |  0:01:13s
epoch 118| loss: 0.07993 | val_0_rmse: 0.24583 | val_1_rmse: 0.40857 |  0:01:14s
epoch 119| loss: 0.07639 | val_0_rmse: 0.25369 | val_1_rmse: 0.40901 |  0:01:14s
epoch 120| loss: 0.07657 | val_0_rmse: 0.26076 | val_1_rmse: 0.42273 |  0:01:15s
epoch 121| loss: 0.07837 | val_0_rmse: 0.24583 | val_1_rmse: 0.41275 |  0:01:16s
epoch 122| loss: 0.07796 | val_0_rmse: 0.25671 | val_1_rmse: 0.42271 |  0:01:16s
epoch 123| loss: 0.07547 | val_0_rmse: 0.23913 | val_1_rmse: 0.41422 |  0:01:17s
epoch 124| loss: 0.07923 | val_0_rmse: 0.25153 | val_1_rmse: 0.42039 |  0:01:17s
epoch 125| loss: 0.075   | val_0_rmse: 0.24583 | val_1_rmse: 0.41015 |  0:01:18s
epoch 126| loss: 0.07422 | val_0_rmse: 0.22941 | val_1_rmse: 0.40689 |  0:01:19s
epoch 127| loss: 0.06999 | val_0_rmse: 0.22795 | val_1_rmse: 0.4187  |  0:01:19s
epoch 128| loss: 0.06959 | val_0_rmse: 0.24101 | val_1_rmse: 0.41667 |  0:01:20s
epoch 129| loss: 0.0738  | val_0_rmse: 0.23256 | val_1_rmse: 0.41429 |  0:01:21s
epoch 130| loss: 0.07395 | val_0_rmse: 0.2462  | val_1_rmse: 0.41072 |  0:01:21s
epoch 131| loss: 0.07222 | val_0_rmse: 0.2426  | val_1_rmse: 0.41135 |  0:01:22s
epoch 132| loss: 0.07756 | val_0_rmse: 0.23871 | val_1_rmse: 0.40724 |  0:01:22s
epoch 133| loss: 0.06993 | val_0_rmse: 0.24009 | val_1_rmse: 0.40712 |  0:01:23s
epoch 134| loss: 0.07111 | val_0_rmse: 0.24133 | val_1_rmse: 0.41701 |  0:01:24s
epoch 135| loss: 0.06925 | val_0_rmse: 0.22986 | val_1_rmse: 0.40823 |  0:01:24s
epoch 136| loss: 0.06752 | val_0_rmse: 0.23084 | val_1_rmse: 0.40122 |  0:01:25s
epoch 137| loss: 0.0723  | val_0_rmse: 0.23435 | val_1_rmse: 0.39934 |  0:01:25s
epoch 138| loss: 0.07036 | val_0_rmse: 0.23833 | val_1_rmse: 0.41024 |  0:01:26s
epoch 139| loss: 0.07216 | val_0_rmse: 0.24812 | val_1_rmse: 0.41527 |  0:01:27s
epoch 140| loss: 0.07676 | val_0_rmse: 0.24172 | val_1_rmse: 0.41242 |  0:01:27s
epoch 141| loss: 0.0756  | val_0_rmse: 0.2349  | val_1_rmse: 0.41193 |  0:01:28s
epoch 142| loss: 0.06922 | val_0_rmse: 0.23442 | val_1_rmse: 0.40218 |  0:01:29s
epoch 143| loss: 0.06968 | val_0_rmse: 0.24242 | val_1_rmse: 0.40434 |  0:01:29s
epoch 144| loss: 0.07575 | val_0_rmse: 0.24386 | val_1_rmse: 0.41513 |  0:01:30s
epoch 145| loss: 0.06715 | val_0_rmse: 0.27132 | val_1_rmse: 0.44217 |  0:01:30s
epoch 146| loss: 0.07044 | val_0_rmse: 0.23567 | val_1_rmse: 0.41257 |  0:01:31s
epoch 147| loss: 0.07214 | val_0_rmse: 0.25563 | val_1_rmse: 0.41607 |  0:01:32s
epoch 148| loss: 0.06477 | val_0_rmse: 0.22443 | val_1_rmse: 0.40299 |  0:01:32s
epoch 149| loss: 0.06535 | val_0_rmse: 0.23293 | val_1_rmse: 0.41101 |  0:01:33s
Stop training because you reached max_epochs = 150 with best_epoch = 137 and best_val_1_rmse = 0.39934
Best weights from best epoch are automatically used!
ended training at: 15:58:51
Feature importance:
Mean squared error is of 3061399647.1378675
Mean absolute error:32982.24758388114
MAPE:0.2789645684571966
R2 score:0.8374213251752642
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: DataBase_Era.csv
Using seed = 4
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 15:58:51
epoch 0  | loss: 1.7308  | val_0_rmse: 0.99466 | val_1_rmse: 1.02518 |  0:00:00s
epoch 1  | loss: 1.04431 | val_0_rmse: 0.98511 | val_1_rmse: 1.01422 |  0:00:01s
epoch 2  | loss: 0.96654 | val_0_rmse: 0.97198 | val_1_rmse: 0.99952 |  0:00:01s
epoch 3  | loss: 0.88852 | val_0_rmse: 0.92454 | val_1_rmse: 0.94443 |  0:00:02s
epoch 4  | loss: 0.77566 | val_0_rmse: 0.83585 | val_1_rmse: 0.81481 |  0:00:03s
epoch 5  | loss: 0.70877 | val_0_rmse: 0.79645 | val_1_rmse: 0.79598 |  0:00:03s
epoch 6  | loss: 0.6192  | val_0_rmse: 0.81061 | val_1_rmse: 0.80614 |  0:00:04s
epoch 7  | loss: 0.57037 | val_0_rmse: 0.7913  | val_1_rmse: 0.78502 |  0:00:04s
epoch 8  | loss: 0.54882 | val_0_rmse: 0.75513 | val_1_rmse: 0.75551 |  0:00:05s
epoch 9  | loss: 0.51648 | val_0_rmse: 0.74963 | val_1_rmse: 0.74817 |  0:00:06s
epoch 10 | loss: 0.48276 | val_0_rmse: 0.74942 | val_1_rmse: 0.73764 |  0:00:06s
epoch 11 | loss: 0.461   | val_0_rmse: 0.71654 | val_1_rmse: 0.71078 |  0:00:07s
epoch 12 | loss: 0.43706 | val_0_rmse: 0.72567 | val_1_rmse: 0.72054 |  0:00:08s
epoch 13 | loss: 0.41174 | val_0_rmse: 0.71376 | val_1_rmse: 0.7165  |  0:00:08s
epoch 14 | loss: 0.42051 | val_0_rmse: 0.72284 | val_1_rmse: 0.72959 |  0:00:09s
epoch 15 | loss: 0.39194 | val_0_rmse: 0.69159 | val_1_rmse: 0.70529 |  0:00:09s
epoch 16 | loss: 0.3674  | val_0_rmse: 0.66975 | val_1_rmse: 0.68038 |  0:00:10s
epoch 17 | loss: 0.35145 | val_0_rmse: 0.67072 | val_1_rmse: 0.687   |  0:00:11s
epoch 18 | loss: 0.33383 | val_0_rmse: 0.6593  | val_1_rmse: 0.66987 |  0:00:11s
epoch 19 | loss: 0.318   | val_0_rmse: 0.65644 | val_1_rmse: 0.66409 |  0:00:12s
epoch 20 | loss: 0.30806 | val_0_rmse: 0.64491 | val_1_rmse: 0.65569 |  0:00:13s
epoch 21 | loss: 0.3048  | val_0_rmse: 0.63768 | val_1_rmse: 0.64898 |  0:00:13s
epoch 22 | loss: 0.28771 | val_0_rmse: 0.62519 | val_1_rmse: 0.64561 |  0:00:14s
epoch 23 | loss: 0.28079 | val_0_rmse: 0.62594 | val_1_rmse: 0.64352 |  0:00:14s
epoch 24 | loss: 0.27213 | val_0_rmse: 0.61303 | val_1_rmse: 0.62652 |  0:00:15s
epoch 25 | loss: 0.26868 | val_0_rmse: 0.60964 | val_1_rmse: 0.61768 |  0:00:16s
epoch 26 | loss: 0.26683 | val_0_rmse: 0.6042  | val_1_rmse: 0.6116  |  0:00:16s
epoch 27 | loss: 0.25416 | val_0_rmse: 0.60739 | val_1_rmse: 0.62232 |  0:00:17s
epoch 28 | loss: 0.2577  | val_0_rmse: 0.60218 | val_1_rmse: 0.61453 |  0:00:18s
epoch 29 | loss: 0.24812 | val_0_rmse: 0.6005  | val_1_rmse: 0.60625 |  0:00:18s
epoch 30 | loss: 0.23355 | val_0_rmse: 0.5854  | val_1_rmse: 0.60444 |  0:00:19s
epoch 31 | loss: 0.22299 | val_0_rmse: 0.59006 | val_1_rmse: 0.60517 |  0:00:19s
epoch 32 | loss: 0.22077 | val_0_rmse: 0.58687 | val_1_rmse: 0.6044  |  0:00:20s
epoch 33 | loss: 0.21092 | val_0_rmse: 0.57612 | val_1_rmse: 0.59767 |  0:00:21s
epoch 34 | loss: 0.21374 | val_0_rmse: 0.57326 | val_1_rmse: 0.59245 |  0:00:21s
epoch 35 | loss: 0.20448 | val_0_rmse: 0.57559 | val_1_rmse: 0.58706 |  0:00:22s
epoch 36 | loss: 0.2047  | val_0_rmse: 0.56801 | val_1_rmse: 0.58144 |  0:00:23s
epoch 37 | loss: 0.2002  | val_0_rmse: 0.56866 | val_1_rmse: 0.58797 |  0:00:23s
epoch 38 | loss: 0.18444 | val_0_rmse: 0.57033 | val_1_rmse: 0.59732 |  0:00:24s
epoch 39 | loss: 0.18854 | val_0_rmse: 0.55369 | val_1_rmse: 0.58271 |  0:00:25s
epoch 40 | loss: 0.18567 | val_0_rmse: 0.54466 | val_1_rmse: 0.57449 |  0:00:25s
epoch 41 | loss: 0.18351 | val_0_rmse: 0.53743 | val_1_rmse: 0.56702 |  0:00:26s
epoch 42 | loss: 0.18156 | val_0_rmse: 0.53273 | val_1_rmse: 0.55755 |  0:00:26s
epoch 43 | loss: 0.17577 | val_0_rmse: 0.53319 | val_1_rmse: 0.56257 |  0:00:27s
epoch 44 | loss: 0.17376 | val_0_rmse: 0.53142 | val_1_rmse: 0.55069 |  0:00:28s
epoch 45 | loss: 0.17812 | val_0_rmse: 0.51677 | val_1_rmse: 0.54007 |  0:00:28s
epoch 46 | loss: 0.16793 | val_0_rmse: 0.50626 | val_1_rmse: 0.54013 |  0:00:29s
epoch 47 | loss: 0.15788 | val_0_rmse: 0.49631 | val_1_rmse: 0.52889 |  0:00:29s
epoch 48 | loss: 0.16581 | val_0_rmse: 0.51765 | val_1_rmse: 0.54235 |  0:00:30s
epoch 49 | loss: 0.17178 | val_0_rmse: 0.52065 | val_1_rmse: 0.55088 |  0:00:31s
epoch 50 | loss: 0.17442 | val_0_rmse: 0.51435 | val_1_rmse: 0.55439 |  0:00:31s
epoch 51 | loss: 0.17723 | val_0_rmse: 0.50679 | val_1_rmse: 0.54869 |  0:00:32s
epoch 52 | loss: 0.18205 | val_0_rmse: 0.51117 | val_1_rmse: 0.55758 |  0:00:33s
epoch 53 | loss: 0.1646  | val_0_rmse: 0.48952 | val_1_rmse: 0.53933 |  0:00:33s
epoch 54 | loss: 0.16206 | val_0_rmse: 0.47314 | val_1_rmse: 0.51829 |  0:00:34s
epoch 55 | loss: 0.15406 | val_0_rmse: 0.45897 | val_1_rmse: 0.51074 |  0:00:34s
epoch 56 | loss: 0.14583 | val_0_rmse: 0.45069 | val_1_rmse: 0.50106 |  0:00:35s
epoch 57 | loss: 0.14416 | val_0_rmse: 0.43998 | val_1_rmse: 0.50288 |  0:00:36s
epoch 58 | loss: 0.14604 | val_0_rmse: 0.44949 | val_1_rmse: 0.50147 |  0:00:36s
epoch 59 | loss: 0.13759 | val_0_rmse: 0.43936 | val_1_rmse: 0.50368 |  0:00:37s
epoch 60 | loss: 0.13816 | val_0_rmse: 0.45329 | val_1_rmse: 0.51338 |  0:00:38s
epoch 61 | loss: 0.1391  | val_0_rmse: 0.42141 | val_1_rmse: 0.48867 |  0:00:38s
epoch 62 | loss: 0.13188 | val_0_rmse: 0.42696 | val_1_rmse: 0.48677 |  0:00:39s
epoch 63 | loss: 0.13076 | val_0_rmse: 0.4049  | val_1_rmse: 0.46695 |  0:00:39s
epoch 64 | loss: 0.12852 | val_0_rmse: 0.40281 | val_1_rmse: 0.46479 |  0:00:40s
epoch 65 | loss: 0.1283  | val_0_rmse: 0.40007 | val_1_rmse: 0.46846 |  0:00:41s
epoch 66 | loss: 0.12599 | val_0_rmse: 0.38392 | val_1_rmse: 0.46344 |  0:00:41s
epoch 67 | loss: 0.12404 | val_0_rmse: 0.39026 | val_1_rmse: 0.46444 |  0:00:42s
epoch 68 | loss: 0.11666 | val_0_rmse: 0.37761 | val_1_rmse: 0.45929 |  0:00:42s
epoch 69 | loss: 0.11557 | val_0_rmse: 0.37455 | val_1_rmse: 0.45215 |  0:00:43s
epoch 70 | loss: 0.11334 | val_0_rmse: 0.36352 | val_1_rmse: 0.44548 |  0:00:44s
epoch 71 | loss: 0.1171  | val_0_rmse: 0.37924 | val_1_rmse: 0.4518  |  0:00:44s
epoch 72 | loss: 0.11211 | val_0_rmse: 0.36912 | val_1_rmse: 0.44935 |  0:00:45s
epoch 73 | loss: 0.11691 | val_0_rmse: 0.363   | val_1_rmse: 0.44912 |  0:00:46s
epoch 74 | loss: 0.12364 | val_0_rmse: 0.36277 | val_1_rmse: 0.43618 |  0:00:46s
epoch 75 | loss: 0.11563 | val_0_rmse: 0.35538 | val_1_rmse: 0.43733 |  0:00:47s
epoch 76 | loss: 0.11626 | val_0_rmse: 0.344   | val_1_rmse: 0.43426 |  0:00:47s
epoch 77 | loss: 0.1094  | val_0_rmse: 0.35449 | val_1_rmse: 0.44052 |  0:00:48s
epoch 78 | loss: 0.10996 | val_0_rmse: 0.33297 | val_1_rmse: 0.42726 |  0:00:49s
epoch 79 | loss: 0.10825 | val_0_rmse: 0.34099 | val_1_rmse: 0.43339 |  0:00:49s
epoch 80 | loss: 0.10922 | val_0_rmse: 0.32489 | val_1_rmse: 0.42784 |  0:00:50s
epoch 81 | loss: 0.10722 | val_0_rmse: 0.32362 | val_1_rmse: 0.42499 |  0:00:51s
epoch 82 | loss: 0.11232 | val_0_rmse: 0.32884 | val_1_rmse: 0.42699 |  0:00:51s
epoch 83 | loss: 0.10875 | val_0_rmse: 0.31682 | val_1_rmse: 0.42282 |  0:00:52s
epoch 84 | loss: 0.10996 | val_0_rmse: 0.31474 | val_1_rmse: 0.40631 |  0:00:52s
epoch 85 | loss: 0.10583 | val_0_rmse: 0.29921 | val_1_rmse: 0.40131 |  0:00:53s
epoch 86 | loss: 0.10382 | val_0_rmse: 0.29862 | val_1_rmse: 0.41028 |  0:00:54s
epoch 87 | loss: 0.10006 | val_0_rmse: 0.30522 | val_1_rmse: 0.40395 |  0:00:54s
epoch 88 | loss: 0.09747 | val_0_rmse: 0.29702 | val_1_rmse: 0.40004 |  0:00:55s
epoch 89 | loss: 0.10162 | val_0_rmse: 0.29124 | val_1_rmse: 0.4046  |  0:00:55s
epoch 90 | loss: 0.09745 | val_0_rmse: 0.28631 | val_1_rmse: 0.40815 |  0:00:56s
epoch 91 | loss: 0.09917 | val_0_rmse: 0.28339 | val_1_rmse: 0.40346 |  0:00:57s
epoch 92 | loss: 0.10091 | val_0_rmse: 0.30704 | val_1_rmse: 0.41825 |  0:00:57s
epoch 93 | loss: 0.0963  | val_0_rmse: 0.2859  | val_1_rmse: 0.41288 |  0:00:58s
epoch 94 | loss: 0.09719 | val_0_rmse: 0.2709  | val_1_rmse: 0.40138 |  0:00:59s
epoch 95 | loss: 0.09608 | val_0_rmse: 0.29105 | val_1_rmse: 0.40492 |  0:00:59s
epoch 96 | loss: 0.09709 | val_0_rmse: 0.28021 | val_1_rmse: 0.4043  |  0:01:00s
epoch 97 | loss: 0.09948 | val_0_rmse: 0.27273 | val_1_rmse: 0.39108 |  0:01:00s
epoch 98 | loss: 0.09462 | val_0_rmse: 0.27301 | val_1_rmse: 0.38949 |  0:01:01s
epoch 99 | loss: 0.08979 | val_0_rmse: 0.27022 | val_1_rmse: 0.38699 |  0:01:02s
epoch 100| loss: 0.09455 | val_0_rmse: 0.27043 | val_1_rmse: 0.38941 |  0:01:02s
epoch 101| loss: 0.09277 | val_0_rmse: 0.27511 | val_1_rmse: 0.39517 |  0:01:03s
epoch 102| loss: 0.09126 | val_0_rmse: 0.26095 | val_1_rmse: 0.39098 |  0:01:04s
epoch 103| loss: 0.09793 | val_0_rmse: 0.26423 | val_1_rmse: 0.38931 |  0:01:04s
epoch 104| loss: 0.08722 | val_0_rmse: 0.25984 | val_1_rmse: 0.39282 |  0:01:05s
epoch 105| loss: 0.09423 | val_0_rmse: 0.25661 | val_1_rmse: 0.39939 |  0:01:05s
epoch 106| loss: 0.08825 | val_0_rmse: 0.25338 | val_1_rmse: 0.38642 |  0:01:06s
epoch 107| loss: 0.08122 | val_0_rmse: 0.25748 | val_1_rmse: 0.38743 |  0:01:07s
epoch 108| loss: 0.08679 | val_0_rmse: 0.25102 | val_1_rmse: 0.39228 |  0:01:07s
epoch 109| loss: 0.08353 | val_0_rmse: 0.26667 | val_1_rmse: 0.40816 |  0:01:08s
epoch 110| loss: 0.0913  | val_0_rmse: 0.25035 | val_1_rmse: 0.38471 |  0:01:09s
epoch 111| loss: 0.0834  | val_0_rmse: 0.24332 | val_1_rmse: 0.38089 |  0:01:09s
epoch 112| loss: 0.0802  | val_0_rmse: 0.24811 | val_1_rmse: 0.38227 |  0:01:10s
epoch 113| loss: 0.0781  | val_0_rmse: 0.24426 | val_1_rmse: 0.38847 |  0:01:10s
epoch 114| loss: 0.08321 | val_0_rmse: 0.24576 | val_1_rmse: 0.37592 |  0:01:11s
epoch 115| loss: 0.08064 | val_0_rmse: 0.24886 | val_1_rmse: 0.37882 |  0:01:12s
epoch 116| loss: 0.07832 | val_0_rmse: 0.2385  | val_1_rmse: 0.37136 |  0:01:12s
epoch 117| loss: 0.07797 | val_0_rmse: 0.25262 | val_1_rmse: 0.39643 |  0:01:13s
epoch 118| loss: 0.08035 | val_0_rmse: 0.23766 | val_1_rmse: 0.38795 |  0:01:14s
epoch 119| loss: 0.08458 | val_0_rmse: 0.27654 | val_1_rmse: 0.40065 |  0:01:14s
epoch 120| loss: 0.10882 | val_0_rmse: 0.29138 | val_1_rmse: 0.41331 |  0:01:15s
epoch 121| loss: 0.11136 | val_0_rmse: 0.29533 | val_1_rmse: 0.41357 |  0:01:15s
epoch 122| loss: 0.10868 | val_0_rmse: 0.2941  | val_1_rmse: 0.43505 |  0:01:16s
epoch 123| loss: 0.10203 | val_0_rmse: 0.28112 | val_1_rmse: 0.4079  |  0:01:17s
epoch 124| loss: 0.09948 | val_0_rmse: 0.26632 | val_1_rmse: 0.40523 |  0:01:17s
epoch 125| loss: 0.08988 | val_0_rmse: 0.25543 | val_1_rmse: 0.38542 |  0:01:18s
epoch 126| loss: 0.0862  | val_0_rmse: 0.25454 | val_1_rmse: 0.38865 |  0:01:18s
epoch 127| loss: 0.08234 | val_0_rmse: 0.25158 | val_1_rmse: 0.38123 |  0:01:19s
epoch 128| loss: 0.08487 | val_0_rmse: 0.2538  | val_1_rmse: 0.37978 |  0:01:20s
epoch 129| loss: 0.08214 | val_0_rmse: 0.24932 | val_1_rmse: 0.381   |  0:01:20s
epoch 130| loss: 0.08315 | val_0_rmse: 0.24507 | val_1_rmse: 0.37847 |  0:01:21s
epoch 131| loss: 0.08041 | val_0_rmse: 0.24399 | val_1_rmse: 0.39124 |  0:01:22s
epoch 132| loss: 0.08703 | val_0_rmse: 0.25439 | val_1_rmse: 0.38396 |  0:01:22s
epoch 133| loss: 0.08877 | val_0_rmse: 0.24291 | val_1_rmse: 0.38704 |  0:01:23s
epoch 134| loss: 0.08349 | val_0_rmse: 0.24582 | val_1_rmse: 0.39178 |  0:01:23s
epoch 135| loss: 0.07924 | val_0_rmse: 0.23944 | val_1_rmse: 0.37321 |  0:01:24s
epoch 136| loss: 0.07648 | val_0_rmse: 0.23613 | val_1_rmse: 0.37807 |  0:01:25s
epoch 137| loss: 0.0724  | val_0_rmse: 0.22725 | val_1_rmse: 0.36465 |  0:01:25s
epoch 138| loss: 0.07058 | val_0_rmse: 0.22758 | val_1_rmse: 0.36091 |  0:01:26s
epoch 139| loss: 0.06637 | val_0_rmse: 0.22661 | val_1_rmse: 0.36533 |  0:01:26s
epoch 140| loss: 0.07016 | val_0_rmse: 0.23072 | val_1_rmse: 0.36666 |  0:01:27s
epoch 141| loss: 0.07814 | val_0_rmse: 0.23288 | val_1_rmse: 0.3697  |  0:01:28s
epoch 142| loss: 0.07003 | val_0_rmse: 0.22702 | val_1_rmse: 0.36827 |  0:01:28s
epoch 143| loss: 0.06633 | val_0_rmse: 0.2283  | val_1_rmse: 0.37037 |  0:01:29s
epoch 144| loss: 0.07236 | val_0_rmse: 0.24438 | val_1_rmse: 0.3843  |  0:01:30s
epoch 145| loss: 0.07728 | val_0_rmse: 0.2387  | val_1_rmse: 0.3786  |  0:01:30s
epoch 146| loss: 0.07441 | val_0_rmse: 0.24348 | val_1_rmse: 0.38267 |  0:01:31s
epoch 147| loss: 0.07137 | val_0_rmse: 0.23598 | val_1_rmse: 0.36583 |  0:01:31s
epoch 148| loss: 0.06948 | val_0_rmse: 0.23261 | val_1_rmse: 0.36624 |  0:01:32s
epoch 149| loss: 0.07046 | val_0_rmse: 0.23741 | val_1_rmse: 0.37789 |  0:01:33s
Stop training because you reached max_epochs = 150 with best_epoch = 138 and best_val_1_rmse = 0.36091
Best weights from best epoch are automatically used!
ended training at: 16:00:24
Feature importance:
Mean squared error is of 2854280641.479895
Mean absolute error:31778.319993409637
MAPE:0.2677830380570384
R2 score:0.847386269163005
------------------------------------------------------------------
