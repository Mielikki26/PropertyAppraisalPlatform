TabNet Logs:

Saving copy of script...
In this script only the South American datasets are used and they have seven new features - Country, Province, City, TotalArea, Rooms, PropertyType, OperationType.This is done to test the possibility that the number of features being used is too low and adding more is helpful
Normalization used is StandardScaler
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 0
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 05:11:29
epoch 0  | loss: 0.73581 | val_0_rmse: 0.70196 | val_1_rmse: 0.69436 |  0:00:15s
epoch 1  | loss: 0.36567 | val_0_rmse: 0.63028 | val_1_rmse: 0.6232  |  0:00:25s
epoch 2  | loss: 0.33138 | val_0_rmse: 0.60417 | val_1_rmse: 0.59643 |  0:00:36s
epoch 3  | loss: 0.31706 | val_0_rmse: 0.58019 | val_1_rmse: 0.57687 |  0:00:48s
epoch 4  | loss: 0.30031 | val_0_rmse: 0.55857 | val_1_rmse: 0.56044 |  0:01:00s
epoch 5  | loss: 0.29728 | val_0_rmse: 0.53561 | val_1_rmse: 0.53692 |  0:01:12s
epoch 6  | loss: 0.28956 | val_0_rmse: 0.52571 | val_1_rmse: 0.53142 |  0:01:25s
epoch 7  | loss: 0.28405 | val_0_rmse: 0.52643 | val_1_rmse: 0.53127 |  0:01:36s
epoch 8  | loss: 0.28045 | val_0_rmse: 0.51289 | val_1_rmse: 0.52223 |  0:01:47s
epoch 9  | loss: 0.2799  | val_0_rmse: 0.51349 | val_1_rmse: 0.52472 |  0:01:58s
epoch 10 | loss: 0.27571 | val_0_rmse: 0.51052 | val_1_rmse: 0.52327 |  0:02:09s
epoch 11 | loss: 0.27061 | val_0_rmse: 0.50982 | val_1_rmse: 0.52654 |  0:02:20s
epoch 12 | loss: 0.27174 | val_0_rmse: 0.52113 | val_1_rmse: 0.53084 |  0:02:31s
epoch 13 | loss: 0.26979 | val_0_rmse: 0.52138 | val_1_rmse: 0.53031 |  0:02:42s
epoch 14 | loss: 0.27185 | val_0_rmse: 0.53913 | val_1_rmse: 0.55135 |  0:02:52s
epoch 15 | loss: 0.26839 | val_0_rmse: 0.52344 | val_1_rmse: 0.55253 |  0:03:03s
epoch 16 | loss: 0.26591 | val_0_rmse: 0.5102  | val_1_rmse: 0.52127 |  0:03:14s
epoch 17 | loss: 0.26228 | val_0_rmse: 0.5223  | val_1_rmse: 0.5608  |  0:03:25s
epoch 18 | loss: 0.26262 | val_0_rmse: 0.5064  | val_1_rmse: 0.51616 |  0:03:36s
epoch 19 | loss: 0.26303 | val_0_rmse: 0.5047  | val_1_rmse: 0.52338 |  0:03:47s
epoch 20 | loss: 0.25932 | val_0_rmse: 0.50462 | val_1_rmse: 0.53966 |  0:03:58s
epoch 21 | loss: 0.25798 | val_0_rmse: 0.5062  | val_1_rmse: 0.52393 |  0:04:09s
epoch 22 | loss: 0.25866 | val_0_rmse: 0.49578 | val_1_rmse: 0.51525 |  0:04:20s
epoch 23 | loss: 0.25821 | val_0_rmse: 0.50413 | val_1_rmse: 0.52636 |  0:04:31s
epoch 24 | loss: 0.2595  | val_0_rmse: 0.51085 | val_1_rmse: 0.64248 |  0:04:41s
epoch 25 | loss: 0.2559  | val_0_rmse: 0.49599 | val_1_rmse: 0.52059 |  0:04:52s
epoch 26 | loss: 0.25645 | val_0_rmse: 0.50554 | val_1_rmse: 0.52629 |  0:05:03s
epoch 27 | loss: 0.2563  | val_0_rmse: 0.51723 | val_1_rmse: 0.56167 |  0:05:14s
epoch 28 | loss: 0.25456 | val_0_rmse: 0.4922  | val_1_rmse: 0.51968 |  0:05:25s
epoch 29 | loss: 0.25085 | val_0_rmse: 0.48817 | val_1_rmse: 0.51733 |  0:05:36s
epoch 30 | loss: 0.2522  | val_0_rmse: 0.48882 | val_1_rmse: 1.66544 |  0:05:47s
epoch 31 | loss: 0.25075 | val_0_rmse: 0.4977  | val_1_rmse: 1.4518  |  0:05:58s
epoch 32 | loss: 0.24912 | val_0_rmse: 0.48923 | val_1_rmse: 0.52046 |  0:06:08s
epoch 33 | loss: 0.25011 | val_0_rmse: 0.48975 | val_1_rmse: 0.51889 |  0:06:19s
epoch 34 | loss: 0.25031 | val_0_rmse: 0.48603 | val_1_rmse: 0.51726 |  0:06:30s
epoch 35 | loss: 0.24801 | val_0_rmse: 0.49024 | val_1_rmse: 0.7029  |  0:06:41s
epoch 36 | loss: 0.24767 | val_0_rmse: 0.48757 | val_1_rmse: 0.99496 |  0:06:52s
epoch 37 | loss: 0.24619 | val_0_rmse: 0.48788 | val_1_rmse: 0.51894 |  0:07:03s
epoch 38 | loss: 0.24609 | val_0_rmse: 0.4967  | val_1_rmse: 0.53081 |  0:07:14s
epoch 39 | loss: 0.24807 | val_0_rmse: 0.49189 | val_1_rmse: 0.52253 |  0:07:25s
epoch 40 | loss: 0.2444  | val_0_rmse: 0.48589 | val_1_rmse: 0.51659 |  0:07:36s
epoch 41 | loss: 0.24498 | val_0_rmse: 0.4827  | val_1_rmse: 1.85309 |  0:07:47s
epoch 42 | loss: 0.244   | val_0_rmse: 0.48236 | val_1_rmse: 0.51707 |  0:07:57s
epoch 43 | loss: 0.24614 | val_0_rmse: 0.48538 | val_1_rmse: 0.51631 |  0:08:08s
epoch 44 | loss: 0.24258 | val_0_rmse: 0.48742 | val_1_rmse: 1.6757  |  0:08:19s
epoch 45 | loss: 0.24115 | val_0_rmse: 0.48941 | val_1_rmse: 0.52629 |  0:08:30s
epoch 46 | loss: 0.24181 | val_0_rmse: 0.48814 | val_1_rmse: 0.52215 |  0:08:41s
epoch 47 | loss: 0.24051 | val_0_rmse: 0.48768 | val_1_rmse: 0.55103 |  0:08:51s
epoch 48 | loss: 0.24382 | val_0_rmse: 0.48469 | val_1_rmse: 0.61276 |  0:09:02s
epoch 49 | loss: 0.2406  | val_0_rmse: 0.48059 | val_1_rmse: 0.55598 |  0:09:13s
epoch 50 | loss: 0.24    | val_0_rmse: 0.48717 | val_1_rmse: 0.5977  |  0:09:24s
epoch 51 | loss: 0.24    | val_0_rmse: 0.48864 | val_1_rmse: 0.53342 |  0:09:34s
epoch 52 | loss: 0.23732 | val_0_rmse: 0.48599 | val_1_rmse: 0.52714 |  0:09:45s

Early stopping occured at epoch 52 with best_epoch = 22 and best_val_1_rmse = 0.51525
Best weights from best epoch are automatically used!
ended training at: 05:21:20
Feature importance:
Mean squared error is of 1808857821.194276
Mean absolute error:30452.788730813114
MAPE:0.2874845103158654
R2 score:0.7344034657113286
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 1
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 05:21:23
epoch 0  | loss: 0.78665 | val_0_rmse: 0.90009 | val_1_rmse: 0.90595 |  0:00:10s
epoch 1  | loss: 0.36688 | val_0_rmse: 0.65922 | val_1_rmse: 0.66037 |  0:00:21s
epoch 2  | loss: 0.32019 | val_0_rmse: 0.61838 | val_1_rmse: 0.6191  |  0:00:32s
epoch 3  | loss: 0.30717 | val_0_rmse: 0.5751  | val_1_rmse: 0.58147 |  0:00:43s
epoch 4  | loss: 0.29607 | val_0_rmse: 0.56202 | val_1_rmse: 0.56539 |  0:00:54s
epoch 5  | loss: 0.29144 | val_0_rmse: 0.53034 | val_1_rmse: 0.53786 |  0:01:05s
epoch 6  | loss: 0.28377 | val_0_rmse: 0.524   | val_1_rmse: 0.53321 |  0:01:16s
epoch 7  | loss: 0.28052 | val_0_rmse: 0.5125  | val_1_rmse: 0.52454 |  0:01:27s
epoch 8  | loss: 0.27962 | val_0_rmse: 0.51188 | val_1_rmse: 0.52462 |  0:01:38s
epoch 9  | loss: 0.27533 | val_0_rmse: 0.51613 | val_1_rmse: 0.5339  |  0:01:49s
epoch 10 | loss: 0.27055 | val_0_rmse: 0.50855 | val_1_rmse: 0.52457 |  0:01:59s
epoch 11 | loss: 0.26958 | val_0_rmse: 0.50931 | val_1_rmse: 0.52349 |  0:02:10s
epoch 12 | loss: 0.26782 | val_0_rmse: 0.50318 | val_1_rmse: 0.52348 |  0:02:21s
epoch 13 | loss: 0.2672  | val_0_rmse: 0.50166 | val_1_rmse: 0.51726 |  0:02:32s
epoch 14 | loss: 0.26482 | val_0_rmse: 0.50688 | val_1_rmse: 0.52938 |  0:02:43s
epoch 15 | loss: 0.26464 | val_0_rmse: 0.50615 | val_1_rmse: 0.52158 |  0:02:54s
epoch 16 | loss: 0.261   | val_0_rmse: 0.50506 | val_1_rmse: 0.5281  |  0:03:05s
epoch 17 | loss: 0.26074 | val_0_rmse: 0.50707 | val_1_rmse: 0.52663 |  0:03:15s
epoch 18 | loss: 0.26234 | val_0_rmse: 0.49382 | val_1_rmse: 0.51728 |  0:03:26s
epoch 19 | loss: 0.25935 | val_0_rmse: 0.50038 | val_1_rmse: 0.52437 |  0:03:37s
epoch 20 | loss: 0.26008 | val_0_rmse: 0.49548 | val_1_rmse: 0.51727 |  0:03:48s
epoch 21 | loss: 0.2586  | val_0_rmse: 0.50239 | val_1_rmse: 0.52771 |  0:03:59s
epoch 22 | loss: 0.25899 | val_0_rmse: 0.50904 | val_1_rmse: 0.53361 |  0:04:10s
epoch 23 | loss: 0.25807 | val_0_rmse: 0.49545 | val_1_rmse: 0.51882 |  0:04:21s
epoch 24 | loss: 0.25639 | val_0_rmse: 0.5072  | val_1_rmse: 0.53247 |  0:04:32s
epoch 25 | loss: 0.25706 | val_0_rmse: 0.50408 | val_1_rmse: 0.52704 |  0:04:43s
epoch 26 | loss: 0.25843 | val_0_rmse: 0.51277 | val_1_rmse: 0.53258 |  0:04:54s
epoch 27 | loss: 0.25318 | val_0_rmse: 0.49393 | val_1_rmse: 0.5211  |  0:05:05s
epoch 28 | loss: 0.25534 | val_0_rmse: 0.49596 | val_1_rmse: 0.53087 |  0:05:15s
epoch 29 | loss: 0.25523 | val_0_rmse: 0.49157 | val_1_rmse: 0.51923 |  0:05:26s
epoch 30 | loss: 0.25172 | val_0_rmse: 0.48993 | val_1_rmse: 0.51973 |  0:05:37s
epoch 31 | loss: 0.2538  | val_0_rmse: 0.49097 | val_1_rmse: 0.52059 |  0:05:48s
epoch 32 | loss: 0.25165 | val_0_rmse: 0.49261 | val_1_rmse: 0.51824 |  0:05:59s
epoch 33 | loss: 0.25187 | val_0_rmse: 0.49245 | val_1_rmse: 0.51911 |  0:06:10s
epoch 34 | loss: 0.25067 | val_0_rmse: 0.50055 | val_1_rmse: 0.52767 |  0:06:20s
epoch 35 | loss: 0.24992 | val_0_rmse: 0.49672 | val_1_rmse: 0.52138 |  0:06:31s
epoch 36 | loss: 0.26071 | val_0_rmse: 0.49665 | val_1_rmse: 0.52779 |  0:06:42s
epoch 37 | loss: 0.25995 | val_0_rmse: 0.50406 | val_1_rmse: 0.53142 |  0:06:53s
epoch 38 | loss: 0.25682 | val_0_rmse: 0.49338 | val_1_rmse: 0.51886 |  0:07:04s
epoch 39 | loss: 0.25425 | val_0_rmse: 0.50294 | val_1_rmse: 0.52836 |  0:07:15s
epoch 40 | loss: 0.26188 | val_0_rmse: 0.50247 | val_1_rmse: 0.52866 |  0:07:26s
epoch 41 | loss: 0.25568 | val_0_rmse: 0.49513 | val_1_rmse: 0.51968 |  0:07:37s
epoch 42 | loss: 0.25119 | val_0_rmse: 0.48636 | val_1_rmse: 0.51704 |  0:07:48s
epoch 43 | loss: 0.24856 | val_0_rmse: 0.4906  | val_1_rmse: 0.52508 |  0:07:59s
epoch 44 | loss: 0.24549 | val_0_rmse: 0.48643 | val_1_rmse: 0.5184  |  0:08:09s
epoch 45 | loss: 0.24534 | val_0_rmse: 0.4854  | val_1_rmse: 0.51829 |  0:08:20s
epoch 46 | loss: 0.24277 | val_0_rmse: 0.48308 | val_1_rmse: 0.5175  |  0:08:31s
epoch 47 | loss: 0.24201 | val_0_rmse: 0.48811 | val_1_rmse: 0.52295 |  0:08:42s
epoch 48 | loss: 0.2433  | val_0_rmse: 0.48426 | val_1_rmse: 0.51738 |  0:08:53s
epoch 49 | loss: 0.24137 | val_0_rmse: 0.48387 | val_1_rmse: 0.51974 |  0:09:04s
epoch 50 | loss: 0.24255 | val_0_rmse: 0.48563 | val_1_rmse: 0.5261  |  0:09:15s
epoch 51 | loss: 0.24185 | val_0_rmse: 0.48042 | val_1_rmse: 0.51827 |  0:09:26s
epoch 52 | loss: 0.24035 | val_0_rmse: 0.48413 | val_1_rmse: 0.52318 |  0:09:37s
epoch 53 | loss: 0.23984 | val_0_rmse: 0.48377 | val_1_rmse: 0.52704 |  0:09:48s
epoch 54 | loss: 0.24045 | val_0_rmse: 0.47856 | val_1_rmse: 0.52054 |  0:09:59s
epoch 55 | loss: 0.24058 | val_0_rmse: 0.48368 | val_1_rmse: 0.51678 |  0:10:09s
epoch 56 | loss: 0.23889 | val_0_rmse: 0.47998 | val_1_rmse: 0.51721 |  0:10:20s
epoch 57 | loss: 0.23787 | val_0_rmse: 0.4813  | val_1_rmse: 0.52619 |  0:10:31s
epoch 58 | loss: 0.23756 | val_0_rmse: 0.48796 | val_1_rmse: 0.52697 |  0:10:42s
epoch 59 | loss: 0.24054 | val_0_rmse: 0.47893 | val_1_rmse: 0.52894 |  0:10:53s
epoch 60 | loss: 0.23651 | val_0_rmse: 0.49134 | val_1_rmse: 0.53049 |  0:11:04s
epoch 61 | loss: 0.23978 | val_0_rmse: 0.48854 | val_1_rmse: 0.5372  |  0:11:15s
epoch 62 | loss: 0.23697 | val_0_rmse: 0.47554 | val_1_rmse: 0.51906 |  0:11:26s
epoch 63 | loss: 0.23517 | val_0_rmse: 0.49993 | val_1_rmse: 0.54399 |  0:11:37s
epoch 64 | loss: 0.23525 | val_0_rmse: 0.4807  | val_1_rmse: 0.51961 |  0:11:48s
epoch 65 | loss: 0.23453 | val_0_rmse: 0.48634 | val_1_rmse: 0.53312 |  0:11:59s
epoch 66 | loss: 0.23593 | val_0_rmse: 0.48346 | val_1_rmse: 0.52716 |  0:12:10s
epoch 67 | loss: 0.23543 | val_0_rmse: 0.48686 | val_1_rmse: 0.52639 |  0:12:22s
epoch 68 | loss: 0.23296 | val_0_rmse: 0.47584 | val_1_rmse: 0.51907 |  0:12:33s
epoch 69 | loss: 0.23437 | val_0_rmse: 0.48249 | val_1_rmse: 0.52225 |  0:12:44s
epoch 70 | loss: 0.23887 | val_0_rmse: 0.47893 | val_1_rmse: 0.51919 |  0:12:55s
epoch 71 | loss: 0.23291 | val_0_rmse: 0.47107 | val_1_rmse: 0.52126 |  0:13:06s
epoch 72 | loss: 0.23395 | val_0_rmse: 0.4802  | val_1_rmse: 0.52376 |  0:13:17s
epoch 73 | loss: 0.23716 | val_0_rmse: 0.47919 | val_1_rmse: 0.5198  |  0:13:28s
epoch 74 | loss: 0.23048 | val_0_rmse: 0.47794 | val_1_rmse: 0.51975 |  0:13:38s
epoch 75 | loss: 0.23287 | val_0_rmse: 0.47242 | val_1_rmse: 0.51903 |  0:13:49s
epoch 76 | loss: 0.23122 | val_0_rmse: 0.47199 | val_1_rmse: 0.51996 |  0:14:00s
epoch 77 | loss: 0.23167 | val_0_rmse: 0.47028 | val_1_rmse: 0.51731 |  0:14:11s
epoch 78 | loss: 0.23181 | val_0_rmse: 0.46938 | val_1_rmse: 0.51897 |  0:14:22s
epoch 79 | loss: 0.23264 | val_0_rmse: 0.47213 | val_1_rmse: 0.52172 |  0:14:33s
epoch 80 | loss: 0.23101 | val_0_rmse: 0.47629 | val_1_rmse: 0.53329 |  0:14:44s
epoch 81 | loss: 0.23173 | val_0_rmse: 0.47169 | val_1_rmse: 0.51755 |  0:14:55s
epoch 82 | loss: 0.23069 | val_0_rmse: 0.47145 | val_1_rmse: 0.52128 |  0:15:06s
epoch 83 | loss: 0.23045 | val_0_rmse: 0.46944 | val_1_rmse: 0.52413 |  0:15:17s
epoch 84 | loss: 0.22944 | val_0_rmse: 0.47652 | val_1_rmse: 0.52669 |  0:15:28s
epoch 85 | loss: 0.22877 | val_0_rmse: 0.47004 | val_1_rmse: 0.51921 |  0:15:41s

Early stopping occured at epoch 85 with best_epoch = 55 and best_val_1_rmse = 0.51678
Best weights from best epoch are automatically used!
ended training at: 05:37:09
Feature importance:
Mean squared error is of 1820339041.8228242
Mean absolute error:31166.780100886517
MAPE:0.3048575594514382
R2 score:0.7330668771286644
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 2
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 05:37:10
epoch 0  | loss: 0.70898 | val_0_rmse: 0.70016 | val_1_rmse: 0.70874 |  0:00:10s
epoch 1  | loss: 0.35624 | val_0_rmse: 0.64721 | val_1_rmse: 0.65647 |  0:00:21s
epoch 2  | loss: 0.32225 | val_0_rmse: 0.59843 | val_1_rmse: 0.60685 |  0:00:32s
epoch 3  | loss: 0.31501 | val_0_rmse: 0.57018 | val_1_rmse: 0.57619 |  0:00:43s
epoch 4  | loss: 0.30231 | val_0_rmse: 0.54411 | val_1_rmse: 0.55275 |  0:00:54s
epoch 5  | loss: 0.29228 | val_0_rmse: 0.53618 | val_1_rmse: 0.54518 |  0:01:05s
epoch 6  | loss: 0.28842 | val_0_rmse: 0.53963 | val_1_rmse: 0.55338 |  0:01:16s
epoch 7  | loss: 0.28755 | val_0_rmse: 0.51944 | val_1_rmse: 0.53264 |  0:01:27s
epoch 8  | loss: 0.28517 | val_0_rmse: 0.52232 | val_1_rmse: 0.5353  |  0:01:38s
epoch 9  | loss: 0.28444 | val_0_rmse: 0.5132  | val_1_rmse: 0.52794 |  0:01:49s
epoch 10 | loss: 0.27834 | val_0_rmse: 0.52941 | val_1_rmse: 0.54515 |  0:01:59s
epoch 11 | loss: 0.27546 | val_0_rmse: 0.51147 | val_1_rmse: 0.52779 |  0:02:10s
epoch 12 | loss: 0.27908 | val_0_rmse: 0.52485 | val_1_rmse: 0.53858 |  0:02:21s
epoch 13 | loss: 0.27532 | val_0_rmse: 0.51195 | val_1_rmse: 0.52647 |  0:02:32s
epoch 14 | loss: 0.27703 | val_0_rmse: 0.54049 | val_1_rmse: 0.56989 |  0:02:43s
epoch 15 | loss: 0.27791 | val_0_rmse: 0.56199 | val_1_rmse: 0.58709 |  0:02:54s
epoch 16 | loss: 0.28083 | val_0_rmse: 0.51301 | val_1_rmse: 0.53077 |  0:03:05s
epoch 17 | loss: 0.27264 | val_0_rmse: 0.52507 | val_1_rmse: 0.54143 |  0:03:16s
epoch 18 | loss: 0.26917 | val_0_rmse: 0.53898 | val_1_rmse: 0.54757 |  0:03:27s
epoch 19 | loss: 0.27463 | val_0_rmse: 0.63961 | val_1_rmse: 0.6981  |  0:03:38s
epoch 20 | loss: 0.27013 | val_0_rmse: 0.72545 | val_1_rmse: 0.83822 |  0:03:49s
epoch 21 | loss: 0.27188 | val_0_rmse: 0.51357 | val_1_rmse: 0.53061 |  0:04:00s
epoch 22 | loss: 0.27396 | val_0_rmse: 0.52366 | val_1_rmse: 0.54076 |  0:04:11s
epoch 23 | loss: 0.26933 | val_0_rmse: 0.52501 | val_1_rmse: 0.53804 |  0:04:22s
epoch 24 | loss: 0.26837 | val_0_rmse: 0.51659 | val_1_rmse: 0.53081 |  0:04:32s
epoch 25 | loss: 0.27046 | val_0_rmse: 0.53246 | val_1_rmse: 0.55023 |  0:04:43s
epoch 26 | loss: 0.26387 | val_0_rmse: 0.51268 | val_1_rmse: 0.5297  |  0:04:54s
epoch 27 | loss: 0.27522 | val_0_rmse: 0.52268 | val_1_rmse: 0.5424  |  0:05:05s
epoch 28 | loss: 0.26842 | val_0_rmse: 0.50831 | val_1_rmse: 0.52742 |  0:05:16s
epoch 29 | loss: 0.2645  | val_0_rmse: 0.51871 | val_1_rmse: 0.53666 |  0:05:27s
epoch 30 | loss: 0.26343 | val_0_rmse: 0.53232 | val_1_rmse: 0.55    |  0:05:38s
epoch 31 | loss: 0.26304 | val_0_rmse: 0.51648 | val_1_rmse: 0.53787 |  0:05:49s
epoch 32 | loss: 0.26054 | val_0_rmse: 0.50474 | val_1_rmse: 0.52514 |  0:06:00s
epoch 33 | loss: 0.26103 | val_0_rmse: 0.52477 | val_1_rmse: 0.54121 |  0:06:11s
epoch 34 | loss: 0.26563 | val_0_rmse: 0.51346 | val_1_rmse: 0.53276 |  0:06:21s
epoch 35 | loss: 0.26482 | val_0_rmse: 0.51989 | val_1_rmse: 0.53599 |  0:06:32s
epoch 36 | loss: 0.26396 | val_0_rmse: 0.50144 | val_1_rmse: 0.52245 |  0:06:43s
epoch 37 | loss: 0.25968 | val_0_rmse: 0.51047 | val_1_rmse: 0.53086 |  0:06:54s
epoch 38 | loss: 0.25777 | val_0_rmse: 0.50347 | val_1_rmse: 0.52237 |  0:07:05s
epoch 39 | loss: 0.25879 | val_0_rmse: 0.49665 | val_1_rmse: 0.51715 |  0:07:16s
epoch 40 | loss: 0.25504 | val_0_rmse: 0.50198 | val_1_rmse: 0.52318 |  0:07:26s
epoch 41 | loss: 0.25714 | val_0_rmse: 0.49671 | val_1_rmse: 0.5167  |  0:07:37s
epoch 42 | loss: 0.25504 | val_0_rmse: 0.48975 | val_1_rmse: 0.51505 |  0:07:48s
epoch 43 | loss: 0.25197 | val_0_rmse: 0.48903 | val_1_rmse: 0.51319 |  0:07:59s
epoch 44 | loss: 0.24932 | val_0_rmse: 0.49129 | val_1_rmse: 0.5155  |  0:08:10s
epoch 45 | loss: 0.24891 | val_0_rmse: 0.4977  | val_1_rmse: 0.52412 |  0:08:21s
epoch 46 | loss: 0.24653 | val_0_rmse: 0.52739 | val_1_rmse: 0.54848 |  0:08:32s
epoch 47 | loss: 0.24652 | val_0_rmse: 0.48915 | val_1_rmse: 0.51771 |  0:08:43s
epoch 48 | loss: 0.24548 | val_0_rmse: 0.49622 | val_1_rmse: 0.52424 |  0:08:53s
epoch 49 | loss: 0.24563 | val_0_rmse: 0.499   | val_1_rmse: 0.52877 |  0:09:04s
epoch 50 | loss: 0.24587 | val_0_rmse: 0.49336 | val_1_rmse: 0.52056 |  0:09:15s
epoch 51 | loss: 0.24447 | val_0_rmse: 0.48867 | val_1_rmse: 0.51833 |  0:09:26s
epoch 52 | loss: 0.24542 | val_0_rmse: 0.48461 | val_1_rmse: 0.51408 |  0:09:37s
epoch 53 | loss: 0.24401 | val_0_rmse: 0.48777 | val_1_rmse: 0.51932 |  0:09:48s
epoch 54 | loss: 0.24598 | val_0_rmse: 0.48492 | val_1_rmse: 0.51768 |  0:09:59s
epoch 55 | loss: 0.24378 | val_0_rmse: 0.49243 | val_1_rmse: 0.52153 |  0:10:10s
epoch 56 | loss: 0.24206 | val_0_rmse: 0.49411 | val_1_rmse: 0.52688 |  0:10:20s
epoch 57 | loss: 0.24022 | val_0_rmse: 0.49001 | val_1_rmse: 0.52131 |  0:10:31s
epoch 58 | loss: 0.24052 | val_0_rmse: 0.49176 | val_1_rmse: 0.52416 |  0:10:42s
epoch 59 | loss: 0.24052 | val_0_rmse: 0.49153 | val_1_rmse: 0.52603 |  0:10:53s
epoch 60 | loss: 0.241   | val_0_rmse: 0.47581 | val_1_rmse: 0.51192 |  0:11:04s
epoch 61 | loss: 0.23871 | val_0_rmse: 0.48687 | val_1_rmse: 0.52396 |  0:11:15s
epoch 62 | loss: 0.23667 | val_0_rmse: 0.47925 | val_1_rmse: 0.51341 |  0:11:26s
epoch 63 | loss: 0.24006 | val_0_rmse: 0.48    | val_1_rmse: 0.51673 |  0:11:37s
epoch 64 | loss: 0.23752 | val_0_rmse: 0.48213 | val_1_rmse: 0.5176  |  0:11:47s
epoch 65 | loss: 0.23591 | val_0_rmse: 0.47907 | val_1_rmse: 0.51645 |  0:11:58s
epoch 66 | loss: 0.23713 | val_0_rmse: 0.47953 | val_1_rmse: 0.51748 |  0:12:09s
epoch 67 | loss: 0.2363  | val_0_rmse: 0.49549 | val_1_rmse: 0.54652 |  0:12:20s
epoch 68 | loss: 0.23521 | val_0_rmse: 0.47788 | val_1_rmse: 0.51476 |  0:12:31s
epoch 69 | loss: 0.23496 | val_0_rmse: 0.47666 | val_1_rmse: 0.51682 |  0:12:42s
epoch 70 | loss: 0.23543 | val_0_rmse: 0.48539 | val_1_rmse: 0.52469 |  0:12:53s
epoch 71 | loss: 0.23444 | val_0_rmse: 0.4834  | val_1_rmse: 0.52381 |  0:13:04s
epoch 72 | loss: 0.23466 | val_0_rmse: 0.48245 | val_1_rmse: 0.52362 |  0:13:14s
epoch 73 | loss: 0.23473 | val_0_rmse: 0.47702 | val_1_rmse: 0.51713 |  0:13:25s
epoch 74 | loss: 0.23428 | val_0_rmse: 0.51131 | val_1_rmse: 0.57492 |  0:13:36s
epoch 75 | loss: 0.23137 | val_0_rmse: 0.46976 | val_1_rmse: 0.51475 |  0:13:47s
epoch 76 | loss: 0.23152 | val_0_rmse: 0.64328 | val_1_rmse: 0.92994 |  0:13:58s
epoch 77 | loss: 0.23094 | val_0_rmse: 0.92423 | val_1_rmse: 0.97022 |  0:14:09s
epoch 78 | loss: 0.23279 | val_0_rmse: 0.68123 | val_1_rmse: 0.78551 |  0:14:19s
epoch 79 | loss: 0.23173 | val_0_rmse: 0.95753 | val_1_rmse: 0.86515 |  0:14:30s
epoch 80 | loss: 0.23143 | val_0_rmse: 0.95342 | val_1_rmse: 1.45307 |  0:14:41s
epoch 81 | loss: 0.23008 | val_0_rmse: 0.4724  | val_1_rmse: 0.5213  |  0:14:52s
epoch 82 | loss: 0.23147 | val_0_rmse: 0.50229 | val_1_rmse: 0.55078 |  0:15:03s
epoch 83 | loss: 0.23004 | val_0_rmse: 0.47156 | val_1_rmse: 0.5197  |  0:15:14s
epoch 84 | loss: 0.23009 | val_0_rmse: 0.48383 | val_1_rmse: 0.53168 |  0:15:25s
epoch 85 | loss: 0.22898 | val_0_rmse: 0.47176 | val_1_rmse: 0.51993 |  0:15:35s
epoch 86 | loss: 0.22939 | val_0_rmse: 0.50017 | val_1_rmse: 0.54748 |  0:15:46s
epoch 87 | loss: 0.22746 | val_0_rmse: 0.46645 | val_1_rmse: 0.51621 |  0:15:57s
epoch 88 | loss: 0.22965 | val_0_rmse: 0.46588 | val_1_rmse: 0.51811 |  0:16:08s
epoch 89 | loss: 0.22723 | val_0_rmse: 0.48261 | val_1_rmse: 0.51876 |  0:16:19s
epoch 90 | loss: 0.22681 | val_0_rmse: 0.46532 | val_1_rmse: 0.51661 |  0:16:30s

Early stopping occured at epoch 90 with best_epoch = 60 and best_val_1_rmse = 0.51192
Best weights from best epoch are automatically used!
ended training at: 05:53:45
Feature importance:
Mean squared error is of 1794806623.029633
Mean absolute error:30634.160381550806
MAPE:0.2893392393604273
R2 score:0.7386169904314637
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 3
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 05:53:46
epoch 0  | loss: 0.66988 | val_0_rmse: 0.70015 | val_1_rmse: 0.70745 |  0:00:10s
epoch 1  | loss: 0.34943 | val_0_rmse: 0.62643 | val_1_rmse: 0.63218 |  0:00:21s
epoch 2  | loss: 0.32038 | val_0_rmse: 0.64476 | val_1_rmse: 0.6541  |  0:00:32s
epoch 3  | loss: 0.31578 | val_0_rmse: 0.58114 | val_1_rmse: 0.58973 |  0:00:43s
epoch 4  | loss: 0.31489 | val_0_rmse: 0.57363 | val_1_rmse: 0.58217 |  0:00:54s
epoch 5  | loss: 0.301   | val_0_rmse: 0.53881 | val_1_rmse: 0.54893 |  0:01:05s
epoch 6  | loss: 0.30058 | val_0_rmse: 0.60863 | val_1_rmse: 0.61999 |  0:01:16s
epoch 7  | loss: 0.30782 | val_0_rmse: 0.53012 | val_1_rmse: 0.5436  |  0:01:27s
epoch 8  | loss: 0.29161 | val_0_rmse: 0.5272  | val_1_rmse: 0.54214 |  0:01:37s
epoch 9  | loss: 0.28622 | val_0_rmse: 0.54854 | val_1_rmse: 0.56189 |  0:01:48s
epoch 10 | loss: 0.28921 | val_0_rmse: 0.52051 | val_1_rmse: 0.53671 |  0:01:59s
epoch 11 | loss: 0.27921 | val_0_rmse: 0.51365 | val_1_rmse: 0.53083 |  0:02:10s
epoch 12 | loss: 0.28307 | val_0_rmse: 0.52216 | val_1_rmse: 0.53774 |  0:02:21s
epoch 13 | loss: 0.28226 | val_0_rmse: 0.53652 | val_1_rmse: 0.55182 |  0:02:32s
epoch 14 | loss: 0.27576 | val_0_rmse: 0.51889 | val_1_rmse: 0.53725 |  0:02:43s
epoch 15 | loss: 0.27385 | val_0_rmse: 0.5146  | val_1_rmse: 0.53276 |  0:02:54s
epoch 16 | loss: 0.27608 | val_0_rmse: 0.54544 | val_1_rmse: 0.5624  |  0:03:05s
epoch 17 | loss: 0.2714  | val_0_rmse: 0.52654 | val_1_rmse: 0.54452 |  0:03:16s
epoch 18 | loss: 0.27196 | val_0_rmse: 0.52262 | val_1_rmse: 0.5377  |  0:03:27s
epoch 19 | loss: 0.26898 | val_0_rmse: 0.51152 | val_1_rmse: 0.5341  |  0:03:38s
epoch 20 | loss: 0.27194 | val_0_rmse: 0.51072 | val_1_rmse: 0.53006 |  0:03:48s
epoch 21 | loss: 0.271   | val_0_rmse: 0.50933 | val_1_rmse: 0.53111 |  0:03:59s
epoch 22 | loss: 0.26653 | val_0_rmse: 0.50644 | val_1_rmse: 0.53207 |  0:04:10s
epoch 23 | loss: 0.26376 | val_0_rmse: 0.5015  | val_1_rmse: 0.52394 |  0:04:21s
epoch 24 | loss: 0.2636  | val_0_rmse: 0.50035 | val_1_rmse: 0.52533 |  0:04:32s
epoch 25 | loss: 0.26326 | val_0_rmse: 0.49908 | val_1_rmse: 0.52508 |  0:04:43s
epoch 26 | loss: 0.25905 | val_0_rmse: 0.50607 | val_1_rmse: 0.53256 |  0:04:54s
epoch 27 | loss: 0.26386 | val_0_rmse: 0.49761 | val_1_rmse: 0.52567 |  0:05:05s
epoch 28 | loss: 0.26265 | val_0_rmse: 0.50595 | val_1_rmse: 0.53184 |  0:05:16s
epoch 29 | loss: 0.25852 | val_0_rmse: 0.513   | val_1_rmse: 0.54094 |  0:05:27s
epoch 30 | loss: 0.26716 | val_0_rmse: 0.50034 | val_1_rmse: 0.52742 |  0:05:38s
epoch 31 | loss: 0.26198 | val_0_rmse: 0.5014  | val_1_rmse: 0.53116 |  0:05:49s
epoch 32 | loss: 0.26753 | val_0_rmse: 0.51487 | val_1_rmse: 0.53662 |  0:06:00s
epoch 33 | loss: 0.26541 | val_0_rmse: 0.52417 | val_1_rmse: 0.55012 |  0:06:11s
epoch 34 | loss: 0.26553 | val_0_rmse: 0.50363 | val_1_rmse: 0.53126 |  0:06:21s
epoch 35 | loss: 0.26516 | val_0_rmse: 0.52385 | val_1_rmse: 0.5488  |  0:06:32s
epoch 36 | loss: 0.28157 | val_0_rmse: 0.50837 | val_1_rmse: 0.53569 |  0:06:43s
epoch 37 | loss: 0.26607 | val_0_rmse: 0.50709 | val_1_rmse: 0.54696 |  0:06:54s
epoch 38 | loss: 0.26339 | val_0_rmse: 0.50327 | val_1_rmse: 0.53299 |  0:07:05s
epoch 39 | loss: 0.25709 | val_0_rmse: 0.49962 | val_1_rmse: 0.53102 |  0:07:16s
epoch 40 | loss: 0.25624 | val_0_rmse: 0.4992  | val_1_rmse: 0.53006 |  0:07:27s
epoch 41 | loss: 0.25933 | val_0_rmse: 0.5022  | val_1_rmse: 0.53631 |  0:07:38s
epoch 42 | loss: 0.26083 | val_0_rmse: 0.49625 | val_1_rmse: 0.52571 |  0:07:49s
epoch 43 | loss: 0.26005 | val_0_rmse: 0.51982 | val_1_rmse: 0.54501 |  0:08:00s
epoch 44 | loss: 0.25765 | val_0_rmse: 0.5012  | val_1_rmse: 0.53156 |  0:08:11s
epoch 45 | loss: 0.26977 | val_0_rmse: 0.50722 | val_1_rmse: 0.53265 |  0:08:22s
epoch 46 | loss: 0.26032 | val_0_rmse: 0.50682 | val_1_rmse: 0.53414 |  0:08:33s
epoch 47 | loss: 0.25733 | val_0_rmse: 0.49722 | val_1_rmse: 0.52916 |  0:08:44s
epoch 48 | loss: 0.25748 | val_0_rmse: 0.49617 | val_1_rmse: 0.52813 |  0:08:54s
epoch 49 | loss: 0.25598 | val_0_rmse: 0.49347 | val_1_rmse: 0.52825 |  0:09:05s
epoch 50 | loss: 0.25598 | val_0_rmse: 0.51911 | val_1_rmse: 0.55439 |  0:09:16s
epoch 51 | loss: 0.25374 | val_0_rmse: 0.4958  | val_1_rmse: 0.5316  |  0:09:27s
epoch 52 | loss: 0.25275 | val_0_rmse: 0.49705 | val_1_rmse: 0.52984 |  0:09:38s
epoch 53 | loss: 0.25817 | val_0_rmse: 0.51966 | val_1_rmse: 0.55989 |  0:09:49s

Early stopping occured at epoch 53 with best_epoch = 23 and best_val_1_rmse = 0.52394
Best weights from best epoch are automatically used!
ended training at: 06:03:39
Feature importance:
Mean squared error is of 1856452300.106374
Mean absolute error:31582.43572127583
MAPE:0.31875189803761256
R2 score:0.7265149177806041
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 4
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 06:03:41
epoch 0  | loss: 0.68877 | val_0_rmse: 0.75633 | val_1_rmse: 0.74992 |  0:00:10s
epoch 1  | loss: 0.35038 | val_0_rmse: 0.68578 | val_1_rmse: 0.68431 |  0:00:21s
epoch 2  | loss: 0.32039 | val_0_rmse: 0.59851 | val_1_rmse: 0.59821 |  0:00:32s
epoch 3  | loss: 0.30313 | val_0_rmse: 0.58204 | val_1_rmse: 0.58474 |  0:00:43s
epoch 4  | loss: 0.30588 | val_0_rmse: 0.57414 | val_1_rmse: 0.57699 |  0:00:54s
epoch 5  | loss: 0.29758 | val_0_rmse: 0.53858 | val_1_rmse: 0.54517 |  0:01:05s
epoch 6  | loss: 0.28731 | val_0_rmse: 0.5376  | val_1_rmse: 0.54459 |  0:01:16s
epoch 7  | loss: 0.29259 | val_0_rmse: 0.53031 | val_1_rmse: 0.54056 |  0:01:27s
epoch 8  | loss: 0.3098  | val_0_rmse: 0.5264  | val_1_rmse: 0.53823 |  0:01:37s
epoch 9  | loss: 0.29088 | val_0_rmse: 0.5246  | val_1_rmse: 0.53589 |  0:01:47s
epoch 10 | loss: 0.28605 | val_0_rmse: 0.52089 | val_1_rmse: 0.53303 |  0:01:58s
epoch 11 | loss: 0.27856 | val_0_rmse: 0.5149  | val_1_rmse: 0.52829 |  0:02:08s
epoch 12 | loss: 0.27547 | val_0_rmse: 0.51226 | val_1_rmse: 0.52453 |  0:02:18s
epoch 13 | loss: 0.28121 | val_0_rmse: 0.51733 | val_1_rmse: 0.5307  |  0:02:29s
epoch 14 | loss: 0.27214 | val_0_rmse: 0.50638 | val_1_rmse: 0.52071 |  0:02:39s
epoch 15 | loss: 0.27013 | val_0_rmse: 0.50638 | val_1_rmse: 0.52245 |  0:02:49s
epoch 16 | loss: 0.26475 | val_0_rmse: 0.50433 | val_1_rmse: 0.52226 |  0:02:59s
epoch 17 | loss: 0.26665 | val_0_rmse: 0.50689 | val_1_rmse: 0.52353 |  0:03:09s
epoch 18 | loss: 0.26843 | val_0_rmse: 0.52516 | val_1_rmse: 0.54352 |  0:03:20s
epoch 19 | loss: 0.26427 | val_0_rmse: 0.50953 | val_1_rmse: 0.51929 |  0:03:30s
epoch 20 | loss: 0.26438 | val_0_rmse: 0.50029 | val_1_rmse: 0.5199  |  0:03:40s
epoch 21 | loss: 0.26185 | val_0_rmse: 0.49939 | val_1_rmse: 0.51995 |  0:03:51s
epoch 22 | loss: 0.2599  | val_0_rmse: 0.56287 | val_1_rmse: 0.57744 |  0:04:01s
epoch 23 | loss: 0.26451 | val_0_rmse: 0.55955 | val_1_rmse: 0.57408 |  0:04:11s
epoch 24 | loss: 0.26326 | val_0_rmse: 0.50956 | val_1_rmse: 0.53084 |  0:04:22s
epoch 25 | loss: 0.26255 | val_0_rmse: 0.50322 | val_1_rmse: 0.52081 |  0:04:32s
epoch 26 | loss: 0.2593  | val_0_rmse: 0.5315  | val_1_rmse: 0.55445 |  0:04:42s
epoch 27 | loss: 0.25602 | val_0_rmse: 0.49307 | val_1_rmse: 0.51726 |  0:04:52s
epoch 28 | loss: 0.25394 | val_0_rmse: 0.49599 | val_1_rmse: 0.51718 |  0:05:03s
epoch 29 | loss: 0.25222 | val_0_rmse: 0.49118 | val_1_rmse: 0.51551 |  0:05:13s
epoch 30 | loss: 0.25276 | val_0_rmse: 0.494   | val_1_rmse: 0.51925 |  0:05:23s
epoch 31 | loss: 0.25035 | val_0_rmse: 0.49392 | val_1_rmse: 0.5197  |  0:05:33s
epoch 32 | loss: 0.25087 | val_0_rmse: 0.49129 | val_1_rmse: 0.51675 |  0:05:43s
epoch 33 | loss: 0.25056 | val_0_rmse: 0.51054 | val_1_rmse: 0.53308 |  0:05:54s
epoch 34 | loss: 0.25086 | val_0_rmse: 0.49104 | val_1_rmse: 0.51692 |  0:06:04s
epoch 35 | loss: 0.24981 | val_0_rmse: 0.4899  | val_1_rmse: 0.51787 |  0:06:14s
epoch 36 | loss: 0.24797 | val_0_rmse: 0.49125 | val_1_rmse: 0.51863 |  0:06:24s
epoch 37 | loss: 0.24766 | val_0_rmse: 0.48392 | val_1_rmse: 0.51553 |  0:06:35s
epoch 38 | loss: 0.24627 | val_0_rmse: 0.48999 | val_1_rmse: 0.52077 |  0:06:45s
epoch 39 | loss: 0.2458  | val_0_rmse: 0.48375 | val_1_rmse: 0.51663 |  0:06:55s
epoch 40 | loss: 0.24662 | val_0_rmse: 0.48324 | val_1_rmse: 0.5154  |  0:07:06s
epoch 41 | loss: 0.24664 | val_0_rmse: 0.48369 | val_1_rmse: 0.51775 |  0:07:16s
epoch 42 | loss: 0.24509 | val_0_rmse: 0.51417 | val_1_rmse: 0.51378 |  0:07:26s
epoch 43 | loss: 0.24553 | val_0_rmse: 0.48851 | val_1_rmse: 0.51806 |  0:07:36s
epoch 44 | loss: 0.24303 | val_0_rmse: 0.48634 | val_1_rmse: 0.51487 |  0:07:46s
epoch 45 | loss: 0.24368 | val_0_rmse: 0.51605 | val_1_rmse: 0.54449 |  0:07:57s
epoch 46 | loss: 0.24426 | val_0_rmse: 0.56644 | val_1_rmse: 0.51647 |  0:08:07s
epoch 47 | loss: 0.24242 | val_0_rmse: 0.48098 | val_1_rmse: 0.51643 |  0:08:17s
epoch 48 | loss: 0.24268 | val_0_rmse: 0.48765 | val_1_rmse: 0.5182  |  0:08:28s
epoch 49 | loss: 0.24192 | val_0_rmse: 0.48908 | val_1_rmse: 0.61534 |  0:08:38s
epoch 50 | loss: 0.24243 | val_0_rmse: 0.49267 | val_1_rmse: 0.51668 |  0:08:48s
epoch 51 | loss: 0.24129 | val_0_rmse: 0.48914 | val_1_rmse: 0.51728 |  0:08:58s
epoch 52 | loss: 0.24077 | val_0_rmse: 0.48861 | val_1_rmse: 0.51455 |  0:09:09s
epoch 53 | loss: 0.23916 | val_0_rmse: 0.51896 | val_1_rmse: 0.53481 |  0:09:19s
epoch 54 | loss: 0.23975 | val_0_rmse: 0.48964 | val_1_rmse: 0.51774 |  0:09:29s
epoch 55 | loss: 0.23851 | val_0_rmse: 0.48298 | val_1_rmse: 0.52205 |  0:09:39s
epoch 56 | loss: 0.23808 | val_0_rmse: 0.48357 | val_1_rmse: 0.522   |  0:09:50s
epoch 57 | loss: 0.23834 | val_0_rmse: 0.48173 | val_1_rmse: 0.52133 |  0:10:00s
epoch 58 | loss: 0.23605 | val_0_rmse: 0.48771 | val_1_rmse: 0.5214  |  0:10:10s
epoch 59 | loss: 0.23574 | val_0_rmse: 0.52115 | val_1_rmse: 0.55092 |  0:10:20s
epoch 60 | loss: 0.23584 | val_0_rmse: 0.49127 | val_1_rmse: 0.52136 |  0:10:31s
epoch 61 | loss: 0.23435 | val_0_rmse: 0.48199 | val_1_rmse: 0.51774 |  0:10:41s
epoch 62 | loss: 0.23772 | val_0_rmse: 0.47958 | val_1_rmse: 0.52212 |  0:10:51s
epoch 63 | loss: 0.23441 | val_0_rmse: 0.47449 | val_1_rmse: 0.5164  |  0:11:01s
epoch 64 | loss: 0.233   | val_0_rmse: 0.5003  | val_1_rmse: 0.54607 |  0:11:12s
epoch 65 | loss: 0.23387 | val_0_rmse: 0.49512 | val_1_rmse: 0.53395 |  0:11:22s
epoch 66 | loss: 0.23434 | val_0_rmse: 0.47682 | val_1_rmse: 0.52208 |  0:11:32s
epoch 67 | loss: 0.2326  | val_0_rmse: 0.48199 | val_1_rmse: 0.52585 |  0:11:43s
epoch 68 | loss: 0.2323  | val_0_rmse: 0.47322 | val_1_rmse: 0.51643 |  0:11:53s
epoch 69 | loss: 0.23293 | val_0_rmse: 0.48116 | val_1_rmse: 0.52823 |  0:12:03s
epoch 70 | loss: 0.23456 | val_0_rmse: 0.50268 | val_1_rmse: 0.53607 |  0:12:13s
epoch 71 | loss: 0.23587 | val_0_rmse: 0.4747  | val_1_rmse: 0.52413 |  0:12:24s
epoch 72 | loss: 0.23486 | val_0_rmse: 0.47552 | val_1_rmse: 0.52108 |  0:12:34s

Early stopping occured at epoch 72 with best_epoch = 42 and best_val_1_rmse = 0.51378
Best weights from best epoch are automatically used!
ended training at: 06:16:19
Feature importance:
Mean squared error is of 4760577344.919065
Mean absolute error:31274.729606031906
MAPE:0.2955538865007423
R2 score:0.3012746283357407
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 5
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 06:16:21
epoch 0  | loss: 0.66695 | val_0_rmse: 0.72844 | val_1_rmse: 0.73105 |  0:00:10s
epoch 1  | loss: 0.37224 | val_0_rmse: 0.62869 | val_1_rmse: 0.63165 |  0:00:20s
epoch 2  | loss: 0.34644 | val_0_rmse: 0.61426 | val_1_rmse: 0.61479 |  0:00:30s
epoch 3  | loss: 0.32606 | val_0_rmse: 0.59538 | val_1_rmse: 0.59799 |  0:00:41s
epoch 4  | loss: 0.31256 | val_0_rmse: 0.58274 | val_1_rmse: 0.58435 |  0:00:51s
epoch 5  | loss: 0.30684 | val_0_rmse: 0.53926 | val_1_rmse: 0.54471 |  0:01:01s
epoch 6  | loss: 0.29543 | val_0_rmse: 0.53669 | val_1_rmse: 0.5458  |  0:01:12s
epoch 7  | loss: 0.28729 | val_0_rmse: 0.53467 | val_1_rmse: 0.54168 |  0:01:22s
epoch 8  | loss: 0.28252 | val_0_rmse: 0.53645 | val_1_rmse: 0.55573 |  0:01:32s
epoch 9  | loss: 0.27969 | val_0_rmse: 0.52344 | val_1_rmse: 0.53254 |  0:01:43s
epoch 10 | loss: 0.27955 | val_0_rmse: 0.51071 | val_1_rmse: 0.5217  |  0:01:53s
epoch 11 | loss: 0.2759  | val_0_rmse: 0.51317 | val_1_rmse: 0.52158 |  0:02:03s
epoch 12 | loss: 0.27229 | val_0_rmse: 0.51156 | val_1_rmse: 0.52547 |  0:02:13s
epoch 13 | loss: 0.27241 | val_0_rmse: 0.5093  | val_1_rmse: 0.52079 |  0:02:24s
epoch 14 | loss: 0.26985 | val_0_rmse: 0.50704 | val_1_rmse: 0.51918 |  0:02:34s
epoch 15 | loss: 0.26822 | val_0_rmse: 0.50998 | val_1_rmse: 0.52626 |  0:02:44s
epoch 16 | loss: 0.26704 | val_0_rmse: 0.51337 | val_1_rmse: 0.52957 |  0:02:54s
epoch 17 | loss: 0.26471 | val_0_rmse: 0.50321 | val_1_rmse: 0.51861 |  0:03:05s
epoch 18 | loss: 0.26543 | val_0_rmse: 0.50675 | val_1_rmse: 0.52461 |  0:03:15s
epoch 19 | loss: 0.26283 | val_0_rmse: 0.51799 | val_1_rmse: 0.55113 |  0:03:25s
epoch 20 | loss: 0.26207 | val_0_rmse: 0.51418 | val_1_rmse: 0.52951 |  0:03:35s
epoch 21 | loss: 0.25801 | val_0_rmse: 0.49832 | val_1_rmse: 0.51526 |  0:03:45s
epoch 22 | loss: 0.25993 | val_0_rmse: 0.52319 | val_1_rmse: 0.53327 |  0:03:56s
epoch 23 | loss: 0.26021 | val_0_rmse: 0.53228 | val_1_rmse: 0.55444 |  0:04:06s
epoch 24 | loss: 0.25573 | val_0_rmse: 0.50884 | val_1_rmse: 0.5279  |  0:04:16s
epoch 25 | loss: 0.25453 | val_0_rmse: 0.50887 | val_1_rmse: 0.5289  |  0:04:26s
epoch 26 | loss: 0.25515 | val_0_rmse: 0.49352 | val_1_rmse: 0.516   |  0:04:36s
epoch 27 | loss: 0.25489 | val_0_rmse: 0.49496 | val_1_rmse: 0.51682 |  0:04:47s
epoch 28 | loss: 0.25559 | val_0_rmse: 0.49401 | val_1_rmse: 0.51961 |  0:04:57s
epoch 29 | loss: 0.25199 | val_0_rmse: 0.4938  | val_1_rmse: 0.51723 |  0:05:07s
epoch 30 | loss: 0.25143 | val_0_rmse: 0.49995 | val_1_rmse: 0.52407 |  0:05:18s
epoch 31 | loss: 0.2533  | val_0_rmse: 0.50097 | val_1_rmse: 0.51522 |  0:05:28s
epoch 32 | loss: 0.25093 | val_0_rmse: 0.62313 | val_1_rmse: 0.51475 |  0:05:38s
epoch 33 | loss: 0.25016 | val_0_rmse: 0.6084  | val_1_rmse: 0.51487 |  0:05:48s
epoch 34 | loss: 0.24751 | val_0_rmse: 0.61473 | val_1_rmse: 0.55966 |  0:05:59s
epoch 35 | loss: 0.24934 | val_0_rmse: 0.4954  | val_1_rmse: 0.5205  |  0:06:09s
epoch 36 | loss: 0.25201 | val_0_rmse: 0.52833 | val_1_rmse: 0.51445 |  0:06:19s
epoch 37 | loss: 0.24781 | val_0_rmse: 0.49063 | val_1_rmse: 0.52145 |  0:06:30s
epoch 38 | loss: 0.24536 | val_0_rmse: 0.54002 | val_1_rmse: 0.53178 |  0:06:40s
epoch 39 | loss: 0.24772 | val_0_rmse: 0.63081 | val_1_rmse: 0.51646 |  0:06:50s
epoch 40 | loss: 0.24653 | val_0_rmse: 0.51065 | val_1_rmse: 0.52021 |  0:07:01s
epoch 41 | loss: 0.24267 | val_0_rmse: 0.48652 | val_1_rmse: 0.51807 |  0:07:11s
epoch 42 | loss: 0.24334 | val_0_rmse: 0.49583 | val_1_rmse: 0.51989 |  0:07:21s
epoch 43 | loss: 0.24194 | val_0_rmse: 0.49767 | val_1_rmse: 0.52436 |  0:07:31s
epoch 44 | loss: 0.27678 | val_0_rmse: 0.53043 | val_1_rmse: 0.53513 |  0:07:42s
epoch 45 | loss: 0.27157 | val_0_rmse: 0.49864 | val_1_rmse: 0.51935 |  0:07:52s
epoch 46 | loss: 0.25691 | val_0_rmse: 0.49545 | val_1_rmse: 0.52079 |  0:08:02s
epoch 47 | loss: 0.2545  | val_0_rmse: 0.4941  | val_1_rmse: 0.52057 |  0:08:13s
epoch 48 | loss: 0.25893 | val_0_rmse: 0.50191 | val_1_rmse: 0.52436 |  0:08:23s
epoch 49 | loss: 0.25437 | val_0_rmse: 0.51038 | val_1_rmse: 0.54153 |  0:08:33s
epoch 50 | loss: 0.25296 | val_0_rmse: 0.49604 | val_1_rmse: 0.52376 |  0:08:44s
epoch 51 | loss: 0.25027 | val_0_rmse: 0.53079 | val_1_rmse: 0.55287 |  0:08:54s
epoch 52 | loss: 0.24784 | val_0_rmse: 0.4811  | val_1_rmse: 0.51103 |  0:09:04s
epoch 53 | loss: 0.24661 | val_0_rmse: 0.49824 | val_1_rmse: 0.52512 |  0:09:14s
epoch 54 | loss: 0.25164 | val_0_rmse: 0.53852 | val_1_rmse: 0.57726 |  0:09:24s
epoch 55 | loss: 0.26337 | val_0_rmse: 0.55036 | val_1_rmse: 0.57024 |  0:09:35s
epoch 56 | loss: 0.24987 | val_0_rmse: 0.48865 | val_1_rmse: 0.51961 |  0:09:45s
epoch 57 | loss: 0.24869 | val_0_rmse: 0.49389 | val_1_rmse: 0.51698 |  0:09:55s
epoch 58 | loss: 0.24343 | val_0_rmse: 0.4802  | val_1_rmse: 0.51337 |  0:10:05s
epoch 59 | loss: 0.24133 | val_0_rmse: 0.48874 | val_1_rmse: 0.52009 |  0:10:15s
epoch 60 | loss: 0.24037 | val_0_rmse: 0.50032 | val_1_rmse: 0.5302  |  0:10:25s
epoch 61 | loss: 0.24044 | val_0_rmse: 0.4786  | val_1_rmse: 0.51356 |  0:10:36s
epoch 62 | loss: 0.24032 | val_0_rmse: 0.48129 | val_1_rmse: 0.51614 |  0:10:46s
epoch 63 | loss: 0.23732 | val_0_rmse: 0.47731 | val_1_rmse: 0.79344 |  0:10:56s
epoch 64 | loss: 0.23854 | val_0_rmse: 0.48194 | val_1_rmse: 0.51856 |  0:11:06s
epoch 65 | loss: 0.23855 | val_0_rmse: 0.47546 | val_1_rmse: 0.51502 |  0:11:17s
epoch 66 | loss: 0.23768 | val_0_rmse: 0.47823 | val_1_rmse: 0.51618 |  0:11:27s
epoch 67 | loss: 0.24015 | val_0_rmse: 0.47894 | val_1_rmse: 0.51588 |  0:11:37s
epoch 68 | loss: 0.23784 | val_0_rmse: 0.4925  | val_1_rmse: 0.53443 |  0:11:48s
epoch 69 | loss: 0.23732 | val_0_rmse: 0.47767 | val_1_rmse: 0.51843 |  0:11:58s
epoch 70 | loss: 0.2365  | val_0_rmse: 0.49419 | val_1_rmse: 0.53747 |  0:12:08s
epoch 71 | loss: 0.2365  | val_0_rmse: 0.47701 | val_1_rmse: 0.51987 |  0:12:18s
epoch 72 | loss: 0.23711 | val_0_rmse: 0.47497 | val_1_rmse: 0.5169  |  0:12:29s
epoch 73 | loss: 0.23451 | val_0_rmse: 0.47532 | val_1_rmse: 0.51748 |  0:12:39s
epoch 74 | loss: 0.2343  | val_0_rmse: 0.49255 | val_1_rmse: 0.53906 |  0:12:49s
epoch 75 | loss: 0.23349 | val_0_rmse: 0.49976 | val_1_rmse: 0.53437 |  0:12:59s
epoch 76 | loss: 0.23379 | val_0_rmse: 0.47821 | val_1_rmse: 0.5231  |  0:13:10s
epoch 77 | loss: 0.23312 | val_0_rmse: 0.47231 | val_1_rmse: 0.51422 |  0:13:20s
epoch 78 | loss: 0.2344  | val_0_rmse: 0.48976 | val_1_rmse: 0.52965 |  0:13:30s
epoch 79 | loss: 0.23233 | val_0_rmse: 0.48925 | val_1_rmse: 0.53919 |  0:13:41s
epoch 80 | loss: 0.23061 | val_0_rmse: 0.47134 | val_1_rmse: 0.51647 |  0:13:51s
epoch 81 | loss: 0.23093 | val_0_rmse: 0.47062 | val_1_rmse: 0.51943 |  0:14:01s
epoch 82 | loss: 0.23226 | val_0_rmse: 0.47467 | val_1_rmse: 0.5249  |  0:14:11s

Early stopping occured at epoch 82 with best_epoch = 52 and best_val_1_rmse = 0.51103
Best weights from best epoch are automatically used!
ended training at: 06:30:36
Feature importance:
Mean squared error is of 1777470602.7124119
Mean absolute error:30183.573591244556
MAPE:0.2748130596542985
R2 score:0.7340647564464977
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 6
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 06:30:38
epoch 0  | loss: 0.67035 | val_0_rmse: 0.71276 | val_1_rmse: 0.71007 |  0:00:10s
epoch 1  | loss: 0.34283 | val_0_rmse: 0.65477 | val_1_rmse: 0.65423 |  0:00:20s
epoch 2  | loss: 0.31499 | val_0_rmse: 0.61145 | val_1_rmse: 0.61343 |  0:00:30s
epoch 3  | loss: 0.30028 | val_0_rmse: 0.5764  | val_1_rmse: 0.58111 |  0:00:41s
epoch 4  | loss: 0.29187 | val_0_rmse: 0.58525 | val_1_rmse: 0.58771 |  0:00:51s
epoch 5  | loss: 0.28665 | val_0_rmse: 0.53204 | val_1_rmse: 0.53677 |  0:01:01s
epoch 6  | loss: 0.28375 | val_0_rmse: 0.51876 | val_1_rmse: 0.53001 |  0:01:12s
epoch 7  | loss: 0.28212 | val_0_rmse: 0.53845 | val_1_rmse: 0.54839 |  0:01:22s
epoch 8  | loss: 0.27875 | val_0_rmse: 0.51416 | val_1_rmse: 0.5248  |  0:01:32s
epoch 9  | loss: 0.27827 | val_0_rmse: 0.52077 | val_1_rmse: 0.53197 |  0:01:42s
epoch 10 | loss: 0.27467 | val_0_rmse: 0.50794 | val_1_rmse: 0.52076 |  0:01:53s
epoch 11 | loss: 0.27307 | val_0_rmse: 0.51742 | val_1_rmse: 0.52881 |  0:02:03s
epoch 12 | loss: 0.27192 | val_0_rmse: 0.51436 | val_1_rmse: 0.52787 |  0:02:13s
epoch 13 | loss: 0.27183 | val_0_rmse: 0.52552 | val_1_rmse: 0.53892 |  0:02:23s
epoch 14 | loss: 0.27086 | val_0_rmse: 0.50717 | val_1_rmse: 0.51945 |  0:02:34s
epoch 15 | loss: 0.27171 | val_0_rmse: 0.51185 | val_1_rmse: 1.16133 |  0:02:44s
epoch 16 | loss: 0.27405 | val_0_rmse: 0.51898 | val_1_rmse: 1.13826 |  0:02:54s
epoch 17 | loss: 0.26516 | val_0_rmse: 0.51162 | val_1_rmse: 1.3353  |  0:03:04s
epoch 18 | loss: 0.26377 | val_0_rmse: 0.50173 | val_1_rmse: 0.83813 |  0:03:15s
epoch 19 | loss: 0.26311 | val_0_rmse: 0.52321 | val_1_rmse: 0.7626  |  0:03:25s
epoch 20 | loss: 0.26131 | val_0_rmse: 0.52147 | val_1_rmse: 1.09688 |  0:03:35s
epoch 21 | loss: 0.25838 | val_0_rmse: 0.49456 | val_1_rmse: 0.76025 |  0:03:46s
epoch 22 | loss: 0.25949 | val_0_rmse: 0.4936  | val_1_rmse: 0.97023 |  0:03:56s
epoch 23 | loss: 0.25842 | val_0_rmse: 0.50722 | val_1_rmse: 1.50731 |  0:04:06s
epoch 24 | loss: 0.25796 | val_0_rmse: 0.50165 | val_1_rmse: 0.87974 |  0:04:17s
epoch 25 | loss: 0.25482 | val_0_rmse: 0.49252 | val_1_rmse: 0.8599  |  0:04:27s
epoch 26 | loss: 0.25507 | val_0_rmse: 0.49277 | val_1_rmse: 0.51775 |  0:04:37s
epoch 27 | loss: 0.256   | val_0_rmse: 0.49505 | val_1_rmse: 1.03557 |  0:04:47s
epoch 28 | loss: 0.2526  | val_0_rmse: 0.59019 | val_1_rmse: 2.61389 |  0:04:58s
epoch 29 | loss: 0.25034 | val_0_rmse: 0.51266 | val_1_rmse: 1.78649 |  0:05:08s
epoch 30 | loss: 0.25126 | val_0_rmse: 0.49153 | val_1_rmse: 0.51947 |  0:05:18s
epoch 31 | loss: 0.25082 | val_0_rmse: 0.50349 | val_1_rmse: 0.53467 |  0:05:28s
epoch 32 | loss: 0.25171 | val_0_rmse: 0.49187 | val_1_rmse: 0.51724 |  0:05:39s
epoch 33 | loss: 0.25183 | val_0_rmse: 0.50021 | val_1_rmse: 0.5253  |  0:05:49s
epoch 34 | loss: 0.24976 | val_0_rmse: 0.49004 | val_1_rmse: 2.11985 |  0:05:59s
epoch 35 | loss: 0.25026 | val_0_rmse: 0.4867  | val_1_rmse: 0.5154  |  0:06:09s
epoch 36 | loss: 0.24766 | val_0_rmse: 0.51125 | val_1_rmse: 0.52392 |  0:06:19s
epoch 37 | loss: 0.2487  | val_0_rmse: 0.56764 | val_1_rmse: 0.56497 |  0:06:30s
epoch 38 | loss: 0.24907 | val_0_rmse: 0.67262 | val_1_rmse: 2.36564 |  0:06:40s
epoch 39 | loss: 0.24684 | val_0_rmse: 0.48239 | val_1_rmse: 1.79268 |  0:06:50s
epoch 40 | loss: 0.24616 | val_0_rmse: 0.48553 | val_1_rmse: 0.52845 |  0:07:00s
epoch 41 | loss: 0.2451  | val_0_rmse: 0.5946  | val_1_rmse: 0.83065 |  0:07:11s
epoch 42 | loss: 0.24522 | val_0_rmse: 0.64947 | val_1_rmse: 0.59283 |  0:07:21s
epoch 43 | loss: 0.24522 | val_0_rmse: 0.61812 | val_1_rmse: 0.53219 |  0:07:31s
epoch 44 | loss: 0.24337 | val_0_rmse: 0.53647 | val_1_rmse: 0.53221 |  0:07:41s
epoch 45 | loss: 0.24307 | val_0_rmse: 0.80146 | val_1_rmse: 0.51964 |  0:07:52s
epoch 46 | loss: 0.24314 | val_0_rmse: 0.67495 | val_1_rmse: 0.8264  |  0:08:02s
epoch 47 | loss: 0.24268 | val_0_rmse: 0.96956 | val_1_rmse: 1.20159 |  0:08:12s
epoch 48 | loss: 0.24439 | val_0_rmse: 0.54095 | val_1_rmse: 1.39365 |  0:08:23s
epoch 49 | loss: 0.24055 | val_0_rmse: 0.47877 | val_1_rmse: 0.64608 |  0:08:33s
epoch 50 | loss: 0.24135 | val_0_rmse: 0.54734 | val_1_rmse: 0.5802  |  0:08:43s
epoch 51 | loss: 0.23982 | val_0_rmse: 0.47789 | val_1_rmse: 0.53165 |  0:08:54s
epoch 52 | loss: 0.23928 | val_0_rmse: 0.47571 | val_1_rmse: 1.00154 |  0:09:04s
epoch 53 | loss: 0.24396 | val_0_rmse: 0.47835 | val_1_rmse: 0.98448 |  0:09:14s
epoch 54 | loss: 0.23993 | val_0_rmse: 0.48658 | val_1_rmse: 1.65552 |  0:09:24s
epoch 55 | loss: 0.24025 | val_0_rmse: 0.47613 | val_1_rmse: 1.39636 |  0:09:35s
epoch 56 | loss: 0.23759 | val_0_rmse: 0.47483 | val_1_rmse: 0.61549 |  0:09:45s
epoch 57 | loss: 0.24043 | val_0_rmse: 0.47945 | val_1_rmse: 0.6261  |  0:09:55s
epoch 58 | loss: 0.23837 | val_0_rmse: 0.47517 | val_1_rmse: 0.56028 |  0:10:06s
epoch 59 | loss: 0.2386  | val_0_rmse: 0.48549 | val_1_rmse: 1.68503 |  0:10:16s
epoch 60 | loss: 0.23771 | val_0_rmse: 0.47391 | val_1_rmse: 0.55018 |  0:10:26s
epoch 61 | loss: 0.2365  | val_0_rmse: 0.47136 | val_1_rmse: 0.93612 |  0:10:36s
epoch 62 | loss: 0.2349  | val_0_rmse: 0.48815 | val_1_rmse: 0.76246 |  0:10:47s
epoch 63 | loss: 0.23644 | val_0_rmse: 0.4714  | val_1_rmse: 0.5217  |  0:10:57s
epoch 64 | loss: 0.2367  | val_0_rmse: 0.58717 | val_1_rmse: 1.07061 |  0:11:07s
epoch 65 | loss: 0.23532 | val_0_rmse: 0.47774 | val_1_rmse: 1.41717 |  0:11:17s

Early stopping occured at epoch 65 with best_epoch = 35 and best_val_1_rmse = 0.5154
Best weights from best epoch are automatically used!
ended training at: 06:41:59
Feature importance:
Mean squared error is of 1751359154.740881
Mean absolute error:30333.599478942888
MAPE:0.2903614280560706
R2 score:0.7398721366732567
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 7
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 06:42:01
epoch 0  | loss: 0.74003 | val_0_rmse: 0.70784 | val_1_rmse: 0.70794 |  0:00:10s
epoch 1  | loss: 0.35455 | val_0_rmse: 0.65324 | val_1_rmse: 0.64777 |  0:00:20s
epoch 2  | loss: 0.31602 | val_0_rmse: 0.60997 | val_1_rmse: 0.60885 |  0:00:30s
epoch 3  | loss: 0.30428 | val_0_rmse: 0.57796 | val_1_rmse: 0.57708 |  0:00:41s
epoch 4  | loss: 0.30176 | val_0_rmse: 0.56697 | val_1_rmse: 0.56619 |  0:00:51s
epoch 5  | loss: 0.29527 | val_0_rmse: 0.53861 | val_1_rmse: 0.54242 |  0:01:01s
epoch 6  | loss: 0.2973  | val_0_rmse: 0.54685 | val_1_rmse: 0.55145 |  0:01:11s
epoch 7  | loss: 0.28938 | val_0_rmse: 0.52513 | val_1_rmse: 0.52913 |  0:01:22s
epoch 8  | loss: 0.28475 | val_0_rmse: 0.52059 | val_1_rmse: 0.52661 |  0:01:32s
epoch 9  | loss: 0.28465 | val_0_rmse: 0.52213 | val_1_rmse: 0.52898 |  0:01:42s
epoch 10 | loss: 0.28775 | val_0_rmse: 0.52894 | val_1_rmse: 0.53628 |  0:01:52s
epoch 11 | loss: 0.28508 | val_0_rmse: 0.51652 | val_1_rmse: 0.5251  |  0:02:03s
epoch 12 | loss: 0.27682 | val_0_rmse: 0.51407 | val_1_rmse: 0.52197 |  0:02:13s
epoch 13 | loss: 0.27708 | val_0_rmse: 0.51755 | val_1_rmse: 0.52594 |  0:02:23s
epoch 14 | loss: 0.27746 | val_0_rmse: 0.51871 | val_1_rmse: 0.53035 |  0:02:33s
epoch 15 | loss: 0.2735  | val_0_rmse: 0.51107 | val_1_rmse: 0.5209  |  0:02:44s
epoch 16 | loss: 0.26899 | val_0_rmse: 0.51733 | val_1_rmse: 0.53193 |  0:02:54s
epoch 17 | loss: 0.26903 | val_0_rmse: 0.5246  | val_1_rmse: 0.53786 |  0:03:04s
epoch 18 | loss: 0.27495 | val_0_rmse: 0.52075 | val_1_rmse: 0.53427 |  0:03:15s
epoch 19 | loss: 0.27045 | val_0_rmse: 0.50732 | val_1_rmse: 0.52144 |  0:03:25s
epoch 20 | loss: 0.2727  | val_0_rmse: 0.53215 | val_1_rmse: 0.54335 |  0:03:35s
epoch 21 | loss: 0.27413 | val_0_rmse: 0.51    | val_1_rmse: 0.52358 |  0:03:46s
epoch 22 | loss: 0.27098 | val_0_rmse: 0.50751 | val_1_rmse: 0.51927 |  0:03:56s
epoch 23 | loss: 0.26941 | val_0_rmse: 0.50313 | val_1_rmse: 0.51534 |  0:04:06s
epoch 24 | loss: 0.26427 | val_0_rmse: 0.50514 | val_1_rmse: 0.52079 |  0:04:16s
epoch 25 | loss: 0.2619  | val_0_rmse: 0.50193 | val_1_rmse: 0.51813 |  0:04:27s
epoch 26 | loss: 0.26119 | val_0_rmse: 0.50393 | val_1_rmse: 0.51904 |  0:04:37s
epoch 27 | loss: 0.26486 | val_0_rmse: 0.50726 | val_1_rmse: 0.52152 |  0:04:47s
epoch 28 | loss: 0.25935 | val_0_rmse: 0.49933 | val_1_rmse: 0.51432 |  0:04:57s
epoch 29 | loss: 0.26322 | val_0_rmse: 0.50435 | val_1_rmse: 0.52518 |  0:05:08s
epoch 30 | loss: 0.25763 | val_0_rmse: 0.50806 | val_1_rmse: 0.53935 |  0:05:18s
epoch 31 | loss: 0.26021 | val_0_rmse: 0.49545 | val_1_rmse: 0.51213 |  0:05:29s
epoch 32 | loss: 0.25843 | val_0_rmse: 0.496   | val_1_rmse: 0.51733 |  0:05:39s
epoch 33 | loss: 0.25512 | val_0_rmse: 0.50762 | val_1_rmse: 0.52712 |  0:05:49s
epoch 34 | loss: 0.25485 | val_0_rmse: 0.50929 | val_1_rmse: 0.53092 |  0:06:00s
epoch 35 | loss: 0.25372 | val_0_rmse: 0.49599 | val_1_rmse: 0.51287 |  0:06:10s
epoch 36 | loss: 0.253   | val_0_rmse: 0.49432 | val_1_rmse: 0.51207 |  0:06:20s
epoch 37 | loss: 0.25134 | val_0_rmse: 0.49132 | val_1_rmse: 0.51176 |  0:06:31s
epoch 38 | loss: 0.25737 | val_0_rmse: 0.50903 | val_1_rmse: 0.5253  |  0:06:41s
epoch 39 | loss: 0.25794 | val_0_rmse: 0.50349 | val_1_rmse: 0.5203  |  0:06:51s
epoch 40 | loss: 0.25375 | val_0_rmse: 0.49654 | val_1_rmse: 0.51544 |  0:07:01s
epoch 41 | loss: 0.25216 | val_0_rmse: 0.49777 | val_1_rmse: 0.51679 |  0:07:12s
epoch 42 | loss: 0.25385 | val_0_rmse: 0.49962 | val_1_rmse: 0.52205 |  0:07:22s
epoch 43 | loss: 0.25275 | val_0_rmse: 0.4973  | val_1_rmse: 0.51728 |  0:07:32s
epoch 44 | loss: 0.25087 | val_0_rmse: 0.50872 | val_1_rmse: 0.52844 |  0:07:42s
epoch 45 | loss: 0.25234 | val_0_rmse: 0.48983 | val_1_rmse: 0.51412 |  0:07:53s
epoch 46 | loss: 0.24923 | val_0_rmse: 0.50882 | val_1_rmse: 0.53258 |  0:08:03s
epoch 47 | loss: 0.24906 | val_0_rmse: 0.49097 | val_1_rmse: 0.51469 |  0:08:13s
epoch 48 | loss: 0.2585  | val_0_rmse: 0.49757 | val_1_rmse: 0.51926 |  0:08:24s
epoch 49 | loss: 0.25227 | val_0_rmse: 0.48981 | val_1_rmse: 0.51362 |  0:08:34s
epoch 50 | loss: 0.24934 | val_0_rmse: 0.49336 | val_1_rmse: 0.5146  |  0:08:44s
epoch 51 | loss: 0.25019 | val_0_rmse: 0.48959 | val_1_rmse: 0.51236 |  0:08:54s
epoch 52 | loss: 0.24763 | val_0_rmse: 0.49734 | val_1_rmse: 0.52043 |  0:09:05s
epoch 53 | loss: 0.24538 | val_0_rmse: 0.48445 | val_1_rmse: 0.50973 |  0:09:15s
epoch 54 | loss: 0.24948 | val_0_rmse: 0.49219 | val_1_rmse: 0.51083 |  0:09:25s
epoch 55 | loss: 0.25011 | val_0_rmse: 0.49536 | val_1_rmse: 0.52151 |  0:09:35s
epoch 56 | loss: 0.24734 | val_0_rmse: 0.49631 | val_1_rmse: 0.53532 |  0:09:46s
epoch 57 | loss: 0.2499  | val_0_rmse: 0.9295  | val_1_rmse: 1.66262 |  0:09:56s
epoch 58 | loss: 0.25668 | val_0_rmse: 0.5392  | val_1_rmse: 0.55591 |  0:10:06s
epoch 59 | loss: 0.2678  | val_0_rmse: 0.50403 | val_1_rmse: 0.52518 |  0:10:16s
epoch 60 | loss: 0.25901 | val_0_rmse: 0.49346 | val_1_rmse: 0.51366 |  0:10:27s
epoch 61 | loss: 0.2527  | val_0_rmse: 0.49242 | val_1_rmse: 0.51436 |  0:10:37s
epoch 62 | loss: 0.25488 | val_0_rmse: 0.51303 | val_1_rmse: 0.53166 |  0:10:47s
epoch 63 | loss: 0.2549  | val_0_rmse: 0.50235 | val_1_rmse: 0.52365 |  0:10:57s
epoch 64 | loss: 0.25244 | val_0_rmse: 0.48944 | val_1_rmse: 0.51671 |  0:11:08s
epoch 65 | loss: 0.24947 | val_0_rmse: 0.48517 | val_1_rmse: 0.51428 |  0:11:18s
epoch 66 | loss: 0.25507 | val_0_rmse: 0.56116 | val_1_rmse: 0.55538 |  0:11:28s
epoch 67 | loss: 0.2498  | val_0_rmse: 0.48647 | val_1_rmse: 0.51424 |  0:11:38s
epoch 68 | loss: 0.2478  | val_0_rmse: 0.4846  | val_1_rmse: 0.51376 |  0:11:49s
epoch 69 | loss: 0.24471 | val_0_rmse: 0.48056 | val_1_rmse: 0.51112 |  0:11:59s
epoch 70 | loss: 0.24233 | val_0_rmse: 0.49037 | val_1_rmse: 0.52053 |  0:12:09s
epoch 71 | loss: 0.2405  | val_0_rmse: 0.48716 | val_1_rmse: 0.51797 |  0:12:20s
epoch 72 | loss: 0.24076 | val_0_rmse: 0.48481 | val_1_rmse: 0.51626 |  0:12:30s
epoch 73 | loss: 0.24098 | val_0_rmse: 0.49131 | val_1_rmse: 0.52106 |  0:12:40s
epoch 74 | loss: 0.24082 | val_0_rmse: 0.48032 | val_1_rmse: 0.5129  |  0:12:51s
epoch 75 | loss: 0.24884 | val_0_rmse: 0.4857  | val_1_rmse: 0.51387 |  0:13:01s
epoch 76 | loss: 0.24301 | val_0_rmse: 0.48367 | val_1_rmse: 0.51482 |  0:13:11s
epoch 77 | loss: 0.24109 | val_0_rmse: 0.48664 | val_1_rmse: 0.52096 |  0:13:22s
epoch 78 | loss: 0.2476  | val_0_rmse: 0.5326  | val_1_rmse: 0.61261 |  0:13:32s
epoch 79 | loss: 0.24404 | val_0_rmse: 0.50448 | val_1_rmse: 0.55581 |  0:13:42s
epoch 80 | loss: 0.24148 | val_0_rmse: 0.48999 | val_1_rmse: 0.52094 |  0:13:53s
epoch 81 | loss: 0.24213 | val_0_rmse: 0.48436 | val_1_rmse: 0.51624 |  0:14:03s
epoch 82 | loss: 0.24149 | val_0_rmse: 0.49577 | val_1_rmse: 0.5255  |  0:14:14s
epoch 83 | loss: 0.24127 | val_0_rmse: 0.49483 | val_1_rmse: 0.52847 |  0:14:24s

Early stopping occured at epoch 83 with best_epoch = 53 and best_val_1_rmse = 0.50973
Best weights from best epoch are automatically used!
ended training at: 06:56:29
Feature importance:
Mean squared error is of 1784429753.2586393
Mean absolute error:30628.44577856409
MAPE:0.28658898889300394
R2 score:0.7352533599865405
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 8
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 06:56:30
epoch 0  | loss: 0.71484 | val_0_rmse: 0.74199 | val_1_rmse: 0.74113 |  0:00:10s
epoch 1  | loss: 0.39047 | val_0_rmse: 0.68632 | val_1_rmse: 0.68769 |  0:00:20s
epoch 2  | loss: 0.35534 | val_0_rmse: 0.62194 | val_1_rmse: 0.62667 |  0:00:31s
epoch 3  | loss: 0.32261 | val_0_rmse: 0.57178 | val_1_rmse: 0.5747  |  0:00:41s
epoch 4  | loss: 0.30789 | val_0_rmse: 0.57046 | val_1_rmse: 0.5765  |  0:00:51s
epoch 5  | loss: 0.30217 | val_0_rmse: 0.54085 | val_1_rmse: 0.55045 |  0:01:01s
epoch 6  | loss: 0.29443 | val_0_rmse: 0.53092 | val_1_rmse: 0.54211 |  0:01:12s
epoch 7  | loss: 0.28686 | val_0_rmse: 0.52911 | val_1_rmse: 0.53729 |  0:01:22s
epoch 8  | loss: 0.29492 | val_0_rmse: 0.53059 | val_1_rmse: 0.54459 |  0:01:32s
epoch 9  | loss: 0.28915 | val_0_rmse: 0.51873 | val_1_rmse: 0.53185 |  0:01:42s
epoch 10 | loss: 0.28514 | val_0_rmse: 0.51651 | val_1_rmse: 0.53042 |  0:01:53s
epoch 11 | loss: 0.28264 | val_0_rmse: 0.51963 | val_1_rmse: 0.52987 |  0:02:03s
epoch 12 | loss: 0.28057 | val_0_rmse: 0.56764 | val_1_rmse: 0.58952 |  0:02:13s
epoch 13 | loss: 0.27584 | val_0_rmse: 0.51739 | val_1_rmse: 0.53246 |  0:02:24s
epoch 14 | loss: 0.27344 | val_0_rmse: 0.51824 | val_1_rmse: 0.53204 |  0:02:34s
epoch 15 | loss: 0.2713  | val_0_rmse: 0.50777 | val_1_rmse: 0.5236  |  0:02:44s
epoch 16 | loss: 0.27006 | val_0_rmse: 0.50783 | val_1_rmse: 0.52292 |  0:02:54s
epoch 17 | loss: 0.2671  | val_0_rmse: 0.50471 | val_1_rmse: 0.52151 |  0:03:05s
epoch 18 | loss: 0.27157 | val_0_rmse: 0.51256 | val_1_rmse: 0.52761 |  0:03:15s
epoch 19 | loss: 0.27011 | val_0_rmse: 0.50599 | val_1_rmse: 0.5234  |  0:03:25s
epoch 20 | loss: 0.26458 | val_0_rmse: 0.50072 | val_1_rmse: 0.52164 |  0:03:35s
epoch 21 | loss: 0.26473 | val_0_rmse: 0.51078 | val_1_rmse: 0.53243 |  0:03:45s
epoch 22 | loss: 0.26372 | val_0_rmse: 0.50602 | val_1_rmse: 0.52969 |  0:03:56s
epoch 23 | loss: 0.2601  | val_0_rmse: 0.49767 | val_1_rmse: 0.51734 |  0:04:06s
epoch 24 | loss: 0.25729 | val_0_rmse: 0.50936 | val_1_rmse: 0.53192 |  0:04:16s
epoch 25 | loss: 0.2584  | val_0_rmse: 0.49605 | val_1_rmse: 0.51605 |  0:04:27s
epoch 26 | loss: 0.25731 | val_0_rmse: 0.50337 | val_1_rmse: 0.52206 |  0:04:37s
epoch 27 | loss: 0.25694 | val_0_rmse: 0.50966 | val_1_rmse: 0.53085 |  0:04:47s
epoch 28 | loss: 0.25358 | val_0_rmse: 0.50388 | val_1_rmse: 0.52636 |  0:04:57s
epoch 29 | loss: 0.25324 | val_0_rmse: 0.49559 | val_1_rmse: 0.52212 |  0:05:08s
epoch 30 | loss: 0.25561 | val_0_rmse: 0.49535 | val_1_rmse: 0.51935 |  0:05:18s
epoch 31 | loss: 0.25364 | val_0_rmse: 0.49576 | val_1_rmse: 0.52068 |  0:05:28s
epoch 32 | loss: 0.25343 | val_0_rmse: 0.49118 | val_1_rmse: 0.5178  |  0:05:39s
epoch 33 | loss: 0.25154 | val_0_rmse: 0.49775 | val_1_rmse: 0.52249 |  0:05:49s
epoch 34 | loss: 0.24971 | val_0_rmse: 0.48719 | val_1_rmse: 0.51428 |  0:05:59s
epoch 35 | loss: 0.24754 | val_0_rmse: 0.49074 | val_1_rmse: 0.5172  |  0:06:09s
epoch 36 | loss: 0.25035 | val_0_rmse: 0.48816 | val_1_rmse: 0.51531 |  0:06:19s
epoch 37 | loss: 0.24787 | val_0_rmse: 0.48949 | val_1_rmse: 0.51726 |  0:06:30s
epoch 38 | loss: 0.24892 | val_0_rmse: 0.49366 | val_1_rmse: 0.5198  |  0:06:40s
epoch 39 | loss: 0.24706 | val_0_rmse: 0.49493 | val_1_rmse: 0.529   |  0:06:50s
epoch 40 | loss: 0.24637 | val_0_rmse: 0.48817 | val_1_rmse: 0.51964 |  0:07:00s
epoch 41 | loss: 0.24529 | val_0_rmse: 0.48346 | val_1_rmse: 0.51614 |  0:07:11s
epoch 42 | loss: 0.24445 | val_0_rmse: 0.48702 | val_1_rmse: 0.51699 |  0:07:21s
epoch 43 | loss: 0.24751 | val_0_rmse: 0.5121  | val_1_rmse: 0.54492 |  0:07:31s
epoch 44 | loss: 0.24528 | val_0_rmse: 0.49319 | val_1_rmse: 0.52809 |  0:07:42s
epoch 45 | loss: 0.24315 | val_0_rmse: 0.48061 | val_1_rmse: 0.51534 |  0:07:52s
epoch 46 | loss: 0.24479 | val_0_rmse: 0.48626 | val_1_rmse: 0.51971 |  0:08:02s
epoch 47 | loss: 0.24401 | val_0_rmse: 0.4968  | val_1_rmse: 0.53534 |  0:08:13s
epoch 48 | loss: 0.24466 | val_0_rmse: 0.49389 | val_1_rmse: 0.52703 |  0:08:23s
epoch 49 | loss: 0.24868 | val_0_rmse: 0.48256 | val_1_rmse: 0.51732 |  0:08:33s
epoch 50 | loss: 0.2455  | val_0_rmse: 0.48579 | val_1_rmse: 0.52203 |  0:08:43s
epoch 51 | loss: 0.24117 | val_0_rmse: 0.49258 | val_1_rmse: 0.5282  |  0:08:54s
epoch 52 | loss: 0.24193 | val_0_rmse: 0.48081 | val_1_rmse: 0.52077 |  0:09:04s
epoch 53 | loss: 0.24112 | val_0_rmse: 0.4793  | val_1_rmse: 0.51901 |  0:09:14s
epoch 54 | loss: 0.23967 | val_0_rmse: 0.47798 | val_1_rmse: 0.51561 |  0:09:25s
epoch 55 | loss: 0.23855 | val_0_rmse: 0.47587 | val_1_rmse: 0.51458 |  0:09:35s
epoch 56 | loss: 0.2432  | val_0_rmse: 0.49141 | val_1_rmse: 0.52687 |  0:09:45s
epoch 57 | loss: 0.24059 | val_0_rmse: 0.48052 | val_1_rmse: 0.51878 |  0:09:56s
epoch 58 | loss: 0.2385  | val_0_rmse: 0.47863 | val_1_rmse: 0.51904 |  0:10:06s
epoch 59 | loss: 0.23822 | val_0_rmse: 0.47508 | val_1_rmse: 0.51636 |  0:10:16s
epoch 60 | loss: 0.23694 | val_0_rmse: 0.48001 | val_1_rmse: 0.52144 |  0:10:27s
epoch 61 | loss: 0.23945 | val_0_rmse: 0.48153 | val_1_rmse: 0.52277 |  0:10:37s
epoch 62 | loss: 0.23586 | val_0_rmse: 0.49563 | val_1_rmse: 0.53326 |  0:10:47s
epoch 63 | loss: 0.23573 | val_0_rmse: 0.47625 | val_1_rmse: 0.52425 |  0:10:57s
epoch 64 | loss: 0.23641 | val_0_rmse: 0.4765  | val_1_rmse: 0.52168 |  0:11:08s

Early stopping occured at epoch 64 with best_epoch = 34 and best_val_1_rmse = 0.51428
Best weights from best epoch are automatically used!
ended training at: 07:07:42
Feature importance:
Mean squared error is of 1794770626.379909
Mean absolute error:30544.61071408507
MAPE:0.2869968824229617
R2 score:0.7339896977712111
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: ar properties.csv
Using seed = 9
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:07:44
epoch 0  | loss: 0.67563 | val_0_rmse: 0.76059 | val_1_rmse: 0.76792 |  0:00:10s
epoch 1  | loss: 0.33102 | val_0_rmse: 0.67437 | val_1_rmse: 0.68049 |  0:00:20s
epoch 2  | loss: 0.30663 | val_0_rmse: 0.60919 | val_1_rmse: 0.61416 |  0:00:30s
epoch 3  | loss: 0.29669 | val_0_rmse: 0.58008 | val_1_rmse: 0.58393 |  0:00:41s
epoch 4  | loss: 0.29113 | val_0_rmse: 0.56401 | val_1_rmse: 0.56727 |  0:00:51s
epoch 5  | loss: 0.28325 | val_0_rmse: 0.53524 | val_1_rmse: 0.53981 |  0:01:01s
epoch 6  | loss: 0.2805  | val_0_rmse: 0.53203 | val_1_rmse: 0.53521 |  0:01:12s
epoch 7  | loss: 0.27822 | val_0_rmse: 0.51055 | val_1_rmse: 0.52484 |  0:01:22s
epoch 8  | loss: 0.27462 | val_0_rmse: 0.50972 | val_1_rmse: 0.55431 |  0:01:32s
epoch 9  | loss: 0.27142 | val_0_rmse: 0.50769 | val_1_rmse: 0.55827 |  0:01:43s
epoch 10 | loss: 0.26897 | val_0_rmse: 0.51243 | val_1_rmse: 0.5312  |  0:01:53s
epoch 11 | loss: 0.26888 | val_0_rmse: 0.5093  | val_1_rmse: 0.51902 |  0:02:03s
epoch 12 | loss: 0.26733 | val_0_rmse: 0.53089 | val_1_rmse: 0.55239 |  0:02:14s
epoch 13 | loss: 0.267   | val_0_rmse: 0.53718 | val_1_rmse: 0.54918 |  0:02:24s
epoch 14 | loss: 0.26455 | val_0_rmse: 0.52274 | val_1_rmse: 0.52239 |  0:02:34s
epoch 15 | loss: 0.26301 | val_0_rmse: 0.51009 | val_1_rmse: 0.52766 |  0:02:44s
epoch 16 | loss: 0.25925 | val_0_rmse: 0.52609 | val_1_rmse: 0.55667 |  0:02:55s
epoch 17 | loss: 0.2598  | val_0_rmse: 0.5235  | val_1_rmse: 0.63948 |  0:03:05s
epoch 18 | loss: 0.26018 | val_0_rmse: 0.54186 | val_1_rmse: 0.61835 |  0:03:15s
epoch 19 | loss: 0.26023 | val_0_rmse: 0.58398 | val_1_rmse: 0.78437 |  0:03:26s
epoch 20 | loss: 0.25799 | val_0_rmse: 0.50687 | val_1_rmse: 0.59127 |  0:03:36s
epoch 21 | loss: 0.25825 | val_0_rmse: 0.4917  | val_1_rmse: 0.59438 |  0:03:46s
epoch 22 | loss: 0.25729 | val_0_rmse: 0.50485 | val_1_rmse: 0.52254 |  0:03:56s
epoch 23 | loss: 0.25557 | val_0_rmse: 0.49735 | val_1_rmse: 0.51817 |  0:04:07s
epoch 24 | loss: 0.25657 | val_0_rmse: 0.50512 | val_1_rmse: 0.52356 |  0:04:17s
epoch 25 | loss: 0.25511 | val_0_rmse: 0.49359 | val_1_rmse: 0.59123 |  0:04:28s
epoch 26 | loss: 0.25448 | val_0_rmse: 0.49086 | val_1_rmse: 0.58676 |  0:04:38s
epoch 27 | loss: 0.25252 | val_0_rmse: 0.54941 | val_1_rmse: 0.60485 |  0:04:48s
epoch 28 | loss: 0.25056 | val_0_rmse: 0.48685 | val_1_rmse: 1.13861 |  0:04:59s
epoch 29 | loss: 0.25113 | val_0_rmse: 0.48595 | val_1_rmse: 1.11964 |  0:05:09s
epoch 30 | loss: 0.24886 | val_0_rmse: 0.48697 | val_1_rmse: 0.57339 |  0:05:19s
epoch 31 | loss: 0.2486  | val_0_rmse: 0.49319 | val_1_rmse: 1.1954  |  0:05:30s
epoch 32 | loss: 0.249   | val_0_rmse: 0.53499 | val_1_rmse: 1.0101  |  0:05:40s
epoch 33 | loss: 0.24833 | val_0_rmse: 0.48483 | val_1_rmse: 0.51349 |  0:05:50s
epoch 34 | loss: 0.24512 | val_0_rmse: 0.49411 | val_1_rmse: 1.18493 |  0:06:01s
epoch 35 | loss: 0.24691 | val_0_rmse: 0.49706 | val_1_rmse: 1.30058 |  0:06:11s
epoch 36 | loss: 0.24806 | val_0_rmse: 0.4953  | val_1_rmse: 1.57031 |  0:06:21s
epoch 37 | loss: 0.24578 | val_0_rmse: 0.48057 | val_1_rmse: 0.97539 |  0:06:32s
epoch 38 | loss: 0.24661 | val_0_rmse: 0.56538 | val_1_rmse: 1.64637 |  0:06:42s
epoch 39 | loss: 0.25302 | val_0_rmse: 0.516   | val_1_rmse: 0.88057 |  0:06:52s
epoch 40 | loss: 0.24912 | val_0_rmse: 0.48702 | val_1_rmse: 0.63066 |  0:07:02s
epoch 41 | loss: 0.2451  | val_0_rmse: 0.51737 | val_1_rmse: 0.54363 |  0:07:13s
epoch 42 | loss: 0.24199 | val_0_rmse: 0.49936 | val_1_rmse: 0.5604  |  0:07:23s
epoch 43 | loss: 0.24256 | val_0_rmse: 0.49408 | val_1_rmse: 0.53211 |  0:07:34s
epoch 44 | loss: 0.24107 | val_0_rmse: 0.4807  | val_1_rmse: 0.56725 |  0:07:44s
epoch 45 | loss: 0.24135 | val_0_rmse: 0.48039 | val_1_rmse: 0.56061 |  0:07:54s
epoch 46 | loss: 0.24221 | val_0_rmse: 0.50697 | val_1_rmse: 0.76832 |  0:08:05s
epoch 47 | loss: 0.24666 | val_0_rmse: 0.53659 | val_1_rmse: 0.56487 |  0:08:15s
epoch 48 | loss: 0.25504 | val_0_rmse: 0.51714 | val_1_rmse: 0.51374 |  0:08:25s
epoch 49 | loss: 0.24374 | val_0_rmse: 0.48025 | val_1_rmse: 0.51203 |  0:08:36s
epoch 50 | loss: 0.24365 | val_0_rmse: 0.4802  | val_1_rmse: 0.5165  |  0:08:46s
epoch 51 | loss: 0.24103 | val_0_rmse: 0.48288 | val_1_rmse: 0.51203 |  0:08:56s
epoch 52 | loss: 0.23829 | val_0_rmse: 0.68492 | val_1_rmse: 0.52898 |  0:09:07s
epoch 53 | loss: 0.24086 | val_0_rmse: 0.50475 | val_1_rmse: 0.77631 |  0:09:17s
epoch 54 | loss: 0.27661 | val_0_rmse: 0.49726 | val_1_rmse: 0.63616 |  0:09:27s
epoch 55 | loss: 0.25689 | val_0_rmse: 0.50222 | val_1_rmse: 0.63621 |  0:09:38s
epoch 56 | loss: 0.24885 | val_0_rmse: 0.49243 | val_1_rmse: 0.52426 |  0:09:48s
epoch 57 | loss: 0.25151 | val_0_rmse: 0.50348 | val_1_rmse: 0.53985 |  0:09:58s
epoch 58 | loss: 0.24611 | val_0_rmse: 0.48423 | val_1_rmse: 0.52603 |  0:10:09s
epoch 59 | loss: 0.2412  | val_0_rmse: 0.48524 | val_1_rmse: 0.55994 |  0:10:19s
epoch 60 | loss: 0.24136 | val_0_rmse: 0.48485 | val_1_rmse: 0.52771 |  0:10:29s
epoch 61 | loss: 0.23748 | val_0_rmse: 0.48635 | val_1_rmse: 0.54113 |  0:10:40s
epoch 62 | loss: 0.24007 | val_0_rmse: 0.50227 | val_1_rmse: 0.60051 |  0:10:50s
epoch 63 | loss: 0.23881 | val_0_rmse: 0.54872 | val_1_rmse: 0.62895 |  0:11:00s
epoch 64 | loss: 0.23703 | val_0_rmse: 0.49476 | val_1_rmse: 0.54336 |  0:11:10s
epoch 65 | loss: 0.23833 | val_0_rmse: 0.48243 | val_1_rmse: 0.53665 |  0:11:21s
epoch 66 | loss: 0.23702 | val_0_rmse: 0.51002 | val_1_rmse: 0.56387 |  0:11:31s
epoch 67 | loss: 0.23675 | val_0_rmse: 0.47676 | val_1_rmse: 0.52171 |  0:11:41s
epoch 68 | loss: 0.23446 | val_0_rmse: 0.48142 | val_1_rmse: 0.53637 |  0:11:52s
epoch 69 | loss: 0.23528 | val_0_rmse: 0.48844 | val_1_rmse: 0.5788  |  0:12:02s
epoch 70 | loss: 0.23551 | val_0_rmse: 0.47103 | val_1_rmse: 0.52195 |  0:12:12s
epoch 71 | loss: 0.23463 | val_0_rmse: 0.48576 | val_1_rmse: 0.5585  |  0:12:23s
epoch 72 | loss: 0.23466 | val_0_rmse: 0.47564 | val_1_rmse: 0.53221 |  0:12:33s
epoch 73 | loss: 0.23413 | val_0_rmse: 0.47326 | val_1_rmse: 0.52831 |  0:12:43s
epoch 74 | loss: 0.23319 | val_0_rmse: 0.49361 | val_1_rmse: 0.63115 |  0:12:54s
epoch 75 | loss: 0.23341 | val_0_rmse: 0.49381 | val_1_rmse: 0.64815 |  0:13:04s
epoch 76 | loss: 0.23348 | val_0_rmse: 0.46947 | val_1_rmse: 0.58995 |  0:13:14s
epoch 77 | loss: 0.23293 | val_0_rmse: 0.4747  | val_1_rmse: 0.53841 |  0:13:25s
epoch 78 | loss: 0.23227 | val_0_rmse: 0.48212 | val_1_rmse: 0.59593 |  0:13:35s
epoch 79 | loss: 0.23064 | val_0_rmse: 0.47272 | val_1_rmse: 0.5578  |  0:13:45s
epoch 80 | loss: 0.23161 | val_0_rmse: 0.49788 | val_1_rmse: 0.53146 |  0:13:55s
epoch 81 | loss: 0.23152 | val_0_rmse: 0.469   | val_1_rmse: 0.5223  |  0:14:06s

Early stopping occured at epoch 81 with best_epoch = 51 and best_val_1_rmse = 0.51203
Best weights from best epoch are automatically used!
ended training at: 07:21:54
Feature importance:
Mean squared error is of 1825013819.4839723
Mean absolute error:30284.31162058536
MAPE:0.2774326144936879
R2 score:0.7273214358154813
------------------------------------------------------------------
Normalization used is StandardScaler
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 0
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:21:55
epoch 0  | loss: 0.84733 | val_0_rmse: 0.71618 | val_1_rmse: 0.72732 |  0:00:03s
epoch 1  | loss: 0.38756 | val_0_rmse: 0.64186 | val_1_rmse: 0.64597 |  0:00:06s
epoch 2  | loss: 0.32012 | val_0_rmse: 0.60566 | val_1_rmse: 0.60823 |  0:00:10s
epoch 3  | loss: 0.29767 | val_0_rmse: 0.55735 | val_1_rmse: 0.55859 |  0:00:13s
epoch 4  | loss: 0.28425 | val_0_rmse: 0.56535 | val_1_rmse: 0.5646  |  0:00:16s
epoch 5  | loss: 0.26873 | val_0_rmse: 0.53398 | val_1_rmse: 0.53543 |  0:00:20s
epoch 6  | loss: 0.26961 | val_0_rmse: 0.56793 | val_1_rmse: 0.56684 |  0:00:23s
epoch 7  | loss: 0.26714 | val_0_rmse: 0.50607 | val_1_rmse: 0.50637 |  0:00:26s
epoch 8  | loss: 0.25631 | val_0_rmse: 0.53293 | val_1_rmse: 0.53291 |  0:00:30s
epoch 9  | loss: 0.24948 | val_0_rmse: 0.52089 | val_1_rmse: 0.52115 |  0:00:33s
epoch 10 | loss: 0.2512  | val_0_rmse: 0.5382  | val_1_rmse: 0.53861 |  0:00:36s
epoch 11 | loss: 0.24742 | val_0_rmse: 0.49537 | val_1_rmse: 0.4987  |  0:00:40s
epoch 12 | loss: 0.24542 | val_0_rmse: 0.49097 | val_1_rmse: 0.4965  |  0:00:43s
epoch 13 | loss: 0.24171 | val_0_rmse: 0.48169 | val_1_rmse: 0.48883 |  0:00:46s
epoch 14 | loss: 0.23629 | val_0_rmse: 0.47884 | val_1_rmse: 0.48347 |  0:00:50s
epoch 15 | loss: 0.23718 | val_0_rmse: 0.47942 | val_1_rmse: 0.48409 |  0:00:53s
epoch 16 | loss: 0.23738 | val_0_rmse: 0.48621 | val_1_rmse: 0.49232 |  0:00:56s
epoch 17 | loss: 0.23546 | val_0_rmse: 0.49315 | val_1_rmse: 0.50017 |  0:01:00s
epoch 18 | loss: 0.23435 | val_0_rmse: 0.52263 | val_1_rmse: 0.52933 |  0:01:03s
epoch 19 | loss: 0.23201 | val_0_rmse: 0.47042 | val_1_rmse: 0.4817  |  0:01:06s
epoch 20 | loss: 0.23129 | val_0_rmse: 0.47596 | val_1_rmse: 0.48343 |  0:01:10s
epoch 21 | loss: 0.23203 | val_0_rmse: 0.47325 | val_1_rmse: 0.48079 |  0:01:13s
epoch 22 | loss: 0.23448 | val_0_rmse: 0.56272 | val_1_rmse: 0.57864 |  0:01:17s
epoch 23 | loss: 0.231   | val_0_rmse: 0.46838 | val_1_rmse: 0.48028 |  0:01:20s
epoch 24 | loss: 0.22883 | val_0_rmse: 0.47425 | val_1_rmse: 0.49096 |  0:01:23s
epoch 25 | loss: 0.22873 | val_0_rmse: 0.46643 | val_1_rmse: 0.48088 |  0:01:27s
epoch 26 | loss: 0.23233 | val_0_rmse: 0.47615 | val_1_rmse: 0.49204 |  0:01:30s
epoch 27 | loss: 0.22661 | val_0_rmse: 0.48234 | val_1_rmse: 0.49467 |  0:01:33s
epoch 28 | loss: 0.2309  | val_0_rmse: 0.46869 | val_1_rmse: 0.48155 |  0:01:37s
epoch 29 | loss: 0.22716 | val_0_rmse: 0.46819 | val_1_rmse: 0.4843  |  0:01:40s
epoch 30 | loss: 0.22728 | val_0_rmse: 0.47669 | val_1_rmse: 0.49767 |  0:01:43s
epoch 31 | loss: 0.22456 | val_0_rmse: 0.47925 | val_1_rmse: 0.50059 |  0:01:47s
epoch 32 | loss: 0.22646 | val_0_rmse: 0.49934 | val_1_rmse: 0.51581 |  0:01:50s
epoch 33 | loss: 0.22597 | val_0_rmse: 0.46457 | val_1_rmse: 0.49874 |  0:01:53s
epoch 34 | loss: 0.2323  | val_0_rmse: 0.47374 | val_1_rmse: 0.48474 |  0:01:57s
epoch 35 | loss: 0.22443 | val_0_rmse: 0.46006 | val_1_rmse: 0.47854 |  0:02:00s
epoch 36 | loss: 0.22434 | val_0_rmse: 0.46013 | val_1_rmse: 0.47724 |  0:02:03s
epoch 37 | loss: 0.22439 | val_0_rmse: 0.45792 | val_1_rmse: 0.47703 |  0:02:07s
epoch 38 | loss: 0.22189 | val_0_rmse: 0.48287 | val_1_rmse: 0.49826 |  0:02:10s
epoch 39 | loss: 0.22185 | val_0_rmse: 0.46205 | val_1_rmse: 0.47983 |  0:02:13s
epoch 40 | loss: 0.2207  | val_0_rmse: 0.47319 | val_1_rmse: 0.48933 |  0:02:17s
epoch 41 | loss: 0.22191 | val_0_rmse: 0.45927 | val_1_rmse: 0.48099 |  0:02:20s
epoch 42 | loss: 0.22106 | val_0_rmse: 0.45612 | val_1_rmse: 0.47726 |  0:02:24s
epoch 43 | loss: 0.22129 | val_0_rmse: 0.46509 | val_1_rmse: 0.48204 |  0:02:27s
epoch 44 | loss: 0.22007 | val_0_rmse: 0.46563 | val_1_rmse: 0.48497 |  0:02:30s
epoch 45 | loss: 0.21713 | val_0_rmse: 0.46274 | val_1_rmse: 0.48282 |  0:02:33s
epoch 46 | loss: 0.21941 | val_0_rmse: 0.45426 | val_1_rmse: 0.47882 |  0:02:37s
epoch 47 | loss: 0.2192  | val_0_rmse: 0.4557  | val_1_rmse: 0.47742 |  0:02:40s
epoch 48 | loss: 0.21478 | val_0_rmse: 0.45379 | val_1_rmse: 0.47804 |  0:02:43s
epoch 49 | loss: 0.2209  | val_0_rmse: 0.46068 | val_1_rmse: 0.47971 |  0:02:47s
epoch 50 | loss: 0.216   | val_0_rmse: 0.52903 | val_1_rmse: 0.52508 |  0:02:50s
epoch 51 | loss: 0.22568 | val_0_rmse: 0.48065 | val_1_rmse: 0.48721 |  0:02:53s
epoch 52 | loss: 0.22002 | val_0_rmse: 0.4796  | val_1_rmse: 0.62333 |  0:02:57s
epoch 53 | loss: 0.22009 | val_0_rmse: 0.46473 | val_1_rmse: 1.07063 |  0:03:00s
epoch 54 | loss: 0.21692 | val_0_rmse: 0.45632 | val_1_rmse: 0.48727 |  0:03:03s
epoch 55 | loss: 0.21414 | val_0_rmse: 0.45281 | val_1_rmse: 0.47882 |  0:03:07s
epoch 56 | loss: 0.21584 | val_0_rmse: 0.45501 | val_1_rmse: 0.47985 |  0:03:10s
epoch 57 | loss: 0.21407 | val_0_rmse: 0.49182 | val_1_rmse: 0.51014 |  0:03:13s
epoch 58 | loss: 0.21212 | val_0_rmse: 0.46156 | val_1_rmse: 0.48637 |  0:03:17s
epoch 59 | loss: 0.21286 | val_0_rmse: 0.45465 | val_1_rmse: 0.53481 |  0:03:20s
epoch 60 | loss: 0.21083 | val_0_rmse: 0.45991 | val_1_rmse: 0.48788 |  0:03:23s
epoch 61 | loss: 0.2129  | val_0_rmse: 0.46494 | val_1_rmse: 0.49281 |  0:03:27s
epoch 62 | loss: 0.21447 | val_0_rmse: 0.45113 | val_1_rmse: 0.47802 |  0:03:30s
epoch 63 | loss: 0.21371 | val_0_rmse: 0.45786 | val_1_rmse: 0.48572 |  0:03:33s
epoch 64 | loss: 0.21143 | val_0_rmse: 0.44962 | val_1_rmse: 0.47829 |  0:03:37s
epoch 65 | loss: 0.21303 | val_0_rmse: 0.45314 | val_1_rmse: 0.4816  |  0:03:40s
epoch 66 | loss: 0.21185 | val_0_rmse: 0.44985 | val_1_rmse: 0.5513  |  0:03:44s
epoch 67 | loss: 0.21024 | val_0_rmse: 0.4516  | val_1_rmse: 0.48058 |  0:03:47s

Early stopping occured at epoch 67 with best_epoch = 37 and best_val_1_rmse = 0.47703
Best weights from best epoch are automatically used!
ended training at: 07:25:44
Feature importance:
Mean squared error is of 883764635.6111057
Mean absolute error:19979.110192137923
MAPE:0.23494277515214765
R2 score:0.7794059698974825
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 1
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:25:45
epoch 0  | loss: 0.81026 | val_0_rmse: 0.83422 | val_1_rmse: 0.84626 |  0:00:03s
epoch 1  | loss: 0.34888 | val_0_rmse: 0.64179 | val_1_rmse: 0.66076 |  0:00:06s
epoch 2  | loss: 0.31449 | val_0_rmse: 0.57707 | val_1_rmse: 0.58944 |  0:00:10s
epoch 3  | loss: 0.2895  | val_0_rmse: 0.5459  | val_1_rmse: 0.55683 |  0:00:13s
epoch 4  | loss: 0.27386 | val_0_rmse: 0.54736 | val_1_rmse: 0.55737 |  0:00:16s
epoch 5  | loss: 0.26794 | val_0_rmse: 0.52174 | val_1_rmse: 0.53285 |  0:00:20s
epoch 6  | loss: 0.27698 | val_0_rmse: 0.59218 | val_1_rmse: 0.60039 |  0:00:23s
epoch 7  | loss: 0.28037 | val_0_rmse: 0.54886 | val_1_rmse: 0.56139 |  0:00:26s
epoch 8  | loss: 0.26552 | val_0_rmse: 0.51103 | val_1_rmse: 0.5238  |  0:00:30s
epoch 9  | loss: 0.25947 | val_0_rmse: 0.50223 | val_1_rmse: 0.51537 |  0:00:33s
epoch 10 | loss: 0.25419 | val_0_rmse: 0.49695 | val_1_rmse: 0.51241 |  0:00:36s
epoch 11 | loss: 0.25479 | val_0_rmse: 0.51186 | val_1_rmse: 0.52928 |  0:00:40s
epoch 12 | loss: 0.25977 | val_0_rmse: 0.50808 | val_1_rmse: 0.52671 |  0:00:43s
epoch 13 | loss: 0.25748 | val_0_rmse: 0.49892 | val_1_rmse: 0.51616 |  0:00:46s
epoch 14 | loss: 0.2538  | val_0_rmse: 0.5035  | val_1_rmse: 0.52301 |  0:00:50s
epoch 15 | loss: 0.25331 | val_0_rmse: 0.50457 | val_1_rmse: 0.52592 |  0:00:53s
epoch 16 | loss: 0.25139 | val_0_rmse: 0.49246 | val_1_rmse: 0.51458 |  0:00:56s
epoch 17 | loss: 0.24912 | val_0_rmse: 0.50477 | val_1_rmse: 0.52495 |  0:01:00s
epoch 18 | loss: 0.24498 | val_0_rmse: 0.49036 | val_1_rmse: 0.51054 |  0:01:03s
epoch 19 | loss: 0.24356 | val_0_rmse: 0.49387 | val_1_rmse: 0.51454 |  0:01:07s
epoch 20 | loss: 0.24084 | val_0_rmse: 0.47909 | val_1_rmse: 0.50299 |  0:01:10s
epoch 21 | loss: 0.23925 | val_0_rmse: 0.47425 | val_1_rmse: 0.50083 |  0:01:13s
epoch 22 | loss: 0.23834 | val_0_rmse: 0.48166 | val_1_rmse: 0.50586 |  0:01:17s
epoch 23 | loss: 0.23615 | val_0_rmse: 0.47719 | val_1_rmse: 0.50078 |  0:01:20s
epoch 24 | loss: 0.23051 | val_0_rmse: 0.49162 | val_1_rmse: 0.51636 |  0:01:23s
epoch 25 | loss: 0.23836 | val_0_rmse: 0.47056 | val_1_rmse: 0.49474 |  0:01:26s
epoch 26 | loss: 0.2329  | val_0_rmse: 0.47033 | val_1_rmse: 0.49403 |  0:01:30s
epoch 27 | loss: 0.2331  | val_0_rmse: 0.47338 | val_1_rmse: 0.49684 |  0:01:33s
epoch 28 | loss: 0.23277 | val_0_rmse: 0.46687 | val_1_rmse: 0.49463 |  0:01:37s
epoch 29 | loss: 0.23056 | val_0_rmse: 0.46906 | val_1_rmse: 0.4952  |  0:01:40s
epoch 30 | loss: 0.23318 | val_0_rmse: 0.47784 | val_1_rmse: 0.50277 |  0:01:43s
epoch 31 | loss: 0.23615 | val_0_rmse: 0.47986 | val_1_rmse: 0.49349 |  0:01:47s
epoch 32 | loss: 0.23311 | val_0_rmse: 0.49289 | val_1_rmse: 0.50854 |  0:01:50s
epoch 33 | loss: 0.23543 | val_0_rmse: 0.51756 | val_1_rmse: 0.50771 |  0:01:53s
epoch 34 | loss: 0.24436 | val_0_rmse: 0.54283 | val_1_rmse: 0.5149  |  0:01:57s
epoch 35 | loss: 0.23459 | val_0_rmse: 0.49748 | val_1_rmse: 0.49675 |  0:02:00s
epoch 36 | loss: 0.24559 | val_0_rmse: 0.58284 | val_1_rmse: 0.55343 |  0:02:03s
epoch 37 | loss: 0.24569 | val_0_rmse: 0.49135 | val_1_rmse: 0.53928 |  0:02:07s
epoch 38 | loss: 0.24854 | val_0_rmse: 0.5241  | val_1_rmse: 0.59363 |  0:02:10s
epoch 39 | loss: 0.24055 | val_0_rmse: 0.47309 | val_1_rmse: 0.50586 |  0:02:13s
epoch 40 | loss: 0.23061 | val_0_rmse: 0.46993 | val_1_rmse: 0.55153 |  0:02:17s
epoch 41 | loss: 0.22802 | val_0_rmse: 0.46993 | val_1_rmse: 0.87001 |  0:02:20s
epoch 42 | loss: 0.22712 | val_0_rmse: 0.46471 | val_1_rmse: 1.10436 |  0:02:23s
epoch 43 | loss: 0.22625 | val_0_rmse: 0.47223 | val_1_rmse: 1.05006 |  0:02:27s
epoch 44 | loss: 0.22521 | val_0_rmse: 0.46685 | val_1_rmse: 1.24069 |  0:02:30s
epoch 45 | loss: 0.22165 | val_0_rmse: 0.46092 | val_1_rmse: 0.9252  |  0:02:33s
epoch 46 | loss: 0.22387 | val_0_rmse: 0.46184 | val_1_rmse: 1.04426 |  0:02:37s
epoch 47 | loss: 0.22432 | val_0_rmse: 0.47879 | val_1_rmse: 1.3802  |  0:02:40s
epoch 48 | loss: 0.22036 | val_0_rmse: 0.47808 | val_1_rmse: 1.06449 |  0:02:43s
epoch 49 | loss: 0.22073 | val_0_rmse: 0.46026 | val_1_rmse: 0.55024 |  0:02:47s
epoch 50 | loss: 0.22206 | val_0_rmse: 0.46569 | val_1_rmse: 0.49465 |  0:02:50s
epoch 51 | loss: 0.2222  | val_0_rmse: 0.46233 | val_1_rmse: 0.49312 |  0:02:53s
epoch 52 | loss: 0.224   | val_0_rmse: 0.45982 | val_1_rmse: 0.48819 |  0:02:57s
epoch 53 | loss: 0.22209 | val_0_rmse: 0.46962 | val_1_rmse: 0.49917 |  0:03:00s
epoch 54 | loss: 0.21951 | val_0_rmse: 0.5979  | val_1_rmse: 0.51637 |  0:03:03s
epoch 55 | loss: 0.22258 | val_0_rmse: 0.4646  | val_1_rmse: 0.49289 |  0:03:07s
epoch 56 | loss: 0.21888 | val_0_rmse: 0.504   | val_1_rmse: 0.4937  |  0:03:10s
epoch 57 | loss: 0.21925 | val_0_rmse: 0.47864 | val_1_rmse: 0.5176  |  0:03:14s
epoch 58 | loss: 0.21943 | val_0_rmse: 0.47232 | val_1_rmse: 0.50242 |  0:03:17s
epoch 59 | loss: 0.21705 | val_0_rmse: 0.4643  | val_1_rmse: 0.49712 |  0:03:20s
epoch 60 | loss: 0.21941 | val_0_rmse: 0.45908 | val_1_rmse: 0.50898 |  0:03:24s
epoch 61 | loss: 0.22215 | val_0_rmse: 0.46227 | val_1_rmse: 0.70009 |  0:03:27s
epoch 62 | loss: 0.21924 | val_0_rmse: 0.45761 | val_1_rmse: 0.57252 |  0:03:30s
epoch 63 | loss: 0.21495 | val_0_rmse: 0.462   | val_1_rmse: 0.76281 |  0:03:33s
epoch 64 | loss: 0.21698 | val_0_rmse: 0.49229 | val_1_rmse: 0.75843 |  0:03:37s
epoch 65 | loss: 0.21469 | val_0_rmse: 0.45983 | val_1_rmse: 0.48922 |  0:03:40s
epoch 66 | loss: 0.2155  | val_0_rmse: 0.47137 | val_1_rmse: 0.50225 |  0:03:44s
epoch 67 | loss: 0.21427 | val_0_rmse: 0.46049 | val_1_rmse: 0.49207 |  0:03:47s
epoch 68 | loss: 0.21239 | val_0_rmse: 0.47602 | val_1_rmse: 0.73663 |  0:03:50s
epoch 69 | loss: 0.21329 | val_0_rmse: 0.44977 | val_1_rmse: 0.80316 |  0:03:54s
epoch 70 | loss: 0.21069 | val_0_rmse: 0.45153 | val_1_rmse: 0.52303 |  0:03:57s
epoch 71 | loss: 0.21442 | val_0_rmse: 0.46555 | val_1_rmse: 0.50998 |  0:04:00s
epoch 72 | loss: 0.21121 | val_0_rmse: 0.45256 | val_1_rmse: 0.4874  |  0:04:04s
epoch 73 | loss: 0.21303 | val_0_rmse: 0.4517  | val_1_rmse: 0.48567 |  0:04:07s
epoch 74 | loss: 0.21544 | val_0_rmse: 0.45585 | val_1_rmse: 0.48979 |  0:04:10s
epoch 75 | loss: 0.20945 | val_0_rmse: 0.47577 | val_1_rmse: 0.507   |  0:04:14s
epoch 76 | loss: 0.21581 | val_0_rmse: 0.50262 | val_1_rmse: 0.5334  |  0:04:17s
epoch 77 | loss: 0.2132  | val_0_rmse: 0.47577 | val_1_rmse: 0.55999 |  0:04:21s
epoch 78 | loss: 0.21779 | val_0_rmse: 0.50457 | val_1_rmse: 0.53454 |  0:04:24s
epoch 79 | loss: 0.22467 | val_0_rmse: 0.46438 | val_1_rmse: 0.49834 |  0:04:27s
epoch 80 | loss: 0.21835 | val_0_rmse: 0.46063 | val_1_rmse: 0.49184 |  0:04:31s
epoch 81 | loss: 0.21518 | val_0_rmse: 0.49808 | val_1_rmse: 0.52746 |  0:04:34s
epoch 82 | loss: 0.21472 | val_0_rmse: 0.46489 | val_1_rmse: 0.4999  |  0:04:37s
epoch 83 | loss: 0.21241 | val_0_rmse: 0.46572 | val_1_rmse: 0.50196 |  0:04:41s
epoch 84 | loss: 0.21372 | val_0_rmse: 0.4968  | val_1_rmse: 0.52831 |  0:04:44s
epoch 85 | loss: 0.21329 | val_0_rmse: 0.49726 | val_1_rmse: 0.53121 |  0:04:48s
epoch 86 | loss: 0.21189 | val_0_rmse: 0.45162 | val_1_rmse: 0.49574 |  0:04:51s
epoch 87 | loss: 0.21058 | val_0_rmse: 0.45939 | val_1_rmse: 0.50596 |  0:04:54s
epoch 88 | loss: 0.21201 | val_0_rmse: 0.45134 | val_1_rmse: 0.49766 |  0:04:58s
epoch 89 | loss: 0.21052 | val_0_rmse: 0.46911 | val_1_rmse: 0.52056 |  0:05:01s
epoch 90 | loss: 0.21192 | val_0_rmse: 0.48145 | val_1_rmse: 0.54501 |  0:05:04s
epoch 91 | loss: 0.20933 | val_0_rmse: 0.45481 | val_1_rmse: 0.51825 |  0:05:08s
epoch 92 | loss: 0.20804 | val_0_rmse: 0.46414 | val_1_rmse: 0.52448 |  0:05:11s
epoch 93 | loss: 0.20868 | val_0_rmse: 0.45631 | val_1_rmse: 0.51697 |  0:05:14s
epoch 94 | loss: 0.20895 | val_0_rmse: 0.45055 | val_1_rmse: 0.53028 |  0:05:18s
epoch 95 | loss: 0.20454 | val_0_rmse: 0.45645 | val_1_rmse: 0.51145 |  0:05:21s
epoch 96 | loss: 0.20573 | val_0_rmse: 0.45962 | val_1_rmse: 0.55084 |  0:05:24s
epoch 97 | loss: 0.20862 | val_0_rmse: 0.48896 | val_1_rmse: 0.58763 |  0:05:28s
epoch 98 | loss: 0.21063 | val_0_rmse: 0.48235 | val_1_rmse: 0.54477 |  0:05:31s
epoch 99 | loss: 0.20822 | val_0_rmse: 0.46053 | val_1_rmse: 0.49876 |  0:05:34s
epoch 100| loss: 0.20721 | val_0_rmse: 0.47389 | val_1_rmse: 0.50094 |  0:05:38s
epoch 101| loss: 0.20884 | val_0_rmse: 0.51898 | val_1_rmse: 0.56533 |  0:05:41s
epoch 102| loss: 0.21141 | val_0_rmse: 0.56995 | val_1_rmse: 0.88672 |  0:05:44s
epoch 103| loss: 0.20472 | val_0_rmse: 0.46911 | val_1_rmse: 0.52544 |  0:05:47s

Early stopping occured at epoch 103 with best_epoch = 73 and best_val_1_rmse = 0.48567
Best weights from best epoch are automatically used!
ended training at: 07:31:34
Feature importance:
Mean squared error is of 889067525.3524001
Mean absolute error:20276.609282876878
MAPE:0.24709523448575174
R2 score:0.7705613876266586
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 2
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:31:34
epoch 0  | loss: 0.94924 | val_0_rmse: 1.71541 | val_1_rmse: 1.71484 |  0:00:03s
epoch 1  | loss: 0.40991 | val_0_rmse: 0.60366 | val_1_rmse: 0.60046 |  0:00:06s
epoch 2  | loss: 0.34487 | val_0_rmse: 0.60437 | val_1_rmse: 0.59145 |  0:00:09s
epoch 3  | loss: 0.30234 | val_0_rmse: 0.57395 | val_1_rmse: 0.56118 |  0:00:13s
epoch 4  | loss: 0.30768 | val_0_rmse: 0.56211 | val_1_rmse: 0.54642 |  0:00:16s
epoch 5  | loss: 0.30201 | val_0_rmse: 0.60688 | val_1_rmse: 0.6007  |  0:00:20s
epoch 6  | loss: 0.29258 | val_0_rmse: 0.53394 | val_1_rmse: 0.52219 |  0:00:23s
epoch 7  | loss: 0.2733  | val_0_rmse: 0.52544 | val_1_rmse: 0.5116  |  0:00:26s
epoch 8  | loss: 0.26775 | val_0_rmse: 0.5223  | val_1_rmse: 0.50867 |  0:00:29s
epoch 9  | loss: 0.2709  | val_0_rmse: 0.51733 | val_1_rmse: 0.50571 |  0:00:33s
epoch 10 | loss: 0.2722  | val_0_rmse: 0.52938 | val_1_rmse: 0.52101 |  0:00:36s
epoch 11 | loss: 0.26618 | val_0_rmse: 0.52884 | val_1_rmse: 0.51863 |  0:00:39s
epoch 12 | loss: 0.25888 | val_0_rmse: 0.5026  | val_1_rmse: 0.49466 |  0:00:43s
epoch 13 | loss: 0.25856 | val_0_rmse: 0.51213 | val_1_rmse: 0.50343 |  0:00:46s
epoch 14 | loss: 0.26235 | val_0_rmse: 0.50065 | val_1_rmse: 0.49327 |  0:00:49s
epoch 15 | loss: 0.25844 | val_0_rmse: 0.50233 | val_1_rmse: 0.49286 |  0:00:53s
epoch 16 | loss: 0.25702 | val_0_rmse: 0.51635 | val_1_rmse: 0.5077  |  0:00:56s
epoch 17 | loss: 0.25683 | val_0_rmse: 0.50873 | val_1_rmse: 0.5015  |  0:00:59s
epoch 18 | loss: 0.25389 | val_0_rmse: 0.49803 | val_1_rmse: 0.49222 |  0:01:03s
epoch 19 | loss: 0.25081 | val_0_rmse: 0.4965  | val_1_rmse: 0.48887 |  0:01:06s
epoch 20 | loss: 0.24999 | val_0_rmse: 0.48522 | val_1_rmse: 0.47724 |  0:01:09s
epoch 21 | loss: 0.2445  | val_0_rmse: 0.53567 | val_1_rmse: 0.52738 |  0:01:13s
epoch 22 | loss: 0.246   | val_0_rmse: 0.52678 | val_1_rmse: 0.5199  |  0:01:16s
epoch 23 | loss: 0.2425  | val_0_rmse: 0.4926  | val_1_rmse: 0.48548 |  0:01:19s
epoch 24 | loss: 0.24539 | val_0_rmse: 0.48193 | val_1_rmse: 0.4768  |  0:01:23s
epoch 25 | loss: 0.24551 | val_0_rmse: 0.48163 | val_1_rmse: 0.4759  |  0:01:26s
epoch 26 | loss: 0.24825 | val_0_rmse: 0.51193 | val_1_rmse: 0.50654 |  0:01:30s
epoch 27 | loss: 0.25006 | val_0_rmse: 0.48742 | val_1_rmse: 0.48434 |  0:01:33s
epoch 28 | loss: 0.24233 | val_0_rmse: 0.51344 | val_1_rmse: 0.50233 |  0:01:36s
epoch 29 | loss: 0.24718 | val_0_rmse: 0.50024 | val_1_rmse: 0.49534 |  0:01:40s
epoch 30 | loss: 0.2451  | val_0_rmse: 0.48939 | val_1_rmse: 0.48583 |  0:01:43s
epoch 31 | loss: 0.23975 | val_0_rmse: 0.49224 | val_1_rmse: 0.48772 |  0:01:46s
epoch 32 | loss: 0.23624 | val_0_rmse: 0.47973 | val_1_rmse: 0.47835 |  0:01:50s
epoch 33 | loss: 0.24003 | val_0_rmse: 0.49369 | val_1_rmse: 0.49238 |  0:01:53s
epoch 34 | loss: 0.2358  | val_0_rmse: 0.48116 | val_1_rmse: 0.47791 |  0:01:56s
epoch 35 | loss: 0.24114 | val_0_rmse: 0.48823 | val_1_rmse: 0.4834  |  0:02:00s
epoch 36 | loss: 0.23766 | val_0_rmse: 0.48038 | val_1_rmse: 0.47829 |  0:02:03s
epoch 37 | loss: 0.24058 | val_0_rmse: 0.4738  | val_1_rmse: 0.47354 |  0:02:06s
epoch 38 | loss: 0.23541 | val_0_rmse: 0.47891 | val_1_rmse: 0.47588 |  0:02:10s
epoch 39 | loss: 0.23511 | val_0_rmse: 0.47442 | val_1_rmse: 0.4699  |  0:02:13s
epoch 40 | loss: 0.23748 | val_0_rmse: 0.50403 | val_1_rmse: 0.50212 |  0:02:16s
epoch 41 | loss: 0.23566 | val_0_rmse: 0.487   | val_1_rmse: 0.51057 |  0:02:20s
epoch 42 | loss: 0.23544 | val_0_rmse: 0.51636 | val_1_rmse: 0.55188 |  0:02:23s
epoch 43 | loss: 0.23493 | val_0_rmse: 0.50929 | val_1_rmse: 0.55093 |  0:02:26s
epoch 44 | loss: 0.23191 | val_0_rmse: 0.53144 | val_1_rmse: 0.61819 |  0:02:30s
epoch 45 | loss: 0.23142 | val_0_rmse: 0.53568 | val_1_rmse: 0.62258 |  0:02:33s
epoch 46 | loss: 0.22963 | val_0_rmse: 0.55459 | val_1_rmse: 0.57974 |  0:02:36s
epoch 47 | loss: 0.23135 | val_0_rmse: 0.54467 | val_1_rmse: 0.50007 |  0:02:40s
epoch 48 | loss: 0.22961 | val_0_rmse: 0.53886 | val_1_rmse: 0.55862 |  0:02:43s
epoch 49 | loss: 0.22968 | val_0_rmse: 0.54309 | val_1_rmse: 0.56299 |  0:02:46s
epoch 50 | loss: 0.23143 | val_0_rmse: 0.53618 | val_1_rmse: 0.53747 |  0:02:50s
epoch 51 | loss: 0.22938 | val_0_rmse: 0.56734 | val_1_rmse: 0.5345  |  0:02:53s
epoch 52 | loss: 0.22685 | val_0_rmse: 0.56085 | val_1_rmse: 0.56191 |  0:02:56s
epoch 53 | loss: 0.22753 | val_0_rmse: 0.56175 | val_1_rmse: 0.50334 |  0:03:00s
epoch 54 | loss: 0.24041 | val_0_rmse: 0.53309 | val_1_rmse: 0.52486 |  0:03:03s
epoch 55 | loss: 0.2313  | val_0_rmse: 0.54785 | val_1_rmse: 0.50012 |  0:03:06s
epoch 56 | loss: 0.2309  | val_0_rmse: 0.48953 | val_1_rmse: 0.47827 |  0:03:10s
epoch 57 | loss: 0.23027 | val_0_rmse: 0.49838 | val_1_rmse: 0.50086 |  0:03:13s
epoch 58 | loss: 0.22879 | val_0_rmse: 0.51679 | val_1_rmse: 0.51731 |  0:03:16s
epoch 59 | loss: 0.23088 | val_0_rmse: 0.49473 | val_1_rmse: 0.49182 |  0:03:20s
epoch 60 | loss: 0.22798 | val_0_rmse: 0.47666 | val_1_rmse: 0.47337 |  0:03:23s
epoch 61 | loss: 0.22734 | val_0_rmse: 0.50886 | val_1_rmse: 0.51227 |  0:03:26s
epoch 62 | loss: 0.23066 | val_0_rmse: 0.47203 | val_1_rmse: 0.47214 |  0:03:30s
epoch 63 | loss: 0.2334  | val_0_rmse: 0.51532 | val_1_rmse: 0.51431 |  0:03:33s
epoch 64 | loss: 0.22474 | val_0_rmse: 0.50808 | val_1_rmse: 0.50772 |  0:03:36s
epoch 65 | loss: 0.22264 | val_0_rmse: 0.53744 | val_1_rmse: 0.53957 |  0:03:40s
epoch 66 | loss: 0.22461 | val_0_rmse: 0.52117 | val_1_rmse: 0.51471 |  0:03:43s
epoch 67 | loss: 0.23664 | val_0_rmse: 0.73472 | val_1_rmse: 0.72612 |  0:03:46s
epoch 68 | loss: 0.23265 | val_0_rmse: 0.47887 | val_1_rmse: 0.47873 |  0:03:50s
epoch 69 | loss: 0.23046 | val_0_rmse: 0.4706  | val_1_rmse: 0.47057 |  0:03:53s

Early stopping occured at epoch 69 with best_epoch = 39 and best_val_1_rmse = 0.4699
Best weights from best epoch are automatically used!
ended training at: 07:35:29
Feature importance:
Mean squared error is of 1503816451.876083
Mean absolute error:21447.420988403
MAPE:0.2665621657970634
R2 score:0.6259876628448079
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 3
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:35:29
epoch 0  | loss: 0.90663 | val_0_rmse: 1.03983 | val_1_rmse: 1.05555 |  0:00:03s
epoch 1  | loss: 0.34989 | val_0_rmse: 0.63921 | val_1_rmse: 0.63154 |  0:00:06s
epoch 2  | loss: 0.30074 | val_0_rmse: 0.55402 | val_1_rmse: 0.5523  |  0:00:09s
epoch 3  | loss: 0.28204 | val_0_rmse: 0.56465 | val_1_rmse: 0.55941 |  0:00:13s
epoch 4  | loss: 0.27026 | val_0_rmse: 0.55571 | val_1_rmse: 0.5617  |  0:00:16s
epoch 5  | loss: 0.27284 | val_0_rmse: 0.52593 | val_1_rmse: 0.52681 |  0:00:20s
epoch 6  | loss: 0.26702 | val_0_rmse: 0.52129 | val_1_rmse: 0.52189 |  0:00:23s
epoch 7  | loss: 0.25542 | val_0_rmse: 0.50972 | val_1_rmse: 0.51147 |  0:00:26s
epoch 8  | loss: 0.24853 | val_0_rmse: 0.50843 | val_1_rmse: 0.50236 |  0:00:30s
epoch 9  | loss: 0.2519  | val_0_rmse: 0.50158 | val_1_rmse: 0.5026  |  0:00:33s
epoch 10 | loss: 0.2474  | val_0_rmse: 0.49825 | val_1_rmse: 0.50312 |  0:00:36s
epoch 11 | loss: 0.24422 | val_0_rmse: 0.51031 | val_1_rmse: 0.5031  |  0:00:40s
epoch 12 | loss: 0.24886 | val_0_rmse: 0.4956  | val_1_rmse: 0.49464 |  0:00:43s
epoch 13 | loss: 0.24322 | val_0_rmse: 0.50415 | val_1_rmse: 0.52444 |  0:00:47s
epoch 14 | loss: 0.24375 | val_0_rmse: 0.49782 | val_1_rmse: 0.4977  |  0:00:50s
epoch 15 | loss: 0.23912 | val_0_rmse: 0.49111 | val_1_rmse: 0.48897 |  0:00:53s
epoch 16 | loss: 0.23875 | val_0_rmse: 0.49525 | val_1_rmse: 0.49516 |  0:00:57s
epoch 17 | loss: 0.23585 | val_0_rmse: 0.49364 | val_1_rmse: 0.49584 |  0:01:00s
epoch 18 | loss: 0.23573 | val_0_rmse: 0.47259 | val_1_rmse: 0.47947 |  0:01:03s
epoch 19 | loss: 0.23372 | val_0_rmse: 0.49208 | val_1_rmse: 0.49758 |  0:01:07s
epoch 20 | loss: 0.23669 | val_0_rmse: 0.47499 | val_1_rmse: 0.48578 |  0:01:10s
epoch 21 | loss: 0.23675 | val_0_rmse: 0.48102 | val_1_rmse: 0.49148 |  0:01:14s
epoch 22 | loss: 0.23302 | val_0_rmse: 0.48071 | val_1_rmse: 0.49005 |  0:01:17s
epoch 23 | loss: 0.23104 | val_0_rmse: 0.48625 | val_1_rmse: 0.49253 |  0:01:20s
epoch 24 | loss: 0.23021 | val_0_rmse: 0.47222 | val_1_rmse: 0.47943 |  0:01:24s
epoch 25 | loss: 0.22859 | val_0_rmse: 0.48925 | val_1_rmse: 0.49761 |  0:01:27s
epoch 26 | loss: 0.23152 | val_0_rmse: 0.46335 | val_1_rmse: 0.47738 |  0:01:30s
epoch 27 | loss: 0.22665 | val_0_rmse: 0.48069 | val_1_rmse: 0.49189 |  0:01:34s
epoch 28 | loss: 0.22894 | val_0_rmse: 0.49271 | val_1_rmse: 0.50079 |  0:01:37s
epoch 29 | loss: 0.2321  | val_0_rmse: 0.4779  | val_1_rmse: 0.491   |  0:01:41s
epoch 30 | loss: 0.22942 | val_0_rmse: 0.49937 | val_1_rmse: 0.50972 |  0:01:44s
epoch 31 | loss: 0.22502 | val_0_rmse: 0.46125 | val_1_rmse: 0.47622 |  0:01:47s
epoch 32 | loss: 0.22437 | val_0_rmse: 0.46443 | val_1_rmse: 0.47921 |  0:01:51s
epoch 33 | loss: 0.2254  | val_0_rmse: 0.48653 | val_1_rmse: 0.50067 |  0:01:54s
epoch 34 | loss: 0.22311 | val_0_rmse: 0.47395 | val_1_rmse: 0.48195 |  0:01:57s
epoch 35 | loss: 0.22297 | val_0_rmse: 0.50608 | val_1_rmse: 0.51547 |  0:02:01s
epoch 36 | loss: 0.22149 | val_0_rmse: 0.47385 | val_1_rmse: 0.48813 |  0:02:04s
epoch 37 | loss: 0.22241 | val_0_rmse: 0.48735 | val_1_rmse: 0.49845 |  0:02:07s
epoch 38 | loss: 0.22421 | val_0_rmse: 0.50955 | val_1_rmse: 0.51545 |  0:02:11s
epoch 39 | loss: 0.21996 | val_0_rmse: 0.46477 | val_1_rmse: 0.47868 |  0:02:14s
epoch 40 | loss: 0.22238 | val_0_rmse: 0.48778 | val_1_rmse: 0.49793 |  0:02:17s
epoch 41 | loss: 0.22308 | val_0_rmse: 0.47777 | val_1_rmse: 0.49187 |  0:02:21s
epoch 42 | loss: 0.2258  | val_0_rmse: 0.47105 | val_1_rmse: 0.48783 |  0:02:24s
epoch 43 | loss: 0.2224  | val_0_rmse: 0.46261 | val_1_rmse: 0.47459 |  0:02:27s
epoch 44 | loss: 0.21619 | val_0_rmse: 0.46743 | val_1_rmse: 0.4812  |  0:02:31s
epoch 45 | loss: 0.22488 | val_0_rmse: 0.46022 | val_1_rmse: 0.47252 |  0:02:34s
epoch 46 | loss: 0.22022 | val_0_rmse: 0.45531 | val_1_rmse: 0.4694  |  0:02:37s
epoch 47 | loss: 0.21803 | val_0_rmse: 0.4879  | val_1_rmse: 0.49648 |  0:02:41s
epoch 48 | loss: 0.21838 | val_0_rmse: 0.49233 | val_1_rmse: 0.50451 |  0:02:44s
epoch 49 | loss: 0.21766 | val_0_rmse: 0.45553 | val_1_rmse: 0.47476 |  0:02:47s
epoch 50 | loss: 0.21941 | val_0_rmse: 0.47881 | val_1_rmse: 0.49138 |  0:02:51s
epoch 51 | loss: 0.21844 | val_0_rmse: 0.45944 | val_1_rmse: 0.47712 |  0:02:54s
epoch 52 | loss: 0.2155  | val_0_rmse: 0.47977 | val_1_rmse: 0.49228 |  0:02:57s
epoch 53 | loss: 0.21318 | val_0_rmse: 0.48921 | val_1_rmse: 0.50231 |  0:03:01s
epoch 54 | loss: 0.21453 | val_0_rmse: 0.46788 | val_1_rmse: 0.48388 |  0:03:04s
epoch 55 | loss: 0.21609 | val_0_rmse: 0.47701 | val_1_rmse: 0.49262 |  0:03:08s
epoch 56 | loss: 0.22004 | val_0_rmse: 0.52327 | val_1_rmse: 0.53446 |  0:03:11s
epoch 57 | loss: 0.21139 | val_0_rmse: 0.46437 | val_1_rmse: 0.48132 |  0:03:14s
epoch 58 | loss: 0.21527 | val_0_rmse: 0.47324 | val_1_rmse: 0.49192 |  0:03:18s
epoch 59 | loss: 0.21684 | val_0_rmse: 0.4712  | val_1_rmse: 0.49217 |  0:03:21s
epoch 60 | loss: 0.21516 | val_0_rmse: 0.45989 | val_1_rmse: 0.48006 |  0:03:24s
epoch 61 | loss: 0.21578 | val_0_rmse: 0.46984 | val_1_rmse: 0.4928  |  0:03:28s
epoch 62 | loss: 0.21473 | val_0_rmse: 0.49892 | val_1_rmse: 0.51608 |  0:03:31s
epoch 63 | loss: 0.21223 | val_0_rmse: 0.45372 | val_1_rmse: 0.47349 |  0:03:35s
epoch 64 | loss: 0.21196 | val_0_rmse: 0.45655 | val_1_rmse: 0.47619 |  0:03:38s
epoch 65 | loss: 0.21295 | val_0_rmse: 0.45088 | val_1_rmse: 0.47474 |  0:03:41s
epoch 66 | loss: 0.20919 | val_0_rmse: 0.47176 | val_1_rmse: 0.492   |  0:03:45s
epoch 67 | loss: 0.21407 | val_0_rmse: 0.46069 | val_1_rmse: 0.48584 |  0:03:48s
epoch 68 | loss: 0.21263 | val_0_rmse: 0.45692 | val_1_rmse: 0.48252 |  0:03:51s
epoch 69 | loss: 0.21488 | val_0_rmse: 0.44534 | val_1_rmse: 0.47259 |  0:03:55s
epoch 70 | loss: 0.20849 | val_0_rmse: 0.45681 | val_1_rmse: 0.47979 |  0:03:58s
epoch 71 | loss: 0.21045 | val_0_rmse: 0.50439 | val_1_rmse: 0.52575 |  0:04:01s
epoch 72 | loss: 0.21153 | val_0_rmse: 0.46183 | val_1_rmse: 0.48196 |  0:04:05s
epoch 73 | loss: 0.2131  | val_0_rmse: 0.48388 | val_1_rmse: 0.50289 |  0:04:08s
epoch 74 | loss: 0.21139 | val_0_rmse: 0.44946 | val_1_rmse: 0.50617 |  0:04:11s
epoch 75 | loss: 0.21418 | val_0_rmse: 0.44884 | val_1_rmse: 1.41802 |  0:04:15s
epoch 76 | loss: 0.21279 | val_0_rmse: 0.46749 | val_1_rmse: 0.89755 |  0:04:18s

Early stopping occured at epoch 76 with best_epoch = 46 and best_val_1_rmse = 0.4694
Best weights from best epoch are automatically used!
ended training at: 07:39:49
Feature importance:
Mean squared error is of 955169637.0385599
Mean absolute error:20352.748990238215
MAPE:0.25284134399939295
R2 score:0.7626508206238676
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 4
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:39:49
epoch 0  | loss: 0.94468 | val_0_rmse: 0.71554 | val_1_rmse: 0.72554 |  0:00:03s
epoch 1  | loss: 0.41775 | val_0_rmse: 0.56872 | val_1_rmse: 0.57289 |  0:00:06s
epoch 2  | loss: 0.32585 | val_0_rmse: 0.56684 | val_1_rmse: 0.56923 |  0:00:09s
epoch 3  | loss: 0.2921  | val_0_rmse: 0.55734 | val_1_rmse: 0.56613 |  0:00:13s
epoch 4  | loss: 0.27416 | val_0_rmse: 0.53108 | val_1_rmse: 0.53995 |  0:00:16s
epoch 5  | loss: 0.26351 | val_0_rmse: 0.53241 | val_1_rmse: 0.54325 |  0:00:20s
epoch 6  | loss: 0.25372 | val_0_rmse: 0.52121 | val_1_rmse: 0.52602 |  0:00:23s
epoch 7  | loss: 0.24928 | val_0_rmse: 0.522   | val_1_rmse: 0.53514 |  0:00:26s
epoch 8  | loss: 0.24458 | val_0_rmse: 0.52291 | val_1_rmse: 0.53718 |  0:00:30s
epoch 9  | loss: 0.24273 | val_0_rmse: 0.51392 | val_1_rmse: 0.52476 |  0:00:33s
epoch 10 | loss: 0.23975 | val_0_rmse: 0.48459 | val_1_rmse: 0.49226 |  0:00:36s
epoch 11 | loss: 0.23805 | val_0_rmse: 0.49317 | val_1_rmse: 0.5007  |  0:00:40s
epoch 12 | loss: 0.23585 | val_0_rmse: 0.47989 | val_1_rmse: 0.48822 |  0:00:43s
epoch 13 | loss: 0.23681 | val_0_rmse: 0.4757  | val_1_rmse: 0.48642 |  0:00:47s
epoch 14 | loss: 0.23423 | val_0_rmse: 0.49662 | val_1_rmse: 0.5069  |  0:00:50s
epoch 15 | loss: 0.23444 | val_0_rmse: 0.4867  | val_1_rmse: 0.49856 |  0:00:53s
epoch 16 | loss: 0.23186 | val_0_rmse: 0.48492 | val_1_rmse: 0.49697 |  0:00:57s
epoch 17 | loss: 0.22688 | val_0_rmse: 0.4695  | val_1_rmse: 0.48492 |  0:01:00s
epoch 18 | loss: 0.22479 | val_0_rmse: 0.46739 | val_1_rmse: 0.48427 |  0:01:03s
epoch 19 | loss: 0.22337 | val_0_rmse: 0.48998 | val_1_rmse: 0.50361 |  0:01:07s
epoch 20 | loss: 0.22488 | val_0_rmse: 0.46393 | val_1_rmse: 0.47893 |  0:01:10s
epoch 21 | loss: 0.22553 | val_0_rmse: 0.49551 | val_1_rmse: 0.49942 |  0:01:13s
epoch 22 | loss: 0.22474 | val_0_rmse: 0.46687 | val_1_rmse: 0.48845 |  0:01:17s
epoch 23 | loss: 0.22257 | val_0_rmse: 0.46051 | val_1_rmse: 0.47937 |  0:01:20s
epoch 24 | loss: 0.22223 | val_0_rmse: 0.47388 | val_1_rmse: 0.49294 |  0:01:24s
epoch 25 | loss: 0.22362 | val_0_rmse: 0.45947 | val_1_rmse: 0.48144 |  0:01:27s
epoch 26 | loss: 0.21867 | val_0_rmse: 0.45579 | val_1_rmse: 0.47789 |  0:01:30s
epoch 27 | loss: 0.22024 | val_0_rmse: 0.45985 | val_1_rmse: 0.48016 |  0:01:33s
epoch 28 | loss: 0.22135 | val_0_rmse: 0.4633  | val_1_rmse: 0.48544 |  0:01:37s
epoch 29 | loss: 0.21651 | val_0_rmse: 0.46889 | val_1_rmse: 0.4935  |  0:01:40s
epoch 30 | loss: 0.21419 | val_0_rmse: 0.4539  | val_1_rmse: 0.47867 |  0:01:43s
epoch 31 | loss: 0.21879 | val_0_rmse: 0.48618 | val_1_rmse: 0.50896 |  0:01:47s
epoch 32 | loss: 0.22167 | val_0_rmse: 0.47753 | val_1_rmse: 0.50385 |  0:01:50s
epoch 33 | loss: 0.21476 | val_0_rmse: 0.44861 | val_1_rmse: 0.47867 |  0:01:53s
epoch 34 | loss: 0.21334 | val_0_rmse: 0.449   | val_1_rmse: 0.4785  |  0:01:57s
epoch 35 | loss: 0.21017 | val_0_rmse: 0.44929 | val_1_rmse: 0.47979 |  0:02:00s
epoch 36 | loss: 0.20969 | val_0_rmse: 0.45271 | val_1_rmse: 0.48377 |  0:02:04s
epoch 37 | loss: 0.2155  | val_0_rmse: 0.49004 | val_1_rmse: 0.48434 |  0:02:07s
epoch 38 | loss: 0.21483 | val_0_rmse: 0.48088 | val_1_rmse: 0.50777 |  0:02:10s
epoch 39 | loss: 0.21053 | val_0_rmse: 0.45366 | val_1_rmse: 0.4807  |  0:02:14s
epoch 40 | loss: 0.21276 | val_0_rmse: 0.45283 | val_1_rmse: 0.47885 |  0:02:17s
epoch 41 | loss: 0.21595 | val_0_rmse: 0.46818 | val_1_rmse: 0.49102 |  0:02:20s
epoch 42 | loss: 0.21429 | val_0_rmse: 0.46624 | val_1_rmse: 0.48908 |  0:02:24s
epoch 43 | loss: 0.21165 | val_0_rmse: 0.4644  | val_1_rmse: 0.48639 |  0:02:27s
epoch 44 | loss: 0.21298 | val_0_rmse: 0.45462 | val_1_rmse: 0.48318 |  0:02:30s
epoch 45 | loss: 0.21202 | val_0_rmse: 0.456   | val_1_rmse: 0.48949 |  0:02:34s
epoch 46 | loss: 0.21224 | val_0_rmse: 0.45123 | val_1_rmse: 0.47977 |  0:02:37s
epoch 47 | loss: 0.21022 | val_0_rmse: 0.46879 | val_1_rmse: 0.49864 |  0:02:41s
epoch 48 | loss: 0.20706 | val_0_rmse: 0.46745 | val_1_rmse: 0.49724 |  0:02:44s
epoch 49 | loss: 0.20906 | val_0_rmse: 0.44338 | val_1_rmse: 0.47724 |  0:02:47s
epoch 50 | loss: 0.20433 | val_0_rmse: 0.44491 | val_1_rmse: 0.48092 |  0:02:51s
epoch 51 | loss: 0.20867 | val_0_rmse: 0.44568 | val_1_rmse: 0.47904 |  0:02:54s
epoch 52 | loss: 0.2059  | val_0_rmse: 0.45322 | val_1_rmse: 0.48775 |  0:02:58s
epoch 53 | loss: 0.20349 | val_0_rmse: 0.44526 | val_1_rmse: 0.48102 |  0:03:01s
epoch 54 | loss: 0.20603 | val_0_rmse: 0.44981 | val_1_rmse: 0.48245 |  0:03:04s
epoch 55 | loss: 0.20649 | val_0_rmse: 0.44454 | val_1_rmse: 0.47815 |  0:03:08s
epoch 56 | loss: 0.2047  | val_0_rmse: 0.45673 | val_1_rmse: 0.49256 |  0:03:11s
epoch 57 | loss: 0.20646 | val_0_rmse: 0.45519 | val_1_rmse: 0.48767 |  0:03:14s
epoch 58 | loss: 0.20424 | val_0_rmse: 0.44171 | val_1_rmse: 0.48176 |  0:03:18s
epoch 59 | loss: 0.20035 | val_0_rmse: 0.45947 | val_1_rmse: 0.49217 |  0:03:21s
epoch 60 | loss: 0.20562 | val_0_rmse: 0.46089 | val_1_rmse: 0.4947  |  0:03:24s
epoch 61 | loss: 0.20475 | val_0_rmse: 0.44136 | val_1_rmse: 0.47829 |  0:03:28s
epoch 62 | loss: 0.2042  | val_0_rmse: 0.44804 | val_1_rmse: 0.48446 |  0:03:31s
epoch 63 | loss: 0.20675 | val_0_rmse: 0.44442 | val_1_rmse: 0.48303 |  0:03:35s
epoch 64 | loss: 0.20543 | val_0_rmse: 0.46998 | val_1_rmse: 0.50581 |  0:03:38s
epoch 65 | loss: 0.20464 | val_0_rmse: 0.44078 | val_1_rmse: 0.48268 |  0:03:41s
epoch 66 | loss: 0.20449 | val_0_rmse: 0.44378 | val_1_rmse: 0.48571 |  0:03:45s
epoch 67 | loss: 0.20583 | val_0_rmse: 0.47854 | val_1_rmse: 0.52466 |  0:03:48s
epoch 68 | loss: 0.20726 | val_0_rmse: 0.46944 | val_1_rmse: 0.50579 |  0:03:51s
epoch 69 | loss: 0.20439 | val_0_rmse: 0.45147 | val_1_rmse: 0.49423 |  0:03:55s
epoch 70 | loss: 0.20949 | val_0_rmse: 0.44912 | val_1_rmse: 0.49398 |  0:03:58s
epoch 71 | loss: 0.20579 | val_0_rmse: 0.45554 | val_1_rmse: 0.50781 |  0:04:01s
epoch 72 | loss: 0.20233 | val_0_rmse: 0.43745 | val_1_rmse: 0.51918 |  0:04:05s
epoch 73 | loss: 0.20042 | val_0_rmse: 0.45669 | val_1_rmse: 0.55114 |  0:04:08s
epoch 74 | loss: 0.20128 | val_0_rmse: 0.4466  | val_1_rmse: 0.486   |  0:04:11s
epoch 75 | loss: 0.20015 | val_0_rmse: 0.46787 | val_1_rmse: 0.50285 |  0:04:15s
epoch 76 | loss: 0.20374 | val_0_rmse: 0.44191 | val_1_rmse: 0.48512 |  0:04:18s
epoch 77 | loss: 0.20472 | val_0_rmse: 0.44517 | val_1_rmse: 0.55234 |  0:04:21s
epoch 78 | loss: 0.20236 | val_0_rmse: 0.4464  | val_1_rmse: 0.49398 |  0:04:25s
epoch 79 | loss: 0.20193 | val_0_rmse: 0.43978 | val_1_rmse: 0.48518 |  0:04:28s

Early stopping occured at epoch 79 with best_epoch = 49 and best_val_1_rmse = 0.47724
Best weights from best epoch are automatically used!
ended training at: 07:44:19
Feature importance:
Mean squared error is of 955569971.4496616
Mean absolute error:20753.10772324816
MAPE:0.25975197515195175
R2 score:0.758999832583805
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 5
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:44:20
epoch 0  | loss: 0.71811 | val_0_rmse: 0.7663  | val_1_rmse: 0.75609 |  0:00:03s
epoch 1  | loss: 0.36889 | val_0_rmse: 0.64102 | val_1_rmse: 0.63637 |  0:00:06s
epoch 2  | loss: 0.32967 | val_0_rmse: 0.57331 | val_1_rmse: 0.56774 |  0:00:10s
epoch 3  | loss: 0.31147 | val_0_rmse: 0.56962 | val_1_rmse: 0.56053 |  0:00:13s
epoch 4  | loss: 0.28707 | val_0_rmse: 0.5394  | val_1_rmse: 0.53116 |  0:00:16s
epoch 5  | loss: 0.28377 | val_0_rmse: 0.53449 | val_1_rmse: 0.52531 |  0:00:20s
epoch 6  | loss: 0.28123 | val_0_rmse: 0.53781 | val_1_rmse: 0.52549 |  0:00:23s
epoch 7  | loss: 0.27597 | val_0_rmse: 0.53444 | val_1_rmse: 0.51922 |  0:00:26s
epoch 8  | loss: 0.263   | val_0_rmse: 0.51526 | val_1_rmse: 0.50689 |  0:00:30s
epoch 9  | loss: 0.26736 | val_0_rmse: 0.50597 | val_1_rmse: 0.49541 |  0:00:33s
epoch 10 | loss: 0.25947 | val_0_rmse: 0.53617 | val_1_rmse: 0.52893 |  0:00:36s
epoch 11 | loss: 0.25434 | val_0_rmse: 0.50562 | val_1_rmse: 0.49375 |  0:00:40s
epoch 12 | loss: 0.26095 | val_0_rmse: 0.51324 | val_1_rmse: 0.5038  |  0:00:43s
epoch 13 | loss: 0.25159 | val_0_rmse: 0.51175 | val_1_rmse: 0.49931 |  0:00:47s
epoch 14 | loss: 0.24958 | val_0_rmse: 0.50259 | val_1_rmse: 0.49558 |  0:00:50s
epoch 15 | loss: 0.24357 | val_0_rmse: 0.49774 | val_1_rmse: 0.48824 |  0:00:53s
epoch 16 | loss: 0.24311 | val_0_rmse: 0.48807 | val_1_rmse: 0.47956 |  0:00:57s
epoch 17 | loss: 0.24275 | val_0_rmse: 0.48776 | val_1_rmse: 0.49028 |  0:01:00s
epoch 18 | loss: 0.24636 | val_0_rmse: 0.50209 | val_1_rmse: 0.50086 |  0:01:03s
epoch 19 | loss: 0.25328 | val_0_rmse: 0.5431  | val_1_rmse: 0.54353 |  0:01:07s
epoch 20 | loss: 0.24814 | val_0_rmse: 0.48119 | val_1_rmse: 0.47609 |  0:01:10s
epoch 21 | loss: 0.24261 | val_0_rmse: 0.48059 | val_1_rmse: 0.47819 |  0:01:14s
epoch 22 | loss: 0.25198 | val_0_rmse: 0.51157 | val_1_rmse: 0.51269 |  0:01:17s
epoch 23 | loss: 0.26185 | val_0_rmse: 0.50653 | val_1_rmse: 0.50469 |  0:01:20s
epoch 24 | loss: 0.25912 | val_0_rmse: 0.4981  | val_1_rmse: 0.50212 |  0:01:24s
epoch 25 | loss: 0.25415 | val_0_rmse: 0.64086 | val_1_rmse: 0.64409 |  0:01:27s
epoch 26 | loss: 0.25367 | val_0_rmse: 0.48529 | val_1_rmse: 0.48243 |  0:01:30s
epoch 27 | loss: 0.26338 | val_0_rmse: 0.64982 | val_1_rmse: 0.63334 |  0:01:34s
epoch 28 | loss: 0.2513  | val_0_rmse: 0.51556 | val_1_rmse: 0.51091 |  0:01:37s
epoch 29 | loss: 0.24176 | val_0_rmse: 0.48438 | val_1_rmse: 0.47814 |  0:01:41s
epoch 30 | loss: 0.24461 | val_0_rmse: 0.48266 | val_1_rmse: 0.47943 |  0:01:44s
epoch 31 | loss: 0.23997 | val_0_rmse: 0.49215 | val_1_rmse: 0.49335 |  0:01:47s
epoch 32 | loss: 0.2354  | val_0_rmse: 0.47643 | val_1_rmse: 0.47457 |  0:01:51s
epoch 33 | loss: 0.23674 | val_0_rmse: 0.58018 | val_1_rmse: 0.57952 |  0:01:54s
epoch 34 | loss: 0.2367  | val_0_rmse: 0.47709 | val_1_rmse: 0.47665 |  0:01:57s
epoch 35 | loss: 0.23592 | val_0_rmse: 0.49096 | val_1_rmse: 0.49385 |  0:02:01s
epoch 36 | loss: 0.23441 | val_0_rmse: 0.48288 | val_1_rmse: 0.47951 |  0:02:04s
epoch 37 | loss: 0.23337 | val_0_rmse: 0.47874 | val_1_rmse: 0.4756  |  0:02:07s
epoch 38 | loss: 0.23056 | val_0_rmse: 0.47434 | val_1_rmse: 0.47327 |  0:02:11s
epoch 39 | loss: 0.23724 | val_0_rmse: 0.47871 | val_1_rmse: 0.48121 |  0:02:14s
epoch 40 | loss: 0.23174 | val_0_rmse: 0.46981 | val_1_rmse: 0.47023 |  0:02:17s
epoch 41 | loss: 0.22885 | val_0_rmse: 0.47739 | val_1_rmse: 0.48235 |  0:02:21s
epoch 42 | loss: 0.22972 | val_0_rmse: 0.47091 | val_1_rmse: 0.46963 |  0:02:24s
epoch 43 | loss: 0.2287  | val_0_rmse: 0.5202  | val_1_rmse: 0.51883 |  0:02:27s
epoch 44 | loss: 0.23272 | val_0_rmse: 0.49301 | val_1_rmse: 0.49374 |  0:02:31s
epoch 45 | loss: 0.233   | val_0_rmse: 0.55288 | val_1_rmse: 0.54617 |  0:02:34s
epoch 46 | loss: 0.24046 | val_0_rmse: 0.54856 | val_1_rmse: 0.55142 |  0:02:38s
epoch 47 | loss: 0.23547 | val_0_rmse: 0.50101 | val_1_rmse: 0.50824 |  0:02:41s
epoch 48 | loss: 0.24854 | val_0_rmse: 0.51174 | val_1_rmse: 0.51242 |  0:02:44s
epoch 49 | loss: 0.24863 | val_0_rmse: 0.48412 | val_1_rmse: 0.48395 |  0:02:47s
epoch 50 | loss: 0.23574 | val_0_rmse: 0.47926 | val_1_rmse: 0.47902 |  0:02:51s
epoch 51 | loss: 0.23282 | val_0_rmse: 0.49131 | val_1_rmse: 0.48659 |  0:02:54s
epoch 52 | loss: 0.23485 | val_0_rmse: 0.49116 | val_1_rmse: 0.48934 |  0:02:57s
epoch 53 | loss: 0.23373 | val_0_rmse: 0.48196 | val_1_rmse: 0.47755 |  0:03:01s
epoch 54 | loss: 0.23417 | val_0_rmse: 0.48089 | val_1_rmse: 0.47908 |  0:03:04s
epoch 55 | loss: 0.22902 | val_0_rmse: 0.4697  | val_1_rmse: 0.47126 |  0:03:07s
epoch 56 | loss: 0.22528 | val_0_rmse: 0.46774 | val_1_rmse: 0.47029 |  0:03:11s
epoch 57 | loss: 0.22727 | val_0_rmse: 0.47884 | val_1_rmse: 0.48061 |  0:03:14s
epoch 58 | loss: 0.23729 | val_0_rmse: 0.53359 | val_1_rmse: 0.52824 |  0:03:18s
epoch 59 | loss: 0.2398  | val_0_rmse: 0.49302 | val_1_rmse: 0.83566 |  0:03:21s
epoch 60 | loss: 0.23116 | val_0_rmse: 0.47139 | val_1_rmse: 0.47176 |  0:03:24s
epoch 61 | loss: 0.22431 | val_0_rmse: 0.46792 | val_1_rmse: 0.47072 |  0:03:28s
epoch 62 | loss: 0.2234  | val_0_rmse: 0.46542 | val_1_rmse: 0.46771 |  0:03:31s
epoch 63 | loss: 0.22347 | val_0_rmse: 0.46778 | val_1_rmse: 0.47167 |  0:03:34s
epoch 64 | loss: 0.22202 | val_0_rmse: 0.47026 | val_1_rmse: 0.46785 |  0:03:38s
epoch 65 | loss: 0.23383 | val_0_rmse: 0.47822 | val_1_rmse: 0.48287 |  0:03:41s
epoch 66 | loss: 0.22858 | val_0_rmse: 0.47055 | val_1_rmse: 0.47148 |  0:03:44s
epoch 67 | loss: 0.22615 | val_0_rmse: 0.47648 | val_1_rmse: 0.47791 |  0:03:48s
epoch 68 | loss: 0.22585 | val_0_rmse: 0.47589 | val_1_rmse: 0.47837 |  0:03:51s
epoch 69 | loss: 0.22794 | val_0_rmse: 0.49185 | val_1_rmse: 0.50088 |  0:03:54s
epoch 70 | loss: 0.22841 | val_0_rmse: 0.50991 | val_1_rmse: 0.51081 |  0:03:58s
epoch 71 | loss: 0.22439 | val_0_rmse: 0.46035 | val_1_rmse: 0.46547 |  0:04:01s
epoch 72 | loss: 0.2225  | val_0_rmse: 0.46211 | val_1_rmse: 0.4664  |  0:04:04s
epoch 73 | loss: 0.22078 | val_0_rmse: 0.4609  | val_1_rmse: 0.4679  |  0:04:08s
epoch 74 | loss: 0.22191 | val_0_rmse: 0.46543 | val_1_rmse: 0.47158 |  0:04:11s
epoch 75 | loss: 0.22125 | val_0_rmse: 0.47127 | val_1_rmse: 0.47499 |  0:04:14s
epoch 76 | loss: 0.2253  | val_0_rmse: 0.46097 | val_1_rmse: 0.46791 |  0:04:18s
epoch 77 | loss: 0.22915 | val_0_rmse: 0.47731 | val_1_rmse: 0.47763 |  0:04:21s
epoch 78 | loss: 0.22657 | val_0_rmse: 0.46798 | val_1_rmse: 0.46735 |  0:04:24s
epoch 79 | loss: 0.222   | val_0_rmse: 0.47915 | val_1_rmse: 0.48412 |  0:04:28s
epoch 80 | loss: 0.22966 | val_0_rmse: 0.46925 | val_1_rmse: 0.4696  |  0:04:31s
epoch 81 | loss: 0.22725 | val_0_rmse: 0.46312 | val_1_rmse: 0.4672  |  0:04:35s
epoch 82 | loss: 0.22147 | val_0_rmse: 0.48611 | val_1_rmse: 0.49364 |  0:04:38s
epoch 83 | loss: 0.22907 | val_0_rmse: 0.48864 | val_1_rmse: 0.48547 |  0:04:41s
epoch 84 | loss: 0.23201 | val_0_rmse: 0.46864 | val_1_rmse: 0.47133 |  0:04:45s
epoch 85 | loss: 0.22383 | val_0_rmse: 0.46317 | val_1_rmse: 0.46756 |  0:04:48s
epoch 86 | loss: 0.23221 | val_0_rmse: 0.47513 | val_1_rmse: 0.47516 |  0:04:51s
epoch 87 | loss: 0.22584 | val_0_rmse: 0.47082 | val_1_rmse: 0.47446 |  0:04:55s
epoch 88 | loss: 0.2204  | val_0_rmse: 0.46171 | val_1_rmse: 0.46966 |  0:04:58s
epoch 89 | loss: 0.22501 | val_0_rmse: 0.49331 | val_1_rmse: 0.48611 |  0:05:01s
epoch 90 | loss: 0.22832 | val_0_rmse: 0.49069 | val_1_rmse: 0.49835 |  0:05:05s
epoch 91 | loss: 0.22346 | val_0_rmse: 0.45991 | val_1_rmse: 0.46594 |  0:05:08s
epoch 92 | loss: 0.22187 | val_0_rmse: 0.46622 | val_1_rmse: 0.46861 |  0:05:11s
epoch 93 | loss: 0.22406 | val_0_rmse: 0.46477 | val_1_rmse: 0.46968 |  0:05:15s
epoch 94 | loss: 0.22458 | val_0_rmse: 0.46152 | val_1_rmse: 0.46694 |  0:05:18s
epoch 95 | loss: 0.22025 | val_0_rmse: 0.45624 | val_1_rmse: 0.4632  |  0:05:21s
epoch 96 | loss: 0.22871 | val_0_rmse: 0.50175 | val_1_rmse: 0.49681 |  0:05:25s
epoch 97 | loss: 0.22711 | val_0_rmse: 0.47767 | val_1_rmse: 0.47951 |  0:05:28s
epoch 98 | loss: 0.22494 | val_0_rmse: 0.4663  | val_1_rmse: 0.47133 |  0:05:32s
epoch 99 | loss: 0.22495 | val_0_rmse: 0.46425 | val_1_rmse: 0.46996 |  0:05:35s
epoch 100| loss: 0.22167 | val_0_rmse: 0.46965 | val_1_rmse: 0.47607 |  0:05:38s
epoch 101| loss: 0.22375 | val_0_rmse: 0.47919 | val_1_rmse: 0.4834  |  0:05:42s
epoch 102| loss: 0.21866 | val_0_rmse: 0.4648  | val_1_rmse: 0.46962 |  0:05:45s
epoch 103| loss: 0.21895 | val_0_rmse: 0.47267 | val_1_rmse: 0.50779 |  0:05:48s
epoch 104| loss: 0.21664 | val_0_rmse: 0.747   | val_1_rmse: 0.51083 |  0:05:52s
epoch 105| loss: 0.22145 | val_0_rmse: 0.58876 | val_1_rmse: 0.50287 |  0:05:55s
epoch 106| loss: 0.22178 | val_0_rmse: 0.47417 | val_1_rmse: 0.50785 |  0:05:58s
epoch 107| loss: 0.21684 | val_0_rmse: 0.50412 | val_1_rmse: 0.5248  |  0:06:02s
epoch 108| loss: 0.21545 | val_0_rmse: 0.55827 | val_1_rmse: 0.51511 |  0:06:05s
epoch 109| loss: 0.21638 | val_0_rmse: 0.61806 | val_1_rmse: 0.47776 |  0:06:08s
epoch 110| loss: 0.21598 | val_0_rmse: 0.50185 | val_1_rmse: 0.51018 |  0:06:12s
epoch 111| loss: 0.22189 | val_0_rmse: 0.55118 | val_1_rmse: 0.54726 |  0:06:15s
epoch 112| loss: 0.2212  | val_0_rmse: 0.4707  | val_1_rmse: 0.47632 |  0:06:18s
epoch 113| loss: 0.21635 | val_0_rmse: 0.46269 | val_1_rmse: 0.46517 |  0:06:22s
epoch 114| loss: 0.2177  | val_0_rmse: 0.49713 | val_1_rmse: 0.49786 |  0:06:25s
epoch 115| loss: 0.21695 | val_0_rmse: 0.45892 | val_1_rmse: 0.46409 |  0:06:28s
epoch 116| loss: 0.21219 | val_0_rmse: 0.45712 | val_1_rmse: 0.45996 |  0:06:32s
epoch 117| loss: 0.21408 | val_0_rmse: 0.46028 | val_1_rmse: 0.46335 |  0:06:35s
epoch 118| loss: 0.21731 | val_0_rmse: 0.46549 | val_1_rmse: 0.47078 |  0:06:38s
epoch 119| loss: 0.2201  | val_0_rmse: 0.47214 | val_1_rmse: 0.47725 |  0:06:42s
epoch 120| loss: 0.21489 | val_0_rmse: 0.45667 | val_1_rmse: 0.4631  |  0:06:45s
epoch 121| loss: 0.21168 | val_0_rmse: 0.45223 | val_1_rmse: 0.46028 |  0:06:48s
epoch 122| loss: 0.21419 | val_0_rmse: 0.45873 | val_1_rmse: 0.46404 |  0:06:52s
epoch 123| loss: 0.21223 | val_0_rmse: 0.46423 | val_1_rmse: 0.47033 |  0:06:55s
epoch 124| loss: 0.20854 | val_0_rmse: 0.4566  | val_1_rmse: 0.46368 |  0:06:58s
epoch 125| loss: 0.21227 | val_0_rmse: 0.4561  | val_1_rmse: 0.46357 |  0:07:02s
epoch 126| loss: 0.21293 | val_0_rmse: 0.48138 | val_1_rmse: 0.49338 |  0:07:05s
epoch 127| loss: 0.21021 | val_0_rmse: 0.45841 | val_1_rmse: 0.46705 |  0:07:09s
epoch 128| loss: 0.21283 | val_0_rmse: 0.46386 | val_1_rmse: 0.47065 |  0:07:12s
epoch 129| loss: 0.21545 | val_0_rmse: 0.45513 | val_1_rmse: 0.4621  |  0:07:15s
epoch 130| loss: 0.21631 | val_0_rmse: 0.46476 | val_1_rmse: 0.47509 |  0:07:19s
epoch 131| loss: 0.21394 | val_0_rmse: 0.46161 | val_1_rmse: 0.46885 |  0:07:22s
epoch 132| loss: 0.21365 | val_0_rmse: 0.45368 | val_1_rmse: 0.46526 |  0:07:25s
epoch 133| loss: 0.21255 | val_0_rmse: 0.45784 | val_1_rmse: 0.46841 |  0:07:29s
epoch 134| loss: 0.21087 | val_0_rmse: 0.45185 | val_1_rmse: 0.46041 |  0:07:32s
epoch 135| loss: 0.21415 | val_0_rmse: 0.46468 | val_1_rmse: 0.47994 |  0:07:35s
epoch 136| loss: 0.23325 | val_0_rmse: 0.48362 | val_1_rmse: 0.49005 |  0:07:39s
epoch 137| loss: 0.23049 | val_0_rmse: 0.49188 | val_1_rmse: 0.49678 |  0:07:42s
epoch 138| loss: 0.22225 | val_0_rmse: 0.50697 | val_1_rmse: 0.50463 |  0:07:46s
epoch 139| loss: 0.22495 | val_0_rmse: 0.46348 | val_1_rmse: 0.47182 |  0:07:49s
epoch 140| loss: 0.21425 | val_0_rmse: 0.45649 | val_1_rmse: 0.47043 |  0:07:52s
epoch 141| loss: 0.21496 | val_0_rmse: 0.47965 | val_1_rmse: 0.4875  |  0:07:56s
epoch 142| loss: 0.21797 | val_0_rmse: 0.46297 | val_1_rmse: 0.46914 |  0:07:59s
epoch 143| loss: 0.22203 | val_0_rmse: 0.45693 | val_1_rmse: 0.46645 |  0:08:02s
epoch 144| loss: 0.21627 | val_0_rmse: 0.45801 | val_1_rmse: 0.47309 |  0:08:06s
epoch 145| loss: 0.21748 | val_0_rmse: 0.48324 | val_1_rmse: 0.49391 |  0:08:09s
epoch 146| loss: 0.22676 | val_0_rmse: 0.46458 | val_1_rmse: 0.47709 |  0:08:12s

Early stopping occured at epoch 146 with best_epoch = 116 and best_val_1_rmse = 0.45996
Best weights from best epoch are automatically used!
ended training at: 07:52:34
Feature importance:
Mean squared error is of 950154583.5845174
Mean absolute error:20646.88691334066
MAPE:0.24220433181806256
R2 score:0.7694639927409848
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 6
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:52:34
epoch 0  | loss: 0.92675 | val_0_rmse: 0.89675 | val_1_rmse: 0.89097 |  0:00:03s
epoch 1  | loss: 0.42475 | val_0_rmse: 0.62303 | val_1_rmse: 0.61257 |  0:00:06s
epoch 2  | loss: 0.32283 | val_0_rmse: 0.57316 | val_1_rmse: 0.56576 |  0:00:10s
epoch 3  | loss: 0.28831 | val_0_rmse: 0.56449 | val_1_rmse: 0.55733 |  0:00:13s
epoch 4  | loss: 0.2758  | val_0_rmse: 0.549   | val_1_rmse: 0.54074 |  0:00:16s
epoch 5  | loss: 0.27308 | val_0_rmse: 0.55049 | val_1_rmse: 0.54373 |  0:00:20s
epoch 6  | loss: 0.26384 | val_0_rmse: 0.51667 | val_1_rmse: 0.51194 |  0:00:23s
epoch 7  | loss: 0.25905 | val_0_rmse: 0.52386 | val_1_rmse: 0.51889 |  0:00:26s
epoch 8  | loss: 0.25205 | val_0_rmse: 0.51058 | val_1_rmse: 0.50346 |  0:00:30s
epoch 9  | loss: 0.24947 | val_0_rmse: 0.51686 | val_1_rmse: 0.50819 |  0:00:33s
epoch 10 | loss: 0.24891 | val_0_rmse: 0.50136 | val_1_rmse: 0.50026 |  0:00:36s
epoch 11 | loss: 0.24604 | val_0_rmse: 0.50334 | val_1_rmse: 0.49779 |  0:00:40s
epoch 12 | loss: 0.24291 | val_0_rmse: 0.48935 | val_1_rmse: 0.4887  |  0:00:43s
epoch 13 | loss: 0.23929 | val_0_rmse: 0.48392 | val_1_rmse: 0.48379 |  0:00:47s
epoch 14 | loss: 0.24262 | val_0_rmse: 0.53151 | val_1_rmse: 0.52808 |  0:00:50s
epoch 15 | loss: 0.24025 | val_0_rmse: 0.48015 | val_1_rmse: 0.47847 |  0:00:53s
epoch 16 | loss: 0.23564 | val_0_rmse: 0.49221 | val_1_rmse: 0.48726 |  0:00:57s
epoch 17 | loss: 0.23843 | val_0_rmse: 0.48021 | val_1_rmse: 0.4776  |  0:01:00s
epoch 18 | loss: 0.23599 | val_0_rmse: 0.48235 | val_1_rmse: 0.47967 |  0:01:03s
epoch 19 | loss: 0.23376 | val_0_rmse: 0.48013 | val_1_rmse: 0.48559 |  0:01:07s
epoch 20 | loss: 0.23873 | val_0_rmse: 0.47435 | val_1_rmse: 0.47773 |  0:01:10s
epoch 21 | loss: 0.23439 | val_0_rmse: 0.51657 | val_1_rmse: 0.52161 |  0:01:13s
epoch 22 | loss: 0.23582 | val_0_rmse: 0.47066 | val_1_rmse: 0.47808 |  0:01:17s
epoch 23 | loss: 0.23721 | val_0_rmse: 0.50146 | val_1_rmse: 0.50434 |  0:01:20s
epoch 24 | loss: 0.23236 | val_0_rmse: 0.48571 | val_1_rmse: 0.49029 |  0:01:23s
epoch 25 | loss: 0.23092 | val_0_rmse: 0.46752 | val_1_rmse: 0.47221 |  0:01:27s
epoch 26 | loss: 0.23169 | val_0_rmse: 0.47667 | val_1_rmse: 0.48172 |  0:01:30s
epoch 27 | loss: 0.2269  | val_0_rmse: 0.46629 | val_1_rmse: 0.47662 |  0:01:33s
epoch 28 | loss: 0.22835 | val_0_rmse: 0.478   | val_1_rmse: 0.48062 |  0:01:37s
epoch 29 | loss: 0.22847 | val_0_rmse: 0.46618 | val_1_rmse: 0.46987 |  0:01:40s
epoch 30 | loss: 0.22797 | val_0_rmse: 0.51165 | val_1_rmse: 0.51691 |  0:01:43s
epoch 31 | loss: 0.22773 | val_0_rmse: 0.50004 | val_1_rmse: 0.50417 |  0:01:47s
epoch 32 | loss: 0.22517 | val_0_rmse: 0.4734  | val_1_rmse: 0.48542 |  0:01:50s
epoch 33 | loss: 0.22755 | val_0_rmse: 0.46343 | val_1_rmse: 0.46915 |  0:01:53s
epoch 34 | loss: 0.22251 | val_0_rmse: 0.47443 | val_1_rmse: 0.50028 |  0:01:57s
epoch 35 | loss: 0.22122 | val_0_rmse: 0.46345 | val_1_rmse: 0.48949 |  0:02:00s
epoch 36 | loss: 0.22464 | val_0_rmse: 0.50065 | val_1_rmse: 0.515   |  0:02:03s
epoch 37 | loss: 0.22409 | val_0_rmse: 0.46243 | val_1_rmse: 0.47097 |  0:02:07s
epoch 38 | loss: 0.22347 | val_0_rmse: 0.46707 | val_1_rmse: 0.47628 |  0:02:10s
epoch 39 | loss: 0.22279 | val_0_rmse: 0.47742 | val_1_rmse: 0.47921 |  0:02:13s
epoch 40 | loss: 0.22323 | val_0_rmse: 0.46312 | val_1_rmse: 0.47353 |  0:02:17s
epoch 41 | loss: 0.22165 | val_0_rmse: 0.4795  | val_1_rmse: 0.54075 |  0:02:20s
epoch 42 | loss: 0.2229  | val_0_rmse: 0.50709 | val_1_rmse: 0.56821 |  0:02:24s
epoch 43 | loss: 0.22688 | val_0_rmse: 0.50083 | val_1_rmse: 0.58628 |  0:02:27s
epoch 44 | loss: 0.21951 | val_0_rmse: 0.47207 | val_1_rmse: 0.477   |  0:02:30s
epoch 45 | loss: 0.22317 | val_0_rmse: 0.50725 | val_1_rmse: 0.53903 |  0:02:34s
epoch 46 | loss: 0.2215  | val_0_rmse: 0.46397 | val_1_rmse: 0.49388 |  0:02:37s
epoch 47 | loss: 0.21437 | val_0_rmse: 0.48479 | val_1_rmse: 0.52017 |  0:02:40s
epoch 48 | loss: 0.21566 | val_0_rmse: 0.47294 | val_1_rmse: 0.53765 |  0:02:44s
epoch 49 | loss: 0.21537 | val_0_rmse: 0.46176 | val_1_rmse: 0.47492 |  0:02:47s
epoch 50 | loss: 0.21866 | val_0_rmse: 0.50633 | val_1_rmse: 0.59135 |  0:02:50s
epoch 51 | loss: 0.21793 | val_0_rmse: 0.48889 | val_1_rmse: 0.56703 |  0:02:54s
epoch 52 | loss: 0.21876 | val_0_rmse: 0.48404 | val_1_rmse: 0.54955 |  0:02:57s
epoch 53 | loss: 0.21631 | val_0_rmse: 0.48516 | val_1_rmse: 0.57046 |  0:03:00s
epoch 54 | loss: 0.21661 | val_0_rmse: 0.49291 | val_1_rmse: 0.59859 |  0:03:04s
epoch 55 | loss: 0.21359 | val_0_rmse: 0.49565 | val_1_rmse: 0.60011 |  0:03:07s
epoch 56 | loss: 0.21661 | val_0_rmse: 0.47588 | val_1_rmse: 0.54426 |  0:03:10s
epoch 57 | loss: 0.21369 | val_0_rmse: 0.50308 | val_1_rmse: 0.51588 |  0:03:14s
epoch 58 | loss: 0.21746 | val_0_rmse: 0.46228 | val_1_rmse: 0.47617 |  0:03:17s
epoch 59 | loss: 0.21472 | val_0_rmse: 0.45064 | val_1_rmse: 0.4684  |  0:03:20s
epoch 60 | loss: 0.21317 | val_0_rmse: 0.45057 | val_1_rmse: 0.4681  |  0:03:24s
epoch 61 | loss: 0.21036 | val_0_rmse: 0.45132 | val_1_rmse: 0.46733 |  0:03:27s
epoch 62 | loss: 0.2096  | val_0_rmse: 0.45363 | val_1_rmse: 0.47739 |  0:03:31s
epoch 63 | loss: 0.20957 | val_0_rmse: 0.44929 | val_1_rmse: 0.47172 |  0:03:34s
epoch 64 | loss: 0.20873 | val_0_rmse: 0.45882 | val_1_rmse: 0.48563 |  0:03:37s
epoch 65 | loss: 0.20994 | val_0_rmse: 0.46398 | val_1_rmse: 0.49904 |  0:03:41s
epoch 66 | loss: 0.21082 | val_0_rmse: 0.45766 | val_1_rmse: 0.47837 |  0:03:44s
epoch 67 | loss: 0.20966 | val_0_rmse: 0.4443  | val_1_rmse: 0.46697 |  0:03:47s
epoch 68 | loss: 0.20838 | val_0_rmse: 0.44941 | val_1_rmse: 0.46948 |  0:03:51s
epoch 69 | loss: 0.21099 | val_0_rmse: 0.44922 | val_1_rmse: 0.47045 |  0:03:54s
epoch 70 | loss: 0.20813 | val_0_rmse: 0.45187 | val_1_rmse: 0.46841 |  0:03:57s
epoch 71 | loss: 0.20711 | val_0_rmse: 0.44759 | val_1_rmse: 0.46623 |  0:04:01s
epoch 72 | loss: 0.2092  | val_0_rmse: 0.45778 | val_1_rmse: 0.48244 |  0:04:04s
epoch 73 | loss: 0.20903 | val_0_rmse: 0.44954 | val_1_rmse: 0.47079 |  0:04:08s
epoch 74 | loss: 0.20749 | val_0_rmse: 0.46383 | val_1_rmse: 0.50478 |  0:04:11s
epoch 75 | loss: 0.2139  | val_0_rmse: 0.45169 | val_1_rmse: 0.47046 |  0:04:14s
epoch 76 | loss: 0.20994 | val_0_rmse: 0.45317 | val_1_rmse: 0.47629 |  0:04:18s
epoch 77 | loss: 0.21205 | val_0_rmse: 0.45238 | val_1_rmse: 0.47331 |  0:04:21s
epoch 78 | loss: 0.208   | val_0_rmse: 0.44667 | val_1_rmse: 0.4665  |  0:04:24s
epoch 79 | loss: 0.21052 | val_0_rmse: 0.45089 | val_1_rmse: 0.47157 |  0:04:28s
epoch 80 | loss: 0.20609 | val_0_rmse: 0.47274 | val_1_rmse: 0.4988  |  0:04:31s
epoch 81 | loss: 0.20753 | val_0_rmse: 0.44179 | val_1_rmse: 0.46541 |  0:04:34s
epoch 82 | loss: 0.20627 | val_0_rmse: 0.44287 | val_1_rmse: 0.46784 |  0:04:38s
epoch 83 | loss: 0.20635 | val_0_rmse: 0.45044 | val_1_rmse: 0.47142 |  0:04:41s
epoch 84 | loss: 0.20678 | val_0_rmse: 0.45199 | val_1_rmse: 0.47481 |  0:04:44s
epoch 85 | loss: 0.21007 | val_0_rmse: 0.44514 | val_1_rmse: 0.46696 |  0:04:48s
epoch 86 | loss: 0.20743 | val_0_rmse: 0.44781 | val_1_rmse: 0.47531 |  0:04:51s
epoch 87 | loss: 0.20898 | val_0_rmse: 0.45906 | val_1_rmse: 0.47905 |  0:04:54s
epoch 88 | loss: 0.2042  | val_0_rmse: 0.48664 | val_1_rmse: 0.51517 |  0:04:58s
epoch 89 | loss: 0.20751 | val_0_rmse: 0.45949 | val_1_rmse: 0.47785 |  0:05:01s
epoch 90 | loss: 0.20479 | val_0_rmse: 0.44197 | val_1_rmse: 0.46843 |  0:05:04s
epoch 91 | loss: 0.20479 | val_0_rmse: 0.45825 | val_1_rmse: 0.48227 |  0:05:08s
epoch 92 | loss: 0.20537 | val_0_rmse: 0.44049 | val_1_rmse: 0.46902 |  0:05:11s
epoch 93 | loss: 0.20546 | val_0_rmse: 0.44453 | val_1_rmse: 0.47165 |  0:05:15s
epoch 94 | loss: 0.20881 | val_0_rmse: 0.4447  | val_1_rmse: 0.4728  |  0:05:18s
epoch 95 | loss: 0.20477 | val_0_rmse: 0.4458  | val_1_rmse: 0.47866 |  0:05:21s
epoch 96 | loss: 0.20651 | val_0_rmse: 0.4477  | val_1_rmse: 0.47325 |  0:05:25s
epoch 97 | loss: 0.20128 | val_0_rmse: 0.44716 | val_1_rmse: 0.4746  |  0:05:28s
epoch 98 | loss: 0.20401 | val_0_rmse: 0.46971 | val_1_rmse: 0.49001 |  0:05:31s
epoch 99 | loss: 0.20365 | val_0_rmse: 0.44791 | val_1_rmse: 0.48551 |  0:05:35s
epoch 100| loss: 0.20322 | val_0_rmse: 0.47664 | val_1_rmse: 0.49809 |  0:05:38s
epoch 101| loss: 0.20428 | val_0_rmse: 0.44699 | val_1_rmse: 0.48083 |  0:05:41s
epoch 102| loss: 0.20045 | val_0_rmse: 0.45387 | val_1_rmse: 0.49127 |  0:05:45s
epoch 103| loss: 0.20389 | val_0_rmse: 0.459   | val_1_rmse: 0.49641 |  0:05:48s
epoch 104| loss: 0.20274 | val_0_rmse: 0.44976 | val_1_rmse: 0.49238 |  0:05:51s
epoch 105| loss: 0.20509 | val_0_rmse: 0.48844 | val_1_rmse: 0.51003 |  0:05:55s
epoch 106| loss: 0.20294 | val_0_rmse: 0.4499  | val_1_rmse: 0.48372 |  0:05:58s
epoch 107| loss: 0.20485 | val_0_rmse: 0.49429 | val_1_rmse: 0.51883 |  0:06:01s
epoch 108| loss: 0.20133 | val_0_rmse: 0.43995 | val_1_rmse: 0.49129 |  0:06:05s
epoch 109| loss: 0.19997 | val_0_rmse: 0.43784 | val_1_rmse: 0.48278 |  0:06:08s
epoch 110| loss: 0.19783 | val_0_rmse: 0.44065 | val_1_rmse: 0.48464 |  0:06:12s
epoch 111| loss: 0.2046  | val_0_rmse: 0.44519 | val_1_rmse: 0.49077 |  0:06:15s

Early stopping occured at epoch 111 with best_epoch = 81 and best_val_1_rmse = 0.46541
Best weights from best epoch are automatically used!
ended training at: 07:58:51
Feature importance:
Mean squared error is of 913574214.9917358
Mean absolute error:20458.616476110084
MAPE:0.2492401159032991
R2 score:0.7697890695647193
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 7
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 07:58:51
epoch 0  | loss: 0.87477 | val_0_rmse: 0.78851 | val_1_rmse: 0.79367 |  0:00:03s
epoch 1  | loss: 0.44423 | val_0_rmse: 0.70186 | val_1_rmse: 0.71523 |  0:00:06s
epoch 2  | loss: 0.34027 | val_0_rmse: 0.66142 | val_1_rmse: 0.67148 |  0:00:10s
epoch 3  | loss: 0.30313 | val_0_rmse: 0.58294 | val_1_rmse: 0.58684 |  0:00:13s
epoch 4  | loss: 0.27854 | val_0_rmse: 0.57278 | val_1_rmse: 0.57958 |  0:00:16s
epoch 5  | loss: 0.28188 | val_0_rmse: 0.53329 | val_1_rmse: 0.53888 |  0:00:20s
epoch 6  | loss: 0.27869 | val_0_rmse: 0.59241 | val_1_rmse: 0.59381 |  0:00:23s
epoch 7  | loss: 0.30534 | val_0_rmse: 0.54334 | val_1_rmse: 0.55401 |  0:00:26s
epoch 8  | loss: 0.27808 | val_0_rmse: 0.52376 | val_1_rmse: 0.5334  |  0:00:30s
epoch 9  | loss: 0.27161 | val_0_rmse: 0.52205 | val_1_rmse: 0.5323  |  0:00:33s
epoch 10 | loss: 0.25707 | val_0_rmse: 0.4992  | val_1_rmse: 0.5071  |  0:00:36s
epoch 11 | loss: 0.25175 | val_0_rmse: 0.50886 | val_1_rmse: 0.51856 |  0:00:40s
epoch 12 | loss: 0.25015 | val_0_rmse: 0.49182 | val_1_rmse: 0.50293 |  0:00:43s
epoch 13 | loss: 0.24416 | val_0_rmse: 0.49301 | val_1_rmse: 0.50533 |  0:00:47s
epoch 14 | loss: 0.26491 | val_0_rmse: 0.52278 | val_1_rmse: 0.52708 |  0:00:50s
epoch 15 | loss: 0.26215 | val_0_rmse: 0.53222 | val_1_rmse: 0.54745 |  0:00:53s
epoch 16 | loss: 0.2616  | val_0_rmse: 0.55252 | val_1_rmse: 0.56535 |  0:00:57s
epoch 17 | loss: 0.25308 | val_0_rmse: 0.50059 | val_1_rmse: 0.51683 |  0:01:00s
epoch 18 | loss: 0.24807 | val_0_rmse: 0.49667 | val_1_rmse: 0.50445 |  0:01:03s
epoch 19 | loss: 0.24688 | val_0_rmse: 0.53329 | val_1_rmse: 0.5565  |  0:01:07s
epoch 20 | loss: 0.24733 | val_0_rmse: 0.50764 | val_1_rmse: 0.52396 |  0:01:10s
epoch 21 | loss: 0.27556 | val_0_rmse: 0.53785 | val_1_rmse: 0.54803 |  0:01:13s
epoch 22 | loss: 0.27988 | val_0_rmse: 0.51521 | val_1_rmse: 0.52431 |  0:01:17s
epoch 23 | loss: 0.27116 | val_0_rmse: 0.52174 | val_1_rmse: 0.53922 |  0:01:20s
epoch 24 | loss: 0.26487 | val_0_rmse: 0.49999 | val_1_rmse: 0.51195 |  0:01:23s
epoch 25 | loss: 0.27122 | val_0_rmse: 0.53013 | val_1_rmse: 0.53924 |  0:01:27s
epoch 26 | loss: 0.26178 | val_0_rmse: 0.50861 | val_1_rmse: 0.51515 |  0:01:30s
epoch 27 | loss: 0.25612 | val_0_rmse: 0.48783 | val_1_rmse: 0.4984  |  0:01:33s
epoch 28 | loss: 0.24977 | val_0_rmse: 0.48769 | val_1_rmse: 0.49908 |  0:01:37s
epoch 29 | loss: 0.27218 | val_0_rmse: 0.51823 | val_1_rmse: 0.5262  |  0:01:40s
epoch 30 | loss: 0.28026 | val_0_rmse: 0.52146 | val_1_rmse: 0.53082 |  0:01:43s
epoch 31 | loss: 0.2744  | val_0_rmse: 0.51619 | val_1_rmse: 0.52709 |  0:01:47s
epoch 32 | loss: 0.27495 | val_0_rmse: 0.5186  | val_1_rmse: 0.52752 |  0:01:50s
epoch 33 | loss: 0.27366 | val_0_rmse: 0.52865 | val_1_rmse: 0.54186 |  0:01:53s
epoch 34 | loss: 0.27095 | val_0_rmse: 0.51097 | val_1_rmse: 0.52027 |  0:01:57s
epoch 35 | loss: 0.27024 | val_0_rmse: 0.52053 | val_1_rmse: 0.5316  |  0:02:00s
epoch 36 | loss: 0.27019 | val_0_rmse: 0.51105 | val_1_rmse: 0.51914 |  0:02:03s
epoch 37 | loss: 0.26576 | val_0_rmse: 0.50967 | val_1_rmse: 0.52249 |  0:02:07s
epoch 38 | loss: 0.26913 | val_0_rmse: 0.52196 | val_1_rmse: 0.5855  |  0:02:10s
epoch 39 | loss: 0.26823 | val_0_rmse: 0.52501 | val_1_rmse: 0.5364  |  0:02:13s
epoch 40 | loss: 0.26347 | val_0_rmse: 0.50981 | val_1_rmse: 0.52442 |  0:02:17s
epoch 41 | loss: 0.26825 | val_0_rmse: 0.51448 | val_1_rmse: 0.53312 |  0:02:20s
epoch 42 | loss: 0.25906 | val_0_rmse: 0.50522 | val_1_rmse: 0.53069 |  0:02:24s
epoch 43 | loss: 0.27373 | val_0_rmse: 0.54077 | val_1_rmse: 0.56434 |  0:02:27s
epoch 44 | loss: 0.2936  | val_0_rmse: 0.60426 | val_1_rmse: 0.81609 |  0:02:30s
epoch 45 | loss: 0.2812  | val_0_rmse: 0.78801 | val_1_rmse: 1.29864 |  0:02:34s
epoch 46 | loss: 0.27221 | val_0_rmse: 0.51855 | val_1_rmse: 0.53349 |  0:02:37s
epoch 47 | loss: 0.26978 | val_0_rmse: 0.5262  | val_1_rmse: 0.54814 |  0:02:40s
epoch 48 | loss: 0.26439 | val_0_rmse: 0.50881 | val_1_rmse: 0.54923 |  0:02:44s
epoch 49 | loss: 0.25561 | val_0_rmse: 0.51171 | val_1_rmse: 0.52796 |  0:02:47s
epoch 50 | loss: 0.25393 | val_0_rmse: 0.59976 | val_1_rmse: 0.86028 |  0:02:50s
epoch 51 | loss: 0.24888 | val_0_rmse: 0.59977 | val_1_rmse: 0.84694 |  0:02:54s
epoch 52 | loss: 0.23869 | val_0_rmse: 0.58543 | val_1_rmse: 0.8239  |  0:02:57s
epoch 53 | loss: 0.24244 | val_0_rmse: 0.57493 | val_1_rmse: 0.78422 |  0:03:00s
epoch 54 | loss: 0.23703 | val_0_rmse: 0.57271 | val_1_rmse: 0.79586 |  0:03:04s
epoch 55 | loss: 0.23436 | val_0_rmse: 0.57381 | val_1_rmse: 0.79408 |  0:03:07s
epoch 56 | loss: 0.23791 | val_0_rmse: 0.5286  | val_1_rmse: 0.80828 |  0:03:10s
epoch 57 | loss: 0.23123 | val_0_rmse: 0.47052 | val_1_rmse: 0.48301 |  0:03:14s
epoch 58 | loss: 0.22887 | val_0_rmse: 0.48269 | val_1_rmse: 0.49901 |  0:03:17s
epoch 59 | loss: 0.22833 | val_0_rmse: 0.47194 | val_1_rmse: 0.48462 |  0:03:20s
epoch 60 | loss: 0.22824 | val_0_rmse: 0.46907 | val_1_rmse: 0.48558 |  0:03:24s
epoch 61 | loss: 0.22681 | val_0_rmse: 0.47574 | val_1_rmse: 0.49477 |  0:03:27s
epoch 62 | loss: 0.22508 | val_0_rmse: 0.47177 | val_1_rmse: 0.49056 |  0:03:30s
epoch 63 | loss: 0.22671 | val_0_rmse: 0.46973 | val_1_rmse: 0.48896 |  0:03:34s
epoch 64 | loss: 0.22447 | val_0_rmse: 0.46383 | val_1_rmse: 0.48123 |  0:03:37s
epoch 65 | loss: 0.22579 | val_0_rmse: 0.47913 | val_1_rmse: 0.49761 |  0:03:40s
epoch 66 | loss: 0.22289 | val_0_rmse: 0.46653 | val_1_rmse: 0.48653 |  0:03:44s
epoch 67 | loss: 0.22322 | val_0_rmse: 0.47545 | val_1_rmse: 0.49698 |  0:03:47s
epoch 68 | loss: 0.22611 | val_0_rmse: 0.50483 | val_1_rmse: 0.51753 |  0:03:50s
epoch 69 | loss: 0.22559 | val_0_rmse: 0.48705 | val_1_rmse: 0.50573 |  0:03:54s
epoch 70 | loss: 0.22645 | val_0_rmse: 0.46323 | val_1_rmse: 0.4807  |  0:03:57s
epoch 71 | loss: 0.22166 | val_0_rmse: 0.46303 | val_1_rmse: 0.4825  |  0:04:00s
epoch 72 | loss: 0.22285 | val_0_rmse: 0.46832 | val_1_rmse: 0.48509 |  0:04:04s
epoch 73 | loss: 0.22478 | val_0_rmse: 0.48524 | val_1_rmse: 0.50578 |  0:04:07s
epoch 74 | loss: 0.22289 | val_0_rmse: 0.47998 | val_1_rmse: 0.50872 |  0:04:10s
epoch 75 | loss: 0.21915 | val_0_rmse: 0.51737 | val_1_rmse: 0.49983 |  0:04:14s
epoch 76 | loss: 0.22019 | val_0_rmse: 0.47086 | val_1_rmse: 0.49711 |  0:04:17s
epoch 77 | loss: 0.21719 | val_0_rmse: 0.47359 | val_1_rmse: 0.50916 |  0:04:20s
epoch 78 | loss: 0.21762 | val_0_rmse: 0.48534 | val_1_rmse: 0.49921 |  0:04:24s
epoch 79 | loss: 0.21599 | val_0_rmse: 0.45603 | val_1_rmse: 0.48218 |  0:04:27s
epoch 80 | loss: 0.21778 | val_0_rmse: 0.46545 | val_1_rmse: 0.49697 |  0:04:31s
epoch 81 | loss: 0.22041 | val_0_rmse: 0.46774 | val_1_rmse: 0.50387 |  0:04:34s
epoch 82 | loss: 0.22095 | val_0_rmse: 0.47243 | val_1_rmse: 0.51282 |  0:04:37s
epoch 83 | loss: 0.22197 | val_0_rmse: 0.46207 | val_1_rmse: 0.4955  |  0:04:41s
epoch 84 | loss: 0.21542 | val_0_rmse: 0.48103 | val_1_rmse: 0.54287 |  0:04:44s
epoch 85 | loss: 0.21581 | val_0_rmse: 0.46605 | val_1_rmse: 0.50664 |  0:04:47s
epoch 86 | loss: 0.21785 | val_0_rmse: 0.46651 | val_1_rmse: 0.52238 |  0:04:51s
epoch 87 | loss: 0.21699 | val_0_rmse: 0.47545 | val_1_rmse: 0.54706 |  0:04:54s
epoch 88 | loss: 0.21355 | val_0_rmse: 0.48571 | val_1_rmse: 0.53797 |  0:04:57s
epoch 89 | loss: 0.21557 | val_0_rmse: 0.46565 | val_1_rmse: 0.50498 |  0:05:01s
epoch 90 | loss: 0.21788 | val_0_rmse: 0.47166 | val_1_rmse: 0.50331 |  0:05:04s
epoch 91 | loss: 0.21546 | val_0_rmse: 0.46198 | val_1_rmse: 0.51959 |  0:05:07s
epoch 92 | loss: 0.21249 | val_0_rmse: 0.4636  | val_1_rmse: 0.52366 |  0:05:11s
epoch 93 | loss: 0.21442 | val_0_rmse: 0.46347 | val_1_rmse: 0.52382 |  0:05:14s
epoch 94 | loss: 0.21343 | val_0_rmse: 0.46822 | val_1_rmse: 0.53214 |  0:05:17s
epoch 95 | loss: 0.21585 | val_0_rmse: 0.46699 | val_1_rmse: 0.5229  |  0:05:21s
epoch 96 | loss: 0.21319 | val_0_rmse: 0.49184 | val_1_rmse: 0.59636 |  0:05:24s
epoch 97 | loss: 0.21188 | val_0_rmse: 0.47177 | val_1_rmse: 0.53496 |  0:05:27s
epoch 98 | loss: 0.20828 | val_0_rmse: 0.45961 | val_1_rmse: 0.49336 |  0:05:31s
epoch 99 | loss: 0.2085  | val_0_rmse: 0.45592 | val_1_rmse: 0.48713 |  0:05:34s
epoch 100| loss: 0.21124 | val_0_rmse: 0.45559 | val_1_rmse: 0.49037 |  0:05:37s

Early stopping occured at epoch 100 with best_epoch = 70 and best_val_1_rmse = 0.4807
Best weights from best epoch are automatically used!
ended training at: 08:04:30
Feature importance:
Mean squared error is of 912674557.2625673
Mean absolute error:20629.81525498503
MAPE:0.2582880553328436
R2 score:0.7690919483124157
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 8
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:04:30
epoch 0  | loss: 0.91144 | val_0_rmse: 0.80097 | val_1_rmse: 0.81915 |  0:00:03s
epoch 1  | loss: 0.36194 | val_0_rmse: 0.67589 | val_1_rmse: 0.68696 |  0:00:06s
epoch 2  | loss: 0.32151 | val_0_rmse: 0.56156 | val_1_rmse: 0.57895 |  0:00:10s
epoch 3  | loss: 0.30157 | val_0_rmse: 0.55898 | val_1_rmse: 0.57334 |  0:00:13s
epoch 4  | loss: 0.29299 | val_0_rmse: 0.56889 | val_1_rmse: 0.58406 |  0:00:16s
epoch 5  | loss: 0.27472 | val_0_rmse: 0.5562  | val_1_rmse: 0.57143 |  0:00:20s
epoch 6  | loss: 0.26546 | val_0_rmse: 0.5172  | val_1_rmse: 0.53122 |  0:00:23s
epoch 7  | loss: 0.26095 | val_0_rmse: 0.50493 | val_1_rmse: 0.52095 |  0:00:27s
epoch 8  | loss: 0.25466 | val_0_rmse: 0.51166 | val_1_rmse: 0.52748 |  0:00:30s
epoch 9  | loss: 0.25735 | val_0_rmse: 0.56087 | val_1_rmse: 0.57438 |  0:00:33s
epoch 10 | loss: 0.26544 | val_0_rmse: 0.49812 | val_1_rmse: 0.5136  |  0:00:37s
epoch 11 | loss: 0.24968 | val_0_rmse: 0.49868 | val_1_rmse: 0.51082 |  0:00:40s
epoch 12 | loss: 0.24575 | val_0_rmse: 0.48982 | val_1_rmse: 0.5065  |  0:00:43s
epoch 13 | loss: 0.24676 | val_0_rmse: 0.49317 | val_1_rmse: 0.50907 |  0:00:47s
epoch 14 | loss: 0.24936 | val_0_rmse: 0.50794 | val_1_rmse: 0.52259 |  0:00:50s
epoch 15 | loss: 0.24723 | val_0_rmse: 0.4874  | val_1_rmse: 0.50172 |  0:00:53s
epoch 16 | loss: 0.24466 | val_0_rmse: 0.48519 | val_1_rmse: 0.49829 |  0:00:57s
epoch 17 | loss: 0.25421 | val_0_rmse: 0.49954 | val_1_rmse: 0.50984 |  0:01:00s
epoch 18 | loss: 0.24572 | val_0_rmse: 0.49554 | val_1_rmse: 0.50881 |  0:01:03s
epoch 19 | loss: 0.24278 | val_0_rmse: 0.47589 | val_1_rmse: 0.49493 |  0:01:07s
epoch 20 | loss: 0.23832 | val_0_rmse: 0.46907 | val_1_rmse: 0.48601 |  0:01:10s
epoch 21 | loss: 0.23294 | val_0_rmse: 0.47185 | val_1_rmse: 0.49092 |  0:01:13s
epoch 22 | loss: 0.23195 | val_0_rmse: 0.46769 | val_1_rmse: 0.48985 |  0:01:17s
epoch 23 | loss: 0.23001 | val_0_rmse: 0.4663  | val_1_rmse: 0.48908 |  0:01:20s
epoch 24 | loss: 0.23456 | val_0_rmse: 0.4694  | val_1_rmse: 0.48887 |  0:01:23s
epoch 25 | loss: 0.23102 | val_0_rmse: 0.49362 | val_1_rmse: 0.51771 |  0:01:27s
epoch 26 | loss: 0.2293  | val_0_rmse: 0.51645 | val_1_rmse: 0.53535 |  0:01:30s
epoch 27 | loss: 0.22979 | val_0_rmse: 0.48378 | val_1_rmse: 0.50603 |  0:01:33s
epoch 28 | loss: 0.23134 | val_0_rmse: 0.48318 | val_1_rmse: 0.49788 |  0:01:37s
epoch 29 | loss: 0.22791 | val_0_rmse: 0.50304 | val_1_rmse: 0.51453 |  0:01:40s
epoch 30 | loss: 0.22973 | val_0_rmse: 0.47434 | val_1_rmse: 0.48601 |  0:01:43s
epoch 31 | loss: 0.2281  | val_0_rmse: 0.49348 | val_1_rmse: 0.5043  |  0:01:47s
epoch 32 | loss: 0.2264  | val_0_rmse: 0.48455 | val_1_rmse: 0.53147 |  0:01:50s
epoch 33 | loss: 0.22178 | val_0_rmse: 0.49444 | val_1_rmse: 0.56992 |  0:01:53s
epoch 34 | loss: 0.23407 | val_0_rmse: 0.49573 | val_1_rmse: 0.52399 |  0:01:57s
epoch 35 | loss: 0.22876 | val_0_rmse: 0.55943 | val_1_rmse: 0.54397 |  0:02:00s
epoch 36 | loss: 0.2249  | val_0_rmse: 0.48576 | val_1_rmse: 0.53648 |  0:02:04s
epoch 37 | loss: 0.22692 | val_0_rmse: 0.53493 | val_1_rmse: 0.51876 |  0:02:07s
epoch 38 | loss: 0.23533 | val_0_rmse: 0.49695 | val_1_rmse: 0.48081 |  0:02:10s
epoch 39 | loss: 0.23785 | val_0_rmse: 0.49425 | val_1_rmse: 0.50769 |  0:02:14s
epoch 40 | loss: 0.24632 | val_0_rmse: 0.48586 | val_1_rmse: 0.50292 |  0:02:17s
epoch 41 | loss: 0.25906 | val_0_rmse: 0.55066 | val_1_rmse: 0.50813 |  0:02:20s
epoch 42 | loss: 0.24627 | val_0_rmse: 0.52036 | val_1_rmse: 0.48799 |  0:02:24s
epoch 43 | loss: 0.22828 | val_0_rmse: 0.87761 | val_1_rmse: 0.55107 |  0:02:27s
epoch 44 | loss: 0.2587  | val_0_rmse: 0.54107 | val_1_rmse: 0.54037 |  0:02:30s
epoch 45 | loss: 0.25659 | val_0_rmse: 0.52589 | val_1_rmse: 0.52438 |  0:02:34s
epoch 46 | loss: 0.2452  | val_0_rmse: 0.5075  | val_1_rmse: 0.51427 |  0:02:37s
epoch 47 | loss: 0.2378  | val_0_rmse: 0.49359 | val_1_rmse: 0.50896 |  0:02:40s
epoch 48 | loss: 0.23773 | val_0_rmse: 0.60354 | val_1_rmse: 0.61091 |  0:02:44s
epoch 49 | loss: 0.23656 | val_0_rmse: 0.57292 | val_1_rmse: 0.54492 |  0:02:47s
epoch 50 | loss: 0.22917 | val_0_rmse: 0.47454 | val_1_rmse: 0.49569 |  0:02:50s
epoch 51 | loss: 0.22434 | val_0_rmse: 0.48633 | val_1_rmse: 0.5061  |  0:02:54s
epoch 52 | loss: 0.22565 | val_0_rmse: 0.46179 | val_1_rmse: 0.48605 |  0:02:57s
epoch 53 | loss: 0.22414 | val_0_rmse: 0.46521 | val_1_rmse: 0.48644 |  0:03:00s
epoch 54 | loss: 0.22028 | val_0_rmse: 0.46534 | val_1_rmse: 0.4839  |  0:03:04s
epoch 55 | loss: 0.2279  | val_0_rmse: 0.4738  | val_1_rmse: 0.50087 |  0:03:07s
epoch 56 | loss: 0.22343 | val_0_rmse: 0.46099 | val_1_rmse: 0.48372 |  0:03:10s
epoch 57 | loss: 0.21797 | val_0_rmse: 0.45886 | val_1_rmse: 0.48371 |  0:03:14s
epoch 58 | loss: 0.2179  | val_0_rmse: 0.45525 | val_1_rmse: 0.48416 |  0:03:17s
epoch 59 | loss: 0.21652 | val_0_rmse: 0.45837 | val_1_rmse: 0.48061 |  0:03:20s
epoch 60 | loss: 0.2139  | val_0_rmse: 0.45614 | val_1_rmse: 0.47984 |  0:03:24s
epoch 61 | loss: 0.21834 | val_0_rmse: 0.46083 | val_1_rmse: 0.48663 |  0:03:27s
epoch 62 | loss: 0.22053 | val_0_rmse: 0.47264 | val_1_rmse: 0.48617 |  0:03:31s
epoch 63 | loss: 0.21252 | val_0_rmse: 0.45122 | val_1_rmse: 0.47621 |  0:03:34s
epoch 64 | loss: 0.21685 | val_0_rmse: 0.56167 | val_1_rmse: 0.49047 |  0:03:38s
epoch 65 | loss: 0.21455 | val_0_rmse: 0.47377 | val_1_rmse: 0.48253 |  0:03:41s
epoch 66 | loss: 0.21425 | val_0_rmse: 0.4958  | val_1_rmse: 0.49017 |  0:03:44s
epoch 67 | loss: 0.21301 | val_0_rmse: 0.46324 | val_1_rmse: 0.47667 |  0:03:47s
epoch 68 | loss: 0.20969 | val_0_rmse: 0.48183 | val_1_rmse: 0.49248 |  0:03:51s
epoch 69 | loss: 0.21371 | val_0_rmse: 0.47517 | val_1_rmse: 0.48554 |  0:03:54s
epoch 70 | loss: 0.21204 | val_0_rmse: 0.51073 | val_1_rmse: 0.50517 |  0:03:57s
epoch 71 | loss: 0.2097  | val_0_rmse: 0.47635 | val_1_rmse: 0.48603 |  0:04:01s
epoch 72 | loss: 0.21265 | val_0_rmse: 0.52722 | val_1_rmse: 0.48328 |  0:04:04s
epoch 73 | loss: 0.21014 | val_0_rmse: 0.4942  | val_1_rmse: 0.48333 |  0:04:07s
epoch 74 | loss: 0.20787 | val_0_rmse: 0.45478 | val_1_rmse: 0.47933 |  0:04:11s
epoch 75 | loss: 0.20788 | val_0_rmse: 0.45697 | val_1_rmse: 0.48486 |  0:04:14s
epoch 76 | loss: 0.20609 | val_0_rmse: 0.45461 | val_1_rmse: 0.48727 |  0:04:18s
epoch 77 | loss: 0.20708 | val_0_rmse: 0.47229 | val_1_rmse: 0.49027 |  0:04:21s
epoch 78 | loss: 0.20895 | val_0_rmse: 0.44564 | val_1_rmse: 0.47791 |  0:04:24s
epoch 79 | loss: 0.21115 | val_0_rmse: 0.4513  | val_1_rmse: 0.48683 |  0:04:28s
epoch 80 | loss: 0.20903 | val_0_rmse: 0.46    | val_1_rmse: 0.49201 |  0:04:31s
epoch 81 | loss: 0.20469 | val_0_rmse: 0.44754 | val_1_rmse: 0.48151 |  0:04:34s
epoch 82 | loss: 0.20502 | val_0_rmse: 0.44449 | val_1_rmse: 0.47685 |  0:04:38s
epoch 83 | loss: 0.20498 | val_0_rmse: 0.45327 | val_1_rmse: 0.4883  |  0:04:41s
epoch 84 | loss: 0.20412 | val_0_rmse: 0.44889 | val_1_rmse: 0.48639 |  0:04:44s
epoch 85 | loss: 0.20787 | val_0_rmse: 0.44773 | val_1_rmse: 0.48191 |  0:04:48s
epoch 86 | loss: 0.20537 | val_0_rmse: 0.44566 | val_1_rmse: 0.47771 |  0:04:51s
epoch 87 | loss: 0.20803 | val_0_rmse: 0.4444  | val_1_rmse: 0.47882 |  0:04:55s
epoch 88 | loss: 0.20542 | val_0_rmse: 0.4435  | val_1_rmse: 0.48048 |  0:04:58s
epoch 89 | loss: 0.20862 | val_0_rmse: 0.44639 | val_1_rmse: 0.48124 |  0:05:01s
epoch 90 | loss: 0.203   | val_0_rmse: 0.44657 | val_1_rmse: 0.48563 |  0:05:04s
epoch 91 | loss: 0.20925 | val_0_rmse: 0.44138 | val_1_rmse: 0.47972 |  0:05:08s
epoch 92 | loss: 0.20299 | val_0_rmse: 0.45079 | val_1_rmse: 0.48793 |  0:05:11s
epoch 93 | loss: 0.20541 | val_0_rmse: 0.44416 | val_1_rmse: 0.47678 |  0:05:14s

Early stopping occured at epoch 93 with best_epoch = 63 and best_val_1_rmse = 0.47621
Best weights from best epoch are automatically used!
ended training at: 08:09:46
Feature importance:
Mean squared error is of 880366811.1720752
Mean absolute error:20142.47415841344
MAPE:0.24376647863499493
R2 score:0.7733665164338641
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: co properties.csv
Using seed = 9
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:09:47
epoch 0  | loss: 0.7858  | val_0_rmse: 0.86791 | val_1_rmse: 0.8615  |  0:00:03s
epoch 1  | loss: 0.36806 | val_0_rmse: 0.62139 | val_1_rmse: 0.61443 |  0:00:06s
epoch 2  | loss: 0.30112 | val_0_rmse: 0.57623 | val_1_rmse: 0.56748 |  0:00:10s
epoch 3  | loss: 0.29556 | val_0_rmse: 0.59047 | val_1_rmse: 0.5842  |  0:00:13s
epoch 4  | loss: 0.27145 | val_0_rmse: 0.55225 | val_1_rmse: 0.54444 |  0:00:16s
epoch 5  | loss: 0.25843 | val_0_rmse: 0.55228 | val_1_rmse: 0.54536 |  0:00:20s
epoch 6  | loss: 0.26623 | val_0_rmse: 0.53524 | val_1_rmse: 0.52526 |  0:00:23s
epoch 7  | loss: 0.25962 | val_0_rmse: 0.5267  | val_1_rmse: 0.51746 |  0:00:26s
epoch 8  | loss: 0.257   | val_0_rmse: 0.51222 | val_1_rmse: 0.50506 |  0:00:30s
epoch 9  | loss: 0.252   | val_0_rmse: 0.51855 | val_1_rmse: 0.50761 |  0:00:33s
epoch 10 | loss: 0.25119 | val_0_rmse: 0.50858 | val_1_rmse: 0.49972 |  0:00:36s
epoch 11 | loss: 0.25074 | val_0_rmse: 0.49621 | val_1_rmse: 0.48628 |  0:00:40s
epoch 12 | loss: 0.24547 | val_0_rmse: 0.49271 | val_1_rmse: 0.48242 |  0:00:43s
epoch 13 | loss: 0.2497  | val_0_rmse: 0.49323 | val_1_rmse: 0.48652 |  0:00:46s
epoch 14 | loss: 0.24352 | val_0_rmse: 0.48381 | val_1_rmse: 0.47509 |  0:00:50s
epoch 15 | loss: 0.24019 | val_0_rmse: 0.48469 | val_1_rmse: 0.47828 |  0:00:53s
epoch 16 | loss: 0.24152 | val_0_rmse: 0.49338 | val_1_rmse: 0.48937 |  0:00:56s
epoch 17 | loss: 0.24098 | val_0_rmse: 0.48876 | val_1_rmse: 0.48263 |  0:01:00s
epoch 18 | loss: 0.23986 | val_0_rmse: 0.47612 | val_1_rmse: 0.47138 |  0:01:03s
epoch 19 | loss: 0.23952 | val_0_rmse: 0.47388 | val_1_rmse: 0.46926 |  0:01:06s
epoch 20 | loss: 0.23656 | val_0_rmse: 0.48596 | val_1_rmse: 0.48337 |  0:01:10s
epoch 21 | loss: 0.23796 | val_0_rmse: 0.47876 | val_1_rmse: 0.47855 |  0:01:13s
epoch 22 | loss: 0.23512 | val_0_rmse: 0.47207 | val_1_rmse: 0.47168 |  0:01:16s
epoch 23 | loss: 0.23563 | val_0_rmse: 0.48783 | val_1_rmse: 0.48801 |  0:01:20s
epoch 24 | loss: 0.23666 | val_0_rmse: 0.47393 | val_1_rmse: 0.47329 |  0:01:23s
epoch 25 | loss: 0.23503 | val_0_rmse: 0.50826 | val_1_rmse: 0.51115 |  0:01:26s
epoch 26 | loss: 0.23665 | val_0_rmse: 0.47532 | val_1_rmse: 0.48007 |  0:01:30s
epoch 27 | loss: 0.23651 | val_0_rmse: 0.4798  | val_1_rmse: 0.48068 |  0:01:33s
epoch 28 | loss: 0.24176 | val_0_rmse: 0.47333 | val_1_rmse: 0.48249 |  0:01:37s
epoch 29 | loss: 0.23259 | val_0_rmse: 0.48718 | val_1_rmse: 0.50151 |  0:01:40s
epoch 30 | loss: 0.232   | val_0_rmse: 0.48467 | val_1_rmse: 0.50271 |  0:01:43s
epoch 31 | loss: 0.23487 | val_0_rmse: 0.47384 | val_1_rmse: 0.47807 |  0:01:47s
epoch 32 | loss: 0.23047 | val_0_rmse: 0.49446 | val_1_rmse: 0.49742 |  0:01:50s
epoch 33 | loss: 0.22795 | val_0_rmse: 0.47447 | val_1_rmse: 0.47889 |  0:01:53s
epoch 34 | loss: 0.23099 | val_0_rmse: 0.4865  | val_1_rmse: 0.49082 |  0:01:57s
epoch 35 | loss: 0.22985 | val_0_rmse: 0.4772  | val_1_rmse: 0.47869 |  0:02:00s
epoch 36 | loss: 0.23034 | val_0_rmse: 0.47198 | val_1_rmse: 0.4789  |  0:02:03s
epoch 37 | loss: 0.22472 | val_0_rmse: 0.47687 | val_1_rmse: 0.48345 |  0:02:07s
epoch 38 | loss: 0.22873 | val_0_rmse: 0.46833 | val_1_rmse: 0.47624 |  0:02:10s
epoch 39 | loss: 0.22681 | val_0_rmse: 0.46804 | val_1_rmse: 0.47529 |  0:02:14s
epoch 40 | loss: 0.22463 | val_0_rmse: 0.46183 | val_1_rmse: 0.46736 |  0:02:17s
epoch 41 | loss: 0.22591 | val_0_rmse: 0.47009 | val_1_rmse: 0.47831 |  0:02:20s
epoch 42 | loss: 0.22731 | val_0_rmse: 0.47156 | val_1_rmse: 0.47936 |  0:02:24s
epoch 43 | loss: 0.22325 | val_0_rmse: 0.46006 | val_1_rmse: 0.46791 |  0:02:27s
epoch 44 | loss: 0.22011 | val_0_rmse: 0.48731 | val_1_rmse: 0.49668 |  0:02:30s
epoch 45 | loss: 0.22167 | val_0_rmse: 0.46393 | val_1_rmse: 0.47117 |  0:02:34s
epoch 46 | loss: 0.22222 | val_0_rmse: 0.45966 | val_1_rmse: 0.47011 |  0:02:37s
epoch 47 | loss: 0.22124 | val_0_rmse: 0.5322  | val_1_rmse: 0.53526 |  0:02:40s
epoch 48 | loss: 0.22545 | val_0_rmse: 0.4757  | val_1_rmse: 0.48722 |  0:02:44s
epoch 49 | loss: 0.22286 | val_0_rmse: 0.46563 | val_1_rmse: 0.47624 |  0:02:47s
epoch 50 | loss: 0.22188 | val_0_rmse: 0.48965 | val_1_rmse: 0.50245 |  0:02:50s
epoch 51 | loss: 0.22195 | val_0_rmse: 0.52673 | val_1_rmse: 0.53596 |  0:02:54s
epoch 52 | loss: 0.22546 | val_0_rmse: 0.48433 | val_1_rmse: 0.49558 |  0:02:57s
epoch 53 | loss: 0.22108 | val_0_rmse: 0.48053 | val_1_rmse: 0.49041 |  0:03:00s
epoch 54 | loss: 0.21971 | val_0_rmse: 0.49349 | val_1_rmse: 0.50434 |  0:03:04s
epoch 55 | loss: 0.2194  | val_0_rmse: 0.45987 | val_1_rmse: 0.4714  |  0:03:07s
epoch 56 | loss: 0.22032 | val_0_rmse: 0.47206 | val_1_rmse: 0.48075 |  0:03:10s
epoch 57 | loss: 0.22471 | val_0_rmse: 0.46436 | val_1_rmse: 0.47589 |  0:03:14s
epoch 58 | loss: 0.2204  | val_0_rmse: 0.45657 | val_1_rmse: 0.47029 |  0:03:17s
epoch 59 | loss: 0.2181  | val_0_rmse: 0.46317 | val_1_rmse: 0.47431 |  0:03:20s
epoch 60 | loss: 0.21922 | val_0_rmse: 0.46079 | val_1_rmse: 0.47358 |  0:03:24s
epoch 61 | loss: 0.21778 | val_0_rmse: 0.4793  | val_1_rmse: 0.48861 |  0:03:27s
epoch 62 | loss: 0.21499 | val_0_rmse: 0.45807 | val_1_rmse: 0.46669 |  0:03:30s
epoch 63 | loss: 0.21309 | val_0_rmse: 0.46296 | val_1_rmse: 0.47837 |  0:03:34s
epoch 64 | loss: 0.21452 | val_0_rmse: 0.48224 | val_1_rmse: 0.49425 |  0:03:37s
epoch 65 | loss: 0.21693 | val_0_rmse: 0.45599 | val_1_rmse: 0.46952 |  0:03:40s
epoch 66 | loss: 0.21592 | val_0_rmse: 0.46733 | val_1_rmse: 0.4817  |  0:03:44s
epoch 67 | loss: 0.21401 | val_0_rmse: 0.45562 | val_1_rmse: 0.46616 |  0:03:47s
epoch 68 | loss: 0.21467 | val_0_rmse: 0.46302 | val_1_rmse: 0.47709 |  0:03:50s
epoch 69 | loss: 0.21786 | val_0_rmse: 0.45595 | val_1_rmse: 0.46835 |  0:03:53s
epoch 70 | loss: 0.21565 | val_0_rmse: 0.45226 | val_1_rmse: 0.467   |  0:03:57s
epoch 71 | loss: 0.21373 | val_0_rmse: 0.47134 | val_1_rmse: 0.48202 |  0:04:00s
epoch 72 | loss: 0.21526 | val_0_rmse: 0.47043 | val_1_rmse: 0.48428 |  0:04:03s
epoch 73 | loss: 0.21072 | val_0_rmse: 0.46221 | val_1_rmse: 0.47671 |  0:04:07s
epoch 74 | loss: 0.21685 | val_0_rmse: 0.469   | val_1_rmse: 0.47982 |  0:04:10s
epoch 75 | loss: 0.21068 | val_0_rmse: 0.45879 | val_1_rmse: 0.46983 |  0:04:13s
epoch 76 | loss: 0.21791 | val_0_rmse: 0.47106 | val_1_rmse: 0.48283 |  0:04:17s
epoch 77 | loss: 0.21235 | val_0_rmse: 0.45708 | val_1_rmse: 0.47113 |  0:04:20s
epoch 78 | loss: 0.21387 | val_0_rmse: 0.46915 | val_1_rmse: 0.48348 |  0:04:24s
epoch 79 | loss: 0.21312 | val_0_rmse: 0.4483  | val_1_rmse: 0.46789 |  0:04:27s
epoch 80 | loss: 0.21061 | val_0_rmse: 0.4508  | val_1_rmse: 0.46574 |  0:04:30s
epoch 81 | loss: 0.20927 | val_0_rmse: 0.47024 | val_1_rmse: 0.48374 |  0:04:34s
epoch 82 | loss: 0.21036 | val_0_rmse: 0.45396 | val_1_rmse: 0.4702  |  0:04:37s
epoch 83 | loss: 0.20723 | val_0_rmse: 0.44693 | val_1_rmse: 0.46631 |  0:04:40s
epoch 84 | loss: 0.2121  | val_0_rmse: 0.45036 | val_1_rmse: 0.46745 |  0:04:44s
epoch 85 | loss: 0.21423 | val_0_rmse: 0.45481 | val_1_rmse: 0.46999 |  0:04:47s
epoch 86 | loss: 0.21293 | val_0_rmse: 0.45398 | val_1_rmse: 0.46939 |  0:04:50s
epoch 87 | loss: 0.20729 | val_0_rmse: 0.44708 | val_1_rmse: 0.4671  |  0:04:54s
epoch 88 | loss: 0.20962 | val_0_rmse: 0.45183 | val_1_rmse: 0.46978 |  0:04:57s
epoch 89 | loss: 0.21019 | val_0_rmse: 0.47096 | val_1_rmse: 0.48947 |  0:05:00s
epoch 90 | loss: 0.21147 | val_0_rmse: 0.4579  | val_1_rmse: 0.479   |  0:05:04s
epoch 91 | loss: 0.21135 | val_0_rmse: 0.45051 | val_1_rmse: 0.47168 |  0:05:07s
epoch 92 | loss: 0.20586 | val_0_rmse: 0.44571 | val_1_rmse: 0.46715 |  0:05:10s
epoch 93 | loss: 0.2073  | val_0_rmse: 0.46025 | val_1_rmse: 0.47177 |  0:05:14s
epoch 94 | loss: 0.20473 | val_0_rmse: 0.44878 | val_1_rmse: 0.46799 |  0:05:17s
epoch 95 | loss: 0.20314 | val_0_rmse: 0.45753 | val_1_rmse: 0.48062 |  0:05:21s
epoch 96 | loss: 0.20626 | val_0_rmse: 0.44838 | val_1_rmse: 0.47383 |  0:05:24s
epoch 97 | loss: 0.20773 | val_0_rmse: 0.45244 | val_1_rmse: 0.47584 |  0:05:27s
epoch 98 | loss: 0.20812 | val_0_rmse: 0.45429 | val_1_rmse: 0.47705 |  0:05:31s
epoch 99 | loss: 0.21026 | val_0_rmse: 0.46163 | val_1_rmse: 0.48244 |  0:05:34s
epoch 100| loss: 0.21105 | val_0_rmse: 0.45875 | val_1_rmse: 0.48196 |  0:05:37s
epoch 101| loss: 0.20689 | val_0_rmse: 0.56969 | val_1_rmse: 0.46709 |  0:05:41s
epoch 102| loss: 0.20607 | val_0_rmse: 0.44978 | val_1_rmse: 0.47191 |  0:05:44s
epoch 103| loss: 0.20562 | val_0_rmse: 0.46773 | val_1_rmse: 0.49215 |  0:05:47s
epoch 104| loss: 0.20378 | val_0_rmse: 0.44316 | val_1_rmse: 0.46827 |  0:05:51s
epoch 105| loss: 0.20384 | val_0_rmse: 0.45106 | val_1_rmse: 0.47619 |  0:05:54s
epoch 106| loss: 0.21827 | val_0_rmse: 0.48546 | val_1_rmse: 0.50823 |  0:05:57s
epoch 107| loss: 0.22351 | val_0_rmse: 0.46833 | val_1_rmse: 0.48654 |  0:06:01s
epoch 108| loss: 0.2202  | val_0_rmse: 0.48218 | val_1_rmse: 0.51014 |  0:06:04s
epoch 109| loss: 0.22375 | val_0_rmse: 0.47058 | val_1_rmse: 0.4899  |  0:06:07s
epoch 110| loss: 0.22186 | val_0_rmse: 0.48664 | val_1_rmse: 0.58981 |  0:06:11s

Early stopping occured at epoch 110 with best_epoch = 80 and best_val_1_rmse = 0.46574
Best weights from best epoch are automatically used!
ended training at: 08:15:59
Feature importance:
Mean squared error is of 911933828.5259426
Mean absolute error:20291.667461548706
MAPE:0.23622043220670771
R2 score:0.7674027109245443
------------------------------------------------------------------
Normalization used is StandardScaler
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 0
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:15:59
epoch 0  | loss: 2.09272 | val_0_rmse: 0.9649  | val_1_rmse: 0.99332 |  0:00:00s
epoch 1  | loss: 1.34161 | val_0_rmse: 0.92653 | val_1_rmse: 0.92783 |  0:00:00s
epoch 2  | loss: 1.06492 | val_0_rmse: 0.84653 | val_1_rmse: 0.82255 |  0:00:00s
epoch 3  | loss: 0.94319 | val_0_rmse: 0.86559 | val_1_rmse: 0.84181 |  0:00:00s
epoch 4  | loss: 0.75316 | val_0_rmse: 0.86114 | val_1_rmse: 0.82049 |  0:00:01s
epoch 5  | loss: 0.62677 | val_0_rmse: 0.85745 | val_1_rmse: 0.84138 |  0:00:01s
epoch 6  | loss: 0.69527 | val_0_rmse: 0.8041  | val_1_rmse: 0.79331 |  0:00:01s
epoch 7  | loss: 0.64848 | val_0_rmse: 0.77372 | val_1_rmse: 0.76272 |  0:00:01s
epoch 8  | loss: 0.57796 | val_0_rmse: 0.77097 | val_1_rmse: 0.77277 |  0:00:01s
epoch 9  | loss: 0.57746 | val_0_rmse: 0.77954 | val_1_rmse: 0.77212 |  0:00:02s
epoch 10 | loss: 0.57851 | val_0_rmse: 0.78524 | val_1_rmse: 0.76812 |  0:00:02s
epoch 11 | loss: 0.54988 | val_0_rmse: 0.78582 | val_1_rmse: 0.75715 |  0:00:02s
epoch 12 | loss: 0.5603  | val_0_rmse: 0.81569 | val_1_rmse: 0.76575 |  0:00:02s
epoch 13 | loss: 0.51732 | val_0_rmse: 0.78776 | val_1_rmse: 0.74192 |  0:00:02s
epoch 14 | loss: 0.49966 | val_0_rmse: 0.82095 | val_1_rmse: 0.75812 |  0:00:03s
epoch 15 | loss: 0.5079  | val_0_rmse: 0.82894 | val_1_rmse: 0.7578  |  0:00:03s
epoch 16 | loss: 0.51276 | val_0_rmse: 0.74642 | val_1_rmse: 0.69948 |  0:00:03s
epoch 17 | loss: 0.49163 | val_0_rmse: 0.74082 | val_1_rmse: 0.69081 |  0:00:03s
epoch 18 | loss: 0.49679 | val_0_rmse: 0.72908 | val_1_rmse: 0.68473 |  0:00:03s
epoch 19 | loss: 0.49385 | val_0_rmse: 0.72782 | val_1_rmse: 0.69457 |  0:00:04s
epoch 20 | loss: 0.49742 | val_0_rmse: 0.73316 | val_1_rmse: 0.68977 |  0:00:04s
epoch 21 | loss: 0.48407 | val_0_rmse: 0.74708 | val_1_rmse: 0.68509 |  0:00:04s
epoch 22 | loss: 0.48682 | val_0_rmse: 0.73266 | val_1_rmse: 0.6865  |  0:00:04s
epoch 23 | loss: 0.48003 | val_0_rmse: 0.72067 | val_1_rmse: 0.69198 |  0:00:04s
epoch 24 | loss: 0.48145 | val_0_rmse: 0.71914 | val_1_rmse: 0.68231 |  0:00:05s
epoch 25 | loss: 0.48163 | val_0_rmse: 0.71281 | val_1_rmse: 0.68837 |  0:00:05s
epoch 26 | loss: 0.47317 | val_0_rmse: 0.71881 | val_1_rmse: 0.69646 |  0:00:05s
epoch 27 | loss: 0.48833 | val_0_rmse: 0.72218 | val_1_rmse: 0.67919 |  0:00:05s
epoch 28 | loss: 0.49392 | val_0_rmse: 0.72184 | val_1_rmse: 0.67935 |  0:00:05s
epoch 29 | loss: 0.47375 | val_0_rmse: 0.71659 | val_1_rmse: 0.69514 |  0:00:06s
epoch 30 | loss: 0.47455 | val_0_rmse: 0.71726 | val_1_rmse: 0.69309 |  0:00:06s
epoch 31 | loss: 0.47332 | val_0_rmse: 0.71035 | val_1_rmse: 0.66916 |  0:00:06s
epoch 32 | loss: 0.46208 | val_0_rmse: 0.70772 | val_1_rmse: 0.67146 |  0:00:06s
epoch 33 | loss: 0.46791 | val_0_rmse: 0.71013 | val_1_rmse: 0.67842 |  0:00:06s
epoch 34 | loss: 0.45914 | val_0_rmse: 0.70707 | val_1_rmse: 0.67573 |  0:00:07s
epoch 35 | loss: 0.47339 | val_0_rmse: 0.71335 | val_1_rmse: 0.68605 |  0:00:07s
epoch 36 | loss: 0.46937 | val_0_rmse: 0.73275 | val_1_rmse: 0.71299 |  0:00:07s
epoch 37 | loss: 0.47015 | val_0_rmse: 0.71259 | val_1_rmse: 0.67431 |  0:00:07s
epoch 38 | loss: 0.48178 | val_0_rmse: 0.7113  | val_1_rmse: 0.66625 |  0:00:08s
epoch 39 | loss: 0.48335 | val_0_rmse: 0.72175 | val_1_rmse: 0.69143 |  0:00:08s
epoch 40 | loss: 0.46718 | val_0_rmse: 0.73276 | val_1_rmse: 0.70903 |  0:00:08s
epoch 41 | loss: 0.46354 | val_0_rmse: 0.70889 | val_1_rmse: 0.67418 |  0:00:08s
epoch 42 | loss: 0.44851 | val_0_rmse: 0.70659 | val_1_rmse: 0.67039 |  0:00:08s
epoch 43 | loss: 0.45459 | val_0_rmse: 0.70511 | val_1_rmse: 0.66906 |  0:00:09s
epoch 44 | loss: 0.46125 | val_0_rmse: 0.69912 | val_1_rmse: 0.66477 |  0:00:09s
epoch 45 | loss: 0.45542 | val_0_rmse: 0.69748 | val_1_rmse: 0.66269 |  0:00:09s
epoch 46 | loss: 0.45677 | val_0_rmse: 0.6893  | val_1_rmse: 0.65436 |  0:00:09s
epoch 47 | loss: 0.46538 | val_0_rmse: 0.69291 | val_1_rmse: 0.66349 |  0:00:09s
epoch 48 | loss: 0.44434 | val_0_rmse: 0.69364 | val_1_rmse: 0.66833 |  0:00:10s
epoch 49 | loss: 0.4502  | val_0_rmse: 0.68896 | val_1_rmse: 0.66008 |  0:00:10s
epoch 50 | loss: 0.45811 | val_0_rmse: 0.68279 | val_1_rmse: 0.63513 |  0:00:10s
epoch 51 | loss: 0.44601 | val_0_rmse: 0.69118 | val_1_rmse: 0.63527 |  0:00:10s
epoch 52 | loss: 0.44967 | val_0_rmse: 0.68728 | val_1_rmse: 0.63851 |  0:00:10s
epoch 53 | loss: 0.43484 | val_0_rmse: 0.67367 | val_1_rmse: 0.62312 |  0:00:11s
epoch 54 | loss: 0.43483 | val_0_rmse: 0.66762 | val_1_rmse: 0.62215 |  0:00:11s
epoch 55 | loss: 0.43161 | val_0_rmse: 0.6711  | val_1_rmse: 0.62808 |  0:00:11s
epoch 56 | loss: 0.44033 | val_0_rmse: 0.66173 | val_1_rmse: 0.6171  |  0:00:11s
epoch 57 | loss: 0.43359 | val_0_rmse: 0.65704 | val_1_rmse: 0.60755 |  0:00:11s
epoch 58 | loss: 0.43739 | val_0_rmse: 0.65709 | val_1_rmse: 0.60278 |  0:00:12s
epoch 59 | loss: 0.42513 | val_0_rmse: 0.65588 | val_1_rmse: 0.60063 |  0:00:12s
epoch 60 | loss: 0.43059 | val_0_rmse: 0.6479  | val_1_rmse: 0.5913  |  0:00:12s
epoch 61 | loss: 0.41077 | val_0_rmse: 0.64823 | val_1_rmse: 0.60047 |  0:00:12s
epoch 62 | loss: 0.41224 | val_0_rmse: 0.6522  | val_1_rmse: 0.6125  |  0:00:12s
epoch 63 | loss: 0.40604 | val_0_rmse: 0.65092 | val_1_rmse: 0.60676 |  0:00:13s
epoch 64 | loss: 0.4112  | val_0_rmse: 0.65286 | val_1_rmse: 0.61064 |  0:00:13s
epoch 65 | loss: 0.42261 | val_0_rmse: 0.65244 | val_1_rmse: 0.6082  |  0:00:13s
epoch 66 | loss: 0.42417 | val_0_rmse: 0.64995 | val_1_rmse: 0.60512 |  0:00:13s
epoch 67 | loss: 0.41648 | val_0_rmse: 0.64996 | val_1_rmse: 0.60891 |  0:00:13s
epoch 68 | loss: 0.40525 | val_0_rmse: 0.65792 | val_1_rmse: 0.62535 |  0:00:14s
epoch 69 | loss: 0.41061 | val_0_rmse: 0.65413 | val_1_rmse: 0.6244  |  0:00:14s
epoch 70 | loss: 0.40965 | val_0_rmse: 0.64833 | val_1_rmse: 0.61619 |  0:00:14s
epoch 71 | loss: 0.40764 | val_0_rmse: 0.64801 | val_1_rmse: 0.61471 |  0:00:14s
epoch 72 | loss: 0.40159 | val_0_rmse: 0.65636 | val_1_rmse: 0.62856 |  0:00:14s
epoch 73 | loss: 0.40253 | val_0_rmse: 0.65094 | val_1_rmse: 0.62543 |  0:00:15s
epoch 74 | loss: 0.40537 | val_0_rmse: 0.64351 | val_1_rmse: 0.61473 |  0:00:15s
epoch 75 | loss: 0.40091 | val_0_rmse: 0.65205 | val_1_rmse: 0.62524 |  0:00:15s
epoch 76 | loss: 0.40507 | val_0_rmse: 0.6836  | val_1_rmse: 0.66798 |  0:00:15s
epoch 77 | loss: 0.40001 | val_0_rmse: 0.67173 | val_1_rmse: 0.6603  |  0:00:15s
epoch 78 | loss: 0.39903 | val_0_rmse: 0.67135 | val_1_rmse: 0.66225 |  0:00:16s
epoch 79 | loss: 0.40154 | val_0_rmse: 0.67121 | val_1_rmse: 0.66089 |  0:00:16s
epoch 80 | loss: 0.39356 | val_0_rmse: 0.66344 | val_1_rmse: 0.64708 |  0:00:16s
epoch 81 | loss: 0.40027 | val_0_rmse: 0.65005 | val_1_rmse: 0.63128 |  0:00:16s
epoch 82 | loss: 0.40045 | val_0_rmse: 0.64776 | val_1_rmse: 0.62948 |  0:00:16s
epoch 83 | loss: 0.40226 | val_0_rmse: 0.63665 | val_1_rmse: 0.60975 |  0:00:17s
epoch 84 | loss: 0.40122 | val_0_rmse: 0.63091 | val_1_rmse: 0.6006  |  0:00:17s
epoch 85 | loss: 0.39765 | val_0_rmse: 0.6354  | val_1_rmse: 0.60782 |  0:00:17s
epoch 86 | loss: 0.40478 | val_0_rmse: 0.62895 | val_1_rmse: 0.59349 |  0:00:17s
epoch 87 | loss: 0.39919 | val_0_rmse: 0.63037 | val_1_rmse: 0.59611 |  0:00:17s
epoch 88 | loss: 0.39328 | val_0_rmse: 0.62897 | val_1_rmse: 0.59442 |  0:00:18s
epoch 89 | loss: 0.4063  | val_0_rmse: 0.63668 | val_1_rmse: 0.60443 |  0:00:18s
epoch 90 | loss: 0.40476 | val_0_rmse: 0.62838 | val_1_rmse: 0.59592 |  0:00:18s

Early stopping occured at epoch 90 with best_epoch = 60 and best_val_1_rmse = 0.5913
Best weights from best epoch are automatically used!
ended training at: 08:16:18
Feature importance:
Mean squared error is of 3323702507.837355
Mean absolute error:43951.31408374452
MAPE:0.41671827513032506
R2 score:0.5154360295809769
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 1
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:16:19
epoch 0  | loss: 2.27073 | val_0_rmse: 0.97209 | val_1_rmse: 0.99609 |  0:00:00s
epoch 1  | loss: 1.35446 | val_0_rmse: 0.96162 | val_1_rmse: 0.98385 |  0:00:00s
epoch 2  | loss: 1.05121 | val_0_rmse: 0.9076  | val_1_rmse: 0.93728 |  0:00:00s
epoch 3  | loss: 0.90399 | val_0_rmse: 0.86808 | val_1_rmse: 0.8874  |  0:00:00s
epoch 4  | loss: 0.69061 | val_0_rmse: 0.88033 | val_1_rmse: 0.85577 |  0:00:01s
epoch 5  | loss: 0.63075 | val_0_rmse: 0.87286 | val_1_rmse: 0.83405 |  0:00:01s
epoch 6  | loss: 0.61629 | val_0_rmse: 0.827   | val_1_rmse: 0.79342 |  0:00:01s
epoch 7  | loss: 0.59286 | val_0_rmse: 0.81068 | val_1_rmse: 0.78006 |  0:00:01s
epoch 8  | loss: 0.58658 | val_0_rmse: 0.80873 | val_1_rmse: 0.77273 |  0:00:01s
epoch 9  | loss: 0.56611 | val_0_rmse: 0.74938 | val_1_rmse: 0.72731 |  0:00:02s
epoch 10 | loss: 0.54288 | val_0_rmse: 0.77468 | val_1_rmse: 0.751   |  0:00:02s
epoch 11 | loss: 0.52658 | val_0_rmse: 0.76774 | val_1_rmse: 0.74786 |  0:00:02s
epoch 12 | loss: 0.51278 | val_0_rmse: 0.73521 | val_1_rmse: 0.70396 |  0:00:02s
epoch 13 | loss: 0.49092 | val_0_rmse: 0.72675 | val_1_rmse: 0.70517 |  0:00:02s
epoch 14 | loss: 0.48452 | val_0_rmse: 0.7255  | val_1_rmse: 0.71083 |  0:00:03s
epoch 15 | loss: 0.47769 | val_0_rmse: 0.71958 | val_1_rmse: 0.71398 |  0:00:03s
epoch 16 | loss: 0.47947 | val_0_rmse: 0.69202 | val_1_rmse: 0.68373 |  0:00:03s
epoch 17 | loss: 0.46531 | val_0_rmse: 0.68601 | val_1_rmse: 0.67603 |  0:00:03s
epoch 18 | loss: 0.45148 | val_0_rmse: 0.68247 | val_1_rmse: 0.6721  |  0:00:03s
epoch 19 | loss: 0.4469  | val_0_rmse: 0.69408 | val_1_rmse: 0.68244 |  0:00:04s
epoch 20 | loss: 0.42298 | val_0_rmse: 0.69818 | val_1_rmse: 0.69431 |  0:00:04s
epoch 21 | loss: 0.43452 | val_0_rmse: 0.67991 | val_1_rmse: 0.67915 |  0:00:04s
epoch 22 | loss: 0.41891 | val_0_rmse: 0.6703  | val_1_rmse: 0.65838 |  0:00:04s
epoch 23 | loss: 0.42418 | val_0_rmse: 0.66573 | val_1_rmse: 0.64779 |  0:00:05s
epoch 24 | loss: 0.41048 | val_0_rmse: 0.6613  | val_1_rmse: 0.65597 |  0:00:05s
epoch 25 | loss: 0.41242 | val_0_rmse: 0.65534 | val_1_rmse: 0.65509 |  0:00:05s
epoch 26 | loss: 0.4131  | val_0_rmse: 0.65321 | val_1_rmse: 0.65502 |  0:00:05s
epoch 27 | loss: 0.40848 | val_0_rmse: 0.65025 | val_1_rmse: 0.65095 |  0:00:05s
epoch 28 | loss: 0.39224 | val_0_rmse: 0.65639 | val_1_rmse: 0.66089 |  0:00:06s
epoch 29 | loss: 0.39938 | val_0_rmse: 0.65566 | val_1_rmse: 0.65663 |  0:00:06s
epoch 30 | loss: 0.40164 | val_0_rmse: 0.64954 | val_1_rmse: 0.64494 |  0:00:06s
epoch 31 | loss: 0.39399 | val_0_rmse: 0.65279 | val_1_rmse: 0.64803 |  0:00:06s
epoch 32 | loss: 0.38347 | val_0_rmse: 0.66482 | val_1_rmse: 0.6596  |  0:00:06s
epoch 33 | loss: 0.38576 | val_0_rmse: 0.65126 | val_1_rmse: 0.6405  |  0:00:07s
epoch 34 | loss: 0.39895 | val_0_rmse: 0.64847 | val_1_rmse: 0.63453 |  0:00:07s
epoch 35 | loss: 0.40221 | val_0_rmse: 0.646   | val_1_rmse: 0.63424 |  0:00:07s
epoch 36 | loss: 0.40694 | val_0_rmse: 0.67524 | val_1_rmse: 0.66612 |  0:00:07s
epoch 37 | loss: 0.44683 | val_0_rmse: 0.69274 | val_1_rmse: 0.67886 |  0:00:07s
epoch 38 | loss: 0.45282 | val_0_rmse: 0.7094  | val_1_rmse: 0.69637 |  0:00:08s
epoch 39 | loss: 0.46426 | val_0_rmse: 0.6958  | val_1_rmse: 0.67581 |  0:00:08s
epoch 40 | loss: 0.43617 | val_0_rmse: 0.67513 | val_1_rmse: 0.66274 |  0:00:08s
epoch 41 | loss: 0.43594 | val_0_rmse: 0.67627 | val_1_rmse: 0.66889 |  0:00:08s
epoch 42 | loss: 0.43016 | val_0_rmse: 0.69758 | val_1_rmse: 0.67597 |  0:00:08s
epoch 43 | loss: 0.41685 | val_0_rmse: 0.68355 | val_1_rmse: 0.65675 |  0:00:09s
epoch 44 | loss: 0.4277  | val_0_rmse: 0.67393 | val_1_rmse: 0.64003 |  0:00:09s
epoch 45 | loss: 0.41971 | val_0_rmse: 0.67401 | val_1_rmse: 0.63894 |  0:00:09s
epoch 46 | loss: 0.42184 | val_0_rmse: 0.68419 | val_1_rmse: 0.65004 |  0:00:09s
epoch 47 | loss: 0.43194 | val_0_rmse: 0.66755 | val_1_rmse: 0.63532 |  0:00:09s
epoch 48 | loss: 0.41868 | val_0_rmse: 0.67854 | val_1_rmse: 0.65973 |  0:00:10s
epoch 49 | loss: 0.42106 | val_0_rmse: 0.67733 | val_1_rmse: 0.66113 |  0:00:10s
epoch 50 | loss: 0.4212  | val_0_rmse: 0.66985 | val_1_rmse: 0.64997 |  0:00:10s
epoch 51 | loss: 0.40587 | val_0_rmse: 0.66407 | val_1_rmse: 0.65246 |  0:00:10s
epoch 52 | loss: 0.40485 | val_0_rmse: 0.67185 | val_1_rmse: 0.66723 |  0:00:10s
epoch 53 | loss: 0.4113  | val_0_rmse: 0.67137 | val_1_rmse: 0.66655 |  0:00:11s
epoch 54 | loss: 0.39803 | val_0_rmse: 0.69144 | val_1_rmse: 0.65919 |  0:00:11s
epoch 55 | loss: 0.42192 | val_0_rmse: 0.71976 | val_1_rmse: 0.67407 |  0:00:11s
epoch 56 | loss: 0.42216 | val_0_rmse: 0.72517 | val_1_rmse: 0.69481 |  0:00:11s
epoch 57 | loss: 0.42598 | val_0_rmse: 0.72975 | val_1_rmse: 0.72259 |  0:00:11s
epoch 58 | loss: 0.42722 | val_0_rmse: 0.71775 | val_1_rmse: 0.70698 |  0:00:12s
epoch 59 | loss: 0.40421 | val_0_rmse: 0.73481 | val_1_rmse: 0.70971 |  0:00:12s
epoch 60 | loss: 0.3997  | val_0_rmse: 0.71136 | val_1_rmse: 0.68682 |  0:00:12s
epoch 61 | loss: 0.4217  | val_0_rmse: 0.68421 | val_1_rmse: 0.66973 |  0:00:12s
epoch 62 | loss: 0.41424 | val_0_rmse: 0.67658 | val_1_rmse: 0.66959 |  0:00:12s
epoch 63 | loss: 0.41106 | val_0_rmse: 0.66835 | val_1_rmse: 0.66205 |  0:00:13s
epoch 64 | loss: 0.40203 | val_0_rmse: 0.66138 | val_1_rmse: 0.65229 |  0:00:13s
epoch 65 | loss: 0.40346 | val_0_rmse: 0.67465 | val_1_rmse: 0.66312 |  0:00:13s

Early stopping occured at epoch 65 with best_epoch = 35 and best_val_1_rmse = 0.63424
Best weights from best epoch are automatically used!
ended training at: 08:16:32
Feature importance:
Mean squared error is of 3194313580.498204
Mean absolute error:42034.6700138432
MAPE:0.3797838308648392
R2 score:0.5890672950460618
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 2
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:16:32
epoch 0  | loss: 2.29404 | val_0_rmse: 0.91804 | val_1_rmse: 0.87919 |  0:00:00s
epoch 1  | loss: 1.26572 | val_0_rmse: 0.84216 | val_1_rmse: 0.80318 |  0:00:00s
epoch 2  | loss: 0.82988 | val_0_rmse: 0.8082  | val_1_rmse: 0.75987 |  0:00:00s
epoch 3  | loss: 0.75172 | val_0_rmse: 0.79342 | val_1_rmse: 0.72863 |  0:00:00s
epoch 4  | loss: 0.6106  | val_0_rmse: 0.81055 | val_1_rmse: 0.74728 |  0:00:01s
epoch 5  | loss: 0.57299 | val_0_rmse: 0.80137 | val_1_rmse: 0.70818 |  0:00:01s
epoch 6  | loss: 0.56502 | val_0_rmse: 0.82062 | val_1_rmse: 0.75906 |  0:00:01s
epoch 7  | loss: 0.5649  | val_0_rmse: 0.78935 | val_1_rmse: 0.69353 |  0:00:01s
epoch 8  | loss: 0.48952 | val_0_rmse: 0.85235 | val_1_rmse: 0.75504 |  0:00:01s
epoch 9  | loss: 0.52908 | val_0_rmse: 0.81901 | val_1_rmse: 0.71664 |  0:00:02s
epoch 10 | loss: 0.50525 | val_0_rmse: 0.91233 | val_1_rmse: 0.80315 |  0:00:02s
epoch 11 | loss: 0.49838 | val_0_rmse: 0.82607 | val_1_rmse: 0.72135 |  0:00:02s
epoch 12 | loss: 0.47353 | val_0_rmse: 0.71608 | val_1_rmse: 0.67579 |  0:00:02s
epoch 13 | loss: 0.48225 | val_0_rmse: 0.75058 | val_1_rmse: 0.74301 |  0:00:02s
epoch 14 | loss: 0.48943 | val_0_rmse: 0.7487  | val_1_rmse: 0.73485 |  0:00:03s
epoch 15 | loss: 0.48111 | val_0_rmse: 0.78592 | val_1_rmse: 0.77982 |  0:00:03s
epoch 16 | loss: 0.48225 | val_0_rmse: 0.74869 | val_1_rmse: 0.70371 |  0:00:03s
epoch 17 | loss: 0.46007 | val_0_rmse: 0.72509 | val_1_rmse: 0.71015 |  0:00:03s
epoch 18 | loss: 0.44976 | val_0_rmse: 0.78058 | val_1_rmse: 0.76736 |  0:00:03s
epoch 19 | loss: 0.43895 | val_0_rmse: 0.73434 | val_1_rmse: 0.72023 |  0:00:04s
epoch 20 | loss: 0.45778 | val_0_rmse: 0.72557 | val_1_rmse: 0.71284 |  0:00:04s
epoch 21 | loss: 0.42031 | val_0_rmse: 0.7188  | val_1_rmse: 0.70366 |  0:00:04s
epoch 22 | loss: 0.44624 | val_0_rmse: 0.67981 | val_1_rmse: 0.66396 |  0:00:04s
epoch 23 | loss: 0.43835 | val_0_rmse: 0.67951 | val_1_rmse: 0.64954 |  0:00:04s
epoch 24 | loss: 0.43014 | val_0_rmse: 0.6814  | val_1_rmse: 0.66936 |  0:00:05s
epoch 25 | loss: 0.43322 | val_0_rmse: 0.68611 | val_1_rmse: 0.67599 |  0:00:05s
epoch 26 | loss: 0.44316 | val_0_rmse: 0.67933 | val_1_rmse: 0.64204 |  0:00:05s
epoch 27 | loss: 0.43168 | val_0_rmse: 0.67378 | val_1_rmse: 0.63672 |  0:00:05s
epoch 28 | loss: 0.41736 | val_0_rmse: 0.65333 | val_1_rmse: 0.63365 |  0:00:05s
epoch 29 | loss: 0.40924 | val_0_rmse: 0.65214 | val_1_rmse: 0.62804 |  0:00:06s
epoch 30 | loss: 0.41202 | val_0_rmse: 0.66674 | val_1_rmse: 0.63316 |  0:00:06s
epoch 31 | loss: 0.40969 | val_0_rmse: 0.64775 | val_1_rmse: 0.62021 |  0:00:06s
epoch 32 | loss: 0.41107 | val_0_rmse: 0.64119 | val_1_rmse: 0.61066 |  0:00:06s
epoch 33 | loss: 0.40432 | val_0_rmse: 0.64276 | val_1_rmse: 0.59966 |  0:00:07s
epoch 34 | loss: 0.39405 | val_0_rmse: 0.64667 | val_1_rmse: 0.5972  |  0:00:07s
epoch 35 | loss: 0.4078  | val_0_rmse: 0.6409  | val_1_rmse: 0.59938 |  0:00:07s
epoch 36 | loss: 0.40347 | val_0_rmse: 0.64163 | val_1_rmse: 0.60766 |  0:00:07s
epoch 37 | loss: 0.39144 | val_0_rmse: 0.63625 | val_1_rmse: 0.6054  |  0:00:07s
epoch 38 | loss: 0.38694 | val_0_rmse: 0.63783 | val_1_rmse: 0.60196 |  0:00:08s
epoch 39 | loss: 0.39887 | val_0_rmse: 0.63327 | val_1_rmse: 0.60801 |  0:00:08s
epoch 40 | loss: 0.39944 | val_0_rmse: 0.63364 | val_1_rmse: 0.62058 |  0:00:08s
epoch 41 | loss: 0.37555 | val_0_rmse: 0.62822 | val_1_rmse: 0.59769 |  0:00:08s
epoch 42 | loss: 0.39002 | val_0_rmse: 0.63465 | val_1_rmse: 0.59671 |  0:00:08s
epoch 43 | loss: 0.38729 | val_0_rmse: 0.64497 | val_1_rmse: 0.62825 |  0:00:09s
epoch 44 | loss: 0.40832 | val_0_rmse: 0.63371 | val_1_rmse: 0.61641 |  0:00:09s
epoch 45 | loss: 0.40036 | val_0_rmse: 0.68275 | val_1_rmse: 0.65561 |  0:00:09s
epoch 46 | loss: 0.39438 | val_0_rmse: 0.63132 | val_1_rmse: 0.61927 |  0:00:09s
epoch 47 | loss: 0.39029 | val_0_rmse: 0.63787 | val_1_rmse: 0.62637 |  0:00:09s
epoch 48 | loss: 0.39371 | val_0_rmse: 0.64252 | val_1_rmse: 0.61627 |  0:00:10s
epoch 49 | loss: 0.38705 | val_0_rmse: 0.63146 | val_1_rmse: 0.6079  |  0:00:10s
epoch 50 | loss: 0.37776 | val_0_rmse: 0.63418 | val_1_rmse: 0.60941 |  0:00:10s
epoch 51 | loss: 0.38657 | val_0_rmse: 0.62585 | val_1_rmse: 0.60702 |  0:00:10s
epoch 52 | loss: 0.39519 | val_0_rmse: 0.62246 | val_1_rmse: 0.61316 |  0:00:10s
epoch 53 | loss: 0.38758 | val_0_rmse: 0.633   | val_1_rmse: 0.62923 |  0:00:11s
epoch 54 | loss: 0.38642 | val_0_rmse: 0.62494 | val_1_rmse: 0.62088 |  0:00:11s
epoch 55 | loss: 0.38159 | val_0_rmse: 0.62549 | val_1_rmse: 0.61112 |  0:00:11s
epoch 56 | loss: 0.38372 | val_0_rmse: 0.61881 | val_1_rmse: 0.60109 |  0:00:11s
epoch 57 | loss: 0.39071 | val_0_rmse: 0.61563 | val_1_rmse: 0.60235 |  0:00:11s
epoch 58 | loss: 0.37754 | val_0_rmse: 0.61386 | val_1_rmse: 0.61204 |  0:00:12s
epoch 59 | loss: 0.37575 | val_0_rmse: 0.61857 | val_1_rmse: 0.60869 |  0:00:12s
epoch 60 | loss: 0.36994 | val_0_rmse: 0.63225 | val_1_rmse: 0.61457 |  0:00:12s
epoch 61 | loss: 0.39462 | val_0_rmse: 0.62769 | val_1_rmse: 0.61147 |  0:00:12s
epoch 62 | loss: 0.38076 | val_0_rmse: 0.64154 | val_1_rmse: 0.62412 |  0:00:12s
epoch 63 | loss: 0.38186 | val_0_rmse: 0.66113 | val_1_rmse: 0.6476  |  0:00:13s
epoch 64 | loss: 0.37531 | val_0_rmse: 0.63502 | val_1_rmse: 0.62898 |  0:00:13s
epoch 65 | loss: 0.37257 | val_0_rmse: 0.62455 | val_1_rmse: 0.61998 |  0:00:13s
epoch 66 | loss: 0.37215 | val_0_rmse: 0.61188 | val_1_rmse: 0.60661 |  0:00:13s
epoch 67 | loss: 0.3516  | val_0_rmse: 0.60348 | val_1_rmse: 0.60253 |  0:00:13s
epoch 68 | loss: 0.37162 | val_0_rmse: 0.59787 | val_1_rmse: 0.5942  |  0:00:14s
epoch 69 | loss: 0.35474 | val_0_rmse: 0.60047 | val_1_rmse: 0.601   |  0:00:14s
epoch 70 | loss: 0.35542 | val_0_rmse: 0.60084 | val_1_rmse: 0.60201 |  0:00:14s
epoch 71 | loss: 0.35637 | val_0_rmse: 0.61796 | val_1_rmse: 0.60535 |  0:00:14s
epoch 72 | loss: 0.35649 | val_0_rmse: 0.64264 | val_1_rmse: 0.63116 |  0:00:14s
epoch 73 | loss: 0.35698 | val_0_rmse: 0.60951 | val_1_rmse: 0.61942 |  0:00:15s
epoch 74 | loss: 0.35816 | val_0_rmse: 0.60869 | val_1_rmse: 0.62491 |  0:00:15s
epoch 75 | loss: 0.34514 | val_0_rmse: 0.62972 | val_1_rmse: 0.63752 |  0:00:15s
epoch 76 | loss: 0.35931 | val_0_rmse: 0.60584 | val_1_rmse: 0.6246  |  0:00:15s
epoch 77 | loss: 0.34955 | val_0_rmse: 0.60213 | val_1_rmse: 0.6201  |  0:00:15s
epoch 78 | loss: 0.34308 | val_0_rmse: 0.59879 | val_1_rmse: 0.61111 |  0:00:16s
epoch 79 | loss: 0.3388  | val_0_rmse: 0.59792 | val_1_rmse: 0.6093  |  0:00:16s
epoch 80 | loss: 0.33862 | val_0_rmse: 0.58605 | val_1_rmse: 0.59858 |  0:00:16s
epoch 81 | loss: 0.33469 | val_0_rmse: 0.59051 | val_1_rmse: 0.60179 |  0:00:16s
epoch 82 | loss: 0.34827 | val_0_rmse: 0.59421 | val_1_rmse: 0.59609 |  0:00:16s
epoch 83 | loss: 0.35022 | val_0_rmse: 0.59747 | val_1_rmse: 0.59858 |  0:00:17s
epoch 84 | loss: 0.35187 | val_0_rmse: 0.5975  | val_1_rmse: 0.59358 |  0:00:17s
epoch 85 | loss: 0.36669 | val_0_rmse: 0.59261 | val_1_rmse: 0.59832 |  0:00:17s
epoch 86 | loss: 0.34263 | val_0_rmse: 0.58991 | val_1_rmse: 0.58752 |  0:00:17s
epoch 87 | loss: 0.35257 | val_0_rmse: 0.59567 | val_1_rmse: 0.58736 |  0:00:18s
epoch 88 | loss: 0.36061 | val_0_rmse: 0.60811 | val_1_rmse: 0.61529 |  0:00:18s
epoch 89 | loss: 0.37621 | val_0_rmse: 0.61116 | val_1_rmse: 0.61569 |  0:00:18s
epoch 90 | loss: 0.3538  | val_0_rmse: 0.61245 | val_1_rmse: 0.59699 |  0:00:18s
epoch 91 | loss: 0.36517 | val_0_rmse: 0.62685 | val_1_rmse: 0.61404 |  0:00:18s
epoch 92 | loss: 0.39492 | val_0_rmse: 0.60865 | val_1_rmse: 0.58596 |  0:00:19s
epoch 93 | loss: 0.37533 | val_0_rmse: 0.62626 | val_1_rmse: 0.60164 |  0:00:19s
epoch 94 | loss: 0.38288 | val_0_rmse: 0.60938 | val_1_rmse: 0.57717 |  0:00:19s
epoch 95 | loss: 0.37241 | val_0_rmse: 0.60853 | val_1_rmse: 0.57113 |  0:00:19s
epoch 96 | loss: 0.37898 | val_0_rmse: 0.61272 | val_1_rmse: 0.60236 |  0:00:19s
epoch 97 | loss: 0.35738 | val_0_rmse: 0.61131 | val_1_rmse: 0.60645 |  0:00:20s
epoch 98 | loss: 0.35913 | val_0_rmse: 0.6063  | val_1_rmse: 0.58588 |  0:00:20s
epoch 99 | loss: 0.38109 | val_0_rmse: 0.60348 | val_1_rmse: 0.57843 |  0:00:20s
epoch 100| loss: 0.36145 | val_0_rmse: 0.59933 | val_1_rmse: 0.57963 |  0:00:20s
epoch 101| loss: 0.35286 | val_0_rmse: 0.58935 | val_1_rmse: 0.58698 |  0:00:20s
epoch 102| loss: 0.34147 | val_0_rmse: 0.59094 | val_1_rmse: 0.59605 |  0:00:21s
epoch 103| loss: 0.35625 | val_0_rmse: 0.61549 | val_1_rmse: 0.63979 |  0:00:21s
epoch 104| loss: 0.34953 | val_0_rmse: 0.60628 | val_1_rmse: 0.62914 |  0:00:21s
epoch 105| loss: 0.35127 | val_0_rmse: 0.59234 | val_1_rmse: 0.59804 |  0:00:21s
epoch 106| loss: 0.35448 | val_0_rmse: 0.61636 | val_1_rmse: 0.61306 |  0:00:21s
epoch 107| loss: 0.34417 | val_0_rmse: 0.578   | val_1_rmse: 0.58972 |  0:00:22s
epoch 108| loss: 0.36119 | val_0_rmse: 0.58151 | val_1_rmse: 0.59484 |  0:00:22s
epoch 109| loss: 0.35131 | val_0_rmse: 0.61598 | val_1_rmse: 0.61577 |  0:00:22s
epoch 110| loss: 0.34646 | val_0_rmse: 0.60676 | val_1_rmse: 0.61535 |  0:00:22s
epoch 111| loss: 0.34873 | val_0_rmse: 0.58791 | val_1_rmse: 0.60539 |  0:00:22s
epoch 112| loss: 0.32869 | val_0_rmse: 0.57625 | val_1_rmse: 0.5908  |  0:00:23s
epoch 113| loss: 0.3425  | val_0_rmse: 0.5859  | val_1_rmse: 0.5825  |  0:00:23s
epoch 114| loss: 0.32805 | val_0_rmse: 0.5942  | val_1_rmse: 0.59147 |  0:00:23s
epoch 115| loss: 0.33519 | val_0_rmse: 0.59665 | val_1_rmse: 0.59476 |  0:00:23s
epoch 116| loss: 0.36091 | val_0_rmse: 0.60638 | val_1_rmse: 0.60297 |  0:00:23s
epoch 117| loss: 0.35726 | val_0_rmse: 0.61339 | val_1_rmse: 0.62545 |  0:00:24s
epoch 118| loss: 0.35475 | val_0_rmse: 0.61609 | val_1_rmse: 0.63532 |  0:00:24s
epoch 119| loss: 0.3535  | val_0_rmse: 0.60905 | val_1_rmse: 0.62316 |  0:00:24s
epoch 120| loss: 0.34797 | val_0_rmse: 0.58212 | val_1_rmse: 0.58798 |  0:00:24s
epoch 121| loss: 0.35988 | val_0_rmse: 0.58289 | val_1_rmse: 0.58473 |  0:00:24s
epoch 122| loss: 0.33641 | val_0_rmse: 0.57117 | val_1_rmse: 0.57472 |  0:00:25s
epoch 123| loss: 0.34046 | val_0_rmse: 0.57992 | val_1_rmse: 0.58126 |  0:00:25s
epoch 124| loss: 0.32434 | val_0_rmse: 0.59676 | val_1_rmse: 0.59185 |  0:00:25s
epoch 125| loss: 0.3351  | val_0_rmse: 0.57733 | val_1_rmse: 0.576   |  0:00:25s

Early stopping occured at epoch 125 with best_epoch = 95 and best_val_1_rmse = 0.57113
Best weights from best epoch are automatically used!
ended training at: 08:16:58
Feature importance:
Mean squared error is of 2857930195.4796147
Mean absolute error:39813.09071984649
MAPE:0.41096773060945463
R2 score:0.5584243479625617
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 3
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:16:58
epoch 0  | loss: 2.06477 | val_0_rmse: 0.99896 | val_1_rmse: 1.0123  |  0:00:00s
epoch 1  | loss: 1.4559  | val_0_rmse: 0.97877 | val_1_rmse: 0.98251 |  0:00:00s
epoch 2  | loss: 1.13843 | val_0_rmse: 0.94864 | val_1_rmse: 0.94394 |  0:00:00s
epoch 3  | loss: 0.84086 | val_0_rmse: 0.89627 | val_1_rmse: 0.89302 |  0:00:00s
epoch 4  | loss: 0.78148 | val_0_rmse: 0.89613 | val_1_rmse: 0.88346 |  0:00:01s
epoch 5  | loss: 0.68367 | val_0_rmse: 0.87376 | val_1_rmse: 0.86297 |  0:00:01s
epoch 6  | loss: 0.58098 | val_0_rmse: 0.79002 | val_1_rmse: 0.78053 |  0:00:01s
epoch 7  | loss: 0.55385 | val_0_rmse: 0.79035 | val_1_rmse: 0.77207 |  0:00:01s
epoch 8  | loss: 0.53759 | val_0_rmse: 0.82127 | val_1_rmse: 0.81926 |  0:00:01s
epoch 9  | loss: 0.52239 | val_0_rmse: 0.73917 | val_1_rmse: 0.75841 |  0:00:02s
epoch 10 | loss: 0.4963  | val_0_rmse: 0.76553 | val_1_rmse: 0.7848  |  0:00:02s
epoch 11 | loss: 0.49205 | val_0_rmse: 0.78219 | val_1_rmse: 0.82545 |  0:00:02s
epoch 12 | loss: 0.49912 | val_0_rmse: 0.78025 | val_1_rmse: 0.81349 |  0:00:02s
epoch 13 | loss: 0.50753 | val_0_rmse: 0.81927 | val_1_rmse: 0.84171 |  0:00:02s
epoch 14 | loss: 0.47895 | val_0_rmse: 0.79886 | val_1_rmse: 0.83178 |  0:00:03s
epoch 15 | loss: 0.49342 | val_0_rmse: 0.81749 | val_1_rmse: 0.83211 |  0:00:03s
epoch 16 | loss: 0.49955 | val_0_rmse: 1.14628 | val_1_rmse: 1.15969 |  0:00:03s
epoch 17 | loss: 0.50991 | val_0_rmse: 1.17019 | val_1_rmse: 1.18076 |  0:00:03s
epoch 18 | loss: 0.50567 | val_0_rmse: 0.81002 | val_1_rmse: 0.82558 |  0:00:03s
epoch 19 | loss: 0.51501 | val_0_rmse: 0.78174 | val_1_rmse: 0.79758 |  0:00:04s
epoch 20 | loss: 0.50225 | val_0_rmse: 0.86282 | val_1_rmse: 0.87928 |  0:00:04s
epoch 21 | loss: 0.48744 | val_0_rmse: 0.884   | val_1_rmse: 0.91779 |  0:00:04s
epoch 22 | loss: 0.49922 | val_0_rmse: 0.83631 | val_1_rmse: 0.88577 |  0:00:04s
epoch 23 | loss: 0.47547 | val_0_rmse: 0.79129 | val_1_rmse: 0.84408 |  0:00:04s
epoch 24 | loss: 0.46967 | val_0_rmse: 0.73944 | val_1_rmse: 0.78348 |  0:00:05s
epoch 25 | loss: 0.4651  | val_0_rmse: 0.73179 | val_1_rmse: 0.79886 |  0:00:05s
epoch 26 | loss: 0.47189 | val_0_rmse: 0.76728 | val_1_rmse: 0.81745 |  0:00:05s
epoch 27 | loss: 0.45123 | val_0_rmse: 0.79941 | val_1_rmse: 0.86256 |  0:00:05s
epoch 28 | loss: 0.47256 | val_0_rmse: 0.81187 | val_1_rmse: 0.86702 |  0:00:05s
epoch 29 | loss: 0.45971 | val_0_rmse: 0.78081 | val_1_rmse: 0.81243 |  0:00:06s
epoch 30 | loss: 0.45794 | val_0_rmse: 0.77416 | val_1_rmse: 0.79051 |  0:00:06s
epoch 31 | loss: 0.45867 | val_0_rmse: 0.7833  | val_1_rmse: 0.79486 |  0:00:06s
epoch 32 | loss: 0.46297 | val_0_rmse: 0.78522 | val_1_rmse: 0.79489 |  0:00:06s
epoch 33 | loss: 0.46054 | val_0_rmse: 0.73871 | val_1_rmse: 0.75713 |  0:00:06s
epoch 34 | loss: 0.43759 | val_0_rmse: 0.68761 | val_1_rmse: 0.72225 |  0:00:07s
epoch 35 | loss: 0.45771 | val_0_rmse: 0.69704 | val_1_rmse: 0.7379  |  0:00:07s
epoch 36 | loss: 0.46414 | val_0_rmse: 0.67962 | val_1_rmse: 0.7296  |  0:00:07s
epoch 37 | loss: 0.45775 | val_0_rmse: 0.68169 | val_1_rmse: 0.74019 |  0:00:07s
epoch 38 | loss: 0.45524 | val_0_rmse: 0.68173 | val_1_rmse: 0.73892 |  0:00:08s
epoch 39 | loss: 0.45897 | val_0_rmse: 0.67914 | val_1_rmse: 0.72068 |  0:00:08s
epoch 40 | loss: 0.44386 | val_0_rmse: 0.67995 | val_1_rmse: 0.71758 |  0:00:08s
epoch 41 | loss: 0.43408 | val_0_rmse: 0.68568 | val_1_rmse: 0.72129 |  0:00:08s
epoch 42 | loss: 0.44233 | val_0_rmse: 0.69209 | val_1_rmse: 0.72369 |  0:00:08s
epoch 43 | loss: 0.437   | val_0_rmse: 0.69611 | val_1_rmse: 0.71911 |  0:00:09s
epoch 44 | loss: 0.43501 | val_0_rmse: 0.69377 | val_1_rmse: 0.711   |  0:00:09s
epoch 45 | loss: 0.42383 | val_0_rmse: 0.68964 | val_1_rmse: 0.70764 |  0:00:09s
epoch 46 | loss: 0.42646 | val_0_rmse: 0.69654 | val_1_rmse: 0.7124  |  0:00:09s
epoch 47 | loss: 0.43506 | val_0_rmse: 0.69553 | val_1_rmse: 0.71215 |  0:00:09s
epoch 48 | loss: 0.42134 | val_0_rmse: 0.68343 | val_1_rmse: 0.69828 |  0:00:10s
epoch 49 | loss: 0.42235 | val_0_rmse: 0.67771 | val_1_rmse: 0.70048 |  0:00:10s
epoch 50 | loss: 0.42845 | val_0_rmse: 0.67507 | val_1_rmse: 0.69969 |  0:00:10s
epoch 51 | loss: 0.42964 | val_0_rmse: 0.66452 | val_1_rmse: 0.69461 |  0:00:10s
epoch 52 | loss: 0.4168  | val_0_rmse: 0.65291 | val_1_rmse: 0.69168 |  0:00:10s
epoch 53 | loss: 0.41848 | val_0_rmse: 0.65343 | val_1_rmse: 0.69054 |  0:00:11s
epoch 54 | loss: 0.41911 | val_0_rmse: 0.65378 | val_1_rmse: 0.68821 |  0:00:11s
epoch 55 | loss: 0.43441 | val_0_rmse: 0.66302 | val_1_rmse: 0.69308 |  0:00:11s
epoch 56 | loss: 0.42299 | val_0_rmse: 0.66862 | val_1_rmse: 0.70175 |  0:00:11s
epoch 57 | loss: 0.4132  | val_0_rmse: 0.6574  | val_1_rmse: 0.69359 |  0:00:11s
epoch 58 | loss: 0.43082 | val_0_rmse: 0.65426 | val_1_rmse: 0.68975 |  0:00:12s
epoch 59 | loss: 0.418   | val_0_rmse: 0.65906 | val_1_rmse: 0.69039 |  0:00:12s
epoch 60 | loss: 0.41507 | val_0_rmse: 0.66442 | val_1_rmse: 0.69648 |  0:00:12s
epoch 61 | loss: 0.40688 | val_0_rmse: 0.65372 | val_1_rmse: 0.69236 |  0:00:12s
epoch 62 | loss: 0.4252  | val_0_rmse: 0.65272 | val_1_rmse: 0.69629 |  0:00:13s
epoch 63 | loss: 0.41827 | val_0_rmse: 0.65549 | val_1_rmse: 0.69836 |  0:00:13s
epoch 64 | loss: 0.41266 | val_0_rmse: 0.65365 | val_1_rmse: 0.69719 |  0:00:13s
epoch 65 | loss: 0.41281 | val_0_rmse: 0.65407 | val_1_rmse: 0.69789 |  0:00:13s
epoch 66 | loss: 0.41507 | val_0_rmse: 0.6653  | val_1_rmse: 0.70585 |  0:00:13s
epoch 67 | loss: 0.41797 | val_0_rmse: 0.66367 | val_1_rmse: 0.7056  |  0:00:13s
epoch 68 | loss: 0.42543 | val_0_rmse: 0.65192 | val_1_rmse: 0.69943 |  0:00:14s
epoch 69 | loss: 0.40608 | val_0_rmse: 0.65579 | val_1_rmse: 0.70028 |  0:00:14s
epoch 70 | loss: 0.40695 | val_0_rmse: 0.65525 | val_1_rmse: 0.70163 |  0:00:14s
epoch 71 | loss: 0.4346  | val_0_rmse: 0.65212 | val_1_rmse: 0.70405 |  0:00:14s
epoch 72 | loss: 0.42105 | val_0_rmse: 0.65626 | val_1_rmse: 0.71077 |  0:00:14s
epoch 73 | loss: 0.41603 | val_0_rmse: 0.67271 | val_1_rmse: 0.72683 |  0:00:15s
epoch 74 | loss: 0.41876 | val_0_rmse: 0.68386 | val_1_rmse: 0.74028 |  0:00:15s
epoch 75 | loss: 0.41419 | val_0_rmse: 0.66662 | val_1_rmse: 0.72769 |  0:00:15s
epoch 76 | loss: 0.42012 | val_0_rmse: 0.6541  | val_1_rmse: 0.72204 |  0:00:15s
epoch 77 | loss: 0.42142 | val_0_rmse: 0.65725 | val_1_rmse: 0.72524 |  0:00:15s
epoch 78 | loss: 0.41249 | val_0_rmse: 0.65925 | val_1_rmse: 0.73089 |  0:00:16s
epoch 79 | loss: 0.41313 | val_0_rmse: 0.64965 | val_1_rmse: 0.72119 |  0:00:16s
epoch 80 | loss: 0.42154 | val_0_rmse: 0.65027 | val_1_rmse: 0.71549 |  0:00:16s
epoch 81 | loss: 0.41438 | val_0_rmse: 0.65471 | val_1_rmse: 0.70577 |  0:00:16s
epoch 82 | loss: 0.40328 | val_0_rmse: 0.65796 | val_1_rmse: 0.70362 |  0:00:16s
epoch 83 | loss: 0.42374 | val_0_rmse: 0.64956 | val_1_rmse: 0.69436 |  0:00:17s
epoch 84 | loss: 0.41921 | val_0_rmse: 0.64834 | val_1_rmse: 0.69634 |  0:00:17s

Early stopping occured at epoch 84 with best_epoch = 54 and best_val_1_rmse = 0.68821
Best weights from best epoch are automatically used!
ended training at: 08:17:16
Feature importance:
Mean squared error is of 3177719963.618717
Mean absolute error:43032.86190679824
MAPE:0.4074605594491007
R2 score:0.5406257328564038
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 4
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:17:16
epoch 0  | loss: 1.83692 | val_0_rmse: 0.96983 | val_1_rmse: 1.03742 |  0:00:00s
epoch 1  | loss: 1.15352 | val_0_rmse: 0.95034 | val_1_rmse: 1.02022 |  0:00:00s
epoch 2  | loss: 0.97152 | val_0_rmse: 0.902   | val_1_rmse: 0.97727 |  0:00:00s
epoch 3  | loss: 0.82504 | val_0_rmse: 0.89884 | val_1_rmse: 0.8972  |  0:00:00s
epoch 4  | loss: 0.71341 | val_0_rmse: 0.84105 | val_1_rmse: 0.89413 |  0:00:01s
epoch 5  | loss: 0.59948 | val_0_rmse: 0.86899 | val_1_rmse: 0.89732 |  0:00:01s
epoch 6  | loss: 0.5548  | val_0_rmse: 0.79414 | val_1_rmse: 0.83077 |  0:00:01s
epoch 7  | loss: 0.51976 | val_0_rmse: 0.77497 | val_1_rmse: 0.80216 |  0:00:01s
epoch 8  | loss: 0.48477 | val_0_rmse: 0.71613 | val_1_rmse: 0.74933 |  0:00:01s
epoch 9  | loss: 0.47443 | val_0_rmse: 0.70946 | val_1_rmse: 0.75508 |  0:00:02s
epoch 10 | loss: 0.47681 | val_0_rmse: 0.68046 | val_1_rmse: 0.70242 |  0:00:02s
epoch 11 | loss: 0.4586  | val_0_rmse: 0.69235 | val_1_rmse: 0.71367 |  0:00:02s
epoch 12 | loss: 0.47922 | val_0_rmse: 0.68115 | val_1_rmse: 0.69267 |  0:00:02s
epoch 13 | loss: 0.45803 | val_0_rmse: 0.6722  | val_1_rmse: 0.71052 |  0:00:02s
epoch 14 | loss: 0.44021 | val_0_rmse: 0.6939  | val_1_rmse: 0.72365 |  0:00:03s
epoch 15 | loss: 0.44706 | val_0_rmse: 0.68431 | val_1_rmse: 0.72331 |  0:00:03s
epoch 16 | loss: 0.45291 | val_0_rmse: 0.6951  | val_1_rmse: 0.71487 |  0:00:03s
epoch 17 | loss: 0.43205 | val_0_rmse: 0.70318 | val_1_rmse: 0.74193 |  0:00:03s
epoch 18 | loss: 0.42792 | val_0_rmse: 0.67367 | val_1_rmse: 0.71242 |  0:00:03s
epoch 19 | loss: 0.44289 | val_0_rmse: 0.68692 | val_1_rmse: 0.72717 |  0:00:04s
epoch 20 | loss: 0.43777 | val_0_rmse: 0.72882 | val_1_rmse: 0.76263 |  0:00:04s
epoch 21 | loss: 0.44366 | val_0_rmse: 0.703   | val_1_rmse: 0.72499 |  0:00:04s
epoch 22 | loss: 0.43285 | val_0_rmse: 0.68512 | val_1_rmse: 0.70508 |  0:00:04s
epoch 23 | loss: 0.42152 | val_0_rmse: 0.68126 | val_1_rmse: 0.70731 |  0:00:04s
epoch 24 | loss: 0.43413 | val_0_rmse: 0.68704 | val_1_rmse: 0.71254 |  0:00:05s
epoch 25 | loss: 0.43847 | val_0_rmse: 0.74366 | val_1_rmse: 0.75789 |  0:00:05s
epoch 26 | loss: 0.43775 | val_0_rmse: 0.70923 | val_1_rmse: 0.72438 |  0:00:05s
epoch 27 | loss: 0.42902 | val_0_rmse: 0.67179 | val_1_rmse: 0.68702 |  0:00:05s
epoch 28 | loss: 0.42287 | val_0_rmse: 0.68899 | val_1_rmse: 0.69476 |  0:00:05s
epoch 29 | loss: 0.42851 | val_0_rmse: 0.67576 | val_1_rmse: 0.67906 |  0:00:06s
epoch 30 | loss: 0.44617 | val_0_rmse: 0.66713 | val_1_rmse: 0.67632 |  0:00:06s
epoch 31 | loss: 0.42861 | val_0_rmse: 0.67895 | val_1_rmse: 0.69285 |  0:00:06s
epoch 32 | loss: 0.41514 | val_0_rmse: 0.68041 | val_1_rmse: 0.69858 |  0:00:06s
epoch 33 | loss: 0.42004 | val_0_rmse: 0.6773  | val_1_rmse: 0.70307 |  0:00:07s
epoch 34 | loss: 0.42499 | val_0_rmse: 0.68338 | val_1_rmse: 0.71342 |  0:00:07s
epoch 35 | loss: 0.43317 | val_0_rmse: 0.70148 | val_1_rmse: 0.72989 |  0:00:07s
epoch 36 | loss: 0.43969 | val_0_rmse: 0.68763 | val_1_rmse: 0.71229 |  0:00:07s
epoch 37 | loss: 0.4367  | val_0_rmse: 0.68528 | val_1_rmse: 0.71133 |  0:00:07s
epoch 38 | loss: 0.41924 | val_0_rmse: 0.69807 | val_1_rmse: 0.72454 |  0:00:08s
epoch 39 | loss: 0.42834 | val_0_rmse: 0.68115 | val_1_rmse: 0.71057 |  0:00:08s
epoch 40 | loss: 0.41848 | val_0_rmse: 0.67542 | val_1_rmse: 0.70569 |  0:00:08s
epoch 41 | loss: 0.43004 | val_0_rmse: 0.67636 | val_1_rmse: 0.70618 |  0:00:08s
epoch 42 | loss: 0.41155 | val_0_rmse: 0.68157 | val_1_rmse: 0.71303 |  0:00:08s
epoch 43 | loss: 0.41706 | val_0_rmse: 0.6796  | val_1_rmse: 0.7115  |  0:00:09s
epoch 44 | loss: 0.41904 | val_0_rmse: 0.67585 | val_1_rmse: 0.70663 |  0:00:09s
epoch 45 | loss: 0.4192  | val_0_rmse: 0.67582 | val_1_rmse: 0.70722 |  0:00:09s
epoch 46 | loss: 0.41562 | val_0_rmse: 0.68138 | val_1_rmse: 0.71081 |  0:00:09s
epoch 47 | loss: 0.41628 | val_0_rmse: 0.67267 | val_1_rmse: 0.70414 |  0:00:09s
epoch 48 | loss: 0.41986 | val_0_rmse: 0.66983 | val_1_rmse: 0.70201 |  0:00:10s
epoch 49 | loss: 0.41819 | val_0_rmse: 0.6803  | val_1_rmse: 0.70915 |  0:00:10s
epoch 50 | loss: 0.41998 | val_0_rmse: 0.67584 | val_1_rmse: 0.70459 |  0:00:10s
epoch 51 | loss: 0.42121 | val_0_rmse: 0.6701  | val_1_rmse: 0.70235 |  0:00:10s
epoch 52 | loss: 0.41854 | val_0_rmse: 0.66856 | val_1_rmse: 0.70576 |  0:00:10s
epoch 53 | loss: 0.41196 | val_0_rmse: 0.68286 | val_1_rmse: 0.71579 |  0:00:11s
epoch 54 | loss: 0.43082 | val_0_rmse: 0.66987 | val_1_rmse: 0.70426 |  0:00:11s
epoch 55 | loss: 0.40895 | val_0_rmse: 0.66806 | val_1_rmse: 0.70392 |  0:00:11s
epoch 56 | loss: 0.42267 | val_0_rmse: 0.6662  | val_1_rmse: 0.70121 |  0:00:11s
epoch 57 | loss: 0.40102 | val_0_rmse: 0.6693  | val_1_rmse: 0.70348 |  0:00:11s
epoch 58 | loss: 0.40954 | val_0_rmse: 0.66584 | val_1_rmse: 0.70291 |  0:00:12s
epoch 59 | loss: 0.41835 | val_0_rmse: 0.65857 | val_1_rmse: 0.70457 |  0:00:12s
epoch 60 | loss: 0.41119 | val_0_rmse: 0.65863 | val_1_rmse: 0.70502 |  0:00:12s

Early stopping occured at epoch 60 with best_epoch = 30 and best_val_1_rmse = 0.67632
Best weights from best epoch are automatically used!
ended training at: 08:17:28
Feature importance:
Mean squared error is of 4217038387.137739
Mean absolute error:48683.32260444079
MAPE:0.45532704808240065
R2 score:0.4716499750626745
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 5
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:17:28
epoch 0  | loss: 1.89351 | val_0_rmse: 1.00114 | val_1_rmse: 1.00354 |  0:00:00s
epoch 1  | loss: 1.36949 | val_0_rmse: 1.0429  | val_1_rmse: 0.99793 |  0:00:00s
epoch 2  | loss: 1.08184 | val_0_rmse: 1.01172 | val_1_rmse: 0.96915 |  0:00:00s
epoch 3  | loss: 0.88876 | val_0_rmse: 0.96256 | val_1_rmse: 0.93142 |  0:00:00s
epoch 4  | loss: 0.73285 | val_0_rmse: 0.89479 | val_1_rmse: 0.87854 |  0:00:01s
epoch 5  | loss: 0.70789 | val_0_rmse: 0.8884  | val_1_rmse: 0.87664 |  0:00:01s
epoch 6  | loss: 0.69105 | val_0_rmse: 0.91948 | val_1_rmse: 0.92165 |  0:00:01s
epoch 7  | loss: 0.68084 | val_0_rmse: 0.84141 | val_1_rmse: 0.85369 |  0:00:01s
epoch 8  | loss: 0.61665 | val_0_rmse: 0.77867 | val_1_rmse: 0.7803  |  0:00:01s
epoch 9  | loss: 0.58789 | val_0_rmse: 0.7503  | val_1_rmse: 0.76397 |  0:00:02s
epoch 10 | loss: 0.5487  | val_0_rmse: 0.74704 | val_1_rmse: 0.75778 |  0:00:02s
epoch 11 | loss: 0.49267 | val_0_rmse: 0.76393 | val_1_rmse: 0.79062 |  0:00:02s
epoch 12 | loss: 0.45714 | val_0_rmse: 0.74502 | val_1_rmse: 0.77589 |  0:00:02s
epoch 13 | loss: 0.46417 | val_0_rmse: 0.74817 | val_1_rmse: 0.78838 |  0:00:02s
epoch 14 | loss: 0.44124 | val_0_rmse: 0.7262  | val_1_rmse: 0.75185 |  0:00:03s
epoch 15 | loss: 0.45228 | val_0_rmse: 0.73681 | val_1_rmse: 0.76364 |  0:00:03s
epoch 16 | loss: 0.4329  | val_0_rmse: 0.7125  | val_1_rmse: 0.7466  |  0:00:03s
epoch 17 | loss: 0.42584 | val_0_rmse: 0.67491 | val_1_rmse: 0.70765 |  0:00:03s
epoch 18 | loss: 0.41558 | val_0_rmse: 0.68273 | val_1_rmse: 0.71201 |  0:00:03s
epoch 19 | loss: 0.42297 | val_0_rmse: 0.67886 | val_1_rmse: 0.70537 |  0:00:04s
epoch 20 | loss: 0.41686 | val_0_rmse: 0.66867 | val_1_rmse: 0.69035 |  0:00:04s
epoch 21 | loss: 0.43238 | val_0_rmse: 0.68868 | val_1_rmse: 0.71539 |  0:00:04s
epoch 22 | loss: 0.41508 | val_0_rmse: 0.6708  | val_1_rmse: 0.69928 |  0:00:04s
epoch 23 | loss: 0.41941 | val_0_rmse: 0.66058 | val_1_rmse: 0.68148 |  0:00:05s
epoch 24 | loss: 0.40844 | val_0_rmse: 0.66855 | val_1_rmse: 0.68882 |  0:00:05s
epoch 25 | loss: 0.39796 | val_0_rmse: 0.67206 | val_1_rmse: 0.69263 |  0:00:05s
epoch 26 | loss: 0.40045 | val_0_rmse: 0.65004 | val_1_rmse: 0.67061 |  0:00:05s
epoch 27 | loss: 0.40045 | val_0_rmse: 0.65997 | val_1_rmse: 0.68132 |  0:00:05s
epoch 28 | loss: 0.40252 | val_0_rmse: 0.66429 | val_1_rmse: 0.67709 |  0:00:06s
epoch 29 | loss: 0.38656 | val_0_rmse: 0.66394 | val_1_rmse: 0.6728  |  0:00:06s
epoch 30 | loss: 0.39461 | val_0_rmse: 0.65877 | val_1_rmse: 0.66129 |  0:00:06s
epoch 31 | loss: 0.38938 | val_0_rmse: 0.67101 | val_1_rmse: 0.68736 |  0:00:06s
epoch 32 | loss: 0.3914  | val_0_rmse: 0.67098 | val_1_rmse: 0.69609 |  0:00:06s
epoch 33 | loss: 0.40397 | val_0_rmse: 0.67292 | val_1_rmse: 0.71118 |  0:00:07s
epoch 34 | loss: 0.40688 | val_0_rmse: 0.67708 | val_1_rmse: 0.68944 |  0:00:07s
epoch 35 | loss: 0.40861 | val_0_rmse: 0.66912 | val_1_rmse: 0.67854 |  0:00:07s
epoch 36 | loss: 0.42041 | val_0_rmse: 0.66873 | val_1_rmse: 0.67855 |  0:00:07s
epoch 37 | loss: 0.39112 | val_0_rmse: 0.66134 | val_1_rmse: 0.68538 |  0:00:07s
epoch 38 | loss: 0.40466 | val_0_rmse: 0.65779 | val_1_rmse: 0.68219 |  0:00:08s
epoch 39 | loss: 0.39617 | val_0_rmse: 0.66768 | val_1_rmse: 0.70204 |  0:00:08s
epoch 40 | loss: 0.40274 | val_0_rmse: 0.66547 | val_1_rmse: 0.71265 |  0:00:08s
epoch 41 | loss: 0.39602 | val_0_rmse: 0.67357 | val_1_rmse: 0.70815 |  0:00:08s
epoch 42 | loss: 0.38956 | val_0_rmse: 0.65744 | val_1_rmse: 0.68828 |  0:00:08s
epoch 43 | loss: 0.40028 | val_0_rmse: 0.64412 | val_1_rmse: 0.66098 |  0:00:09s
epoch 44 | loss: 0.39763 | val_0_rmse: 0.65634 | val_1_rmse: 0.65554 |  0:00:09s
epoch 45 | loss: 0.38344 | val_0_rmse: 0.65255 | val_1_rmse: 0.65651 |  0:00:09s
epoch 46 | loss: 0.39436 | val_0_rmse: 0.64874 | val_1_rmse: 0.65841 |  0:00:09s
epoch 47 | loss: 0.40416 | val_0_rmse: 0.64963 | val_1_rmse: 0.65969 |  0:00:09s
epoch 48 | loss: 0.40415 | val_0_rmse: 0.65231 | val_1_rmse: 0.66627 |  0:00:10s
epoch 49 | loss: 0.40657 | val_0_rmse: 0.65538 | val_1_rmse: 0.66844 |  0:00:10s
epoch 50 | loss: 0.39825 | val_0_rmse: 0.66099 | val_1_rmse: 0.67309 |  0:00:10s
epoch 51 | loss: 0.39863 | val_0_rmse: 0.66579 | val_1_rmse: 0.66995 |  0:00:10s
epoch 52 | loss: 0.40034 | val_0_rmse: 0.65518 | val_1_rmse: 0.66682 |  0:00:10s
epoch 53 | loss: 0.40338 | val_0_rmse: 0.64406 | val_1_rmse: 0.67595 |  0:00:11s
epoch 54 | loss: 0.40995 | val_0_rmse: 0.65035 | val_1_rmse: 0.67899 |  0:00:11s
epoch 55 | loss: 0.40283 | val_0_rmse: 0.65279 | val_1_rmse: 0.67485 |  0:00:11s
epoch 56 | loss: 0.38677 | val_0_rmse: 0.64488 | val_1_rmse: 0.67646 |  0:00:11s
epoch 57 | loss: 0.39358 | val_0_rmse: 0.63909 | val_1_rmse: 0.66404 |  0:00:11s
epoch 58 | loss: 0.40841 | val_0_rmse: 0.64199 | val_1_rmse: 0.65797 |  0:00:12s
epoch 59 | loss: 0.38281 | val_0_rmse: 0.65084 | val_1_rmse: 0.67065 |  0:00:12s
epoch 60 | loss: 0.39009 | val_0_rmse: 0.66131 | val_1_rmse: 0.68038 |  0:00:12s
epoch 61 | loss: 0.39438 | val_0_rmse: 0.64458 | val_1_rmse: 0.66134 |  0:00:12s
epoch 62 | loss: 0.38808 | val_0_rmse: 0.63651 | val_1_rmse: 0.66143 |  0:00:12s
epoch 63 | loss: 0.39696 | val_0_rmse: 0.63112 | val_1_rmse: 0.64391 |  0:00:13s
epoch 64 | loss: 0.38208 | val_0_rmse: 0.63458 | val_1_rmse: 0.64143 |  0:00:13s
epoch 65 | loss: 0.3787  | val_0_rmse: 0.63021 | val_1_rmse: 0.64707 |  0:00:13s
epoch 66 | loss: 0.38521 | val_0_rmse: 0.62784 | val_1_rmse: 0.65272 |  0:00:13s
epoch 67 | loss: 0.37021 | val_0_rmse: 0.63215 | val_1_rmse: 0.65293 |  0:00:13s
epoch 68 | loss: 0.37389 | val_0_rmse: 0.63547 | val_1_rmse: 0.65346 |  0:00:14s
epoch 69 | loss: 0.3791  | val_0_rmse: 0.63276 | val_1_rmse: 0.65588 |  0:00:14s
epoch 70 | loss: 0.37951 | val_0_rmse: 0.63333 | val_1_rmse: 0.65631 |  0:00:14s
epoch 71 | loss: 0.37699 | val_0_rmse: 0.64824 | val_1_rmse: 0.66546 |  0:00:14s
epoch 72 | loss: 0.37678 | val_0_rmse: 0.64031 | val_1_rmse: 0.66851 |  0:00:14s
epoch 73 | loss: 0.38826 | val_0_rmse: 0.64308 | val_1_rmse: 0.67703 |  0:00:15s
epoch 74 | loss: 0.3751  | val_0_rmse: 0.66406 | val_1_rmse: 0.69255 |  0:00:15s
epoch 75 | loss: 0.37897 | val_0_rmse: 0.64682 | val_1_rmse: 0.68097 |  0:00:15s
epoch 76 | loss: 0.36651 | val_0_rmse: 0.63427 | val_1_rmse: 0.67822 |  0:00:15s
epoch 77 | loss: 0.36526 | val_0_rmse: 0.63467 | val_1_rmse: 0.67258 |  0:00:16s
epoch 78 | loss: 0.36284 | val_0_rmse: 0.64096 | val_1_rmse: 0.67166 |  0:00:16s
epoch 79 | loss: 0.36847 | val_0_rmse: 0.63261 | val_1_rmse: 0.67606 |  0:00:16s
epoch 80 | loss: 0.37646 | val_0_rmse: 0.63243 | val_1_rmse: 0.67476 |  0:00:16s
epoch 81 | loss: 0.37054 | val_0_rmse: 0.63548 | val_1_rmse: 0.66279 |  0:00:16s
epoch 82 | loss: 0.38706 | val_0_rmse: 0.63491 | val_1_rmse: 0.66612 |  0:00:17s
epoch 83 | loss: 0.37088 | val_0_rmse: 0.62807 | val_1_rmse: 0.67604 |  0:00:17s
epoch 84 | loss: 0.36414 | val_0_rmse: 0.63053 | val_1_rmse: 0.67037 |  0:00:17s
epoch 85 | loss: 0.36794 | val_0_rmse: 0.64174 | val_1_rmse: 0.67693 |  0:00:17s
epoch 86 | loss: 0.37787 | val_0_rmse: 0.63985 | val_1_rmse: 0.67739 |  0:00:17s
epoch 87 | loss: 0.35933 | val_0_rmse: 0.6403  | val_1_rmse: 0.67473 |  0:00:18s
epoch 88 | loss: 0.37141 | val_0_rmse: 0.63669 | val_1_rmse: 0.67419 |  0:00:18s
epoch 89 | loss: 0.36929 | val_0_rmse: 0.63151 | val_1_rmse: 0.66869 |  0:00:18s
epoch 90 | loss: 0.36046 | val_0_rmse: 0.64395 | val_1_rmse: 0.67017 |  0:00:18s
epoch 91 | loss: 0.38056 | val_0_rmse: 0.63515 | val_1_rmse: 0.66525 |  0:00:18s
epoch 92 | loss: 0.36367 | val_0_rmse: 0.6259  | val_1_rmse: 0.66543 |  0:00:19s
epoch 93 | loss: 0.38502 | val_0_rmse: 0.61939 | val_1_rmse: 0.67224 |  0:00:19s
epoch 94 | loss: 0.36735 | val_0_rmse: 0.63169 | val_1_rmse: 0.67889 |  0:00:19s

Early stopping occured at epoch 94 with best_epoch = 64 and best_val_1_rmse = 0.64143
Best weights from best epoch are automatically used!
ended training at: 08:17:48
Feature importance:
Mean squared error is of 3305235917.976028
Mean absolute error:42441.83270600329
MAPE:0.3963264290426596
R2 score:0.5649366014603232
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 6
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:17:48
epoch 0  | loss: 1.9644  | val_0_rmse: 0.97337 | val_1_rmse: 0.97755 |  0:00:00s
epoch 1  | loss: 1.48052 | val_0_rmse: 1.03621 | val_1_rmse: 0.98897 |  0:00:00s
epoch 2  | loss: 1.20645 | val_0_rmse: 0.99404 | val_1_rmse: 0.99899 |  0:00:00s
epoch 3  | loss: 1.00044 | val_0_rmse: 0.94846 | val_1_rmse: 0.95234 |  0:00:00s
epoch 4  | loss: 0.90862 | val_0_rmse: 0.83544 | val_1_rmse: 0.83318 |  0:00:01s
epoch 5  | loss: 0.85996 | val_0_rmse: 0.81947 | val_1_rmse: 0.81907 |  0:00:01s
epoch 6  | loss: 0.81641 | val_0_rmse: 0.82867 | val_1_rmse: 0.82706 |  0:00:01s
epoch 7  | loss: 0.72964 | val_0_rmse: 0.80704 | val_1_rmse: 0.8312  |  0:00:01s
epoch 8  | loss: 0.66753 | val_0_rmse: 0.76488 | val_1_rmse: 0.80287 |  0:00:01s
epoch 9  | loss: 0.64507 | val_0_rmse: 0.75765 | val_1_rmse: 0.7714  |  0:00:02s
epoch 10 | loss: 0.60744 | val_0_rmse: 0.74382 | val_1_rmse: 0.77083 |  0:00:02s
epoch 11 | loss: 0.59668 | val_0_rmse: 0.79975 | val_1_rmse: 0.79009 |  0:00:02s
epoch 12 | loss: 0.59835 | val_0_rmse: 0.88959 | val_1_rmse: 0.94588 |  0:00:02s
epoch 13 | loss: 0.57865 | val_0_rmse: 0.81649 | val_1_rmse: 0.86626 |  0:00:02s
epoch 14 | loss: 0.5702  | val_0_rmse: 0.87015 | val_1_rmse: 0.93055 |  0:00:03s
epoch 15 | loss: 0.57951 | val_0_rmse: 0.90747 | val_1_rmse: 0.97718 |  0:00:03s
epoch 16 | loss: 0.55201 | val_0_rmse: 0.75862 | val_1_rmse: 0.80764 |  0:00:03s
epoch 17 | loss: 0.53057 | val_0_rmse: 0.735   | val_1_rmse: 0.76332 |  0:00:03s
epoch 18 | loss: 0.55106 | val_0_rmse: 0.76673 | val_1_rmse: 0.81884 |  0:00:03s
epoch 19 | loss: 0.50962 | val_0_rmse: 0.79084 | val_1_rmse: 0.85139 |  0:00:04s
epoch 20 | loss: 0.51863 | val_0_rmse: 0.74259 | val_1_rmse: 0.80021 |  0:00:04s
epoch 21 | loss: 0.51684 | val_0_rmse: 0.73303 | val_1_rmse: 0.75922 |  0:00:04s
epoch 22 | loss: 0.52345 | val_0_rmse: 0.74251 | val_1_rmse: 0.75655 |  0:00:04s
epoch 23 | loss: 0.47887 | val_0_rmse: 0.73708 | val_1_rmse: 0.75545 |  0:00:04s
epoch 24 | loss: 0.49003 | val_0_rmse: 0.73671 | val_1_rmse: 0.75405 |  0:00:05s
epoch 25 | loss: 0.45941 | val_0_rmse: 0.72385 | val_1_rmse: 0.75552 |  0:00:05s
epoch 26 | loss: 0.45575 | val_0_rmse: 0.70859 | val_1_rmse: 0.75324 |  0:00:05s
epoch 27 | loss: 0.45649 | val_0_rmse: 0.76271 | val_1_rmse: 0.80473 |  0:00:05s
epoch 28 | loss: 0.4582  | val_0_rmse: 0.76483 | val_1_rmse: 0.8155  |  0:00:06s
epoch 29 | loss: 0.466   | val_0_rmse: 0.73252 | val_1_rmse: 0.76396 |  0:00:06s
epoch 30 | loss: 0.44362 | val_0_rmse: 0.7135  | val_1_rmse: 0.74972 |  0:00:06s
epoch 31 | loss: 0.44334 | val_0_rmse: 0.6897  | val_1_rmse: 0.72854 |  0:00:06s
epoch 32 | loss: 0.45574 | val_0_rmse: 0.68745 | val_1_rmse: 0.72736 |  0:00:06s
epoch 33 | loss: 0.44787 | val_0_rmse: 0.68147 | val_1_rmse: 0.71566 |  0:00:07s
epoch 34 | loss: 0.44526 | val_0_rmse: 0.68798 | val_1_rmse: 0.72408 |  0:00:07s
epoch 35 | loss: 0.44992 | val_0_rmse: 0.69324 | val_1_rmse: 0.72958 |  0:00:07s
epoch 36 | loss: 0.45238 | val_0_rmse: 0.70492 | val_1_rmse: 0.73788 |  0:00:07s
epoch 37 | loss: 0.43408 | val_0_rmse: 0.68246 | val_1_rmse: 0.71749 |  0:00:07s
epoch 38 | loss: 0.41338 | val_0_rmse: 0.68099 | val_1_rmse: 0.71637 |  0:00:08s
epoch 39 | loss: 0.42767 | val_0_rmse: 0.69817 | val_1_rmse: 0.72284 |  0:00:08s
epoch 40 | loss: 0.41493 | val_0_rmse: 0.71362 | val_1_rmse: 0.73212 |  0:00:08s
epoch 41 | loss: 0.41667 | val_0_rmse: 0.71471 | val_1_rmse: 0.74471 |  0:00:08s
epoch 42 | loss: 0.40942 | val_0_rmse: 0.72815 | val_1_rmse: 0.75858 |  0:00:08s
epoch 43 | loss: 0.43596 | val_0_rmse: 0.74276 | val_1_rmse: 0.76498 |  0:00:09s
epoch 44 | loss: 0.42503 | val_0_rmse: 0.75419 | val_1_rmse: 0.77746 |  0:00:09s
epoch 45 | loss: 0.41862 | val_0_rmse: 0.74298 | val_1_rmse: 0.77293 |  0:00:09s
epoch 46 | loss: 0.42907 | val_0_rmse: 0.72371 | val_1_rmse: 0.75591 |  0:00:09s
epoch 47 | loss: 0.41904 | val_0_rmse: 0.70701 | val_1_rmse: 0.73064 |  0:00:09s
epoch 48 | loss: 0.41916 | val_0_rmse: 0.70151 | val_1_rmse: 0.72022 |  0:00:10s
epoch 49 | loss: 0.41602 | val_0_rmse: 0.6917  | val_1_rmse: 0.71639 |  0:00:10s
epoch 50 | loss: 0.4202  | val_0_rmse: 0.68769 | val_1_rmse: 0.71709 |  0:00:10s
epoch 51 | loss: 0.40342 | val_0_rmse: 0.68206 | val_1_rmse: 0.71118 |  0:00:10s
epoch 52 | loss: 0.40656 | val_0_rmse: 0.68725 | val_1_rmse: 0.71587 |  0:00:10s
epoch 53 | loss: 0.41442 | val_0_rmse: 0.69411 | val_1_rmse: 0.72591 |  0:00:11s
epoch 54 | loss: 0.41578 | val_0_rmse: 0.70008 | val_1_rmse: 0.73859 |  0:00:11s
epoch 55 | loss: 0.42025 | val_0_rmse: 0.67518 | val_1_rmse: 0.72691 |  0:00:11s
epoch 56 | loss: 0.41077 | val_0_rmse: 0.66595 | val_1_rmse: 0.70731 |  0:00:11s
epoch 57 | loss: 0.42112 | val_0_rmse: 0.68181 | val_1_rmse: 0.70847 |  0:00:11s
epoch 58 | loss: 0.41911 | val_0_rmse: 0.69087 | val_1_rmse: 0.71871 |  0:00:12s
epoch 59 | loss: 0.42651 | val_0_rmse: 0.69594 | val_1_rmse: 0.73064 |  0:00:12s
epoch 60 | loss: 0.40884 | val_0_rmse: 0.69926 | val_1_rmse: 0.72863 |  0:00:12s
epoch 61 | loss: 0.40947 | val_0_rmse: 0.70124 | val_1_rmse: 0.72478 |  0:00:12s
epoch 62 | loss: 0.40299 | val_0_rmse: 0.70123 | val_1_rmse: 0.7196  |  0:00:12s
epoch 63 | loss: 0.41062 | val_0_rmse: 0.69533 | val_1_rmse: 0.71249 |  0:00:13s
epoch 64 | loss: 0.38128 | val_0_rmse: 0.69709 | val_1_rmse: 0.71223 |  0:00:13s
epoch 65 | loss: 0.3875  | val_0_rmse: 0.69002 | val_1_rmse: 0.70518 |  0:00:13s
epoch 66 | loss: 0.39059 | val_0_rmse: 0.68088 | val_1_rmse: 0.69919 |  0:00:13s
epoch 67 | loss: 0.38827 | val_0_rmse: 0.67406 | val_1_rmse: 0.70054 |  0:00:13s
epoch 68 | loss: 0.38084 | val_0_rmse: 0.68005 | val_1_rmse: 0.70788 |  0:00:14s
epoch 69 | loss: 0.39173 | val_0_rmse: 0.69023 | val_1_rmse: 0.72301 |  0:00:14s
epoch 70 | loss: 0.38626 | val_0_rmse: 0.68254 | val_1_rmse: 0.72075 |  0:00:14s
epoch 71 | loss: 0.37801 | val_0_rmse: 0.67126 | val_1_rmse: 0.71007 |  0:00:14s
epoch 72 | loss: 0.37976 | val_0_rmse: 0.65663 | val_1_rmse: 0.69764 |  0:00:14s
epoch 73 | loss: 0.38376 | val_0_rmse: 0.65274 | val_1_rmse: 0.69215 |  0:00:15s
epoch 74 | loss: 0.3973  | val_0_rmse: 0.65731 | val_1_rmse: 0.68989 |  0:00:15s
epoch 75 | loss: 0.37729 | val_0_rmse: 0.66274 | val_1_rmse: 0.69626 |  0:00:15s
epoch 76 | loss: 0.37516 | val_0_rmse: 0.66043 | val_1_rmse: 0.69194 |  0:00:15s
epoch 77 | loss: 0.36548 | val_0_rmse: 0.65921 | val_1_rmse: 0.68775 |  0:00:16s
epoch 78 | loss: 0.37763 | val_0_rmse: 0.6587  | val_1_rmse: 0.68229 |  0:00:16s
epoch 79 | loss: 0.38451 | val_0_rmse: 0.6667  | val_1_rmse: 0.68447 |  0:00:16s
epoch 80 | loss: 0.38404 | val_0_rmse: 0.65376 | val_1_rmse: 0.67404 |  0:00:16s
epoch 81 | loss: 0.37783 | val_0_rmse: 0.64691 | val_1_rmse: 0.65696 |  0:00:16s
epoch 82 | loss: 0.37066 | val_0_rmse: 0.65604 | val_1_rmse: 0.66551 |  0:00:17s
epoch 83 | loss: 0.37614 | val_0_rmse: 0.66403 | val_1_rmse: 0.67638 |  0:00:17s
epoch 84 | loss: 0.37864 | val_0_rmse: 0.65269 | val_1_rmse: 0.6655  |  0:00:17s
epoch 85 | loss: 0.38237 | val_0_rmse: 0.65003 | val_1_rmse: 0.66082 |  0:00:17s
epoch 86 | loss: 0.37661 | val_0_rmse: 0.65376 | val_1_rmse: 0.66249 |  0:00:17s
epoch 87 | loss: 0.36453 | val_0_rmse: 0.65441 | val_1_rmse: 0.67229 |  0:00:18s
epoch 88 | loss: 0.37764 | val_0_rmse: 0.64393 | val_1_rmse: 0.67359 |  0:00:18s
epoch 89 | loss: 0.37493 | val_0_rmse: 0.64346 | val_1_rmse: 0.67562 |  0:00:18s
epoch 90 | loss: 0.38534 | val_0_rmse: 0.64376 | val_1_rmse: 0.6701  |  0:00:18s
epoch 91 | loss: 0.3879  | val_0_rmse: 0.6451  | val_1_rmse: 0.65518 |  0:00:18s
epoch 92 | loss: 0.37334 | val_0_rmse: 0.64303 | val_1_rmse: 0.64474 |  0:00:19s
epoch 93 | loss: 0.39318 | val_0_rmse: 0.64352 | val_1_rmse: 0.64486 |  0:00:19s
epoch 94 | loss: 0.38367 | val_0_rmse: 0.64546 | val_1_rmse: 0.64489 |  0:00:19s
epoch 95 | loss: 0.37859 | val_0_rmse: 0.63614 | val_1_rmse: 0.63951 |  0:00:19s
epoch 96 | loss: 0.37011 | val_0_rmse: 0.64011 | val_1_rmse: 0.64816 |  0:00:19s
epoch 97 | loss: 0.38423 | val_0_rmse: 0.64224 | val_1_rmse: 0.64665 |  0:00:20s
epoch 98 | loss: 0.36841 | val_0_rmse: 0.64467 | val_1_rmse: 0.6418  |  0:00:20s
epoch 99 | loss: 0.37373 | val_0_rmse: 0.64445 | val_1_rmse: 0.64072 |  0:00:20s
epoch 100| loss: 0.36731 | val_0_rmse: 0.64346 | val_1_rmse: 0.64116 |  0:00:20s
epoch 101| loss: 0.37204 | val_0_rmse: 0.63782 | val_1_rmse: 0.63607 |  0:00:20s
epoch 102| loss: 0.36123 | val_0_rmse: 0.6394  | val_1_rmse: 0.63945 |  0:00:21s
epoch 103| loss: 0.37728 | val_0_rmse: 0.63584 | val_1_rmse: 0.6322  |  0:00:21s
epoch 104| loss: 0.37007 | val_0_rmse: 0.6361  | val_1_rmse: 0.63087 |  0:00:21s
epoch 105| loss: 0.3684  | val_0_rmse: 0.63853 | val_1_rmse: 0.6354  |  0:00:21s
epoch 106| loss: 0.36773 | val_0_rmse: 0.63533 | val_1_rmse: 0.64035 |  0:00:22s
epoch 107| loss: 0.36726 | val_0_rmse: 0.63205 | val_1_rmse: 0.64244 |  0:00:22s
epoch 108| loss: 0.37155 | val_0_rmse: 0.63507 | val_1_rmse: 0.64758 |  0:00:22s
epoch 109| loss: 0.36462 | val_0_rmse: 0.63579 | val_1_rmse: 0.65122 |  0:00:22s
epoch 110| loss: 0.37026 | val_0_rmse: 0.62476 | val_1_rmse: 0.63958 |  0:00:22s
epoch 111| loss: 0.37391 | val_0_rmse: 0.62201 | val_1_rmse: 0.63433 |  0:00:23s
epoch 112| loss: 0.37981 | val_0_rmse: 0.62695 | val_1_rmse: 0.64339 |  0:00:23s
epoch 113| loss: 0.37166 | val_0_rmse: 0.62049 | val_1_rmse: 0.63525 |  0:00:23s
epoch 114| loss: 0.36469 | val_0_rmse: 0.62251 | val_1_rmse: 0.63603 |  0:00:23s
epoch 115| loss: 0.36376 | val_0_rmse: 0.62252 | val_1_rmse: 0.63513 |  0:00:23s
epoch 116| loss: 0.36346 | val_0_rmse: 0.62516 | val_1_rmse: 0.63751 |  0:00:24s
epoch 117| loss: 0.36715 | val_0_rmse: 0.64218 | val_1_rmse: 0.64031 |  0:00:24s
epoch 118| loss: 0.37179 | val_0_rmse: 0.64437 | val_1_rmse: 0.64881 |  0:00:24s
epoch 119| loss: 0.38328 | val_0_rmse: 0.63547 | val_1_rmse: 0.64222 |  0:00:24s
epoch 120| loss: 0.37508 | val_0_rmse: 0.63034 | val_1_rmse: 0.63847 |  0:00:24s
epoch 121| loss: 0.38296 | val_0_rmse: 0.63212 | val_1_rmse: 0.64247 |  0:00:24s
epoch 122| loss: 0.37025 | val_0_rmse: 0.61408 | val_1_rmse: 0.62343 |  0:00:25s
epoch 123| loss: 0.36769 | val_0_rmse: 0.6136  | val_1_rmse: 0.62453 |  0:00:25s
epoch 124| loss: 0.38718 | val_0_rmse: 0.60722 | val_1_rmse: 0.63339 |  0:00:25s
epoch 125| loss: 0.36981 | val_0_rmse: 0.61061 | val_1_rmse: 0.63581 |  0:00:25s
epoch 126| loss: 0.36958 | val_0_rmse: 0.61387 | val_1_rmse: 0.64449 |  0:00:25s
epoch 127| loss: 0.36963 | val_0_rmse: 0.61345 | val_1_rmse: 0.64341 |  0:00:26s
epoch 128| loss: 0.36573 | val_0_rmse: 0.606   | val_1_rmse: 0.63127 |  0:00:26s
epoch 129| loss: 0.35465 | val_0_rmse: 0.60836 | val_1_rmse: 0.63627 |  0:00:26s
epoch 130| loss: 0.376   | val_0_rmse: 0.61336 | val_1_rmse: 0.63377 |  0:00:26s
epoch 131| loss: 0.36021 | val_0_rmse: 0.62351 | val_1_rmse: 0.63993 |  0:00:26s
epoch 132| loss: 0.36265 | val_0_rmse: 0.62886 | val_1_rmse: 0.63677 |  0:00:27s
epoch 133| loss: 0.35747 | val_0_rmse: 0.62974 | val_1_rmse: 0.62988 |  0:00:27s
epoch 134| loss: 0.35639 | val_0_rmse: 0.6279  | val_1_rmse: 0.62408 |  0:00:27s
epoch 135| loss: 0.36371 | val_0_rmse: 0.62159 | val_1_rmse: 0.61986 |  0:00:27s
epoch 136| loss: 0.35589 | val_0_rmse: 0.61736 | val_1_rmse: 0.6283  |  0:00:27s
epoch 137| loss: 0.35681 | val_0_rmse: 0.61551 | val_1_rmse: 0.63472 |  0:00:28s
epoch 138| loss: 0.35721 | val_0_rmse: 0.61528 | val_1_rmse: 0.63299 |  0:00:28s
epoch 139| loss: 0.35734 | val_0_rmse: 0.61622 | val_1_rmse: 0.62698 |  0:00:28s
epoch 140| loss: 0.35436 | val_0_rmse: 0.62546 | val_1_rmse: 0.63556 |  0:00:28s
epoch 141| loss: 0.3559  | val_0_rmse: 0.6346  | val_1_rmse: 0.64573 |  0:00:29s
epoch 142| loss: 0.3549  | val_0_rmse: 0.64426 | val_1_rmse: 0.65903 |  0:00:29s
epoch 143| loss: 0.35467 | val_0_rmse: 0.6387  | val_1_rmse: 0.65069 |  0:00:29s
epoch 144| loss: 0.35411 | val_0_rmse: 0.63091 | val_1_rmse: 0.63997 |  0:00:29s
epoch 145| loss: 0.3553  | val_0_rmse: 0.62617 | val_1_rmse: 0.6326  |  0:00:29s
epoch 146| loss: 0.36452 | val_0_rmse: 0.62869 | val_1_rmse: 0.63475 |  0:00:30s
epoch 147| loss: 0.35955 | val_0_rmse: 0.6384  | val_1_rmse: 0.64626 |  0:00:30s
epoch 148| loss: 0.35435 | val_0_rmse: 0.63547 | val_1_rmse: 0.64837 |  0:00:30s
epoch 149| loss: 0.35424 | val_0_rmse: 0.62132 | val_1_rmse: 0.63314 |  0:00:30s
Stop training because you reached max_epochs = 150 with best_epoch = 135 and best_val_1_rmse = 0.61986
Best weights from best epoch are automatically used!
ended training at: 08:18:18
Feature importance:
Mean squared error is of 3066278897.7747416
Mean absolute error:40737.23114268093
MAPE:0.31268157759383186
R2 score:0.606067284989297
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 7
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:18:18
epoch 0  | loss: 2.13749 | val_0_rmse: 0.97076 | val_1_rmse: 0.9594  |  0:00:00s
epoch 1  | loss: 1.12887 | val_0_rmse: 0.95719 | val_1_rmse: 0.94826 |  0:00:00s
epoch 2  | loss: 0.91517 | val_0_rmse: 0.90792 | val_1_rmse: 0.90636 |  0:00:00s
epoch 3  | loss: 0.85905 | val_0_rmse: 0.89646 | val_1_rmse: 0.89189 |  0:00:00s
epoch 4  | loss: 0.79657 | val_0_rmse: 0.84583 | val_1_rmse: 0.84346 |  0:00:01s
epoch 5  | loss: 0.65493 | val_0_rmse: 0.78067 | val_1_rmse: 0.78928 |  0:00:01s
epoch 6  | loss: 0.60701 | val_0_rmse: 0.7383  | val_1_rmse: 0.75281 |  0:00:01s
epoch 7  | loss: 0.55815 | val_0_rmse: 0.7477  | val_1_rmse: 0.76517 |  0:00:01s
epoch 8  | loss: 0.53615 | val_0_rmse: 0.74863 | val_1_rmse: 0.76205 |  0:00:01s
epoch 9  | loss: 0.48888 | val_0_rmse: 0.74207 | val_1_rmse: 0.76082 |  0:00:02s
epoch 10 | loss: 0.46791 | val_0_rmse: 0.74434 | val_1_rmse: 0.78316 |  0:00:02s
epoch 11 | loss: 0.48779 | val_0_rmse: 0.72349 | val_1_rmse: 0.74587 |  0:00:02s
epoch 12 | loss: 0.46709 | val_0_rmse: 0.7191  | val_1_rmse: 0.74235 |  0:00:02s
epoch 13 | loss: 0.47178 | val_0_rmse: 0.77091 | val_1_rmse: 0.78948 |  0:00:02s
epoch 14 | loss: 0.45983 | val_0_rmse: 0.76839 | val_1_rmse: 0.7736  |  0:00:03s
epoch 15 | loss: 0.45586 | val_0_rmse: 0.76468 | val_1_rmse: 0.79204 |  0:00:03s
epoch 16 | loss: 0.44465 | val_0_rmse: 0.7448  | val_1_rmse: 0.79055 |  0:00:03s
epoch 17 | loss: 0.43902 | val_0_rmse: 0.75913 | val_1_rmse: 0.79863 |  0:00:03s
epoch 18 | loss: 0.44452 | val_0_rmse: 0.7545  | val_1_rmse: 0.80448 |  0:00:03s
epoch 19 | loss: 0.43313 | val_0_rmse: 0.73052 | val_1_rmse: 0.76614 |  0:00:04s
epoch 20 | loss: 0.42969 | val_0_rmse: 0.71195 | val_1_rmse: 0.75316 |  0:00:04s
epoch 21 | loss: 0.43992 | val_0_rmse: 0.72382 | val_1_rmse: 0.77739 |  0:00:04s
epoch 22 | loss: 0.43245 | val_0_rmse: 0.72252 | val_1_rmse: 0.78018 |  0:00:04s
epoch 23 | loss: 0.42283 | val_0_rmse: 0.71018 | val_1_rmse: 0.74949 |  0:00:04s
epoch 24 | loss: 0.42841 | val_0_rmse: 0.75946 | val_1_rmse: 0.79766 |  0:00:05s
epoch 25 | loss: 0.42914 | val_0_rmse: 0.74484 | val_1_rmse: 0.79439 |  0:00:05s
epoch 26 | loss: 0.41646 | val_0_rmse: 0.67089 | val_1_rmse: 0.71708 |  0:00:05s
epoch 27 | loss: 0.4193  | val_0_rmse: 0.70682 | val_1_rmse: 0.75484 |  0:00:05s
epoch 28 | loss: 0.41224 | val_0_rmse: 0.73731 | val_1_rmse: 0.79121 |  0:00:05s
epoch 29 | loss: 0.41261 | val_0_rmse: 0.66481 | val_1_rmse: 0.71891 |  0:00:06s
epoch 30 | loss: 0.424   | val_0_rmse: 0.66776 | val_1_rmse: 0.71438 |  0:00:06s
epoch 31 | loss: 0.40744 | val_0_rmse: 0.72583 | val_1_rmse: 0.76795 |  0:00:06s
epoch 32 | loss: 0.42019 | val_0_rmse: 0.67595 | val_1_rmse: 0.72284 |  0:00:06s
epoch 33 | loss: 0.40822 | val_0_rmse: 0.6854  | val_1_rmse: 0.73926 |  0:00:06s
epoch 34 | loss: 0.40608 | val_0_rmse: 0.71901 | val_1_rmse: 0.77796 |  0:00:07s
epoch 35 | loss: 0.40232 | val_0_rmse: 0.70797 | val_1_rmse: 0.76239 |  0:00:07s
epoch 36 | loss: 0.40443 | val_0_rmse: 0.66923 | val_1_rmse: 0.7133  |  0:00:07s
epoch 37 | loss: 0.3875  | val_0_rmse: 0.69646 | val_1_rmse: 0.74536 |  0:00:07s
epoch 38 | loss: 0.39051 | val_0_rmse: 0.74106 | val_1_rmse: 0.79248 |  0:00:07s
epoch 39 | loss: 0.38862 | val_0_rmse: 0.72704 | val_1_rmse: 0.76872 |  0:00:08s
epoch 40 | loss: 0.39103 | val_0_rmse: 0.72431 | val_1_rmse: 0.75768 |  0:00:08s
epoch 41 | loss: 0.39036 | val_0_rmse: 0.73111 | val_1_rmse: 0.76972 |  0:00:08s
epoch 42 | loss: 0.38697 | val_0_rmse: 0.71147 | val_1_rmse: 0.7604  |  0:00:08s
epoch 43 | loss: 0.39165 | val_0_rmse: 0.68881 | val_1_rmse: 0.7368  |  0:00:08s
epoch 44 | loss: 0.38198 | val_0_rmse: 0.67288 | val_1_rmse: 0.72404 |  0:00:09s
epoch 45 | loss: 0.39058 | val_0_rmse: 0.674   | val_1_rmse: 0.72318 |  0:00:09s
epoch 46 | loss: 0.39173 | val_0_rmse: 0.66705 | val_1_rmse: 0.71621 |  0:00:09s
epoch 47 | loss: 0.38413 | val_0_rmse: 0.69432 | val_1_rmse: 0.741   |  0:00:09s
epoch 48 | loss: 0.38719 | val_0_rmse: 0.68501 | val_1_rmse: 0.74423 |  0:00:09s
epoch 49 | loss: 0.38545 | val_0_rmse: 0.65055 | val_1_rmse: 0.71183 |  0:00:10s
epoch 50 | loss: 0.38805 | val_0_rmse: 0.64272 | val_1_rmse: 0.70077 |  0:00:10s
epoch 51 | loss: 0.37973 | val_0_rmse: 0.64416 | val_1_rmse: 0.70786 |  0:00:10s
epoch 52 | loss: 0.39601 | val_0_rmse: 0.6385  | val_1_rmse: 0.69798 |  0:00:10s
epoch 53 | loss: 0.37067 | val_0_rmse: 0.64121 | val_1_rmse: 0.69508 |  0:00:10s
epoch 54 | loss: 0.38333 | val_0_rmse: 0.63101 | val_1_rmse: 0.69248 |  0:00:11s
epoch 55 | loss: 0.38184 | val_0_rmse: 0.63489 | val_1_rmse: 0.70622 |  0:00:11s
epoch 56 | loss: 0.38891 | val_0_rmse: 0.63652 | val_1_rmse: 0.70047 |  0:00:11s
epoch 57 | loss: 0.38045 | val_0_rmse: 0.63413 | val_1_rmse: 0.69351 |  0:00:11s
epoch 58 | loss: 0.38516 | val_0_rmse: 0.63165 | val_1_rmse: 0.69036 |  0:00:11s
epoch 59 | loss: 0.38048 | val_0_rmse: 0.63278 | val_1_rmse: 0.69018 |  0:00:12s
epoch 60 | loss: 0.38732 | val_0_rmse: 0.62901 | val_1_rmse: 0.67693 |  0:00:12s
epoch 61 | loss: 0.3808  | val_0_rmse: 0.6337  | val_1_rmse: 0.67858 |  0:00:12s
epoch 62 | loss: 0.38499 | val_0_rmse: 0.63443 | val_1_rmse: 0.68741 |  0:00:12s
epoch 63 | loss: 0.37789 | val_0_rmse: 0.64677 | val_1_rmse: 0.70869 |  0:00:13s
epoch 64 | loss: 0.39337 | val_0_rmse: 0.62646 | val_1_rmse: 0.68523 |  0:00:13s
epoch 65 | loss: 0.38344 | val_0_rmse: 0.63237 | val_1_rmse: 0.68281 |  0:00:13s
epoch 66 | loss: 0.38483 | val_0_rmse: 0.62654 | val_1_rmse: 0.68091 |  0:00:13s
epoch 67 | loss: 0.37445 | val_0_rmse: 0.62509 | val_1_rmse: 0.67768 |  0:00:13s
epoch 68 | loss: 0.38149 | val_0_rmse: 0.6298  | val_1_rmse: 0.67959 |  0:00:14s
epoch 69 | loss: 0.37269 | val_0_rmse: 0.63646 | val_1_rmse: 0.68713 |  0:00:14s
epoch 70 | loss: 0.39224 | val_0_rmse: 0.64208 | val_1_rmse: 0.70289 |  0:00:14s
epoch 71 | loss: 0.37109 | val_0_rmse: 0.62704 | val_1_rmse: 0.69264 |  0:00:14s
epoch 72 | loss: 0.366   | val_0_rmse: 0.62449 | val_1_rmse: 0.68397 |  0:00:14s
epoch 73 | loss: 0.36978 | val_0_rmse: 0.62217 | val_1_rmse: 0.67686 |  0:00:15s
epoch 74 | loss: 0.37433 | val_0_rmse: 0.62648 | val_1_rmse: 0.68624 |  0:00:15s
epoch 75 | loss: 0.37002 | val_0_rmse: 0.62707 | val_1_rmse: 0.6881  |  0:00:15s
epoch 76 | loss: 0.36427 | val_0_rmse: 0.62981 | val_1_rmse: 0.68275 |  0:00:15s
epoch 77 | loss: 0.36594 | val_0_rmse: 0.62415 | val_1_rmse: 0.67799 |  0:00:15s
epoch 78 | loss: 0.36147 | val_0_rmse: 0.61968 | val_1_rmse: 0.68141 |  0:00:16s
epoch 79 | loss: 0.37446 | val_0_rmse: 0.61579 | val_1_rmse: 0.6807  |  0:00:16s
epoch 80 | loss: 0.37251 | val_0_rmse: 0.61529 | val_1_rmse: 0.6898  |  0:00:16s
epoch 81 | loss: 0.37557 | val_0_rmse: 0.62258 | val_1_rmse: 0.70566 |  0:00:16s
epoch 82 | loss: 0.38043 | val_0_rmse: 0.62975 | val_1_rmse: 0.70917 |  0:00:16s
epoch 83 | loss: 0.37813 | val_0_rmse: 0.63453 | val_1_rmse: 0.70766 |  0:00:17s
epoch 84 | loss: 0.37424 | val_0_rmse: 0.63339 | val_1_rmse: 0.70404 |  0:00:17s
epoch 85 | loss: 0.39453 | val_0_rmse: 0.62916 | val_1_rmse: 0.69265 |  0:00:17s
epoch 86 | loss: 0.37648 | val_0_rmse: 0.63833 | val_1_rmse: 0.69204 |  0:00:17s
epoch 87 | loss: 0.36629 | val_0_rmse: 0.64041 | val_1_rmse: 0.68659 |  0:00:17s
epoch 88 | loss: 0.36798 | val_0_rmse: 0.6268  | val_1_rmse: 0.66687 |  0:00:18s
epoch 89 | loss: 0.36952 | val_0_rmse: 0.62562 | val_1_rmse: 0.67316 |  0:00:18s
epoch 90 | loss: 0.37517 | val_0_rmse: 0.63719 | val_1_rmse: 0.6875  |  0:00:18s
epoch 91 | loss: 0.37848 | val_0_rmse: 0.64192 | val_1_rmse: 0.67736 |  0:00:18s
epoch 92 | loss: 0.39492 | val_0_rmse: 0.62472 | val_1_rmse: 0.66724 |  0:00:18s
epoch 93 | loss: 0.37614 | val_0_rmse: 0.63208 | val_1_rmse: 0.66799 |  0:00:19s
epoch 94 | loss: 0.38246 | val_0_rmse: 0.62252 | val_1_rmse: 0.66154 |  0:00:19s
epoch 95 | loss: 0.37969 | val_0_rmse: 0.62055 | val_1_rmse: 0.67083 |  0:00:19s
epoch 96 | loss: 0.38673 | val_0_rmse: 0.62314 | val_1_rmse: 0.67215 |  0:00:19s
epoch 97 | loss: 0.38609 | val_0_rmse: 0.62772 | val_1_rmse: 0.67325 |  0:00:19s
epoch 98 | loss: 0.38581 | val_0_rmse: 0.62704 | val_1_rmse: 0.67647 |  0:00:20s
epoch 99 | loss: 0.38757 | val_0_rmse: 0.6255  | val_1_rmse: 0.67123 |  0:00:20s
epoch 100| loss: 0.38005 | val_0_rmse: 0.62731 | val_1_rmse: 0.67025 |  0:00:20s
epoch 101| loss: 0.37858 | val_0_rmse: 0.61951 | val_1_rmse: 0.66094 |  0:00:20s
epoch 102| loss: 0.37273 | val_0_rmse: 0.61921 | val_1_rmse: 0.66786 |  0:00:20s
epoch 103| loss: 0.37045 | val_0_rmse: 0.61058 | val_1_rmse: 0.65834 |  0:00:21s
epoch 104| loss: 0.3666  | val_0_rmse: 0.61293 | val_1_rmse: 0.66297 |  0:00:21s
epoch 105| loss: 0.38009 | val_0_rmse: 0.61466 | val_1_rmse: 0.68051 |  0:00:21s
epoch 106| loss: 0.37033 | val_0_rmse: 0.61913 | val_1_rmse: 0.69375 |  0:00:21s
epoch 107| loss: 0.37093 | val_0_rmse: 0.62157 | val_1_rmse: 0.68915 |  0:00:21s
epoch 108| loss: 0.37388 | val_0_rmse: 0.61864 | val_1_rmse: 0.67529 |  0:00:22s
epoch 109| loss: 0.37684 | val_0_rmse: 0.61923 | val_1_rmse: 0.68464 |  0:00:22s
epoch 110| loss: 0.3756  | val_0_rmse: 0.61971 | val_1_rmse: 0.68553 |  0:00:22s
epoch 111| loss: 0.36699 | val_0_rmse: 0.61999 | val_1_rmse: 0.68441 |  0:00:22s
epoch 112| loss: 0.37576 | val_0_rmse: 0.61153 | val_1_rmse: 0.68662 |  0:00:22s
epoch 113| loss: 0.37085 | val_0_rmse: 0.60358 | val_1_rmse: 0.67807 |  0:00:23s
epoch 114| loss: 0.37523 | val_0_rmse: 0.60763 | val_1_rmse: 0.67802 |  0:00:23s
epoch 115| loss: 0.36465 | val_0_rmse: 0.6036  | val_1_rmse: 0.68097 |  0:00:23s
epoch 116| loss: 0.3637  | val_0_rmse: 0.60941 | val_1_rmse: 0.68461 |  0:00:23s
epoch 117| loss: 0.37339 | val_0_rmse: 0.6109  | val_1_rmse: 0.68061 |  0:00:23s
epoch 118| loss: 0.36333 | val_0_rmse: 0.60435 | val_1_rmse: 0.67646 |  0:00:24s
epoch 119| loss: 0.36065 | val_0_rmse: 0.60345 | val_1_rmse: 0.67893 |  0:00:24s
epoch 120| loss: 0.36876 | val_0_rmse: 0.6026  | val_1_rmse: 0.67687 |  0:00:24s
epoch 121| loss: 0.36461 | val_0_rmse: 0.61378 | val_1_rmse: 0.67944 |  0:00:24s
epoch 122| loss: 0.36677 | val_0_rmse: 0.61142 | val_1_rmse: 0.67497 |  0:00:24s
epoch 123| loss: 0.37021 | val_0_rmse: 0.59723 | val_1_rmse: 0.66728 |  0:00:25s
epoch 124| loss: 0.36157 | val_0_rmse: 0.59495 | val_1_rmse: 0.66595 |  0:00:25s
epoch 125| loss: 0.36233 | val_0_rmse: 0.60115 | val_1_rmse: 0.66683 |  0:00:25s
epoch 126| loss: 0.36592 | val_0_rmse: 0.61512 | val_1_rmse: 0.67607 |  0:00:25s
epoch 127| loss: 0.36907 | val_0_rmse: 0.60122 | val_1_rmse: 0.67188 |  0:00:25s
epoch 128| loss: 0.36693 | val_0_rmse: 0.60507 | val_1_rmse: 0.68259 |  0:00:26s
epoch 129| loss: 0.35887 | val_0_rmse: 0.59693 | val_1_rmse: 0.66691 |  0:00:26s
epoch 130| loss: 0.36876 | val_0_rmse: 0.60055 | val_1_rmse: 0.67041 |  0:00:26s
epoch 131| loss: 0.36497 | val_0_rmse: 0.61558 | val_1_rmse: 0.67349 |  0:00:26s
epoch 132| loss: 0.37412 | val_0_rmse: 0.63083 | val_1_rmse: 0.6859  |  0:00:26s
epoch 133| loss: 0.37447 | val_0_rmse: 0.62142 | val_1_rmse: 0.67728 |  0:00:27s

Early stopping occured at epoch 133 with best_epoch = 103 and best_val_1_rmse = 0.65834
Best weights from best epoch are automatically used!
ended training at: 08:18:46
Feature importance:
Mean squared error is of 3272117149.195345
Mean absolute error:40983.006286753865
MAPE:0.38494818568580474
R2 score:0.5554379821679974
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 8
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:18:46
epoch 0  | loss: 2.0026  | val_0_rmse: 0.99911 | val_1_rmse: 1.03263 |  0:00:00s
epoch 1  | loss: 1.39094 | val_0_rmse: 0.9952  | val_1_rmse: 1.02974 |  0:00:00s
epoch 2  | loss: 1.15997 | val_0_rmse: 0.99687 | val_1_rmse: 1.00966 |  0:00:00s
epoch 3  | loss: 1.11363 | val_0_rmse: 1.00999 | val_1_rmse: 1.0098  |  0:00:00s
epoch 4  | loss: 0.91872 | val_0_rmse: 0.99076 | val_1_rmse: 1.00398 |  0:00:01s
epoch 5  | loss: 0.7655  | val_0_rmse: 0.956   | val_1_rmse: 0.95784 |  0:00:01s
epoch 6  | loss: 0.7775  | val_0_rmse: 0.94205 | val_1_rmse: 0.89127 |  0:00:01s
epoch 7  | loss: 0.73959 | val_0_rmse: 0.8474  | val_1_rmse: 0.87485 |  0:00:01s
epoch 8  | loss: 0.62187 | val_0_rmse: 0.83932 | val_1_rmse: 0.87141 |  0:00:01s
epoch 9  | loss: 0.57133 | val_0_rmse: 0.80572 | val_1_rmse: 0.82407 |  0:00:02s
epoch 10 | loss: 0.54931 | val_0_rmse: 0.75738 | val_1_rmse: 0.76719 |  0:00:02s
epoch 11 | loss: 0.53238 | val_0_rmse: 0.71309 | val_1_rmse: 0.72282 |  0:00:02s
epoch 12 | loss: 0.51638 | val_0_rmse: 0.70264 | val_1_rmse: 0.71434 |  0:00:02s
epoch 13 | loss: 0.48034 | val_0_rmse: 0.72542 | val_1_rmse: 0.74046 |  0:00:02s
epoch 14 | loss: 0.49796 | val_0_rmse: 0.73982 | val_1_rmse: 0.76004 |  0:00:03s
epoch 15 | loss: 0.4595  | val_0_rmse: 0.72299 | val_1_rmse: 0.74888 |  0:00:03s
epoch 16 | loss: 0.47163 | val_0_rmse: 0.72989 | val_1_rmse: 0.76222 |  0:00:03s
epoch 17 | loss: 0.44364 | val_0_rmse: 0.71344 | val_1_rmse: 0.75396 |  0:00:03s
epoch 18 | loss: 0.46195 | val_0_rmse: 0.69991 | val_1_rmse: 0.7468  |  0:00:03s
epoch 19 | loss: 0.44809 | val_0_rmse: 0.72574 | val_1_rmse: 0.7836  |  0:00:04s
epoch 20 | loss: 0.45181 | val_0_rmse: 0.70269 | val_1_rmse: 0.75645 |  0:00:04s
epoch 21 | loss: 0.43497 | val_0_rmse: 0.66918 | val_1_rmse: 0.7274  |  0:00:04s
epoch 22 | loss: 0.42574 | val_0_rmse: 0.67512 | val_1_rmse: 0.74698 |  0:00:04s
epoch 23 | loss: 0.42143 | val_0_rmse: 0.6836  | val_1_rmse: 0.75262 |  0:00:04s
epoch 24 | loss: 0.41951 | val_0_rmse: 0.67099 | val_1_rmse: 0.74006 |  0:00:05s
epoch 25 | loss: 0.4437  | val_0_rmse: 0.65677 | val_1_rmse: 0.72337 |  0:00:05s
epoch 26 | loss: 0.44212 | val_0_rmse: 0.68267 | val_1_rmse: 0.73816 |  0:00:05s
epoch 27 | loss: 0.42672 | val_0_rmse: 0.68186 | val_1_rmse: 0.72725 |  0:00:05s
epoch 28 | loss: 0.42724 | val_0_rmse: 0.68563 | val_1_rmse: 0.71932 |  0:00:05s
epoch 29 | loss: 0.44028 | val_0_rmse: 0.69323 | val_1_rmse: 0.72049 |  0:00:06s
epoch 30 | loss: 0.44013 | val_0_rmse: 0.7131  | val_1_rmse: 0.74919 |  0:00:06s
epoch 31 | loss: 0.43145 | val_0_rmse: 0.68017 | val_1_rmse: 0.71353 |  0:00:06s
epoch 32 | loss: 0.43917 | val_0_rmse: 0.67972 | val_1_rmse: 0.71911 |  0:00:06s
epoch 33 | loss: 0.41135 | val_0_rmse: 0.68957 | val_1_rmse: 0.73623 |  0:00:06s
epoch 34 | loss: 0.4148  | val_0_rmse: 0.67031 | val_1_rmse: 0.71896 |  0:00:07s
epoch 35 | loss: 0.40899 | val_0_rmse: 0.66266 | val_1_rmse: 0.70568 |  0:00:07s
epoch 36 | loss: 0.40325 | val_0_rmse: 0.66902 | val_1_rmse: 0.71126 |  0:00:07s
epoch 37 | loss: 0.39746 | val_0_rmse: 0.69942 | val_1_rmse: 0.74037 |  0:00:07s
epoch 38 | loss: 0.40037 | val_0_rmse: 0.68982 | val_1_rmse: 0.74471 |  0:00:07s
epoch 39 | loss: 0.39389 | val_0_rmse: 0.67839 | val_1_rmse: 0.73824 |  0:00:08s
epoch 40 | loss: 0.3911  | val_0_rmse: 0.69902 | val_1_rmse: 0.75833 |  0:00:08s
epoch 41 | loss: 0.40468 | val_0_rmse: 0.7143  | val_1_rmse: 0.77778 |  0:00:08s
epoch 42 | loss: 0.39368 | val_0_rmse: 0.66384 | val_1_rmse: 0.72133 |  0:00:08s
epoch 43 | loss: 0.39401 | val_0_rmse: 0.65541 | val_1_rmse: 0.70278 |  0:00:09s
epoch 44 | loss: 0.3854  | val_0_rmse: 0.67394 | val_1_rmse: 0.72023 |  0:00:09s
epoch 45 | loss: 0.41111 | val_0_rmse: 0.69693 | val_1_rmse: 0.74523 |  0:00:09s
epoch 46 | loss: 0.38232 | val_0_rmse: 0.65035 | val_1_rmse: 0.69553 |  0:00:09s
epoch 47 | loss: 0.38835 | val_0_rmse: 0.62927 | val_1_rmse: 0.67234 |  0:00:09s
epoch 48 | loss: 0.40674 | val_0_rmse: 0.6355  | val_1_rmse: 0.67846 |  0:00:10s
epoch 49 | loss: 0.40267 | val_0_rmse: 0.65467 | val_1_rmse: 0.70604 |  0:00:10s
epoch 50 | loss: 0.39409 | val_0_rmse: 0.65066 | val_1_rmse: 0.70294 |  0:00:10s
epoch 51 | loss: 0.38026 | val_0_rmse: 0.64513 | val_1_rmse: 0.69648 |  0:00:10s
epoch 52 | loss: 0.39182 | val_0_rmse: 0.66027 | val_1_rmse: 0.71552 |  0:00:10s
epoch 53 | loss: 0.39335 | val_0_rmse: 0.68554 | val_1_rmse: 0.7453  |  0:00:11s
epoch 54 | loss: 0.40415 | val_0_rmse: 0.68526 | val_1_rmse: 0.75063 |  0:00:11s
epoch 55 | loss: 0.41312 | val_0_rmse: 0.67306 | val_1_rmse: 0.73725 |  0:00:11s
epoch 56 | loss: 0.39982 | val_0_rmse: 0.65861 | val_1_rmse: 0.72477 |  0:00:11s
epoch 57 | loss: 0.38515 | val_0_rmse: 0.64818 | val_1_rmse: 0.69856 |  0:00:11s
epoch 58 | loss: 0.39915 | val_0_rmse: 0.64339 | val_1_rmse: 0.69243 |  0:00:12s
epoch 59 | loss: 0.40998 | val_0_rmse: 0.63711 | val_1_rmse: 0.68331 |  0:00:12s
epoch 60 | loss: 0.40768 | val_0_rmse: 0.63441 | val_1_rmse: 0.68418 |  0:00:12s
epoch 61 | loss: 0.41396 | val_0_rmse: 0.63722 | val_1_rmse: 0.68899 |  0:00:12s
epoch 62 | loss: 0.41391 | val_0_rmse: 0.64944 | val_1_rmse: 0.70372 |  0:00:12s
epoch 63 | loss: 0.4151  | val_0_rmse: 0.63617 | val_1_rmse: 0.69559 |  0:00:12s
epoch 64 | loss: 0.40394 | val_0_rmse: 0.6183  | val_1_rmse: 0.68556 |  0:00:13s
epoch 65 | loss: 0.39698 | val_0_rmse: 0.62354 | val_1_rmse: 0.68932 |  0:00:13s
epoch 66 | loss: 0.38856 | val_0_rmse: 0.64017 | val_1_rmse: 0.70064 |  0:00:13s
epoch 67 | loss: 0.37381 | val_0_rmse: 0.62587 | val_1_rmse: 0.68628 |  0:00:13s
epoch 68 | loss: 0.38272 | val_0_rmse: 0.61462 | val_1_rmse: 0.67071 |  0:00:13s
epoch 69 | loss: 0.387   | val_0_rmse: 0.61516 | val_1_rmse: 0.66316 |  0:00:14s
epoch 70 | loss: 0.39398 | val_0_rmse: 0.63176 | val_1_rmse: 0.67568 |  0:00:14s
epoch 71 | loss: 0.39007 | val_0_rmse: 0.64015 | val_1_rmse: 0.6819  |  0:00:14s
epoch 72 | loss: 0.38724 | val_0_rmse: 0.63473 | val_1_rmse: 0.67762 |  0:00:14s
epoch 73 | loss: 0.39842 | val_0_rmse: 0.6256  | val_1_rmse: 0.67254 |  0:00:14s
epoch 74 | loss: 0.38834 | val_0_rmse: 0.617   | val_1_rmse: 0.66362 |  0:00:15s
epoch 75 | loss: 0.37807 | val_0_rmse: 0.61988 | val_1_rmse: 0.66749 |  0:00:15s
epoch 76 | loss: 0.37802 | val_0_rmse: 0.61603 | val_1_rmse: 0.67083 |  0:00:15s
epoch 77 | loss: 0.37186 | val_0_rmse: 0.6167  | val_1_rmse: 0.67632 |  0:00:15s
epoch 78 | loss: 0.37519 | val_0_rmse: 0.62245 | val_1_rmse: 0.68333 |  0:00:15s
epoch 79 | loss: 0.3701  | val_0_rmse: 0.63552 | val_1_rmse: 0.69431 |  0:00:16s
epoch 80 | loss: 0.37191 | val_0_rmse: 0.65195 | val_1_rmse: 0.71197 |  0:00:16s
epoch 81 | loss: 0.36796 | val_0_rmse: 0.63407 | val_1_rmse: 0.6929  |  0:00:16s
epoch 82 | loss: 0.37022 | val_0_rmse: 0.60702 | val_1_rmse: 0.66115 |  0:00:16s
epoch 83 | loss: 0.37624 | val_0_rmse: 0.61077 | val_1_rmse: 0.6595  |  0:00:16s
epoch 84 | loss: 0.37433 | val_0_rmse: 0.61751 | val_1_rmse: 0.66071 |  0:00:17s
epoch 85 | loss: 0.37076 | val_0_rmse: 0.62488 | val_1_rmse: 0.66977 |  0:00:17s
epoch 86 | loss: 0.37755 | val_0_rmse: 0.61775 | val_1_rmse: 0.66328 |  0:00:17s
epoch 87 | loss: 0.37577 | val_0_rmse: 0.60623 | val_1_rmse: 0.64986 |  0:00:17s
epoch 88 | loss: 0.36828 | val_0_rmse: 0.60466 | val_1_rmse: 0.65282 |  0:00:18s
epoch 89 | loss: 0.36046 | val_0_rmse: 0.61024 | val_1_rmse: 0.66435 |  0:00:18s
epoch 90 | loss: 0.36929 | val_0_rmse: 0.61223 | val_1_rmse: 0.67142 |  0:00:18s
epoch 91 | loss: 0.35759 | val_0_rmse: 0.61476 | val_1_rmse: 0.6709  |  0:00:18s
epoch 92 | loss: 0.35652 | val_0_rmse: 0.62599 | val_1_rmse: 0.68099 |  0:00:18s
epoch 93 | loss: 0.35908 | val_0_rmse: 0.64182 | val_1_rmse: 0.69927 |  0:00:19s
epoch 94 | loss: 0.36721 | val_0_rmse: 0.63267 | val_1_rmse: 0.69606 |  0:00:19s
epoch 95 | loss: 0.36239 | val_0_rmse: 0.62481 | val_1_rmse: 0.67578 |  0:00:19s
epoch 96 | loss: 0.36438 | val_0_rmse: 0.60892 | val_1_rmse: 0.65745 |  0:00:19s
epoch 97 | loss: 0.36047 | val_0_rmse: 0.5996  | val_1_rmse: 0.65246 |  0:00:19s
epoch 98 | loss: 0.36154 | val_0_rmse: 0.61189 | val_1_rmse: 0.66639 |  0:00:20s
epoch 99 | loss: 0.35486 | val_0_rmse: 0.61575 | val_1_rmse: 0.67521 |  0:00:20s
epoch 100| loss: 0.35204 | val_0_rmse: 0.61361 | val_1_rmse: 0.67656 |  0:00:20s
epoch 101| loss: 0.35759 | val_0_rmse: 0.6109  | val_1_rmse: 0.67695 |  0:00:20s
epoch 102| loss: 0.35313 | val_0_rmse: 0.60148 | val_1_rmse: 0.66229 |  0:00:20s
epoch 103| loss: 0.3585  | val_0_rmse: 0.60292 | val_1_rmse: 0.66258 |  0:00:21s
epoch 104| loss: 0.35286 | val_0_rmse: 0.60103 | val_1_rmse: 0.66224 |  0:00:21s
epoch 105| loss: 0.35879 | val_0_rmse: 0.59435 | val_1_rmse: 0.65446 |  0:00:21s
epoch 106| loss: 0.35825 | val_0_rmse: 0.60128 | val_1_rmse: 0.65936 |  0:00:21s
epoch 107| loss: 0.35727 | val_0_rmse: 0.60225 | val_1_rmse: 0.65426 |  0:00:21s
epoch 108| loss: 0.35264 | val_0_rmse: 0.63549 | val_1_rmse: 0.66478 |  0:00:22s
epoch 109| loss: 0.37808 | val_0_rmse: 0.63199 | val_1_rmse: 0.66385 |  0:00:22s
epoch 110| loss: 0.371   | val_0_rmse: 0.62182 | val_1_rmse: 0.67473 |  0:00:22s
epoch 111| loss: 0.37828 | val_0_rmse: 0.62879 | val_1_rmse: 0.68842 |  0:00:22s
epoch 112| loss: 0.37308 | val_0_rmse: 0.61587 | val_1_rmse: 0.66862 |  0:00:22s
epoch 113| loss: 0.37203 | val_0_rmse: 0.60892 | val_1_rmse: 0.66269 |  0:00:23s
epoch 114| loss: 0.36754 | val_0_rmse: 0.6031  | val_1_rmse: 0.66709 |  0:00:23s
epoch 115| loss: 0.37881 | val_0_rmse: 0.60604 | val_1_rmse: 0.67276 |  0:00:23s
epoch 116| loss: 0.37774 | val_0_rmse: 0.61216 | val_1_rmse: 0.68393 |  0:00:23s
epoch 117| loss: 0.3626  | val_0_rmse: 0.62966 | val_1_rmse: 0.68986 |  0:00:23s

Early stopping occured at epoch 117 with best_epoch = 87 and best_val_1_rmse = 0.64986
Best weights from best epoch are automatically used!
ended training at: 08:19:10
Feature importance:
Mean squared error is of 3392864493.6571846
Mean absolute error:42712.494727521924
MAPE:0.39799207302403405
R2 score:0.5126971378699604
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: pe properties.csv
Using seed = 9
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:19:10
epoch 0  | loss: 2.18695 | val_0_rmse: 1.03502 | val_1_rmse: 1.10201 |  0:00:00s
epoch 1  | loss: 1.38892 | val_0_rmse: 1.00062 | val_1_rmse: 1.06142 |  0:00:00s
epoch 2  | loss: 1.31592 | val_0_rmse: 1.00096 | val_1_rmse: 1.06234 |  0:00:00s
epoch 3  | loss: 1.1481  | val_0_rmse: 0.99577 | val_1_rmse: 1.06064 |  0:00:00s
epoch 4  | loss: 1.00885 | val_0_rmse: 0.98794 | val_1_rmse: 1.05751 |  0:00:01s
epoch 5  | loss: 0.90564 | val_0_rmse: 0.97289 | val_1_rmse: 1.05031 |  0:00:01s
epoch 6  | loss: 0.87385 | val_0_rmse: 0.96656 | val_1_rmse: 1.0442  |  0:00:01s
epoch 7  | loss: 0.76801 | val_0_rmse: 0.92317 | val_1_rmse: 1.00577 |  0:00:01s
epoch 8  | loss: 0.72112 | val_0_rmse: 0.92538 | val_1_rmse: 1.00012 |  0:00:01s
epoch 9  | loss: 0.66782 | val_0_rmse: 0.86399 | val_1_rmse: 0.94234 |  0:00:02s
epoch 10 | loss: 0.61186 | val_0_rmse: 0.83443 | val_1_rmse: 0.90405 |  0:00:02s
epoch 11 | loss: 0.58656 | val_0_rmse: 0.80826 | val_1_rmse: 0.88003 |  0:00:02s
epoch 12 | loss: 0.56146 | val_0_rmse: 0.77356 | val_1_rmse: 0.84872 |  0:00:02s
epoch 13 | loss: 0.54819 | val_0_rmse: 0.77744 | val_1_rmse: 0.84895 |  0:00:02s
epoch 14 | loss: 0.552   | val_0_rmse: 0.78628 | val_1_rmse: 0.85841 |  0:00:03s
epoch 15 | loss: 0.57416 | val_0_rmse: 0.76976 | val_1_rmse: 0.85472 |  0:00:03s
epoch 16 | loss: 0.51137 | val_0_rmse: 0.83391 | val_1_rmse: 0.91015 |  0:00:03s
epoch 17 | loss: 0.48467 | val_0_rmse: 0.78548 | val_1_rmse: 0.85757 |  0:00:03s
epoch 18 | loss: 0.47307 | val_0_rmse: 0.81539 | val_1_rmse: 0.87148 |  0:00:03s
epoch 19 | loss: 0.47204 | val_0_rmse: 0.84606 | val_1_rmse: 0.9042  |  0:00:04s
epoch 20 | loss: 0.4838  | val_0_rmse: 0.78093 | val_1_rmse: 0.82323 |  0:00:04s
epoch 21 | loss: 0.46468 | val_0_rmse: 0.76618 | val_1_rmse: 0.80237 |  0:00:04s
epoch 22 | loss: 0.44104 | val_0_rmse: 0.81551 | val_1_rmse: 0.85084 |  0:00:04s
epoch 23 | loss: 0.45406 | val_0_rmse: 0.75379 | val_1_rmse: 0.79117 |  0:00:04s
epoch 24 | loss: 0.43926 | val_0_rmse: 0.7391  | val_1_rmse: 0.77386 |  0:00:05s
epoch 25 | loss: 0.44327 | val_0_rmse: 0.75594 | val_1_rmse: 0.78933 |  0:00:05s
epoch 26 | loss: 0.45098 | val_0_rmse: 0.75395 | val_1_rmse: 0.78603 |  0:00:05s
epoch 27 | loss: 0.43081 | val_0_rmse: 0.71674 | val_1_rmse: 0.75133 |  0:00:05s
epoch 28 | loss: 0.43177 | val_0_rmse: 0.72967 | val_1_rmse: 0.76906 |  0:00:06s
epoch 29 | loss: 0.43325 | val_0_rmse: 0.73863 | val_1_rmse: 0.77947 |  0:00:06s
epoch 30 | loss: 0.4201  | val_0_rmse: 0.72301 | val_1_rmse: 0.76825 |  0:00:06s
epoch 31 | loss: 0.40961 | val_0_rmse: 0.71702 | val_1_rmse: 0.76689 |  0:00:06s
epoch 32 | loss: 0.41522 | val_0_rmse: 0.74214 | val_1_rmse: 0.78919 |  0:00:06s
epoch 33 | loss: 0.41937 | val_0_rmse: 0.78183 | val_1_rmse: 0.82266 |  0:00:07s
epoch 34 | loss: 0.4042  | val_0_rmse: 0.76428 | val_1_rmse: 0.80633 |  0:00:07s
epoch 35 | loss: 0.40384 | val_0_rmse: 0.72001 | val_1_rmse: 0.77136 |  0:00:07s
epoch 36 | loss: 0.41055 | val_0_rmse: 0.73677 | val_1_rmse: 0.7943  |  0:00:07s
epoch 37 | loss: 0.40276 | val_0_rmse: 0.73926 | val_1_rmse: 0.78954 |  0:00:07s
epoch 38 | loss: 0.39591 | val_0_rmse: 0.7042  | val_1_rmse: 0.75589 |  0:00:08s
epoch 39 | loss: 0.4128  | val_0_rmse: 0.68677 | val_1_rmse: 0.73345 |  0:00:08s
epoch 40 | loss: 0.39247 | val_0_rmse: 0.68123 | val_1_rmse: 0.72001 |  0:00:08s
epoch 41 | loss: 0.41081 | val_0_rmse: 0.66304 | val_1_rmse: 0.69134 |  0:00:08s
epoch 42 | loss: 0.39344 | val_0_rmse: 0.66239 | val_1_rmse: 0.69412 |  0:00:08s
epoch 43 | loss: 0.40567 | val_0_rmse: 0.6722  | val_1_rmse: 0.7099  |  0:00:09s
epoch 44 | loss: 0.38289 | val_0_rmse: 0.67355 | val_1_rmse: 0.71717 |  0:00:09s
epoch 45 | loss: 0.39824 | val_0_rmse: 0.666   | val_1_rmse: 0.71638 |  0:00:09s
epoch 46 | loss: 0.40131 | val_0_rmse: 0.66859 | val_1_rmse: 0.71534 |  0:00:09s
epoch 47 | loss: 0.39002 | val_0_rmse: 0.68315 | val_1_rmse: 0.72711 |  0:00:09s
epoch 48 | loss: 0.40051 | val_0_rmse: 0.67951 | val_1_rmse: 0.725   |  0:00:10s
epoch 49 | loss: 0.39452 | val_0_rmse: 0.66851 | val_1_rmse: 0.72474 |  0:00:10s
epoch 50 | loss: 0.37863 | val_0_rmse: 0.65646 | val_1_rmse: 0.71401 |  0:00:10s
epoch 51 | loss: 0.3875  | val_0_rmse: 0.65204 | val_1_rmse: 0.70736 |  0:00:10s
epoch 52 | loss: 0.38256 | val_0_rmse: 0.65067 | val_1_rmse: 0.70144 |  0:00:10s
epoch 53 | loss: 0.39364 | val_0_rmse: 0.64644 | val_1_rmse: 0.69393 |  0:00:11s
epoch 54 | loss: 0.38077 | val_0_rmse: 0.64407 | val_1_rmse: 0.68758 |  0:00:11s
epoch 55 | loss: 0.38111 | val_0_rmse: 0.64787 | val_1_rmse: 0.68684 |  0:00:11s
epoch 56 | loss: 0.38148 | val_0_rmse: 0.65011 | val_1_rmse: 0.68727 |  0:00:11s
epoch 57 | loss: 0.36961 | val_0_rmse: 0.64257 | val_1_rmse: 0.6849  |  0:00:11s
epoch 58 | loss: 0.37382 | val_0_rmse: 0.64045 | val_1_rmse: 0.69232 |  0:00:12s
epoch 59 | loss: 0.37559 | val_0_rmse: 0.65503 | val_1_rmse: 0.70626 |  0:00:12s
epoch 60 | loss: 0.37397 | val_0_rmse: 0.66257 | val_1_rmse: 0.71179 |  0:00:12s
epoch 61 | loss: 0.38128 | val_0_rmse: 0.64632 | val_1_rmse: 0.69292 |  0:00:12s
epoch 62 | loss: 0.36669 | val_0_rmse: 0.64661 | val_1_rmse: 0.69507 |  0:00:12s
epoch 63 | loss: 0.37165 | val_0_rmse: 0.6605  | val_1_rmse: 0.7082  |  0:00:13s
epoch 64 | loss: 0.37128 | val_0_rmse: 0.6632  | val_1_rmse: 0.70761 |  0:00:13s
epoch 65 | loss: 0.37295 | val_0_rmse: 0.63723 | val_1_rmse: 0.6811  |  0:00:13s
epoch 66 | loss: 0.37002 | val_0_rmse: 0.63467 | val_1_rmse: 0.67926 |  0:00:13s
epoch 67 | loss: 0.35845 | val_0_rmse: 0.65067 | val_1_rmse: 0.68632 |  0:00:13s
epoch 68 | loss: 0.37757 | val_0_rmse: 0.65063 | val_1_rmse: 0.67866 |  0:00:14s
epoch 69 | loss: 0.37656 | val_0_rmse: 0.64384 | val_1_rmse: 0.67967 |  0:00:14s
epoch 70 | loss: 0.37083 | val_0_rmse: 0.64079 | val_1_rmse: 0.68429 |  0:00:14s
epoch 71 | loss: 0.3596  | val_0_rmse: 0.63945 | val_1_rmse: 0.68384 |  0:00:14s
epoch 72 | loss: 0.36331 | val_0_rmse: 0.6448  | val_1_rmse: 0.69396 |  0:00:14s
epoch 73 | loss: 0.37057 | val_0_rmse: 0.65606 | val_1_rmse: 0.69826 |  0:00:15s
epoch 74 | loss: 0.36322 | val_0_rmse: 0.64862 | val_1_rmse: 0.68733 |  0:00:15s
epoch 75 | loss: 0.36626 | val_0_rmse: 0.63932 | val_1_rmse: 0.67688 |  0:00:15s
epoch 76 | loss: 0.35549 | val_0_rmse: 0.6344  | val_1_rmse: 0.68194 |  0:00:15s
epoch 77 | loss: 0.3611  | val_0_rmse: 0.64292 | val_1_rmse: 0.68623 |  0:00:15s
epoch 78 | loss: 0.36497 | val_0_rmse: 0.64276 | val_1_rmse: 0.68387 |  0:00:16s
epoch 79 | loss: 0.38094 | val_0_rmse: 0.6354  | val_1_rmse: 0.67933 |  0:00:16s
epoch 80 | loss: 0.37351 | val_0_rmse: 0.63106 | val_1_rmse: 0.6742  |  0:00:16s
epoch 81 | loss: 0.37552 | val_0_rmse: 0.63159 | val_1_rmse: 0.6748  |  0:00:16s
epoch 82 | loss: 0.38558 | val_0_rmse: 0.63077 | val_1_rmse: 0.67398 |  0:00:16s
epoch 83 | loss: 0.38534 | val_0_rmse: 0.62805 | val_1_rmse: 0.66882 |  0:00:17s
epoch 84 | loss: 0.37699 | val_0_rmse: 0.62343 | val_1_rmse: 0.66073 |  0:00:17s
epoch 85 | loss: 0.37233 | val_0_rmse: 0.62325 | val_1_rmse: 0.66418 |  0:00:17s
epoch 86 | loss: 0.37109 | val_0_rmse: 0.62623 | val_1_rmse: 0.67163 |  0:00:17s
epoch 87 | loss: 0.36293 | val_0_rmse: 0.62472 | val_1_rmse: 0.67474 |  0:00:18s
epoch 88 | loss: 0.37705 | val_0_rmse: 0.61776 | val_1_rmse: 0.67648 |  0:00:18s
epoch 89 | loss: 0.35535 | val_0_rmse: 0.62434 | val_1_rmse: 0.69257 |  0:00:18s
epoch 90 | loss: 0.37172 | val_0_rmse: 0.62953 | val_1_rmse: 0.69179 |  0:00:18s
epoch 91 | loss: 0.38821 | val_0_rmse: 0.63009 | val_1_rmse: 0.6882  |  0:00:18s
epoch 92 | loss: 0.3658  | val_0_rmse: 0.62567 | val_1_rmse: 0.68063 |  0:00:19s
epoch 93 | loss: 0.37289 | val_0_rmse: 0.61524 | val_1_rmse: 0.6631  |  0:00:19s
epoch 94 | loss: 0.36817 | val_0_rmse: 0.61961 | val_1_rmse: 0.66234 |  0:00:19s
epoch 95 | loss: 0.3772  | val_0_rmse: 0.62205 | val_1_rmse: 0.66254 |  0:00:19s
epoch 96 | loss: 0.37749 | val_0_rmse: 0.62192 | val_1_rmse: 0.6617  |  0:00:19s
epoch 97 | loss: 0.37406 | val_0_rmse: 0.62013 | val_1_rmse: 0.65782 |  0:00:20s
epoch 98 | loss: 0.36687 | val_0_rmse: 0.61945 | val_1_rmse: 0.6526  |  0:00:20s
epoch 99 | loss: 0.36979 | val_0_rmse: 0.6167  | val_1_rmse: 0.6456  |  0:00:20s
epoch 100| loss: 0.36833 | val_0_rmse: 0.61031 | val_1_rmse: 0.64129 |  0:00:20s
epoch 101| loss: 0.36821 | val_0_rmse: 0.61055 | val_1_rmse: 0.64832 |  0:00:20s
epoch 102| loss: 0.37567 | val_0_rmse: 0.63324 | val_1_rmse: 0.67413 |  0:00:21s
epoch 103| loss: 0.39398 | val_0_rmse: 0.64757 | val_1_rmse: 0.69518 |  0:00:21s
epoch 104| loss: 0.38972 | val_0_rmse: 0.63761 | val_1_rmse: 0.68403 |  0:00:21s
epoch 105| loss: 0.38943 | val_0_rmse: 0.63056 | val_1_rmse: 0.67745 |  0:00:21s
epoch 106| loss: 0.38076 | val_0_rmse: 0.64036 | val_1_rmse: 0.69337 |  0:00:21s
epoch 107| loss: 0.362   | val_0_rmse: 0.64012 | val_1_rmse: 0.69109 |  0:00:22s
epoch 108| loss: 0.3726  | val_0_rmse: 0.62564 | val_1_rmse: 0.67505 |  0:00:22s
epoch 109| loss: 0.3771  | val_0_rmse: 0.62053 | val_1_rmse: 0.68481 |  0:00:22s
epoch 110| loss: 0.35162 | val_0_rmse: 0.62846 | val_1_rmse: 0.69449 |  0:00:22s
epoch 111| loss: 0.3581  | val_0_rmse: 0.63038 | val_1_rmse: 0.69713 |  0:00:22s
epoch 112| loss: 0.36164 | val_0_rmse: 0.61709 | val_1_rmse: 0.68826 |  0:00:23s
epoch 113| loss: 0.36401 | val_0_rmse: 0.61711 | val_1_rmse: 0.68643 |  0:00:23s
epoch 114| loss: 0.36468 | val_0_rmse: 0.61012 | val_1_rmse: 0.67498 |  0:00:23s
epoch 115| loss: 0.35596 | val_0_rmse: 0.6036  | val_1_rmse: 0.66832 |  0:00:23s
epoch 116| loss: 0.35178 | val_0_rmse: 0.59853 | val_1_rmse: 0.66391 |  0:00:23s
epoch 117| loss: 0.34851 | val_0_rmse: 0.60068 | val_1_rmse: 0.67041 |  0:00:24s
epoch 118| loss: 0.35013 | val_0_rmse: 0.6047  | val_1_rmse: 0.67316 |  0:00:24s
epoch 119| loss: 0.34905 | val_0_rmse: 0.5961  | val_1_rmse: 0.66261 |  0:00:24s
epoch 120| loss: 0.34844 | val_0_rmse: 0.59816 | val_1_rmse: 0.66441 |  0:00:24s
epoch 121| loss: 0.34281 | val_0_rmse: 0.59995 | val_1_rmse: 0.66396 |  0:00:24s
epoch 122| loss: 0.34913 | val_0_rmse: 0.60236 | val_1_rmse: 0.66739 |  0:00:25s
epoch 123| loss: 0.34203 | val_0_rmse: 0.59331 | val_1_rmse: 0.65962 |  0:00:25s
epoch 124| loss: 0.35076 | val_0_rmse: 0.59223 | val_1_rmse: 0.66055 |  0:00:25s
epoch 125| loss: 0.34027 | val_0_rmse: 0.59853 | val_1_rmse: 0.66379 |  0:00:25s
epoch 126| loss: 0.35074 | val_0_rmse: 0.60078 | val_1_rmse: 0.66413 |  0:00:25s
epoch 127| loss: 0.35595 | val_0_rmse: 0.5906  | val_1_rmse: 0.65699 |  0:00:26s
epoch 128| loss: 0.34097 | val_0_rmse: 0.59715 | val_1_rmse: 0.66117 |  0:00:26s
epoch 129| loss: 0.35002 | val_0_rmse: 0.60002 | val_1_rmse: 0.66267 |  0:00:26s
epoch 130| loss: 0.35117 | val_0_rmse: 0.6085  | val_1_rmse: 0.67702 |  0:00:26s

Early stopping occured at epoch 130 with best_epoch = 100 and best_val_1_rmse = 0.64129
Best weights from best epoch are automatically used!
ended training at: 08:19:36
Feature importance:
Mean squared error is of 2878931059.5482597
Mean absolute error:39751.02755838816
MAPE:0.3663791641994339
R2 score:0.5452500639017166
------------------------------------------------------------------
Normalization used is StandardScaler
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 0
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:19:37
epoch 0  | loss: 1.44107 | val_0_rmse: 1.00507 | val_1_rmse: 1.02805 |  0:00:00s
epoch 1  | loss: 1.03171 | val_0_rmse: 0.98329 | val_1_rmse: 1.00631 |  0:00:00s
epoch 2  | loss: 0.80258 | val_0_rmse: 0.83657 | val_1_rmse: 0.86941 |  0:00:01s
epoch 3  | loss: 0.59617 | val_0_rmse: 0.74938 | val_1_rmse: 0.76647 |  0:00:01s
epoch 4  | loss: 0.54976 | val_0_rmse: 0.7167  | val_1_rmse: 0.75183 |  0:00:02s
epoch 5  | loss: 0.51677 | val_0_rmse: 0.75848 | val_1_rmse: 0.80591 |  0:00:02s
epoch 6  | loss: 0.4814  | val_0_rmse: 0.68174 | val_1_rmse: 0.70201 |  0:00:03s
epoch 7  | loss: 0.46726 | val_0_rmse: 0.72435 | val_1_rmse: 0.74232 |  0:00:03s
epoch 8  | loss: 0.44756 | val_0_rmse: 0.69456 | val_1_rmse: 0.71851 |  0:00:04s
epoch 9  | loss: 0.44755 | val_0_rmse: 0.75512 | val_1_rmse: 0.7525  |  0:00:04s
epoch 10 | loss: 0.43472 | val_0_rmse: 0.68446 | val_1_rmse: 0.69443 |  0:00:05s
epoch 11 | loss: 0.41579 | val_0_rmse: 0.68481 | val_1_rmse: 0.68683 |  0:00:05s
epoch 12 | loss: 0.40254 | val_0_rmse: 0.67099 | val_1_rmse: 0.67955 |  0:00:05s
epoch 13 | loss: 0.3915  | val_0_rmse: 0.65846 | val_1_rmse: 0.66646 |  0:00:06s
epoch 14 | loss: 0.38497 | val_0_rmse: 0.67224 | val_1_rmse: 0.68739 |  0:00:06s
epoch 15 | loss: 0.38097 | val_0_rmse: 0.68939 | val_1_rmse: 0.69472 |  0:00:07s
epoch 16 | loss: 0.3839  | val_0_rmse: 0.63994 | val_1_rmse: 0.64663 |  0:00:07s
epoch 17 | loss: 0.37864 | val_0_rmse: 0.65591 | val_1_rmse: 0.65559 |  0:00:08s
epoch 18 | loss: 0.372   | val_0_rmse: 0.62475 | val_1_rmse: 0.63097 |  0:00:08s
epoch 19 | loss: 0.37323 | val_0_rmse: 0.66846 | val_1_rmse: 0.69173 |  0:00:09s
epoch 20 | loss: 0.3859  | val_0_rmse: 0.65052 | val_1_rmse: 0.65528 |  0:00:09s
epoch 21 | loss: 0.38251 | val_0_rmse: 0.65504 | val_1_rmse: 0.66253 |  0:00:10s
epoch 22 | loss: 0.37118 | val_0_rmse: 0.65648 | val_1_rmse: 0.67116 |  0:00:10s
epoch 23 | loss: 0.35212 | val_0_rmse: 0.64186 | val_1_rmse: 0.65936 |  0:00:11s
epoch 24 | loss: 0.34201 | val_0_rmse: 0.65916 | val_1_rmse: 0.66395 |  0:00:11s
epoch 25 | loss: 0.35993 | val_0_rmse: 0.63405 | val_1_rmse: 0.6405  |  0:00:11s
epoch 26 | loss: 0.35966 | val_0_rmse: 0.6306  | val_1_rmse: 0.64098 |  0:00:12s
epoch 27 | loss: 0.33789 | val_0_rmse: 0.62856 | val_1_rmse: 0.64359 |  0:00:12s
epoch 28 | loss: 0.33207 | val_0_rmse: 0.63219 | val_1_rmse: 0.65411 |  0:00:13s
epoch 29 | loss: 0.33255 | val_0_rmse: 0.65147 | val_1_rmse: 0.67345 |  0:00:13s
epoch 30 | loss: 0.32953 | val_0_rmse: 0.63027 | val_1_rmse: 0.65108 |  0:00:14s
epoch 31 | loss: 0.3205  | val_0_rmse: 0.62406 | val_1_rmse: 0.65332 |  0:00:14s
epoch 32 | loss: 0.31647 | val_0_rmse: 0.64805 | val_1_rmse: 0.67195 |  0:00:15s
epoch 33 | loss: 0.32018 | val_0_rmse: 0.63556 | val_1_rmse: 0.65561 |  0:00:15s
epoch 34 | loss: 0.31509 | val_0_rmse: 0.61519 | val_1_rmse: 0.62973 |  0:00:16s
epoch 35 | loss: 0.30749 | val_0_rmse: 0.5988  | val_1_rmse: 0.61701 |  0:00:16s
epoch 36 | loss: 0.30852 | val_0_rmse: 0.61472 | val_1_rmse: 0.63104 |  0:00:17s
epoch 37 | loss: 0.30048 | val_0_rmse: 0.6175  | val_1_rmse: 0.63198 |  0:00:17s
epoch 38 | loss: 0.30023 | val_0_rmse: 0.61753 | val_1_rmse: 0.62208 |  0:00:17s
epoch 39 | loss: 0.30325 | val_0_rmse: 0.61749 | val_1_rmse: 0.61152 |  0:00:18s
epoch 40 | loss: 0.30729 | val_0_rmse: 0.63334 | val_1_rmse: 0.63339 |  0:00:18s
epoch 41 | loss: 0.3013  | val_0_rmse: 0.59657 | val_1_rmse: 0.61534 |  0:00:19s
epoch 42 | loss: 0.29654 | val_0_rmse: 0.60929 | val_1_rmse: 0.63766 |  0:00:19s
epoch 43 | loss: 0.29394 | val_0_rmse: 0.60365 | val_1_rmse: 0.61733 |  0:00:20s
epoch 44 | loss: 0.28435 | val_0_rmse: 0.61148 | val_1_rmse: 0.6012  |  0:00:20s
epoch 45 | loss: 0.29993 | val_0_rmse: 0.60134 | val_1_rmse: 0.61335 |  0:00:21s
epoch 46 | loss: 0.29767 | val_0_rmse: 0.59999 | val_1_rmse: 0.61555 |  0:00:21s
epoch 47 | loss: 0.28105 | val_0_rmse: 0.60189 | val_1_rmse: 0.61795 |  0:00:22s
epoch 48 | loss: 0.28321 | val_0_rmse: 0.59058 | val_1_rmse: 0.60685 |  0:00:22s
epoch 49 | loss: 0.27546 | val_0_rmse: 0.56861 | val_1_rmse: 0.58383 |  0:00:22s
epoch 50 | loss: 0.28457 | val_0_rmse: 0.56805 | val_1_rmse: 0.58784 |  0:00:23s
epoch 51 | loss: 0.2834  | val_0_rmse: 0.56088 | val_1_rmse: 0.58242 |  0:00:23s
epoch 52 | loss: 0.28018 | val_0_rmse: 0.56886 | val_1_rmse: 0.5945  |  0:00:24s
epoch 53 | loss: 0.27076 | val_0_rmse: 0.56325 | val_1_rmse: 0.58668 |  0:00:24s
epoch 54 | loss: 0.2698  | val_0_rmse: 0.56131 | val_1_rmse: 0.58792 |  0:00:25s
epoch 55 | loss: 0.2704  | val_0_rmse: 0.57423 | val_1_rmse: 0.59593 |  0:00:25s
epoch 56 | loss: 0.27073 | val_0_rmse: 0.56872 | val_1_rmse: 0.59741 |  0:00:26s
epoch 57 | loss: 0.26326 | val_0_rmse: 0.5653  | val_1_rmse: 0.5977  |  0:00:26s
epoch 58 | loss: 0.26034 | val_0_rmse: 0.56255 | val_1_rmse: 0.58518 |  0:00:27s
epoch 59 | loss: 0.25752 | val_0_rmse: 0.55349 | val_1_rmse: 0.57575 |  0:00:27s
epoch 60 | loss: 0.26254 | val_0_rmse: 0.5614  | val_1_rmse: 0.59113 |  0:00:28s
epoch 61 | loss: 0.25396 | val_0_rmse: 0.55168 | val_1_rmse: 0.58338 |  0:00:28s
epoch 62 | loss: 0.25392 | val_0_rmse: 0.55264 | val_1_rmse: 0.58301 |  0:00:28s
epoch 63 | loss: 0.25058 | val_0_rmse: 0.5585  | val_1_rmse: 0.59274 |  0:00:29s
epoch 64 | loss: 0.24842 | val_0_rmse: 0.55507 | val_1_rmse: 0.59213 |  0:00:29s
epoch 65 | loss: 0.25719 | val_0_rmse: 0.55958 | val_1_rmse: 0.58824 |  0:00:30s
epoch 66 | loss: 0.25025 | val_0_rmse: 0.54695 | val_1_rmse: 0.57855 |  0:00:30s
epoch 67 | loss: 0.25028 | val_0_rmse: 0.54757 | val_1_rmse: 0.58162 |  0:00:31s
epoch 68 | loss: 0.25335 | val_0_rmse: 0.54129 | val_1_rmse: 0.56894 |  0:00:31s
epoch 69 | loss: 0.24313 | val_0_rmse: 0.53963 | val_1_rmse: 0.57727 |  0:00:32s
epoch 70 | loss: 0.24962 | val_0_rmse: 0.53501 | val_1_rmse: 0.57376 |  0:00:32s
epoch 71 | loss: 0.24263 | val_0_rmse: 0.52951 | val_1_rmse: 0.57275 |  0:00:33s
epoch 72 | loss: 0.24567 | val_0_rmse: 0.52577 | val_1_rmse: 0.56833 |  0:00:33s
epoch 73 | loss: 0.24783 | val_0_rmse: 0.53401 | val_1_rmse: 0.57137 |  0:00:33s
epoch 74 | loss: 0.2448  | val_0_rmse: 0.52389 | val_1_rmse: 0.56299 |  0:00:34s
epoch 75 | loss: 0.24373 | val_0_rmse: 0.53057 | val_1_rmse: 0.56855 |  0:00:34s
epoch 76 | loss: 0.23434 | val_0_rmse: 0.51771 | val_1_rmse: 0.56659 |  0:00:35s
epoch 77 | loss: 0.238   | val_0_rmse: 0.52311 | val_1_rmse: 0.56226 |  0:00:35s
epoch 78 | loss: 0.23542 | val_0_rmse: 0.52331 | val_1_rmse: 0.56363 |  0:00:36s
epoch 79 | loss: 0.23302 | val_0_rmse: 0.51758 | val_1_rmse: 0.5702  |  0:00:36s
epoch 80 | loss: 0.23258 | val_0_rmse: 0.51777 | val_1_rmse: 0.56937 |  0:00:37s
epoch 81 | loss: 0.23482 | val_0_rmse: 0.51295 | val_1_rmse: 0.56302 |  0:00:37s
epoch 82 | loss: 0.24009 | val_0_rmse: 0.51012 | val_1_rmse: 0.5655  |  0:00:37s
epoch 83 | loss: 0.22732 | val_0_rmse: 0.5096  | val_1_rmse: 0.56757 |  0:00:38s
epoch 84 | loss: 0.23184 | val_0_rmse: 0.51802 | val_1_rmse: 0.57626 |  0:00:38s
epoch 85 | loss: 0.23848 | val_0_rmse: 0.53205 | val_1_rmse: 0.58182 |  0:00:39s
epoch 86 | loss: 0.24402 | val_0_rmse: 0.53009 | val_1_rmse: 0.58635 |  0:00:39s
epoch 87 | loss: 0.25247 | val_0_rmse: 0.51645 | val_1_rmse: 0.56725 |  0:00:40s
epoch 88 | loss: 0.25821 | val_0_rmse: 0.54239 | val_1_rmse: 0.59288 |  0:00:40s
epoch 89 | loss: 0.24905 | val_0_rmse: 0.51883 | val_1_rmse: 0.58136 |  0:00:41s
epoch 90 | loss: 0.24676 | val_0_rmse: 0.51933 | val_1_rmse: 0.575   |  0:00:41s
epoch 91 | loss: 0.24535 | val_0_rmse: 0.51893 | val_1_rmse: 0.57695 |  0:00:42s
epoch 92 | loss: 0.24429 | val_0_rmse: 0.5107  | val_1_rmse: 0.56809 |  0:00:42s
epoch 93 | loss: 0.24769 | val_0_rmse: 0.51402 | val_1_rmse: 0.56227 |  0:00:42s
epoch 94 | loss: 0.24253 | val_0_rmse: 0.50803 | val_1_rmse: 0.56428 |  0:00:43s
epoch 95 | loss: 0.23784 | val_0_rmse: 0.50424 | val_1_rmse: 0.56859 |  0:00:43s
epoch 96 | loss: 0.24022 | val_0_rmse: 0.49819 | val_1_rmse: 0.55519 |  0:00:44s
epoch 97 | loss: 0.23478 | val_0_rmse: 0.49625 | val_1_rmse: 0.55005 |  0:00:44s
epoch 98 | loss: 0.23978 | val_0_rmse: 0.49206 | val_1_rmse: 0.55223 |  0:00:45s
epoch 99 | loss: 0.22645 | val_0_rmse: 0.50167 | val_1_rmse: 0.55424 |  0:00:45s
epoch 100| loss: 0.2372  | val_0_rmse: 0.49141 | val_1_rmse: 0.54691 |  0:00:46s
epoch 101| loss: 0.23257 | val_0_rmse: 0.48822 | val_1_rmse: 0.54846 |  0:00:46s
epoch 102| loss: 0.23347 | val_0_rmse: 0.48225 | val_1_rmse: 0.55266 |  0:00:47s
epoch 103| loss: 0.22662 | val_0_rmse: 0.48924 | val_1_rmse: 0.55468 |  0:00:47s
epoch 104| loss: 0.22155 | val_0_rmse: 0.48316 | val_1_rmse: 0.54591 |  0:00:47s
epoch 105| loss: 0.22176 | val_0_rmse: 0.48339 | val_1_rmse: 0.54914 |  0:00:48s
epoch 106| loss: 0.22587 | val_0_rmse: 0.47557 | val_1_rmse: 0.54642 |  0:00:48s
epoch 107| loss: 0.22518 | val_0_rmse: 0.47169 | val_1_rmse: 0.56468 |  0:00:49s
epoch 108| loss: 0.22161 | val_0_rmse: 0.47996 | val_1_rmse: 0.56326 |  0:00:49s
epoch 109| loss: 0.21883 | val_0_rmse: 0.46754 | val_1_rmse: 0.54397 |  0:00:50s
epoch 110| loss: 0.2299  | val_0_rmse: 0.47437 | val_1_rmse: 0.54457 |  0:00:50s
epoch 111| loss: 0.21464 | val_0_rmse: 0.47314 | val_1_rmse: 0.54453 |  0:00:51s
epoch 112| loss: 0.21665 | val_0_rmse: 0.46956 | val_1_rmse: 0.54084 |  0:00:51s
epoch 113| loss: 0.22937 | val_0_rmse: 0.46574 | val_1_rmse: 0.53896 |  0:00:52s
epoch 114| loss: 0.22331 | val_0_rmse: 0.46313 | val_1_rmse: 0.53755 |  0:00:52s
epoch 115| loss: 0.2313  | val_0_rmse: 0.4845  | val_1_rmse: 0.55049 |  0:00:52s
epoch 116| loss: 0.24647 | val_0_rmse: 0.49171 | val_1_rmse: 0.56031 |  0:00:53s
epoch 117| loss: 0.23244 | val_0_rmse: 0.4745  | val_1_rmse: 0.56468 |  0:00:53s
epoch 118| loss: 0.23011 | val_0_rmse: 0.47787 | val_1_rmse: 0.56071 |  0:00:54s
epoch 119| loss: 0.23736 | val_0_rmse: 0.47834 | val_1_rmse: 0.55287 |  0:00:54s
epoch 120| loss: 0.23411 | val_0_rmse: 0.47842 | val_1_rmse: 0.55513 |  0:00:55s
epoch 121| loss: 0.22351 | val_0_rmse: 0.49712 | val_1_rmse: 0.56772 |  0:00:55s
epoch 122| loss: 0.22246 | val_0_rmse: 0.46632 | val_1_rmse: 0.55924 |  0:00:56s
epoch 123| loss: 0.21717 | val_0_rmse: 0.46993 | val_1_rmse: 0.5558  |  0:00:56s
epoch 124| loss: 0.21803 | val_0_rmse: 0.46521 | val_1_rmse: 0.54634 |  0:00:57s
epoch 125| loss: 0.21759 | val_0_rmse: 0.46628 | val_1_rmse: 0.55179 |  0:00:57s
epoch 126| loss: 0.22214 | val_0_rmse: 0.46064 | val_1_rmse: 0.54255 |  0:00:57s
epoch 127| loss: 0.2186  | val_0_rmse: 0.4568  | val_1_rmse: 0.53062 |  0:00:58s
epoch 128| loss: 0.215   | val_0_rmse: 0.45363 | val_1_rmse: 0.53533 |  0:00:58s
epoch 129| loss: 0.21248 | val_0_rmse: 0.45115 | val_1_rmse: 0.5446  |  0:00:59s
epoch 130| loss: 0.21617 | val_0_rmse: 0.45692 | val_1_rmse: 0.55289 |  0:00:59s
epoch 131| loss: 0.21353 | val_0_rmse: 0.45948 | val_1_rmse: 0.5644  |  0:01:00s
epoch 132| loss: 0.22106 | val_0_rmse: 0.46875 | val_1_rmse: 0.57614 |  0:01:00s
epoch 133| loss: 0.2196  | val_0_rmse: 0.45912 | val_1_rmse: 0.56906 |  0:01:01s
epoch 134| loss: 0.21713 | val_0_rmse: 0.44899 | val_1_rmse: 0.57297 |  0:01:01s
epoch 135| loss: 0.21542 | val_0_rmse: 0.44309 | val_1_rmse: 0.55102 |  0:01:02s
epoch 136| loss: 0.21075 | val_0_rmse: 0.44828 | val_1_rmse: 0.54961 |  0:01:02s
epoch 137| loss: 0.21143 | val_0_rmse: 0.45072 | val_1_rmse: 0.54158 |  0:01:02s
epoch 138| loss: 0.20979 | val_0_rmse: 0.44512 | val_1_rmse: 0.53618 |  0:01:03s
epoch 139| loss: 0.21243 | val_0_rmse: 0.45064 | val_1_rmse: 0.54922 |  0:01:03s
epoch 140| loss: 0.21243 | val_0_rmse: 0.46204 | val_1_rmse: 0.54551 |  0:01:04s
epoch 141| loss: 0.22886 | val_0_rmse: 0.47047 | val_1_rmse: 0.54227 |  0:01:04s
epoch 142| loss: 0.22298 | val_0_rmse: 0.46878 | val_1_rmse: 0.54342 |  0:01:05s
epoch 143| loss: 0.22357 | val_0_rmse: 0.45606 | val_1_rmse: 0.52104 |  0:01:05s
epoch 144| loss: 0.22573 | val_0_rmse: 0.46099 | val_1_rmse: 0.53579 |  0:01:06s
epoch 145| loss: 0.22063 | val_0_rmse: 0.45125 | val_1_rmse: 0.52818 |  0:01:06s
epoch 146| loss: 0.2155  | val_0_rmse: 0.44998 | val_1_rmse: 0.53139 |  0:01:06s
epoch 147| loss: 0.21471 | val_0_rmse: 0.45179 | val_1_rmse: 0.54286 |  0:01:07s
epoch 148| loss: 0.2116  | val_0_rmse: 0.46412 | val_1_rmse: 0.54531 |  0:01:07s
epoch 149| loss: 0.22428 | val_0_rmse: 0.44692 | val_1_rmse: 0.5286  |  0:01:08s
Stop training because you reached max_epochs = 150 with best_epoch = 143 and best_val_1_rmse = 0.52104
Best weights from best epoch are automatically used!
ended training at: 08:20:45
Feature importance:
Mean squared error is of 2512524214.10106
Mean absolute error:33506.06060950753
MAPE:0.24534035536195714
R2 score:0.6936785608626308
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 1
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:20:46
epoch 0  | loss: 1.41889 | val_0_rmse: 0.98333 | val_1_rmse: 1.00537 |  0:00:00s
epoch 1  | loss: 1.03293 | val_0_rmse: 0.98744 | val_1_rmse: 1.01221 |  0:00:00s
epoch 2  | loss: 0.89619 | val_0_rmse: 0.9756  | val_1_rmse: 0.99808 |  0:00:01s
epoch 3  | loss: 0.77118 | val_0_rmse: 0.86347 | val_1_rmse: 0.88059 |  0:00:01s
epoch 4  | loss: 0.62335 | val_0_rmse: 0.73691 | val_1_rmse: 0.7584  |  0:00:02s
epoch 5  | loss: 0.55006 | val_0_rmse: 0.78377 | val_1_rmse: 0.80452 |  0:00:02s
epoch 6  | loss: 0.52863 | val_0_rmse: 0.71847 | val_1_rmse: 0.73422 |  0:00:03s
epoch 7  | loss: 0.49717 | val_0_rmse: 0.79946 | val_1_rmse: 0.8315  |  0:00:03s
epoch 8  | loss: 0.45247 | val_0_rmse: 0.72283 | val_1_rmse: 0.75407 |  0:00:04s
epoch 9  | loss: 0.43241 | val_0_rmse: 0.70016 | val_1_rmse: 0.73324 |  0:00:04s
epoch 10 | loss: 0.38941 | val_0_rmse: 0.68271 | val_1_rmse: 0.71716 |  0:00:05s
epoch 11 | loss: 0.3714  | val_0_rmse: 0.67131 | val_1_rmse: 0.70453 |  0:00:05s
epoch 12 | loss: 0.36028 | val_0_rmse: 0.65495 | val_1_rmse: 0.68856 |  0:00:05s
epoch 13 | loss: 0.36108 | val_0_rmse: 0.65493 | val_1_rmse: 0.68928 |  0:00:06s
epoch 14 | loss: 0.34577 | val_0_rmse: 0.64454 | val_1_rmse: 0.67986 |  0:00:06s
epoch 15 | loss: 0.33608 | val_0_rmse: 0.64206 | val_1_rmse: 0.67641 |  0:00:07s
epoch 16 | loss: 0.32952 | val_0_rmse: 0.64539 | val_1_rmse: 0.67833 |  0:00:07s
epoch 17 | loss: 0.32501 | val_0_rmse: 0.6394  | val_1_rmse: 0.67282 |  0:00:08s
epoch 18 | loss: 0.31708 | val_0_rmse: 0.65159 | val_1_rmse: 0.68429 |  0:00:08s
epoch 19 | loss: 0.31523 | val_0_rmse: 0.63223 | val_1_rmse: 0.66221 |  0:00:09s
epoch 20 | loss: 0.31087 | val_0_rmse: 0.62209 | val_1_rmse: 0.65761 |  0:00:09s
epoch 21 | loss: 0.30274 | val_0_rmse: 0.61806 | val_1_rmse: 0.65104 |  0:00:10s
epoch 22 | loss: 0.30608 | val_0_rmse: 0.61549 | val_1_rmse: 0.64858 |  0:00:10s
epoch 23 | loss: 0.30889 | val_0_rmse: 0.60843 | val_1_rmse: 0.65039 |  0:00:11s
epoch 24 | loss: 0.30445 | val_0_rmse: 0.61991 | val_1_rmse: 0.65361 |  0:00:11s
epoch 25 | loss: 0.30413 | val_0_rmse: 0.60208 | val_1_rmse: 0.63921 |  0:00:11s
epoch 26 | loss: 0.30993 | val_0_rmse: 0.6637  | val_1_rmse: 0.69086 |  0:00:12s
epoch 27 | loss: 0.31759 | val_0_rmse: 0.61249 | val_1_rmse: 0.65248 |  0:00:12s
epoch 28 | loss: 0.31156 | val_0_rmse: 0.62012 | val_1_rmse: 0.65655 |  0:00:13s
epoch 29 | loss: 0.30784 | val_0_rmse: 0.61164 | val_1_rmse: 0.65293 |  0:00:13s
epoch 30 | loss: 0.30307 | val_0_rmse: 0.59835 | val_1_rmse: 0.63689 |  0:00:14s
epoch 31 | loss: 0.28518 | val_0_rmse: 0.61945 | val_1_rmse: 0.65218 |  0:00:14s
epoch 32 | loss: 0.2855  | val_0_rmse: 0.60435 | val_1_rmse: 0.63948 |  0:00:15s
epoch 33 | loss: 0.28131 | val_0_rmse: 0.60063 | val_1_rmse: 0.63255 |  0:00:15s
epoch 34 | loss: 0.28108 | val_0_rmse: 0.59404 | val_1_rmse: 0.62859 |  0:00:16s
epoch 35 | loss: 0.26995 | val_0_rmse: 0.59603 | val_1_rmse: 0.62695 |  0:00:16s
epoch 36 | loss: 0.28111 | val_0_rmse: 0.59293 | val_1_rmse: 0.62662 |  0:00:17s
epoch 37 | loss: 0.2733  | val_0_rmse: 0.5882  | val_1_rmse: 0.62591 |  0:00:17s
epoch 38 | loss: 0.2785  | val_0_rmse: 0.58823 | val_1_rmse: 0.62637 |  0:00:17s
epoch 39 | loss: 0.27328 | val_0_rmse: 0.59545 | val_1_rmse: 0.62823 |  0:00:18s
epoch 40 | loss: 0.27491 | val_0_rmse: 0.59632 | val_1_rmse: 0.62904 |  0:00:18s
epoch 41 | loss: 0.26843 | val_0_rmse: 0.59867 | val_1_rmse: 0.63146 |  0:00:19s
epoch 42 | loss: 0.25966 | val_0_rmse: 0.6384  | val_1_rmse: 0.66805 |  0:00:19s
epoch 43 | loss: 0.26011 | val_0_rmse: 0.58975 | val_1_rmse: 0.6265  |  0:00:20s
epoch 44 | loss: 0.26451 | val_0_rmse: 0.60121 | val_1_rmse: 0.6336  |  0:00:20s
epoch 45 | loss: 0.2692  | val_0_rmse: 0.56996 | val_1_rmse: 0.6176  |  0:00:21s
epoch 46 | loss: 0.26065 | val_0_rmse: 0.60587 | val_1_rmse: 0.63581 |  0:00:21s
epoch 47 | loss: 0.25838 | val_0_rmse: 0.57202 | val_1_rmse: 0.61765 |  0:00:22s
epoch 48 | loss: 0.25348 | val_0_rmse: 0.62178 | val_1_rmse: 0.64998 |  0:00:22s
epoch 49 | loss: 0.25694 | val_0_rmse: 0.55626 | val_1_rmse: 0.60555 |  0:00:23s
epoch 50 | loss: 0.2493  | val_0_rmse: 0.58366 | val_1_rmse: 0.61636 |  0:00:23s
epoch 51 | loss: 0.24555 | val_0_rmse: 0.55069 | val_1_rmse: 0.59795 |  0:00:23s
epoch 52 | loss: 0.24783 | val_0_rmse: 0.57704 | val_1_rmse: 0.6092  |  0:00:24s
epoch 53 | loss: 0.2418  | val_0_rmse: 0.5681  | val_1_rmse: 0.60131 |  0:00:24s
epoch 54 | loss: 0.24752 | val_0_rmse: 0.5731  | val_1_rmse: 0.60566 |  0:00:25s
epoch 55 | loss: 0.23959 | val_0_rmse: 0.56851 | val_1_rmse: 0.61252 |  0:00:25s
epoch 56 | loss: 0.24222 | val_0_rmse: 0.5427  | val_1_rmse: 0.5983  |  0:00:26s
epoch 57 | loss: 0.23643 | val_0_rmse: 0.54341 | val_1_rmse: 0.59604 |  0:00:26s
epoch 58 | loss: 0.23969 | val_0_rmse: 0.55053 | val_1_rmse: 0.59692 |  0:00:27s
epoch 59 | loss: 0.23832 | val_0_rmse: 0.53506 | val_1_rmse: 0.59907 |  0:00:27s
epoch 60 | loss: 0.23548 | val_0_rmse: 0.56487 | val_1_rmse: 0.61325 |  0:00:27s
epoch 61 | loss: 0.24515 | val_0_rmse: 0.54029 | val_1_rmse: 0.61401 |  0:00:28s
epoch 62 | loss: 0.2354  | val_0_rmse: 0.53507 | val_1_rmse: 0.59179 |  0:00:28s
epoch 63 | loss: 0.23794 | val_0_rmse: 0.53572 | val_1_rmse: 0.59554 |  0:00:29s
epoch 64 | loss: 0.2359  | val_0_rmse: 0.54683 | val_1_rmse: 0.59557 |  0:00:29s
epoch 65 | loss: 0.23219 | val_0_rmse: 0.54705 | val_1_rmse: 0.59677 |  0:00:30s
epoch 66 | loss: 0.23053 | val_0_rmse: 0.58217 | val_1_rmse: 0.61194 |  0:00:30s
epoch 67 | loss: 0.2268  | val_0_rmse: 0.52784 | val_1_rmse: 0.58123 |  0:00:31s
epoch 68 | loss: 0.22468 | val_0_rmse: 0.51727 | val_1_rmse: 0.57898 |  0:00:31s
epoch 69 | loss: 0.22391 | val_0_rmse: 0.51479 | val_1_rmse: 0.58003 |  0:00:32s
epoch 70 | loss: 0.22003 | val_0_rmse: 0.54038 | val_1_rmse: 0.59412 |  0:00:32s
epoch 71 | loss: 0.21943 | val_0_rmse: 0.5162  | val_1_rmse: 0.59606 |  0:00:32s
epoch 72 | loss: 0.21699 | val_0_rmse: 0.51627 | val_1_rmse: 0.58645 |  0:00:33s
epoch 73 | loss: 0.21618 | val_0_rmse: 0.50924 | val_1_rmse: 0.6049  |  0:00:33s
epoch 74 | loss: 0.21634 | val_0_rmse: 0.50964 | val_1_rmse: 0.58231 |  0:00:34s
epoch 75 | loss: 0.20946 | val_0_rmse: 0.50218 | val_1_rmse: 0.57182 |  0:00:34s
epoch 76 | loss: 0.20775 | val_0_rmse: 0.52781 | val_1_rmse: 0.58785 |  0:00:35s
epoch 77 | loss: 0.20675 | val_0_rmse: 0.49273 | val_1_rmse: 0.57984 |  0:00:35s
epoch 78 | loss: 0.20927 | val_0_rmse: 0.49282 | val_1_rmse: 0.58989 |  0:00:36s
epoch 79 | loss: 0.20293 | val_0_rmse: 0.4971  | val_1_rmse: 0.5994  |  0:00:36s
epoch 80 | loss: 0.20329 | val_0_rmse: 0.4995  | val_1_rmse: 0.57828 |  0:00:37s
epoch 81 | loss: 0.2007  | val_0_rmse: 0.49053 | val_1_rmse: 0.59238 |  0:00:37s
epoch 82 | loss: 0.20116 | val_0_rmse: 0.51216 | val_1_rmse: 0.58448 |  0:00:38s
epoch 83 | loss: 0.19715 | val_0_rmse: 0.48801 | val_1_rmse: 0.5916  |  0:00:38s
epoch 84 | loss: 0.19819 | val_0_rmse: 0.49221 | val_1_rmse: 0.57645 |  0:00:38s
epoch 85 | loss: 0.19531 | val_0_rmse: 0.49763 | val_1_rmse: 0.59402 |  0:00:39s
epoch 86 | loss: 0.1965  | val_0_rmse: 0.48173 | val_1_rmse: 0.58421 |  0:00:39s
epoch 87 | loss: 0.19874 | val_0_rmse: 0.47704 | val_1_rmse: 0.58819 |  0:00:40s
epoch 88 | loss: 0.19439 | val_0_rmse: 0.47445 | val_1_rmse: 0.578   |  0:00:40s
epoch 89 | loss: 0.19121 | val_0_rmse: 0.4662  | val_1_rmse: 0.58155 |  0:00:41s
epoch 90 | loss: 0.19282 | val_0_rmse: 0.46775 | val_1_rmse: 0.58894 |  0:00:41s
epoch 91 | loss: 0.19431 | val_0_rmse: 0.4769  | val_1_rmse: 0.59087 |  0:00:42s
epoch 92 | loss: 0.19895 | val_0_rmse: 0.45864 | val_1_rmse: 0.59964 |  0:00:42s
epoch 93 | loss: 0.19952 | val_0_rmse: 0.45888 | val_1_rmse: 0.58256 |  0:00:43s
epoch 94 | loss: 0.2003  | val_0_rmse: 0.45399 | val_1_rmse: 0.60284 |  0:00:43s
epoch 95 | loss: 0.1947  | val_0_rmse: 0.50044 | val_1_rmse: 0.60973 |  0:00:43s
epoch 96 | loss: 0.19083 | val_0_rmse: 0.46313 | val_1_rmse: 0.5906  |  0:00:44s
epoch 97 | loss: 0.19125 | val_0_rmse: 0.46087 | val_1_rmse: 0.59849 |  0:00:44s
epoch 98 | loss: 0.18521 | val_0_rmse: 0.45478 | val_1_rmse: 0.58075 |  0:00:45s
epoch 99 | loss: 0.18714 | val_0_rmse: 0.45337 | val_1_rmse: 0.589   |  0:00:45s
epoch 100| loss: 0.18616 | val_0_rmse: 0.44835 | val_1_rmse: 0.58085 |  0:00:46s
epoch 101| loss: 0.18712 | val_0_rmse: 0.44676 | val_1_rmse: 0.59502 |  0:00:46s
epoch 102| loss: 0.18909 | val_0_rmse: 0.46285 | val_1_rmse: 0.58611 |  0:00:47s
epoch 103| loss: 0.17771 | val_0_rmse: 0.4425  | val_1_rmse: 0.58746 |  0:00:47s
epoch 104| loss: 0.18176 | val_0_rmse: 0.4447  | val_1_rmse: 0.58171 |  0:00:48s
epoch 105| loss: 0.18586 | val_0_rmse: 0.44988 | val_1_rmse: 0.58463 |  0:00:48s

Early stopping occured at epoch 105 with best_epoch = 75 and best_val_1_rmse = 0.57182
Best weights from best epoch are automatically used!
ended training at: 08:21:35
Feature importance:
Mean squared error is of 2656039377.3170304
Mean absolute error:35396.10571326336
MAPE:0.29936041299100624
R2 score:0.7040018348472964
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 2
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:21:35
epoch 0  | loss: 1.4611  | val_0_rmse: 1.00315 | val_1_rmse: 0.98604 |  0:00:00s
epoch 1  | loss: 1.07523 | val_0_rmse: 0.99352 | val_1_rmse: 0.98603 |  0:00:00s
epoch 2  | loss: 0.95932 | val_0_rmse: 0.95407 | val_1_rmse: 0.95232 |  0:00:01s
epoch 3  | loss: 0.82958 | val_0_rmse: 1.0584  | val_1_rmse: 1.14465 |  0:00:01s
epoch 4  | loss: 0.69064 | val_0_rmse: 0.81    | val_1_rmse: 0.86057 |  0:00:02s
epoch 5  | loss: 0.57964 | val_0_rmse: 0.80076 | val_1_rmse: 0.85215 |  0:00:02s
epoch 6  | loss: 0.5315  | val_0_rmse: 0.85797 | val_1_rmse: 0.89934 |  0:00:03s
epoch 7  | loss: 0.48253 | val_0_rmse: 0.76015 | val_1_rmse: 0.78777 |  0:00:03s
epoch 8  | loss: 0.46281 | val_0_rmse: 0.81067 | val_1_rmse: 0.84967 |  0:00:04s
epoch 9  | loss: 0.44701 | val_0_rmse: 0.74869 | val_1_rmse: 0.77676 |  0:00:04s
epoch 10 | loss: 0.40661 | val_0_rmse: 0.73146 | val_1_rmse: 0.75037 |  0:00:05s
epoch 11 | loss: 0.39133 | val_0_rmse: 0.68984 | val_1_rmse: 0.6962  |  0:00:05s
epoch 12 | loss: 0.37608 | val_0_rmse: 0.684   | val_1_rmse: 0.69171 |  0:00:06s
epoch 13 | loss: 0.36476 | val_0_rmse: 0.67626 | val_1_rmse: 0.68849 |  0:00:06s
epoch 14 | loss: 0.36105 | val_0_rmse: 0.66846 | val_1_rmse: 0.68385 |  0:00:06s
epoch 15 | loss: 0.36264 | val_0_rmse: 0.65567 | val_1_rmse: 0.67044 |  0:00:07s
epoch 16 | loss: 0.35321 | val_0_rmse: 0.65739 | val_1_rmse: 0.67358 |  0:00:07s
epoch 17 | loss: 0.34036 | val_0_rmse: 0.63907 | val_1_rmse: 0.65838 |  0:00:08s
epoch 18 | loss: 0.34123 | val_0_rmse: 0.63934 | val_1_rmse: 0.6582  |  0:00:08s
epoch 19 | loss: 0.31884 | val_0_rmse: 0.65172 | val_1_rmse: 0.6662  |  0:00:09s
epoch 20 | loss: 0.31497 | val_0_rmse: 0.67791 | val_1_rmse: 0.68357 |  0:00:09s
epoch 21 | loss: 0.31792 | val_0_rmse: 0.64306 | val_1_rmse: 0.66597 |  0:00:10s
epoch 22 | loss: 0.30636 | val_0_rmse: 0.64396 | val_1_rmse: 0.67166 |  0:00:10s
epoch 23 | loss: 0.29798 | val_0_rmse: 0.64839 | val_1_rmse: 0.66818 |  0:00:11s
epoch 24 | loss: 0.30723 | val_0_rmse: 0.68635 | val_1_rmse: 0.69229 |  0:00:11s
epoch 25 | loss: 0.30262 | val_0_rmse: 0.63777 | val_1_rmse: 0.66253 |  0:00:11s
epoch 26 | loss: 0.30733 | val_0_rmse: 0.64182 | val_1_rmse: 0.66989 |  0:00:12s
epoch 27 | loss: 0.28857 | val_0_rmse: 0.64052 | val_1_rmse: 0.67049 |  0:00:12s
epoch 28 | loss: 0.28853 | val_0_rmse: 0.63103 | val_1_rmse: 0.64869 |  0:00:13s
epoch 29 | loss: 0.28831 | val_0_rmse: 0.62963 | val_1_rmse: 0.64766 |  0:00:13s
epoch 30 | loss: 0.27252 | val_0_rmse: 0.61152 | val_1_rmse: 0.63625 |  0:00:14s
epoch 31 | loss: 0.27417 | val_0_rmse: 0.61979 | val_1_rmse: 0.64706 |  0:00:14s
epoch 32 | loss: 0.27152 | val_0_rmse: 0.64569 | val_1_rmse: 0.67827 |  0:00:15s
epoch 33 | loss: 0.27906 | val_0_rmse: 0.63654 | val_1_rmse: 0.66777 |  0:00:15s
epoch 34 | loss: 0.27084 | val_0_rmse: 0.62125 | val_1_rmse: 0.64982 |  0:00:16s
epoch 35 | loss: 0.26934 | val_0_rmse: 0.60343 | val_1_rmse: 0.63873 |  0:00:16s
epoch 36 | loss: 0.25983 | val_0_rmse: 0.60352 | val_1_rmse: 0.64137 |  0:00:16s
epoch 37 | loss: 0.25866 | val_0_rmse: 0.60003 | val_1_rmse: 0.63545 |  0:00:17s
epoch 38 | loss: 0.254   | val_0_rmse: 0.60588 | val_1_rmse: 0.63901 |  0:00:17s
epoch 39 | loss: 0.26389 | val_0_rmse: 0.59479 | val_1_rmse: 0.62635 |  0:00:18s
epoch 40 | loss: 0.25098 | val_0_rmse: 0.57832 | val_1_rmse: 0.62478 |  0:00:18s
epoch 41 | loss: 0.25451 | val_0_rmse: 0.59808 | val_1_rmse: 0.63029 |  0:00:19s
epoch 42 | loss: 0.25634 | val_0_rmse: 0.5989  | val_1_rmse: 0.63653 |  0:00:19s
epoch 43 | loss: 0.2494  | val_0_rmse: 0.60141 | val_1_rmse: 0.64225 |  0:00:20s
epoch 44 | loss: 0.25754 | val_0_rmse: 0.58053 | val_1_rmse: 0.62105 |  0:00:20s
epoch 45 | loss: 0.25006 | val_0_rmse: 0.57474 | val_1_rmse: 0.61735 |  0:00:21s
epoch 46 | loss: 0.24717 | val_0_rmse: 0.59374 | val_1_rmse: 0.62381 |  0:00:21s
epoch 47 | loss: 0.24482 | val_0_rmse: 0.58318 | val_1_rmse: 0.62384 |  0:00:22s
epoch 48 | loss: 0.23879 | val_0_rmse: 0.58114 | val_1_rmse: 0.62013 |  0:00:22s
epoch 49 | loss: 0.2476  | val_0_rmse: 0.57667 | val_1_rmse: 0.62464 |  0:00:22s
epoch 50 | loss: 0.24019 | val_0_rmse: 0.56572 | val_1_rmse: 0.61612 |  0:00:23s
epoch 51 | loss: 0.25184 | val_0_rmse: 0.57055 | val_1_rmse: 0.61178 |  0:00:23s
epoch 52 | loss: 0.23807 | val_0_rmse: 0.57522 | val_1_rmse: 0.62352 |  0:00:24s
epoch 53 | loss: 0.23954 | val_0_rmse: 0.55982 | val_1_rmse: 0.61365 |  0:00:24s
epoch 54 | loss: 0.23389 | val_0_rmse: 0.5544  | val_1_rmse: 0.59862 |  0:00:25s
epoch 55 | loss: 0.22933 | val_0_rmse: 0.55124 | val_1_rmse: 0.60884 |  0:00:25s
epoch 56 | loss: 0.22826 | val_0_rmse: 0.57059 | val_1_rmse: 0.62316 |  0:00:26s
epoch 57 | loss: 0.22805 | val_0_rmse: 0.55734 | val_1_rmse: 0.60932 |  0:00:26s
epoch 58 | loss: 0.23349 | val_0_rmse: 0.55848 | val_1_rmse: 0.61027 |  0:00:27s
epoch 59 | loss: 0.22899 | val_0_rmse: 0.5584  | val_1_rmse: 0.60215 |  0:00:27s
epoch 60 | loss: 0.23718 | val_0_rmse: 0.54847 | val_1_rmse: 0.59567 |  0:00:28s
epoch 61 | loss: 0.23225 | val_0_rmse: 0.54438 | val_1_rmse: 0.60254 |  0:00:28s
epoch 62 | loss: 0.23664 | val_0_rmse: 0.5419  | val_1_rmse: 0.61087 |  0:00:28s
epoch 63 | loss: 0.22785 | val_0_rmse: 0.54523 | val_1_rmse: 0.61622 |  0:00:29s
epoch 64 | loss: 0.23022 | val_0_rmse: 0.53203 | val_1_rmse: 0.58681 |  0:00:29s
epoch 65 | loss: 0.22248 | val_0_rmse: 0.52588 | val_1_rmse: 0.57123 |  0:00:30s
epoch 66 | loss: 0.22908 | val_0_rmse: 0.52606 | val_1_rmse: 0.59679 |  0:00:30s
epoch 67 | loss: 0.22226 | val_0_rmse: 0.52494 | val_1_rmse: 0.59866 |  0:00:31s
epoch 68 | loss: 0.21759 | val_0_rmse: 0.53319 | val_1_rmse: 0.60698 |  0:00:31s
epoch 69 | loss: 0.2147  | val_0_rmse: 0.52453 | val_1_rmse: 0.5958  |  0:00:32s
epoch 70 | loss: 0.22367 | val_0_rmse: 0.52582 | val_1_rmse: 0.59543 |  0:00:32s
epoch 71 | loss: 0.22604 | val_0_rmse: 0.5279  | val_1_rmse: 0.59152 |  0:00:33s
epoch 72 | loss: 0.2315  | val_0_rmse: 0.53069 | val_1_rmse: 0.59728 |  0:00:33s
epoch 73 | loss: 0.23522 | val_0_rmse: 0.52102 | val_1_rmse: 0.5833  |  0:00:33s
epoch 74 | loss: 0.22348 | val_0_rmse: 0.51387 | val_1_rmse: 0.57885 |  0:00:34s
epoch 75 | loss: 0.22743 | val_0_rmse: 0.52148 | val_1_rmse: 0.58487 |  0:00:34s
epoch 76 | loss: 0.21209 | val_0_rmse: 0.5096  | val_1_rmse: 0.5733  |  0:00:35s
epoch 77 | loss: 0.21389 | val_0_rmse: 0.5049  | val_1_rmse: 0.56824 |  0:00:35s
epoch 78 | loss: 0.21047 | val_0_rmse: 0.50602 | val_1_rmse: 0.57433 |  0:00:36s
epoch 79 | loss: 0.2109  | val_0_rmse: 0.51145 | val_1_rmse: 0.57814 |  0:00:36s
epoch 80 | loss: 0.2124  | val_0_rmse: 0.52482 | val_1_rmse: 0.59    |  0:00:37s
epoch 81 | loss: 0.20803 | val_0_rmse: 0.50134 | val_1_rmse: 0.57218 |  0:00:37s
epoch 82 | loss: 0.20727 | val_0_rmse: 0.50386 | val_1_rmse: 0.57358 |  0:00:37s
epoch 83 | loss: 0.21335 | val_0_rmse: 0.49765 | val_1_rmse: 0.5632  |  0:00:38s
epoch 84 | loss: 0.20787 | val_0_rmse: 0.49067 | val_1_rmse: 0.55717 |  0:00:38s
epoch 85 | loss: 0.2115  | val_0_rmse: 0.47999 | val_1_rmse: 0.55574 |  0:00:39s
epoch 86 | loss: 0.20621 | val_0_rmse: 0.48101 | val_1_rmse: 0.56194 |  0:00:39s
epoch 87 | loss: 0.20069 | val_0_rmse: 0.48365 | val_1_rmse: 0.56389 |  0:00:40s
epoch 88 | loss: 0.2039  | val_0_rmse: 0.47743 | val_1_rmse: 0.55421 |  0:00:40s
epoch 89 | loss: 0.21173 | val_0_rmse: 0.4816  | val_1_rmse: 0.5664  |  0:00:41s
epoch 90 | loss: 0.21174 | val_0_rmse: 0.49388 | val_1_rmse: 0.57172 |  0:00:41s
epoch 91 | loss: 0.21311 | val_0_rmse: 0.48941 | val_1_rmse: 0.56842 |  0:00:42s
epoch 92 | loss: 0.20879 | val_0_rmse: 0.48314 | val_1_rmse: 0.55239 |  0:00:42s
epoch 93 | loss: 0.20787 | val_0_rmse: 0.47639 | val_1_rmse: 0.55899 |  0:00:43s
epoch 94 | loss: 0.20749 | val_0_rmse: 0.46821 | val_1_rmse: 0.55948 |  0:00:43s
epoch 95 | loss: 0.20053 | val_0_rmse: 0.46127 | val_1_rmse: 0.55943 |  0:00:43s
epoch 96 | loss: 0.20321 | val_0_rmse: 0.46246 | val_1_rmse: 0.5586  |  0:00:44s
epoch 97 | loss: 0.20061 | val_0_rmse: 0.46266 | val_1_rmse: 0.55686 |  0:00:44s
epoch 98 | loss: 0.19148 | val_0_rmse: 0.45479 | val_1_rmse: 0.56071 |  0:00:45s
epoch 99 | loss: 0.19981 | val_0_rmse: 0.45391 | val_1_rmse: 0.54355 |  0:00:45s
epoch 100| loss: 0.19143 | val_0_rmse: 0.45667 | val_1_rmse: 0.54174 |  0:00:46s
epoch 101| loss: 0.19413 | val_0_rmse: 0.4528  | val_1_rmse: 0.5502  |  0:00:46s
epoch 102| loss: 0.18809 | val_0_rmse: 0.47344 | val_1_rmse: 0.555   |  0:00:47s
epoch 103| loss: 0.19856 | val_0_rmse: 0.44748 | val_1_rmse: 0.54636 |  0:00:47s
epoch 104| loss: 0.18543 | val_0_rmse: 0.46631 | val_1_rmse: 0.56819 |  0:00:48s
epoch 105| loss: 0.19738 | val_0_rmse: 0.45645 | val_1_rmse: 0.56328 |  0:00:48s
epoch 106| loss: 0.19929 | val_0_rmse: 0.44441 | val_1_rmse: 0.54324 |  0:00:48s
epoch 107| loss: 0.20285 | val_0_rmse: 0.44505 | val_1_rmse: 0.54223 |  0:00:49s
epoch 108| loss: 0.18863 | val_0_rmse: 0.43931 | val_1_rmse: 0.55684 |  0:00:49s
epoch 109| loss: 0.1976  | val_0_rmse: 0.44869 | val_1_rmse: 0.55414 |  0:00:50s
epoch 110| loss: 0.20599 | val_0_rmse: 0.4707  | val_1_rmse: 0.57767 |  0:00:50s
epoch 111| loss: 0.20449 | val_0_rmse: 0.43729 | val_1_rmse: 0.54136 |  0:00:51s
epoch 112| loss: 0.19176 | val_0_rmse: 0.4292  | val_1_rmse: 0.54822 |  0:00:51s
epoch 113| loss: 0.18955 | val_0_rmse: 0.43622 | val_1_rmse: 0.57421 |  0:00:52s
epoch 114| loss: 0.18659 | val_0_rmse: 0.43665 | val_1_rmse: 0.5651  |  0:00:52s
epoch 115| loss: 0.18745 | val_0_rmse: 0.43342 | val_1_rmse: 0.55496 |  0:00:53s
epoch 116| loss: 0.18783 | val_0_rmse: 0.42791 | val_1_rmse: 0.55225 |  0:00:53s
epoch 117| loss: 0.18806 | val_0_rmse: 0.42626 | val_1_rmse: 0.55274 |  0:00:53s
epoch 118| loss: 0.18448 | val_0_rmse: 0.41631 | val_1_rmse: 0.55268 |  0:00:54s
epoch 119| loss: 0.1811  | val_0_rmse: 0.4194  | val_1_rmse: 0.55496 |  0:00:54s
epoch 120| loss: 0.19306 | val_0_rmse: 0.41916 | val_1_rmse: 0.54727 |  0:00:55s
epoch 121| loss: 0.18601 | val_0_rmse: 0.42608 | val_1_rmse: 0.55036 |  0:00:55s
epoch 122| loss: 0.18314 | val_0_rmse: 0.4185  | val_1_rmse: 0.55024 |  0:00:56s
epoch 123| loss: 0.18585 | val_0_rmse: 0.40844 | val_1_rmse: 0.54802 |  0:00:56s
epoch 124| loss: 0.17887 | val_0_rmse: 0.40977 | val_1_rmse: 0.55585 |  0:00:57s
epoch 125| loss: 0.17415 | val_0_rmse: 0.4372  | val_1_rmse: 0.56779 |  0:00:57s
epoch 126| loss: 0.18077 | val_0_rmse: 0.40547 | val_1_rmse: 0.55425 |  0:00:58s
epoch 127| loss: 0.17937 | val_0_rmse: 0.40365 | val_1_rmse: 0.55372 |  0:00:58s
epoch 128| loss: 0.17373 | val_0_rmse: 0.42277 | val_1_rmse: 0.56565 |  0:00:59s
epoch 129| loss: 0.17481 | val_0_rmse: 0.40085 | val_1_rmse: 0.56725 |  0:00:59s
epoch 130| loss: 0.17617 | val_0_rmse: 0.41879 | val_1_rmse: 0.57109 |  0:00:59s
epoch 131| loss: 0.1704  | val_0_rmse: 0.41413 | val_1_rmse: 0.57166 |  0:01:00s
epoch 132| loss: 0.18897 | val_0_rmse: 0.40941 | val_1_rmse: 0.55976 |  0:01:00s
epoch 133| loss: 0.17826 | val_0_rmse: 0.39545 | val_1_rmse: 0.56655 |  0:01:01s
epoch 134| loss: 0.17863 | val_0_rmse: 0.40046 | val_1_rmse: 0.56388 |  0:01:01s
epoch 135| loss: 0.17319 | val_0_rmse: 0.4164  | val_1_rmse: 0.56462 |  0:01:02s
epoch 136| loss: 0.17698 | val_0_rmse: 0.41104 | val_1_rmse: 0.56519 |  0:01:02s
epoch 137| loss: 0.18204 | val_0_rmse: 0.40338 | val_1_rmse: 0.56405 |  0:01:03s
epoch 138| loss: 0.17911 | val_0_rmse: 0.39915 | val_1_rmse: 0.55108 |  0:01:03s
epoch 139| loss: 0.1756  | val_0_rmse: 0.40302 | val_1_rmse: 0.55722 |  0:01:03s
epoch 140| loss: 0.16996 | val_0_rmse: 0.39903 | val_1_rmse: 0.57133 |  0:01:04s
epoch 141| loss: 0.17457 | val_0_rmse: 0.40733 | val_1_rmse: 0.57872 |  0:01:04s

Early stopping occured at epoch 141 with best_epoch = 111 and best_val_1_rmse = 0.54136
Best weights from best epoch are automatically used!
ended training at: 08:22:40
Feature importance:
Mean squared error is of 2569877614.4677505
Mean absolute error:33049.15124777354
MAPE:0.22146845560764825
R2 score:0.7016022215424929
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 3
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:22:40
epoch 0  | loss: 1.56481 | val_0_rmse: 1.00979 | val_1_rmse: 1.01019 |  0:00:00s
epoch 1  | loss: 1.00517 | val_0_rmse: 1.00304 | val_1_rmse: 1.00061 |  0:00:00s
epoch 2  | loss: 0.79579 | val_0_rmse: 0.89993 | val_1_rmse: 0.8867  |  0:00:01s
epoch 3  | loss: 0.76732 | val_0_rmse: 0.80989 | val_1_rmse: 0.78534 |  0:00:01s
epoch 4  | loss: 0.67704 | val_0_rmse: 0.79535 | val_1_rmse: 0.76851 |  0:00:02s
epoch 5  | loss: 0.58452 | val_0_rmse: 0.77474 | val_1_rmse: 0.74354 |  0:00:02s
epoch 6  | loss: 0.53185 | val_0_rmse: 0.80942 | val_1_rmse: 0.75355 |  0:00:03s
epoch 7  | loss: 0.48189 | val_0_rmse: 0.76072 | val_1_rmse: 0.71297 |  0:00:03s
epoch 8  | loss: 0.40455 | val_0_rmse: 0.72187 | val_1_rmse: 0.6661  |  0:00:04s
epoch 9  | loss: 0.41385 | val_0_rmse: 0.76411 | val_1_rmse: 0.7214  |  0:00:04s
epoch 10 | loss: 0.44001 | val_0_rmse: 0.81555 | val_1_rmse: 0.78064 |  0:00:05s
epoch 11 | loss: 0.43868 | val_0_rmse: 0.82112 | val_1_rmse: 0.78723 |  0:00:05s
epoch 12 | loss: 0.41924 | val_0_rmse: 0.77826 | val_1_rmse: 0.74298 |  0:00:06s
epoch 13 | loss: 0.41088 | val_0_rmse: 0.81527 | val_1_rmse: 0.77983 |  0:00:06s
epoch 14 | loss: 0.40444 | val_0_rmse: 0.78377 | val_1_rmse: 0.74261 |  0:00:06s
epoch 15 | loss: 0.38974 | val_0_rmse: 0.77296 | val_1_rmse: 0.73199 |  0:00:07s
epoch 16 | loss: 0.37951 | val_0_rmse: 0.79367 | val_1_rmse: 0.76158 |  0:00:07s
epoch 17 | loss: 0.37006 | val_0_rmse: 0.79803 | val_1_rmse: 0.76808 |  0:00:08s
epoch 18 | loss: 0.36783 | val_0_rmse: 0.78797 | val_1_rmse: 0.75354 |  0:00:08s
epoch 19 | loss: 0.38739 | val_0_rmse: 0.74398 | val_1_rmse: 0.70521 |  0:00:09s
epoch 20 | loss: 0.36097 | val_0_rmse: 0.78195 | val_1_rmse: 0.74838 |  0:00:09s
epoch 21 | loss: 0.35708 | val_0_rmse: 0.80013 | val_1_rmse: 0.76553 |  0:00:10s
epoch 22 | loss: 0.34427 | val_0_rmse: 0.79849 | val_1_rmse: 0.76879 |  0:00:10s
epoch 23 | loss: 0.34307 | val_0_rmse: 0.74303 | val_1_rmse: 0.71276 |  0:00:10s
epoch 24 | loss: 0.32507 | val_0_rmse: 0.73755 | val_1_rmse: 0.70319 |  0:00:11s
epoch 25 | loss: 0.31897 | val_0_rmse: 0.70617 | val_1_rmse: 0.67198 |  0:00:11s
epoch 26 | loss: 0.30861 | val_0_rmse: 0.7213  | val_1_rmse: 0.69541 |  0:00:12s
epoch 27 | loss: 0.31345 | val_0_rmse: 0.69306 | val_1_rmse: 0.66358 |  0:00:12s
epoch 28 | loss: 0.30611 | val_0_rmse: 0.73603 | val_1_rmse: 0.71423 |  0:00:13s
epoch 29 | loss: 0.30379 | val_0_rmse: 0.68244 | val_1_rmse: 0.65046 |  0:00:13s
epoch 30 | loss: 0.29564 | val_0_rmse: 0.75133 | val_1_rmse: 0.72969 |  0:00:14s
epoch 31 | loss: 0.29833 | val_0_rmse: 0.6791  | val_1_rmse: 0.64946 |  0:00:14s
epoch 32 | loss: 0.2911  | val_0_rmse: 0.68881 | val_1_rmse: 0.66549 |  0:00:15s
epoch 33 | loss: 0.2913  | val_0_rmse: 0.68727 | val_1_rmse: 0.66336 |  0:00:15s
epoch 34 | loss: 0.29774 | val_0_rmse: 0.65494 | val_1_rmse: 0.62396 |  0:00:15s
epoch 35 | loss: 0.28894 | val_0_rmse: 0.69186 | val_1_rmse: 0.66499 |  0:00:16s
epoch 36 | loss: 0.28672 | val_0_rmse: 0.63976 | val_1_rmse: 0.60908 |  0:00:16s
epoch 37 | loss: 0.30101 | val_0_rmse: 0.64825 | val_1_rmse: 0.62    |  0:00:17s
epoch 38 | loss: 0.27949 | val_0_rmse: 0.6247  | val_1_rmse: 0.59974 |  0:00:17s
epoch 39 | loss: 0.28446 | val_0_rmse: 0.63292 | val_1_rmse: 0.60512 |  0:00:18s
epoch 40 | loss: 0.27839 | val_0_rmse: 0.63112 | val_1_rmse: 0.60548 |  0:00:18s
epoch 41 | loss: 0.27459 | val_0_rmse: 0.6422  | val_1_rmse: 0.61854 |  0:00:19s
epoch 42 | loss: 0.28003 | val_0_rmse: 0.6289  | val_1_rmse: 0.5999  |  0:00:19s
epoch 43 | loss: 0.27967 | val_0_rmse: 0.64617 | val_1_rmse: 0.6251  |  0:00:20s
epoch 44 | loss: 0.26731 | val_0_rmse: 0.63273 | val_1_rmse: 0.61158 |  0:00:20s
epoch 45 | loss: 0.29036 | val_0_rmse: 0.65801 | val_1_rmse: 0.65696 |  0:00:20s
epoch 46 | loss: 0.28489 | val_0_rmse: 0.60022 | val_1_rmse: 0.57195 |  0:00:21s
epoch 47 | loss: 0.29299 | val_0_rmse: 0.6385  | val_1_rmse: 0.60872 |  0:00:21s
epoch 48 | loss: 0.28885 | val_0_rmse: 0.61302 | val_1_rmse: 0.58111 |  0:00:22s
epoch 49 | loss: 0.27931 | val_0_rmse: 0.62225 | val_1_rmse: 0.59551 |  0:00:22s
epoch 50 | loss: 0.28262 | val_0_rmse: 0.61625 | val_1_rmse: 0.58895 |  0:00:23s
epoch 51 | loss: 0.29675 | val_0_rmse: 0.62126 | val_1_rmse: 0.59883 |  0:00:23s
epoch 52 | loss: 0.28294 | val_0_rmse: 0.61129 | val_1_rmse: 0.59366 |  0:00:24s
epoch 53 | loss: 0.27893 | val_0_rmse: 0.60333 | val_1_rmse: 0.58166 |  0:00:24s
epoch 54 | loss: 0.27635 | val_0_rmse: 0.61155 | val_1_rmse: 0.59497 |  0:00:25s
epoch 55 | loss: 0.26317 | val_0_rmse: 0.57823 | val_1_rmse: 0.57049 |  0:00:25s
epoch 56 | loss: 0.27117 | val_0_rmse: 0.58581 | val_1_rmse: 0.57657 |  0:00:25s
epoch 57 | loss: 0.27625 | val_0_rmse: 0.5747  | val_1_rmse: 0.56589 |  0:00:26s
epoch 58 | loss: 0.26733 | val_0_rmse: 0.58033 | val_1_rmse: 0.56903 |  0:00:26s
epoch 59 | loss: 0.27114 | val_0_rmse: 0.57315 | val_1_rmse: 0.56228 |  0:00:27s
epoch 60 | loss: 0.25805 | val_0_rmse: 0.58598 | val_1_rmse: 0.58403 |  0:00:27s
epoch 61 | loss: 0.26805 | val_0_rmse: 0.59243 | val_1_rmse: 0.58196 |  0:00:28s
epoch 62 | loss: 0.26641 | val_0_rmse: 0.56634 | val_1_rmse: 0.55868 |  0:00:28s
epoch 63 | loss: 0.25902 | val_0_rmse: 0.57084 | val_1_rmse: 0.55575 |  0:00:29s
epoch 64 | loss: 0.26398 | val_0_rmse: 0.55574 | val_1_rmse: 0.54571 |  0:00:29s
epoch 65 | loss: 0.26144 | val_0_rmse: 0.56017 | val_1_rmse: 0.55036 |  0:00:30s
epoch 66 | loss: 0.25327 | val_0_rmse: 0.56089 | val_1_rmse: 0.55412 |  0:00:30s
epoch 67 | loss: 0.2585  | val_0_rmse: 0.56179 | val_1_rmse: 0.55189 |  0:00:31s
epoch 68 | loss: 0.2554  | val_0_rmse: 0.55581 | val_1_rmse: 0.54938 |  0:00:31s
epoch 69 | loss: 0.25571 | val_0_rmse: 0.56904 | val_1_rmse: 0.56235 |  0:00:31s
epoch 70 | loss: 0.25652 | val_0_rmse: 0.55671 | val_1_rmse: 0.55584 |  0:00:32s
epoch 71 | loss: 0.25329 | val_0_rmse: 0.55002 | val_1_rmse: 0.55003 |  0:00:32s
epoch 72 | loss: 0.25049 | val_0_rmse: 0.55154 | val_1_rmse: 0.55507 |  0:00:33s
epoch 73 | loss: 0.24711 | val_0_rmse: 0.54189 | val_1_rmse: 0.55163 |  0:00:33s
epoch 74 | loss: 0.24381 | val_0_rmse: 0.539   | val_1_rmse: 0.54843 |  0:00:34s
epoch 75 | loss: 0.25539 | val_0_rmse: 0.52974 | val_1_rmse: 0.53462 |  0:00:34s
epoch 76 | loss: 0.24022 | val_0_rmse: 0.54404 | val_1_rmse: 0.55355 |  0:00:35s
epoch 77 | loss: 0.23785 | val_0_rmse: 0.53673 | val_1_rmse: 0.54648 |  0:00:35s
epoch 78 | loss: 0.24141 | val_0_rmse: 0.53263 | val_1_rmse: 0.54941 |  0:00:36s
epoch 79 | loss: 0.24098 | val_0_rmse: 0.5328  | val_1_rmse: 0.54071 |  0:00:36s
epoch 80 | loss: 0.23986 | val_0_rmse: 0.52988 | val_1_rmse: 0.54366 |  0:00:36s
epoch 81 | loss: 0.23668 | val_0_rmse: 0.54772 | val_1_rmse: 0.57243 |  0:00:37s
epoch 82 | loss: 0.24005 | val_0_rmse: 0.53737 | val_1_rmse: 0.55427 |  0:00:37s
epoch 83 | loss: 0.23311 | val_0_rmse: 0.5294  | val_1_rmse: 0.55519 |  0:00:38s
epoch 84 | loss: 0.23169 | val_0_rmse: 0.52118 | val_1_rmse: 0.54236 |  0:00:38s
epoch 85 | loss: 0.23224 | val_0_rmse: 0.55407 | val_1_rmse: 0.57041 |  0:00:39s
epoch 86 | loss: 0.24243 | val_0_rmse: 0.522   | val_1_rmse: 0.5495  |  0:00:39s
epoch 87 | loss: 0.23938 | val_0_rmse: 0.53713 | val_1_rmse: 0.55782 |  0:00:40s
epoch 88 | loss: 0.24544 | val_0_rmse: 0.53104 | val_1_rmse: 0.5542  |  0:00:40s
epoch 89 | loss: 0.23866 | val_0_rmse: 0.51748 | val_1_rmse: 0.53759 |  0:00:40s
epoch 90 | loss: 0.23247 | val_0_rmse: 0.51268 | val_1_rmse: 0.53411 |  0:00:41s
epoch 91 | loss: 0.23125 | val_0_rmse: 0.50727 | val_1_rmse: 0.53481 |  0:00:41s
epoch 92 | loss: 0.23122 | val_0_rmse: 0.4961  | val_1_rmse: 0.52171 |  0:00:42s
epoch 93 | loss: 0.23078 | val_0_rmse: 0.50015 | val_1_rmse: 0.52685 |  0:00:42s
epoch 94 | loss: 0.22988 | val_0_rmse: 0.48556 | val_1_rmse: 0.52467 |  0:00:43s
epoch 95 | loss: 0.2346  | val_0_rmse: 0.50421 | val_1_rmse: 0.54249 |  0:00:43s
epoch 96 | loss: 0.24408 | val_0_rmse: 0.48871 | val_1_rmse: 0.52514 |  0:00:44s
epoch 97 | loss: 0.22484 | val_0_rmse: 0.49507 | val_1_rmse: 0.5353  |  0:00:44s
epoch 98 | loss: 0.22302 | val_0_rmse: 0.51082 | val_1_rmse: 0.53948 |  0:00:45s
epoch 99 | loss: 0.22025 | val_0_rmse: 0.48888 | val_1_rmse: 0.52941 |  0:00:45s
epoch 100| loss: 0.22822 | val_0_rmse: 0.48012 | val_1_rmse: 0.52112 |  0:00:45s
epoch 101| loss: 0.2152  | val_0_rmse: 0.49094 | val_1_rmse: 0.52256 |  0:00:46s
epoch 102| loss: 0.22717 | val_0_rmse: 0.48393 | val_1_rmse: 0.52108 |  0:00:46s
epoch 103| loss: 0.23372 | val_0_rmse: 0.48174 | val_1_rmse: 0.52471 |  0:00:47s
epoch 104| loss: 0.22548 | val_0_rmse: 0.47499 | val_1_rmse: 0.52596 |  0:00:47s
epoch 105| loss: 0.22566 | val_0_rmse: 0.47145 | val_1_rmse: 0.52216 |  0:00:48s
epoch 106| loss: 0.2245  | val_0_rmse: 0.48227 | val_1_rmse: 0.52486 |  0:00:48s
epoch 107| loss: 0.22058 | val_0_rmse: 0.46687 | val_1_rmse: 0.52601 |  0:00:49s
epoch 108| loss: 0.22368 | val_0_rmse: 0.47259 | val_1_rmse: 0.52303 |  0:00:49s
epoch 109| loss: 0.22306 | val_0_rmse: 0.46939 | val_1_rmse: 0.51878 |  0:00:50s
epoch 110| loss: 0.21689 | val_0_rmse: 0.46645 | val_1_rmse: 0.51744 |  0:00:50s
epoch 111| loss: 0.22106 | val_0_rmse: 0.47541 | val_1_rmse: 0.52713 |  0:00:51s
epoch 112| loss: 0.21166 | val_0_rmse: 0.46108 | val_1_rmse: 0.52546 |  0:00:51s
epoch 113| loss: 0.20969 | val_0_rmse: 0.4588  | val_1_rmse: 0.52133 |  0:00:51s
epoch 114| loss: 0.21696 | val_0_rmse: 0.45616 | val_1_rmse: 0.51855 |  0:00:52s
epoch 115| loss: 0.20964 | val_0_rmse: 0.45345 | val_1_rmse: 0.51884 |  0:00:52s
epoch 116| loss: 0.2131  | val_0_rmse: 0.48129 | val_1_rmse: 0.53059 |  0:00:53s
epoch 117| loss: 0.21565 | val_0_rmse: 0.45524 | val_1_rmse: 0.52165 |  0:00:53s
epoch 118| loss: 0.21418 | val_0_rmse: 0.45781 | val_1_rmse: 0.5205  |  0:00:54s
epoch 119| loss: 0.21094 | val_0_rmse: 0.45863 | val_1_rmse: 0.52943 |  0:00:54s
epoch 120| loss: 0.21668 | val_0_rmse: 0.44651 | val_1_rmse: 0.51965 |  0:00:55s
epoch 121| loss: 0.21643 | val_0_rmse: 0.45742 | val_1_rmse: 0.53543 |  0:00:55s
epoch 122| loss: 0.21166 | val_0_rmse: 0.4485  | val_1_rmse: 0.52025 |  0:00:55s
epoch 123| loss: 0.21731 | val_0_rmse: 0.45141 | val_1_rmse: 0.53367 |  0:00:56s
epoch 124| loss: 0.22489 | val_0_rmse: 0.44806 | val_1_rmse: 0.522   |  0:00:56s
epoch 125| loss: 0.21986 | val_0_rmse: 0.44648 | val_1_rmse: 0.53104 |  0:00:57s
epoch 126| loss: 0.20843 | val_0_rmse: 0.44967 | val_1_rmse: 0.54223 |  0:00:57s
epoch 127| loss: 0.21337 | val_0_rmse: 0.43988 | val_1_rmse: 0.52511 |  0:00:58s
epoch 128| loss: 0.20198 | val_0_rmse: 0.43488 | val_1_rmse: 0.5292  |  0:00:58s
epoch 129| loss: 0.19998 | val_0_rmse: 0.43879 | val_1_rmse: 0.52318 |  0:00:59s
epoch 130| loss: 0.19727 | val_0_rmse: 0.4335  | val_1_rmse: 0.52446 |  0:00:59s
epoch 131| loss: 0.19203 | val_0_rmse: 0.42761 | val_1_rmse: 0.52293 |  0:01:00s
epoch 132| loss: 0.19351 | val_0_rmse: 0.43274 | val_1_rmse: 0.53554 |  0:01:00s
epoch 133| loss: 0.20355 | val_0_rmse: 0.42808 | val_1_rmse: 0.52768 |  0:01:00s
epoch 134| loss: 0.19811 | val_0_rmse: 0.42864 | val_1_rmse: 0.52819 |  0:01:01s
epoch 135| loss: 0.20002 | val_0_rmse: 0.42764 | val_1_rmse: 0.52517 |  0:01:01s
epoch 136| loss: 0.19345 | val_0_rmse: 0.42482 | val_1_rmse: 0.52608 |  0:01:02s
epoch 137| loss: 0.19551 | val_0_rmse: 0.42206 | val_1_rmse: 0.53291 |  0:01:02s
epoch 138| loss: 0.19601 | val_0_rmse: 0.42827 | val_1_rmse: 0.53735 |  0:01:03s
epoch 139| loss: 0.18697 | val_0_rmse: 0.41972 | val_1_rmse: 0.54595 |  0:01:03s
epoch 140| loss: 0.19267 | val_0_rmse: 0.41757 | val_1_rmse: 0.53909 |  0:01:04s

Early stopping occured at epoch 140 with best_epoch = 110 and best_val_1_rmse = 0.51744
Best weights from best epoch are automatically used!
ended training at: 08:23:44
Feature importance:
Mean squared error is of 2303067190.7412314
Mean absolute error:33275.860504452925
MAPE:0.28533654694691907
R2 score:0.7087560295928175
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 4
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:23:44
epoch 0  | loss: 1.62795 | val_0_rmse: 0.9998  | val_1_rmse: 0.96452 |  0:00:00s
epoch 1  | loss: 1.06995 | val_0_rmse: 0.92396 | val_1_rmse: 0.89576 |  0:00:00s
epoch 2  | loss: 0.94038 | val_0_rmse: 0.87602 | val_1_rmse: 0.8456  |  0:00:01s
epoch 3  | loss: 0.74968 | val_0_rmse: 0.82925 | val_1_rmse: 0.84375 |  0:00:01s
epoch 4  | loss: 0.61376 | val_0_rmse: 0.8257  | val_1_rmse: 0.86914 |  0:00:02s
epoch 5  | loss: 0.50113 | val_0_rmse: 0.93622 | val_1_rmse: 1.01382 |  0:00:02s
epoch 6  | loss: 0.48301 | val_0_rmse: 0.80559 | val_1_rmse: 0.86111 |  0:00:03s
epoch 7  | loss: 0.44414 | val_0_rmse: 0.96739 | val_1_rmse: 1.03228 |  0:00:03s
epoch 8  | loss: 0.41844 | val_0_rmse: 0.72557 | val_1_rmse: 0.73748 |  0:00:04s
epoch 9  | loss: 0.41886 | val_0_rmse: 0.7809  | val_1_rmse: 0.80348 |  0:00:04s
epoch 10 | loss: 0.39256 | val_0_rmse: 0.68402 | val_1_rmse: 0.69085 |  0:00:05s
epoch 11 | loss: 0.37195 | val_0_rmse: 0.7036  | val_1_rmse: 0.70664 |  0:00:05s
epoch 12 | loss: 0.36944 | val_0_rmse: 0.65682 | val_1_rmse: 0.64968 |  0:00:05s
epoch 13 | loss: 0.35341 | val_0_rmse: 0.65715 | val_1_rmse: 0.66197 |  0:00:06s
epoch 14 | loss: 0.34069 | val_0_rmse: 0.6647  | val_1_rmse: 0.66851 |  0:00:06s
epoch 15 | loss: 0.33387 | val_0_rmse: 0.67756 | val_1_rmse: 0.68962 |  0:00:07s
epoch 16 | loss: 0.32272 | val_0_rmse: 0.66113 | val_1_rmse: 0.65714 |  0:00:07s
epoch 17 | loss: 0.32458 | val_0_rmse: 0.6957  | val_1_rmse: 0.67176 |  0:00:08s
epoch 18 | loss: 0.32192 | val_0_rmse: 0.68982 | val_1_rmse: 0.66517 |  0:00:08s
epoch 19 | loss: 0.32709 | val_0_rmse: 0.67656 | val_1_rmse: 0.65709 |  0:00:09s
epoch 20 | loss: 0.31863 | val_0_rmse: 0.69997 | val_1_rmse: 0.68893 |  0:00:09s
epoch 21 | loss: 0.31034 | val_0_rmse: 0.67605 | val_1_rmse: 0.66367 |  0:00:10s
epoch 22 | loss: 0.30006 | val_0_rmse: 0.67692 | val_1_rmse: 0.65837 |  0:00:10s
epoch 23 | loss: 0.30938 | val_0_rmse: 0.69366 | val_1_rmse: 0.66614 |  0:00:11s
epoch 24 | loss: 0.30315 | val_0_rmse: 0.72364 | val_1_rmse: 0.69369 |  0:00:11s
epoch 25 | loss: 0.30789 | val_0_rmse: 0.70998 | val_1_rmse: 0.68446 |  0:00:11s
epoch 26 | loss: 0.28325 | val_0_rmse: 0.69541 | val_1_rmse: 0.67424 |  0:00:12s
epoch 27 | loss: 0.28185 | val_0_rmse: 0.67821 | val_1_rmse: 0.65563 |  0:00:12s
epoch 28 | loss: 0.27945 | val_0_rmse: 0.66633 | val_1_rmse: 0.65217 |  0:00:13s
epoch 29 | loss: 0.26186 | val_0_rmse: 0.67404 | val_1_rmse: 0.65223 |  0:00:13s
epoch 30 | loss: 0.27268 | val_0_rmse: 0.67087 | val_1_rmse: 0.65019 |  0:00:14s
epoch 31 | loss: 0.27202 | val_0_rmse: 0.66275 | val_1_rmse: 0.63953 |  0:00:14s
epoch 32 | loss: 0.27658 | val_0_rmse: 0.64328 | val_1_rmse: 0.6353  |  0:00:15s
epoch 33 | loss: 0.27082 | val_0_rmse: 0.63553 | val_1_rmse: 0.62334 |  0:00:15s
epoch 34 | loss: 0.27078 | val_0_rmse: 0.64793 | val_1_rmse: 0.62817 |  0:00:16s
epoch 35 | loss: 0.26146 | val_0_rmse: 0.64725 | val_1_rmse: 0.63322 |  0:00:16s
epoch 36 | loss: 0.25639 | val_0_rmse: 0.63654 | val_1_rmse: 0.62276 |  0:00:16s
epoch 37 | loss: 0.26137 | val_0_rmse: 0.65598 | val_1_rmse: 0.64488 |  0:00:17s
epoch 38 | loss: 0.2512  | val_0_rmse: 0.64768 | val_1_rmse: 0.63462 |  0:00:17s
epoch 39 | loss: 0.2524  | val_0_rmse: 0.62913 | val_1_rmse: 0.61625 |  0:00:18s
epoch 40 | loss: 0.23822 | val_0_rmse: 0.66198 | val_1_rmse: 0.64659 |  0:00:18s
epoch 41 | loss: 0.24886 | val_0_rmse: 0.64359 | val_1_rmse: 0.63768 |  0:00:19s
epoch 42 | loss: 0.25399 | val_0_rmse: 0.61568 | val_1_rmse: 0.61253 |  0:00:19s
epoch 43 | loss: 0.24656 | val_0_rmse: 0.60885 | val_1_rmse: 0.61073 |  0:00:20s
epoch 44 | loss: 0.25236 | val_0_rmse: 0.59444 | val_1_rmse: 0.60368 |  0:00:20s
epoch 45 | loss: 0.25958 | val_0_rmse: 0.59924 | val_1_rmse: 0.59849 |  0:00:21s
epoch 46 | loss: 0.23965 | val_0_rmse: 0.5865  | val_1_rmse: 0.59297 |  0:00:21s
epoch 47 | loss: 0.23474 | val_0_rmse: 0.59768 | val_1_rmse: 0.60295 |  0:00:22s
epoch 48 | loss: 0.23695 | val_0_rmse: 0.61736 | val_1_rmse: 0.61793 |  0:00:22s
epoch 49 | loss: 0.23587 | val_0_rmse: 0.5961  | val_1_rmse: 0.59983 |  0:00:22s
epoch 50 | loss: 0.22985 | val_0_rmse: 0.60236 | val_1_rmse: 0.6065  |  0:00:23s
epoch 51 | loss: 0.22882 | val_0_rmse: 0.57821 | val_1_rmse: 0.5929  |  0:00:23s
epoch 52 | loss: 0.23228 | val_0_rmse: 0.59512 | val_1_rmse: 0.60622 |  0:00:24s
epoch 53 | loss: 0.22283 | val_0_rmse: 0.58375 | val_1_rmse: 0.59712 |  0:00:24s
epoch 54 | loss: 0.22239 | val_0_rmse: 0.57737 | val_1_rmse: 0.59371 |  0:00:25s
epoch 55 | loss: 0.23095 | val_0_rmse: 0.58638 | val_1_rmse: 0.59178 |  0:00:25s
epoch 56 | loss: 0.22764 | val_0_rmse: 0.55885 | val_1_rmse: 0.57444 |  0:00:26s
epoch 57 | loss: 0.21306 | val_0_rmse: 0.55492 | val_1_rmse: 0.57479 |  0:00:26s
epoch 58 | loss: 0.21553 | val_0_rmse: 0.55909 | val_1_rmse: 0.57968 |  0:00:27s
epoch 59 | loss: 0.22562 | val_0_rmse: 0.55551 | val_1_rmse: 0.57166 |  0:00:27s
epoch 60 | loss: 0.2213  | val_0_rmse: 0.56364 | val_1_rmse: 0.57508 |  0:00:27s
epoch 61 | loss: 0.22612 | val_0_rmse: 0.5993  | val_1_rmse: 0.59865 |  0:00:28s
epoch 62 | loss: 0.22211 | val_0_rmse: 0.57594 | val_1_rmse: 0.58041 |  0:00:28s
epoch 63 | loss: 0.21988 | val_0_rmse: 0.58537 | val_1_rmse: 0.59025 |  0:00:29s
epoch 64 | loss: 0.21935 | val_0_rmse: 0.55578 | val_1_rmse: 0.57579 |  0:00:29s
epoch 65 | loss: 0.2137  | val_0_rmse: 0.54054 | val_1_rmse: 0.57036 |  0:00:30s
epoch 66 | loss: 0.2149  | val_0_rmse: 0.54796 | val_1_rmse: 0.57549 |  0:00:30s
epoch 67 | loss: 0.21892 | val_0_rmse: 0.52701 | val_1_rmse: 0.55331 |  0:00:31s
epoch 68 | loss: 0.22269 | val_0_rmse: 0.53271 | val_1_rmse: 0.55155 |  0:00:31s
epoch 69 | loss: 0.22163 | val_0_rmse: 0.546   | val_1_rmse: 0.56266 |  0:00:32s
epoch 70 | loss: 0.22161 | val_0_rmse: 0.55307 | val_1_rmse: 0.57812 |  0:00:32s
epoch 71 | loss: 0.23173 | val_0_rmse: 0.57426 | val_1_rmse: 0.57738 |  0:00:32s
epoch 72 | loss: 0.22919 | val_0_rmse: 0.54692 | val_1_rmse: 0.56087 |  0:00:33s
epoch 73 | loss: 0.22166 | val_0_rmse: 0.53679 | val_1_rmse: 0.56116 |  0:00:33s
epoch 74 | loss: 0.23092 | val_0_rmse: 0.51772 | val_1_rmse: 0.54927 |  0:00:34s
epoch 75 | loss: 0.22199 | val_0_rmse: 0.52402 | val_1_rmse: 0.53939 |  0:00:34s
epoch 76 | loss: 0.20797 | val_0_rmse: 0.51382 | val_1_rmse: 0.53699 |  0:00:35s
epoch 77 | loss: 0.21317 | val_0_rmse: 0.53011 | val_1_rmse: 0.55103 |  0:00:35s
epoch 78 | loss: 0.21523 | val_0_rmse: 0.51872 | val_1_rmse: 0.54845 |  0:00:36s
epoch 79 | loss: 0.21728 | val_0_rmse: 0.52904 | val_1_rmse: 0.55798 |  0:00:36s
epoch 80 | loss: 0.2135  | val_0_rmse: 0.51569 | val_1_rmse: 0.54569 |  0:00:36s
epoch 81 | loss: 0.21045 | val_0_rmse: 0.50062 | val_1_rmse: 0.53452 |  0:00:37s
epoch 82 | loss: 0.20797 | val_0_rmse: 0.50022 | val_1_rmse: 0.53586 |  0:00:37s
epoch 83 | loss: 0.20286 | val_0_rmse: 0.52791 | val_1_rmse: 0.55126 |  0:00:38s
epoch 84 | loss: 0.20162 | val_0_rmse: 0.51137 | val_1_rmse: 0.53769 |  0:00:38s
epoch 85 | loss: 0.20514 | val_0_rmse: 0.49754 | val_1_rmse: 0.53284 |  0:00:39s
epoch 86 | loss: 0.20818 | val_0_rmse: 0.51063 | val_1_rmse: 0.53853 |  0:00:39s
epoch 87 | loss: 0.20887 | val_0_rmse: 0.48351 | val_1_rmse: 0.5385  |  0:00:40s
epoch 88 | loss: 0.18957 | val_0_rmse: 0.48999 | val_1_rmse: 0.54386 |  0:00:40s
epoch 89 | loss: 0.20295 | val_0_rmse: 0.50404 | val_1_rmse: 0.54969 |  0:00:41s
epoch 90 | loss: 0.19819 | val_0_rmse: 0.49492 | val_1_rmse: 0.5435  |  0:00:41s
epoch 91 | loss: 0.1927  | val_0_rmse: 0.48    | val_1_rmse: 0.53171 |  0:00:41s
epoch 92 | loss: 0.19365 | val_0_rmse: 0.48    | val_1_rmse: 0.541   |  0:00:42s
epoch 93 | loss: 0.19667 | val_0_rmse: 0.48137 | val_1_rmse: 0.54208 |  0:00:42s
epoch 94 | loss: 0.19795 | val_0_rmse: 0.54459 | val_1_rmse: 0.57788 |  0:00:43s
epoch 95 | loss: 0.19066 | val_0_rmse: 0.49298 | val_1_rmse: 0.55406 |  0:00:43s
epoch 96 | loss: 0.19978 | val_0_rmse: 0.47565 | val_1_rmse: 0.54366 |  0:00:44s
epoch 97 | loss: 0.19496 | val_0_rmse: 0.48794 | val_1_rmse: 0.55892 |  0:00:44s
epoch 98 | loss: 0.19559 | val_0_rmse: 0.46627 | val_1_rmse: 0.55101 |  0:00:45s
epoch 99 | loss: 0.19191 | val_0_rmse: 0.47189 | val_1_rmse: 0.54348 |  0:00:45s
epoch 100| loss: 0.20313 | val_0_rmse: 0.47221 | val_1_rmse: 0.55409 |  0:00:45s
epoch 101| loss: 0.19078 | val_0_rmse: 0.47672 | val_1_rmse: 0.54701 |  0:00:46s
epoch 102| loss: 0.20567 | val_0_rmse: 0.47821 | val_1_rmse: 0.5446  |  0:00:46s
epoch 103| loss: 0.19826 | val_0_rmse: 0.47395 | val_1_rmse: 0.55318 |  0:00:47s
epoch 104| loss: 0.19792 | val_0_rmse: 0.49222 | val_1_rmse: 0.58056 |  0:00:47s
epoch 105| loss: 0.19633 | val_0_rmse: 0.46504 | val_1_rmse: 0.54604 |  0:00:48s
epoch 106| loss: 0.18942 | val_0_rmse: 0.46406 | val_1_rmse: 0.53771 |  0:00:48s
epoch 107| loss: 0.18533 | val_0_rmse: 0.47161 | val_1_rmse: 0.5528  |  0:00:49s
epoch 108| loss: 0.1919  | val_0_rmse: 0.45555 | val_1_rmse: 0.55233 |  0:00:49s
epoch 109| loss: 0.18583 | val_0_rmse: 0.4519  | val_1_rmse: 0.53316 |  0:00:50s
epoch 110| loss: 0.20216 | val_0_rmse: 0.44845 | val_1_rmse: 0.52131 |  0:00:50s
epoch 111| loss: 0.18888 | val_0_rmse: 0.45715 | val_1_rmse: 0.54047 |  0:00:50s
epoch 112| loss: 0.19784 | val_0_rmse: 0.45127 | val_1_rmse: 0.53302 |  0:00:51s
epoch 113| loss: 0.19593 | val_0_rmse: 0.46101 | val_1_rmse: 0.54459 |  0:00:51s
epoch 114| loss: 0.19419 | val_0_rmse: 0.44063 | val_1_rmse: 0.56942 |  0:00:52s
epoch 115| loss: 0.20508 | val_0_rmse: 0.43491 | val_1_rmse: 0.54865 |  0:00:52s
epoch 116| loss: 0.19843 | val_0_rmse: 0.42918 | val_1_rmse: 0.55847 |  0:00:53s
epoch 117| loss: 0.18771 | val_0_rmse: 0.4299  | val_1_rmse: 0.54237 |  0:00:53s
epoch 118| loss: 0.18239 | val_0_rmse: 0.43196 | val_1_rmse: 0.54568 |  0:00:54s
epoch 119| loss: 0.18669 | val_0_rmse: 0.41755 | val_1_rmse: 0.56955 |  0:00:54s
epoch 120| loss: 0.18151 | val_0_rmse: 0.43152 | val_1_rmse: 0.5445  |  0:00:55s
epoch 121| loss: 0.18598 | val_0_rmse: 0.41701 | val_1_rmse: 0.53467 |  0:00:55s
epoch 122| loss: 0.17853 | val_0_rmse: 0.41377 | val_1_rmse: 0.52901 |  0:00:55s
epoch 123| loss: 0.17534 | val_0_rmse: 0.41432 | val_1_rmse: 0.54286 |  0:00:56s
epoch 124| loss: 0.18429 | val_0_rmse: 0.41613 | val_1_rmse: 0.54084 |  0:00:56s
epoch 125| loss: 0.1914  | val_0_rmse: 0.42293 | val_1_rmse: 0.56248 |  0:00:57s
epoch 126| loss: 0.18283 | val_0_rmse: 0.4236  | val_1_rmse: 0.52534 |  0:00:57s
epoch 127| loss: 0.18165 | val_0_rmse: 0.40821 | val_1_rmse: 0.53126 |  0:00:58s
epoch 128| loss: 0.17886 | val_0_rmse: 0.40712 | val_1_rmse: 0.53087 |  0:00:58s
epoch 129| loss: 0.17569 | val_0_rmse: 0.40809 | val_1_rmse: 0.53541 |  0:00:59s
epoch 130| loss: 0.17219 | val_0_rmse: 0.39913 | val_1_rmse: 0.52793 |  0:00:59s
epoch 131| loss: 0.17286 | val_0_rmse: 0.39046 | val_1_rmse: 0.53474 |  0:01:00s
epoch 132| loss: 0.17158 | val_0_rmse: 0.38949 | val_1_rmse: 0.53688 |  0:01:00s
epoch 133| loss: 0.16777 | val_0_rmse: 0.39481 | val_1_rmse: 0.53562 |  0:01:00s
epoch 134| loss: 0.17437 | val_0_rmse: 0.39303 | val_1_rmse: 0.55025 |  0:01:01s
epoch 135| loss: 0.18081 | val_0_rmse: 0.39895 | val_1_rmse: 0.53468 |  0:01:01s
epoch 136| loss: 0.17038 | val_0_rmse: 0.39473 | val_1_rmse: 0.53751 |  0:01:02s
epoch 137| loss: 0.16794 | val_0_rmse: 0.3995  | val_1_rmse: 0.54751 |  0:01:02s
epoch 138| loss: 0.16467 | val_0_rmse: 0.38694 | val_1_rmse: 0.55877 |  0:01:03s
epoch 139| loss: 0.17089 | val_0_rmse: 0.38501 | val_1_rmse: 0.53988 |  0:01:03s
epoch 140| loss: 0.16715 | val_0_rmse: 0.38693 | val_1_rmse: 0.54439 |  0:01:04s

Early stopping occured at epoch 140 with best_epoch = 110 and best_val_1_rmse = 0.52131
Best weights from best epoch are automatically used!
ended training at: 08:24:48
Feature importance:
Mean squared error is of 2840650000.383226
Mean absolute error:34879.32123061785
MAPE:0.23825406981364902
R2 score:0.6813511037467743
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 5
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:24:48
epoch 0  | loss: 1.52561 | val_0_rmse: 0.98714 | val_1_rmse: 0.98463 |  0:00:00s
epoch 1  | loss: 0.96032 | val_0_rmse: 0.92126 | val_1_rmse: 0.92309 |  0:00:00s
epoch 2  | loss: 0.82834 | val_0_rmse: 0.86923 | val_1_rmse: 0.89429 |  0:00:01s
epoch 3  | loss: 0.64324 | val_0_rmse: 0.76982 | val_1_rmse: 0.78353 |  0:00:01s
epoch 4  | loss: 0.58436 | val_0_rmse: 0.76215 | val_1_rmse: 0.77271 |  0:00:02s
epoch 5  | loss: 0.54046 | val_0_rmse: 0.82387 | val_1_rmse: 0.83411 |  0:00:02s
epoch 6  | loss: 0.51879 | val_0_rmse: 0.86539 | val_1_rmse: 0.79038 |  0:00:03s
epoch 7  | loss: 0.52479 | val_0_rmse: 0.77375 | val_1_rmse: 0.77876 |  0:00:03s
epoch 8  | loss: 0.51469 | val_0_rmse: 0.74013 | val_1_rmse: 0.7612  |  0:00:04s
epoch 9  | loss: 0.46888 | val_0_rmse: 0.73006 | val_1_rmse: 0.73463 |  0:00:04s
epoch 10 | loss: 0.4513  | val_0_rmse: 0.71888 | val_1_rmse: 0.71935 |  0:00:05s
epoch 11 | loss: 0.44179 | val_0_rmse: 0.71757 | val_1_rmse: 0.71907 |  0:00:05s
epoch 12 | loss: 0.41385 | val_0_rmse: 0.76484 | val_1_rmse: 0.77029 |  0:00:06s
epoch 13 | loss: 0.41347 | val_0_rmse: 0.74386 | val_1_rmse: 0.74448 |  0:00:06s
epoch 14 | loss: 0.39191 | val_0_rmse: 0.73199 | val_1_rmse: 0.74898 |  0:00:06s
epoch 15 | loss: 0.38251 | val_0_rmse: 0.77699 | val_1_rmse: 0.79279 |  0:00:07s
epoch 16 | loss: 0.39051 | val_0_rmse: 0.74667 | val_1_rmse: 0.76029 |  0:00:07s
epoch 17 | loss: 0.36942 | val_0_rmse: 0.72677 | val_1_rmse: 0.75652 |  0:00:08s
epoch 18 | loss: 0.37569 | val_0_rmse: 0.67302 | val_1_rmse: 0.68369 |  0:00:08s
epoch 19 | loss: 0.36617 | val_0_rmse: 0.67688 | val_1_rmse: 0.68952 |  0:00:09s
epoch 20 | loss: 0.34241 | val_0_rmse: 0.65503 | val_1_rmse: 0.66436 |  0:00:09s
epoch 21 | loss: 0.35214 | val_0_rmse: 0.67734 | val_1_rmse: 0.68302 |  0:00:10s
epoch 22 | loss: 0.35063 | val_0_rmse: 0.67814 | val_1_rmse: 0.67574 |  0:00:10s
epoch 23 | loss: 0.33786 | val_0_rmse: 0.65048 | val_1_rmse: 0.65915 |  0:00:11s
epoch 24 | loss: 0.32649 | val_0_rmse: 0.65495 | val_1_rmse: 0.6658  |  0:00:11s
epoch 25 | loss: 0.32297 | val_0_rmse: 0.67179 | val_1_rmse: 0.67218 |  0:00:11s
epoch 26 | loss: 0.30491 | val_0_rmse: 0.65659 | val_1_rmse: 0.65886 |  0:00:12s
epoch 27 | loss: 0.30103 | val_0_rmse: 0.65417 | val_1_rmse: 0.65953 |  0:00:12s
epoch 28 | loss: 0.29541 | val_0_rmse: 0.6728  | val_1_rmse: 0.67959 |  0:00:13s
epoch 29 | loss: 0.3097  | val_0_rmse: 0.65379 | val_1_rmse: 0.66094 |  0:00:13s
epoch 30 | loss: 0.29389 | val_0_rmse: 0.63726 | val_1_rmse: 0.64614 |  0:00:14s
epoch 31 | loss: 0.29313 | val_0_rmse: 0.6429  | val_1_rmse: 0.65732 |  0:00:14s
epoch 32 | loss: 0.28323 | val_0_rmse: 0.64468 | val_1_rmse: 0.65461 |  0:00:15s
epoch 33 | loss: 0.28107 | val_0_rmse: 0.62265 | val_1_rmse: 0.64215 |  0:00:15s
epoch 34 | loss: 0.28296 | val_0_rmse: 0.62845 | val_1_rmse: 0.64069 |  0:00:16s
epoch 35 | loss: 0.27126 | val_0_rmse: 0.63879 | val_1_rmse: 0.65001 |  0:00:16s
epoch 36 | loss: 0.26776 | val_0_rmse: 0.61954 | val_1_rmse: 0.6362  |  0:00:17s
epoch 37 | loss: 0.28123 | val_0_rmse: 0.64935 | val_1_rmse: 0.66028 |  0:00:17s
epoch 38 | loss: 0.29642 | val_0_rmse: 0.66544 | val_1_rmse: 0.68    |  0:00:17s
epoch 39 | loss: 0.27593 | val_0_rmse: 0.62528 | val_1_rmse: 0.63722 |  0:00:18s
epoch 40 | loss: 0.28033 | val_0_rmse: 0.63791 | val_1_rmse: 0.65106 |  0:00:18s
epoch 41 | loss: 0.27321 | val_0_rmse: 0.63995 | val_1_rmse: 0.64901 |  0:00:19s
epoch 42 | loss: 0.27005 | val_0_rmse: 0.61032 | val_1_rmse: 0.62106 |  0:00:19s
epoch 43 | loss: 0.26262 | val_0_rmse: 0.60201 | val_1_rmse: 0.62609 |  0:00:20s
epoch 44 | loss: 0.2731  | val_0_rmse: 0.62736 | val_1_rmse: 0.65341 |  0:00:20s
epoch 45 | loss: 0.26863 | val_0_rmse: 0.64607 | val_1_rmse: 0.65672 |  0:00:21s
epoch 46 | loss: 0.2661  | val_0_rmse: 0.6186  | val_1_rmse: 0.64296 |  0:00:21s
epoch 47 | loss: 0.26408 | val_0_rmse: 0.61158 | val_1_rmse: 0.6422  |  0:00:22s
epoch 48 | loss: 0.25994 | val_0_rmse: 0.62359 | val_1_rmse: 0.6439  |  0:00:22s
epoch 49 | loss: 0.27053 | val_0_rmse: 0.63702 | val_1_rmse: 0.65312 |  0:00:22s
epoch 50 | loss: 0.26203 | val_0_rmse: 0.60328 | val_1_rmse: 0.63123 |  0:00:23s
epoch 51 | loss: 0.25681 | val_0_rmse: 0.61476 | val_1_rmse: 0.63733 |  0:00:23s
epoch 52 | loss: 0.26855 | val_0_rmse: 0.60165 | val_1_rmse: 0.63849 |  0:00:24s
epoch 53 | loss: 0.2527  | val_0_rmse: 0.61631 | val_1_rmse: 0.63179 |  0:00:24s
epoch 54 | loss: 0.26692 | val_0_rmse: 0.60354 | val_1_rmse: 0.63425 |  0:00:25s
epoch 55 | loss: 0.26311 | val_0_rmse: 0.59598 | val_1_rmse: 0.6258  |  0:00:25s
epoch 56 | loss: 0.2515  | val_0_rmse: 0.60281 | val_1_rmse: 0.62922 |  0:00:26s
epoch 57 | loss: 0.25582 | val_0_rmse: 0.59031 | val_1_rmse: 0.61719 |  0:00:26s
epoch 58 | loss: 0.25147 | val_0_rmse: 0.59393 | val_1_rmse: 0.62061 |  0:00:27s
epoch 59 | loss: 0.24124 | val_0_rmse: 0.5821  | val_1_rmse: 0.60957 |  0:00:27s
epoch 60 | loss: 0.24321 | val_0_rmse: 0.58165 | val_1_rmse: 0.61467 |  0:00:27s
epoch 61 | loss: 0.24141 | val_0_rmse: 0.57776 | val_1_rmse: 0.61504 |  0:00:28s
epoch 62 | loss: 0.24756 | val_0_rmse: 0.58439 | val_1_rmse: 0.61408 |  0:00:28s
epoch 63 | loss: 0.23846 | val_0_rmse: 0.57947 | val_1_rmse: 0.62462 |  0:00:29s
epoch 64 | loss: 0.23373 | val_0_rmse: 0.58125 | val_1_rmse: 0.61232 |  0:00:29s
epoch 65 | loss: 0.23782 | val_0_rmse: 0.5598  | val_1_rmse: 0.60049 |  0:00:30s
epoch 66 | loss: 0.2438  | val_0_rmse: 0.56134 | val_1_rmse: 0.60157 |  0:00:30s
epoch 67 | loss: 0.24485 | val_0_rmse: 0.56429 | val_1_rmse: 0.59739 |  0:00:31s
epoch 68 | loss: 0.23356 | val_0_rmse: 0.54598 | val_1_rmse: 0.58393 |  0:00:31s
epoch 69 | loss: 0.22743 | val_0_rmse: 0.5726  | val_1_rmse: 0.6045  |  0:00:32s
epoch 70 | loss: 0.22458 | val_0_rmse: 0.56448 | val_1_rmse: 0.6027  |  0:00:32s
epoch 71 | loss: 0.22068 | val_0_rmse: 0.56442 | val_1_rmse: 0.60211 |  0:00:32s
epoch 72 | loss: 0.22915 | val_0_rmse: 0.54342 | val_1_rmse: 0.58857 |  0:00:33s
epoch 73 | loss: 0.22326 | val_0_rmse: 0.54791 | val_1_rmse: 0.60101 |  0:00:33s
epoch 74 | loss: 0.22509 | val_0_rmse: 0.54358 | val_1_rmse: 0.60266 |  0:00:34s
epoch 75 | loss: 0.22262 | val_0_rmse: 0.53474 | val_1_rmse: 0.59306 |  0:00:34s
epoch 76 | loss: 0.22677 | val_0_rmse: 0.54117 | val_1_rmse: 0.5937  |  0:00:35s
epoch 77 | loss: 0.22739 | val_0_rmse: 0.53202 | val_1_rmse: 0.59019 |  0:00:35s
epoch 78 | loss: 0.21268 | val_0_rmse: 0.53227 | val_1_rmse: 0.60244 |  0:00:36s
epoch 79 | loss: 0.21361 | val_0_rmse: 0.5282  | val_1_rmse: 0.58662 |  0:00:36s
epoch 80 | loss: 0.20969 | val_0_rmse: 0.51985 | val_1_rmse: 0.58445 |  0:00:37s
epoch 81 | loss: 0.21747 | val_0_rmse: 0.55515 | val_1_rmse: 0.60601 |  0:00:37s
epoch 82 | loss: 0.2156  | val_0_rmse: 0.52439 | val_1_rmse: 0.58428 |  0:00:37s
epoch 83 | loss: 0.21167 | val_0_rmse: 0.51893 | val_1_rmse: 0.58519 |  0:00:38s
epoch 84 | loss: 0.21853 | val_0_rmse: 0.51266 | val_1_rmse: 0.58178 |  0:00:38s
epoch 85 | loss: 0.20981 | val_0_rmse: 0.5279  | val_1_rmse: 0.58578 |  0:00:39s
epoch 86 | loss: 0.20561 | val_0_rmse: 0.51249 | val_1_rmse: 0.5955  |  0:00:39s
epoch 87 | loss: 0.20566 | val_0_rmse: 0.51389 | val_1_rmse: 0.59006 |  0:00:40s
epoch 88 | loss: 0.20262 | val_0_rmse: 0.50511 | val_1_rmse: 0.58899 |  0:00:40s
epoch 89 | loss: 0.20643 | val_0_rmse: 0.50153 | val_1_rmse: 0.59675 |  0:00:41s
epoch 90 | loss: 0.20483 | val_0_rmse: 0.49956 | val_1_rmse: 0.57975 |  0:00:41s
epoch 91 | loss: 0.20396 | val_0_rmse: 0.50935 | val_1_rmse: 0.583   |  0:00:42s
epoch 92 | loss: 0.20782 | val_0_rmse: 0.48279 | val_1_rmse: 0.57279 |  0:00:42s
epoch 93 | loss: 0.20561 | val_0_rmse: 0.4884  | val_1_rmse: 0.58224 |  0:00:42s
epoch 94 | loss: 0.20339 | val_0_rmse: 0.47439 | val_1_rmse: 0.57534 |  0:00:43s
epoch 95 | loss: 0.19735 | val_0_rmse: 0.48736 | val_1_rmse: 0.57631 |  0:00:43s
epoch 96 | loss: 0.2038  | val_0_rmse: 0.47949 | val_1_rmse: 0.57142 |  0:00:44s
epoch 97 | loss: 0.20115 | val_0_rmse: 0.50057 | val_1_rmse: 0.58556 |  0:00:44s
epoch 98 | loss: 0.20567 | val_0_rmse: 0.45872 | val_1_rmse: 0.56992 |  0:00:45s
epoch 99 | loss: 0.19664 | val_0_rmse: 0.47497 | val_1_rmse: 0.59507 |  0:00:45s
epoch 100| loss: 0.20282 | val_0_rmse: 0.46855 | val_1_rmse: 0.59657 |  0:00:46s
epoch 101| loss: 0.19386 | val_0_rmse: 0.46342 | val_1_rmse: 0.57863 |  0:00:46s
epoch 102| loss: 0.18736 | val_0_rmse: 0.47716 | val_1_rmse: 0.59212 |  0:00:47s
epoch 103| loss: 0.19788 | val_0_rmse: 0.47066 | val_1_rmse: 0.59185 |  0:00:47s
epoch 104| loss: 0.19136 | val_0_rmse: 0.46105 | val_1_rmse: 0.58142 |  0:00:47s
epoch 105| loss: 0.19191 | val_0_rmse: 0.45056 | val_1_rmse: 0.59231 |  0:00:48s
epoch 106| loss: 0.19971 | val_0_rmse: 0.44979 | val_1_rmse: 0.57002 |  0:00:48s
epoch 107| loss: 0.20446 | val_0_rmse: 0.45067 | val_1_rmse: 0.57992 |  0:00:49s
epoch 108| loss: 0.20363 | val_0_rmse: 0.46685 | val_1_rmse: 0.57544 |  0:00:49s
epoch 109| loss: 0.19222 | val_0_rmse: 0.45264 | val_1_rmse: 0.57637 |  0:00:50s
epoch 110| loss: 0.19408 | val_0_rmse: 0.45072 | val_1_rmse: 0.55154 |  0:00:50s
epoch 111| loss: 0.19791 | val_0_rmse: 0.46178 | val_1_rmse: 0.55153 |  0:00:51s
epoch 112| loss: 0.18858 | val_0_rmse: 0.44771 | val_1_rmse: 0.56076 |  0:00:51s
epoch 113| loss: 0.18802 | val_0_rmse: 0.45034 | val_1_rmse: 0.56242 |  0:00:52s
epoch 114| loss: 0.19049 | val_0_rmse: 0.43764 | val_1_rmse: 0.5709  |  0:00:52s
epoch 115| loss: 0.18847 | val_0_rmse: 0.4368  | val_1_rmse: 0.56337 |  0:00:53s
epoch 116| loss: 0.18172 | val_0_rmse: 0.42766 | val_1_rmse: 0.56268 |  0:00:53s
epoch 117| loss: 0.18628 | val_0_rmse: 0.42571 | val_1_rmse: 0.5571  |  0:00:53s
epoch 118| loss: 0.18474 | val_0_rmse: 0.42716 | val_1_rmse: 0.57874 |  0:00:54s
epoch 119| loss: 0.18435 | val_0_rmse: 0.43323 | val_1_rmse: 0.57556 |  0:00:54s
epoch 120| loss: 0.18045 | val_0_rmse: 0.4237  | val_1_rmse: 0.57427 |  0:00:55s
epoch 121| loss: 0.18285 | val_0_rmse: 0.42778 | val_1_rmse: 0.58254 |  0:00:55s
epoch 122| loss: 0.17938 | val_0_rmse: 0.42013 | val_1_rmse: 0.58344 |  0:00:56s
epoch 123| loss: 0.18144 | val_0_rmse: 0.41576 | val_1_rmse: 0.59451 |  0:00:56s
epoch 124| loss: 0.17834 | val_0_rmse: 0.41887 | val_1_rmse: 0.5808  |  0:00:57s
epoch 125| loss: 0.18134 | val_0_rmse: 0.42636 | val_1_rmse: 0.58147 |  0:00:57s
epoch 126| loss: 0.1861  | val_0_rmse: 0.41847 | val_1_rmse: 0.56496 |  0:00:58s
epoch 127| loss: 0.17862 | val_0_rmse: 0.42848 | val_1_rmse: 0.56576 |  0:00:58s
epoch 128| loss: 0.17401 | val_0_rmse: 0.41601 | val_1_rmse: 0.57702 |  0:00:58s
epoch 129| loss: 0.1755  | val_0_rmse: 0.40148 | val_1_rmse: 0.58426 |  0:00:59s
epoch 130| loss: 0.18268 | val_0_rmse: 0.40321 | val_1_rmse: 0.56088 |  0:00:59s
epoch 131| loss: 0.17063 | val_0_rmse: 0.39853 | val_1_rmse: 0.57186 |  0:01:00s
epoch 132| loss: 0.17249 | val_0_rmse: 0.40441 | val_1_rmse: 0.56751 |  0:01:00s
epoch 133| loss: 0.16972 | val_0_rmse: 0.39687 | val_1_rmse: 0.58005 |  0:01:01s
epoch 134| loss: 0.17195 | val_0_rmse: 0.39852 | val_1_rmse: 0.56441 |  0:01:01s
epoch 135| loss: 0.17087 | val_0_rmse: 0.40465 | val_1_rmse: 0.5755  |  0:01:02s
epoch 136| loss: 0.17286 | val_0_rmse: 0.40993 | val_1_rmse: 0.57569 |  0:01:02s
epoch 137| loss: 0.17068 | val_0_rmse: 0.40368 | val_1_rmse: 0.60988 |  0:01:03s
epoch 138| loss: 0.16781 | val_0_rmse: 0.41142 | val_1_rmse: 0.57456 |  0:01:03s
epoch 139| loss: 0.16532 | val_0_rmse: 0.40619 | val_1_rmse: 0.57041 |  0:01:03s
epoch 140| loss: 0.1708  | val_0_rmse: 0.41805 | val_1_rmse: 0.59246 |  0:01:04s
epoch 141| loss: 0.16241 | val_0_rmse: 0.40633 | val_1_rmse: 0.59139 |  0:01:04s

Early stopping occured at epoch 141 with best_epoch = 111 and best_val_1_rmse = 0.55153
Best weights from best epoch are automatically used!
ended training at: 08:25:53
Feature importance:
Mean squared error is of 2804778300.123431
Mean absolute error:35322.85449252545
MAPE:0.27939163045029336
R2 score:0.6983851215340122
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 6
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:25:53
epoch 0  | loss: 1.52871 | val_0_rmse: 1.00175 | val_1_rmse: 0.99351 |  0:00:00s
epoch 1  | loss: 0.91151 | val_0_rmse: 0.95008 | val_1_rmse: 0.93432 |  0:00:00s
epoch 2  | loss: 0.69467 | val_0_rmse: 1.79623 | val_1_rmse: 1.6938  |  0:00:01s
epoch 3  | loss: 0.57087 | val_0_rmse: 1.49878 | val_1_rmse: 1.40791 |  0:00:01s
epoch 4  | loss: 0.53165 | val_0_rmse: 1.35588 | val_1_rmse: 1.26137 |  0:00:02s
epoch 5  | loss: 0.46343 | val_0_rmse: 0.99485 | val_1_rmse: 0.91576 |  0:00:02s
epoch 6  | loss: 0.44609 | val_0_rmse: 1.01984 | val_1_rmse: 0.93195 |  0:00:03s
epoch 7  | loss: 0.43983 | val_0_rmse: 0.82987 | val_1_rmse: 0.76285 |  0:00:03s
epoch 8  | loss: 0.40311 | val_0_rmse: 0.9061  | val_1_rmse: 0.82834 |  0:00:04s
epoch 9  | loss: 0.39788 | val_0_rmse: 0.8118  | val_1_rmse: 0.75299 |  0:00:04s
epoch 10 | loss: 0.39885 | val_0_rmse: 0.82749 | val_1_rmse: 0.77079 |  0:00:05s
epoch 11 | loss: 0.3748  | val_0_rmse: 0.78762 | val_1_rmse: 0.74922 |  0:00:05s
epoch 12 | loss: 0.37407 | val_0_rmse: 0.75806 | val_1_rmse: 0.72126 |  0:00:05s
epoch 13 | loss: 0.3464  | val_0_rmse: 0.74602 | val_1_rmse: 0.72171 |  0:00:06s
epoch 14 | loss: 0.3391  | val_0_rmse: 0.80403 | val_1_rmse: 0.75533 |  0:00:06s
epoch 15 | loss: 0.32494 | val_0_rmse: 0.78841 | val_1_rmse: 0.7469  |  0:00:07s
epoch 16 | loss: 0.31765 | val_0_rmse: 0.73796 | val_1_rmse: 0.70893 |  0:00:07s
epoch 17 | loss: 0.31641 | val_0_rmse: 0.73106 | val_1_rmse: 0.70233 |  0:00:08s
epoch 18 | loss: 0.30827 | val_0_rmse: 0.71175 | val_1_rmse: 0.68431 |  0:00:08s
epoch 19 | loss: 0.31009 | val_0_rmse: 0.73622 | val_1_rmse: 0.70505 |  0:00:09s
epoch 20 | loss: 0.30479 | val_0_rmse: 0.72957 | val_1_rmse: 0.70068 |  0:00:09s
epoch 21 | loss: 0.30468 | val_0_rmse: 0.7382  | val_1_rmse: 0.70459 |  0:00:10s
epoch 22 | loss: 0.29227 | val_0_rmse: 0.71739 | val_1_rmse: 0.68532 |  0:00:10s
epoch 23 | loss: 0.30338 | val_0_rmse: 0.8167  | val_1_rmse: 0.76113 |  0:00:11s
epoch 24 | loss: 0.30127 | val_0_rmse: 0.67961 | val_1_rmse: 0.6502  |  0:00:11s
epoch 25 | loss: 0.29868 | val_0_rmse: 0.71976 | val_1_rmse: 0.67855 |  0:00:11s
epoch 26 | loss: 0.29588 | val_0_rmse: 0.7101  | val_1_rmse: 0.66975 |  0:00:12s
epoch 27 | loss: 0.28404 | val_0_rmse: 0.67446 | val_1_rmse: 0.64278 |  0:00:12s
epoch 28 | loss: 0.27532 | val_0_rmse: 0.68448 | val_1_rmse: 0.65286 |  0:00:13s
epoch 29 | loss: 0.27974 | val_0_rmse: 0.66236 | val_1_rmse: 0.63314 |  0:00:13s
epoch 30 | loss: 0.28656 | val_0_rmse: 0.69222 | val_1_rmse: 0.65696 |  0:00:14s
epoch 31 | loss: 0.28806 | val_0_rmse: 0.67452 | val_1_rmse: 0.64113 |  0:00:14s
epoch 32 | loss: 0.28579 | val_0_rmse: 0.70053 | val_1_rmse: 0.65264 |  0:00:15s
epoch 33 | loss: 0.27829 | val_0_rmse: 0.65732 | val_1_rmse: 0.62775 |  0:00:15s
epoch 34 | loss: 0.27369 | val_0_rmse: 0.63994 | val_1_rmse: 0.61863 |  0:00:16s
epoch 35 | loss: 0.267   | val_0_rmse: 0.63217 | val_1_rmse: 0.61003 |  0:00:16s
epoch 36 | loss: 0.27136 | val_0_rmse: 0.63372 | val_1_rmse: 0.60506 |  0:00:16s
epoch 37 | loss: 0.25471 | val_0_rmse: 0.62946 | val_1_rmse: 0.60187 |  0:00:17s
epoch 38 | loss: 0.26004 | val_0_rmse: 0.62576 | val_1_rmse: 0.6032  |  0:00:17s
epoch 39 | loss: 0.24786 | val_0_rmse: 0.63317 | val_1_rmse: 0.6084  |  0:00:18s
epoch 40 | loss: 0.2502  | val_0_rmse: 0.61831 | val_1_rmse: 0.60274 |  0:00:18s
epoch 41 | loss: 0.25673 | val_0_rmse: 0.61995 | val_1_rmse: 0.60264 |  0:00:19s
epoch 42 | loss: 0.24803 | val_0_rmse: 0.64248 | val_1_rmse: 0.61478 |  0:00:19s
epoch 43 | loss: 0.25304 | val_0_rmse: 0.61144 | val_1_rmse: 0.59716 |  0:00:20s
epoch 44 | loss: 0.25554 | val_0_rmse: 0.60937 | val_1_rmse: 0.59221 |  0:00:20s
epoch 45 | loss: 0.24081 | val_0_rmse: 0.60889 | val_1_rmse: 0.59461 |  0:00:21s
epoch 46 | loss: 0.24987 | val_0_rmse: 0.6018  | val_1_rmse: 0.58961 |  0:00:21s
epoch 47 | loss: 0.23831 | val_0_rmse: 0.6046  | val_1_rmse: 0.58943 |  0:00:21s
epoch 48 | loss: 0.23517 | val_0_rmse: 0.59932 | val_1_rmse: 0.59015 |  0:00:22s
epoch 49 | loss: 0.23554 | val_0_rmse: 0.59857 | val_1_rmse: 0.58406 |  0:00:22s
epoch 50 | loss: 0.23963 | val_0_rmse: 0.60917 | val_1_rmse: 0.59101 |  0:00:23s
epoch 51 | loss: 0.23643 | val_0_rmse: 0.59326 | val_1_rmse: 0.58193 |  0:00:23s
epoch 52 | loss: 0.23844 | val_0_rmse: 0.58525 | val_1_rmse: 0.57652 |  0:00:24s
epoch 53 | loss: 0.23832 | val_0_rmse: 0.59584 | val_1_rmse: 0.58408 |  0:00:24s
epoch 54 | loss: 0.24285 | val_0_rmse: 0.58577 | val_1_rmse: 0.57674 |  0:00:25s
epoch 55 | loss: 0.22527 | val_0_rmse: 0.57458 | val_1_rmse: 0.56964 |  0:00:25s
epoch 56 | loss: 0.24371 | val_0_rmse: 0.57754 | val_1_rmse: 0.57278 |  0:00:26s
epoch 57 | loss: 0.24362 | val_0_rmse: 0.57386 | val_1_rmse: 0.56528 |  0:00:26s
epoch 58 | loss: 0.23199 | val_0_rmse: 0.57173 | val_1_rmse: 0.56638 |  0:00:27s
epoch 59 | loss: 0.23253 | val_0_rmse: 0.57417 | val_1_rmse: 0.57442 |  0:00:27s
epoch 60 | loss: 0.23122 | val_0_rmse: 0.56381 | val_1_rmse: 0.56558 |  0:00:27s
epoch 61 | loss: 0.23009 | val_0_rmse: 0.58153 | val_1_rmse: 0.59257 |  0:00:28s
epoch 62 | loss: 0.22752 | val_0_rmse: 0.56118 | val_1_rmse: 0.56428 |  0:00:28s
epoch 63 | loss: 0.22094 | val_0_rmse: 0.55876 | val_1_rmse: 0.56152 |  0:00:29s
epoch 64 | loss: 0.22205 | val_0_rmse: 0.56311 | val_1_rmse: 0.57788 |  0:00:29s
epoch 65 | loss: 0.23573 | val_0_rmse: 0.56312 | val_1_rmse: 0.5706  |  0:00:30s
epoch 66 | loss: 0.2223  | val_0_rmse: 0.56619 | val_1_rmse: 0.58259 |  0:00:30s
epoch 67 | loss: 0.21418 | val_0_rmse: 0.56637 | val_1_rmse: 0.58269 |  0:00:31s
epoch 68 | loss: 0.21748 | val_0_rmse: 0.54369 | val_1_rmse: 0.55782 |  0:00:31s
epoch 69 | loss: 0.21376 | val_0_rmse: 0.54487 | val_1_rmse: 0.55806 |  0:00:32s
epoch 70 | loss: 0.21509 | val_0_rmse: 0.54256 | val_1_rmse: 0.55262 |  0:00:32s
epoch 71 | loss: 0.21455 | val_0_rmse: 0.54027 | val_1_rmse: 0.54754 |  0:00:32s
epoch 72 | loss: 0.21461 | val_0_rmse: 0.54073 | val_1_rmse: 0.54846 |  0:00:33s
epoch 73 | loss: 0.20069 | val_0_rmse: 0.55877 | val_1_rmse: 0.5719  |  0:00:33s
epoch 74 | loss: 0.21307 | val_0_rmse: 0.57803 | val_1_rmse: 0.5943  |  0:00:34s
epoch 75 | loss: 0.20496 | val_0_rmse: 0.52606 | val_1_rmse: 0.54872 |  0:00:34s
epoch 76 | loss: 0.20498 | val_0_rmse: 0.52317 | val_1_rmse: 0.54539 |  0:00:35s
epoch 77 | loss: 0.20913 | val_0_rmse: 0.53587 | val_1_rmse: 0.56172 |  0:00:35s
epoch 78 | loss: 0.20546 | val_0_rmse: 0.52134 | val_1_rmse: 0.5566  |  0:00:36s
epoch 79 | loss: 0.20844 | val_0_rmse: 0.53736 | val_1_rmse: 0.58429 |  0:00:36s
epoch 80 | loss: 0.212   | val_0_rmse: 0.50284 | val_1_rmse: 0.53957 |  0:00:36s
epoch 81 | loss: 0.21106 | val_0_rmse: 0.49912 | val_1_rmse: 0.53593 |  0:00:37s
epoch 82 | loss: 0.21071 | val_0_rmse: 0.49461 | val_1_rmse: 0.54355 |  0:00:37s
epoch 83 | loss: 0.20701 | val_0_rmse: 0.52411 | val_1_rmse: 0.57588 |  0:00:38s
epoch 84 | loss: 0.2057  | val_0_rmse: 0.49142 | val_1_rmse: 0.53822 |  0:00:38s
epoch 85 | loss: 0.20707 | val_0_rmse: 0.49058 | val_1_rmse: 0.54527 |  0:00:39s
epoch 86 | loss: 0.21053 | val_0_rmse: 0.49027 | val_1_rmse: 0.55324 |  0:00:39s
epoch 87 | loss: 0.20673 | val_0_rmse: 0.4811  | val_1_rmse: 0.53155 |  0:00:40s
epoch 88 | loss: 0.19898 | val_0_rmse: 0.4861  | val_1_rmse: 0.54474 |  0:00:40s
epoch 89 | loss: 0.20618 | val_0_rmse: 0.4771  | val_1_rmse: 0.54831 |  0:00:41s
epoch 90 | loss: 0.19645 | val_0_rmse: 0.47435 | val_1_rmse: 0.52467 |  0:00:41s
epoch 91 | loss: 0.21451 | val_0_rmse: 0.47016 | val_1_rmse: 0.53415 |  0:00:42s
epoch 92 | loss: 0.206   | val_0_rmse: 0.47462 | val_1_rmse: 0.54441 |  0:00:42s
epoch 93 | loss: 0.19607 | val_0_rmse: 0.48606 | val_1_rmse: 0.55999 |  0:00:42s
epoch 94 | loss: 0.20607 | val_0_rmse: 0.54001 | val_1_rmse: 0.57523 |  0:00:43s
epoch 95 | loss: 0.2105  | val_0_rmse: 0.47679 | val_1_rmse: 0.52531 |  0:00:43s
epoch 96 | loss: 0.21242 | val_0_rmse: 0.49174 | val_1_rmse: 0.55746 |  0:00:44s
epoch 97 | loss: 0.20866 | val_0_rmse: 0.48696 | val_1_rmse: 0.54581 |  0:00:44s
epoch 98 | loss: 0.21634 | val_0_rmse: 0.47823 | val_1_rmse: 0.56619 |  0:00:45s
epoch 99 | loss: 0.21067 | val_0_rmse: 0.47309 | val_1_rmse: 0.54692 |  0:00:45s
epoch 100| loss: 0.2033  | val_0_rmse: 0.49963 | val_1_rmse: 0.55512 |  0:00:46s
epoch 101| loss: 0.20159 | val_0_rmse: 0.46299 | val_1_rmse: 0.52804 |  0:00:46s
epoch 102| loss: 0.20028 | val_0_rmse: 0.45795 | val_1_rmse: 0.54134 |  0:00:47s
epoch 103| loss: 0.19676 | val_0_rmse: 0.45113 | val_1_rmse: 0.53602 |  0:00:47s
epoch 104| loss: 0.20209 | val_0_rmse: 0.46359 | val_1_rmse: 0.55111 |  0:00:47s
epoch 105| loss: 0.19155 | val_0_rmse: 0.46196 | val_1_rmse: 0.55309 |  0:00:48s
epoch 106| loss: 0.19591 | val_0_rmse: 0.45811 | val_1_rmse: 0.53151 |  0:00:48s
epoch 107| loss: 0.18604 | val_0_rmse: 0.44554 | val_1_rmse: 0.53803 |  0:00:49s
epoch 108| loss: 0.187   | val_0_rmse: 0.45256 | val_1_rmse: 0.53272 |  0:00:49s
epoch 109| loss: 0.18948 | val_0_rmse: 0.45008 | val_1_rmse: 0.5489  |  0:00:50s
epoch 110| loss: 0.18876 | val_0_rmse: 0.43859 | val_1_rmse: 0.54081 |  0:00:50s
epoch 111| loss: 0.18601 | val_0_rmse: 0.44403 | val_1_rmse: 0.55463 |  0:00:51s
epoch 112| loss: 0.19237 | val_0_rmse: 0.43688 | val_1_rmse: 0.55096 |  0:00:51s
epoch 113| loss: 0.18696 | val_0_rmse: 0.43754 | val_1_rmse: 0.54089 |  0:00:52s
epoch 114| loss: 0.1956  | val_0_rmse: 0.42615 | val_1_rmse: 0.54597 |  0:00:52s
epoch 115| loss: 0.18564 | val_0_rmse: 0.42353 | val_1_rmse: 0.54593 |  0:00:52s
epoch 116| loss: 0.19024 | val_0_rmse: 0.44471 | val_1_rmse: 0.5521  |  0:00:53s
epoch 117| loss: 0.18282 | val_0_rmse: 0.43363 | val_1_rmse: 0.54989 |  0:00:53s
epoch 118| loss: 0.18226 | val_0_rmse: 0.46704 | val_1_rmse: 0.56753 |  0:00:54s
epoch 119| loss: 0.17955 | val_0_rmse: 0.42146 | val_1_rmse: 0.5602  |  0:00:54s
epoch 120| loss: 0.18023 | val_0_rmse: 0.43205 | val_1_rmse: 0.54614 |  0:00:55s

Early stopping occured at epoch 120 with best_epoch = 90 and best_val_1_rmse = 0.52467
Best weights from best epoch are automatically used!
ended training at: 08:26:49
Feature importance:
Mean squared error is of 2208010283.424586
Mean absolute error:32680.810864808627
MAPE:0.24808658061865818
R2 score:0.7145111515656741
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 7
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:26:49
epoch 0  | loss: 1.56583 | val_0_rmse: 1.01076 | val_1_rmse: 0.97821 |  0:00:00s
epoch 1  | loss: 1.12088 | val_0_rmse: 0.9961  | val_1_rmse: 0.97689 |  0:00:00s
epoch 2  | loss: 0.9587  | val_0_rmse: 0.99249 | val_1_rmse: 0.97691 |  0:00:01s
epoch 3  | loss: 0.94495 | val_0_rmse: 0.99064 | val_1_rmse: 0.97597 |  0:00:01s
epoch 4  | loss: 0.89564 | val_0_rmse: 0.97061 | val_1_rmse: 0.95718 |  0:00:02s
epoch 5  | loss: 0.74289 | val_0_rmse: 0.84994 | val_1_rmse: 0.84875 |  0:00:02s
epoch 6  | loss: 0.60698 | val_0_rmse: 0.78981 | val_1_rmse: 0.79746 |  0:00:03s
epoch 7  | loss: 0.51094 | val_0_rmse: 0.88149 | val_1_rmse: 0.90244 |  0:00:03s
epoch 8  | loss: 0.45623 | val_0_rmse: 0.93272 | val_1_rmse: 0.98256 |  0:00:04s
epoch 9  | loss: 0.42113 | val_0_rmse: 0.73134 | val_1_rmse: 0.77327 |  0:00:04s
epoch 10 | loss: 0.406   | val_0_rmse: 0.7307  | val_1_rmse: 0.78951 |  0:00:05s
epoch 11 | loss: 0.37228 | val_0_rmse: 0.66886 | val_1_rmse: 0.71071 |  0:00:05s
epoch 12 | loss: 0.36588 | val_0_rmse: 0.67636 | val_1_rmse: 0.72785 |  0:00:06s
epoch 13 | loss: 0.34246 | val_0_rmse: 0.66883 | val_1_rmse: 0.73394 |  0:00:06s
epoch 14 | loss: 0.3233  | val_0_rmse: 0.66088 | val_1_rmse: 0.72604 |  0:00:06s
epoch 15 | loss: 0.32441 | val_0_rmse: 0.67066 | val_1_rmse: 0.73444 |  0:00:07s
epoch 16 | loss: 0.31885 | val_0_rmse: 0.6537  | val_1_rmse: 0.71154 |  0:00:07s
epoch 17 | loss: 0.30083 | val_0_rmse: 0.64569 | val_1_rmse: 0.70268 |  0:00:08s
epoch 18 | loss: 0.29137 | val_0_rmse: 0.6407  | val_1_rmse: 0.69836 |  0:00:08s
epoch 19 | loss: 0.28822 | val_0_rmse: 0.64424 | val_1_rmse: 0.70124 |  0:00:09s
epoch 20 | loss: 0.28253 | val_0_rmse: 0.63852 | val_1_rmse: 0.70083 |  0:00:09s
epoch 21 | loss: 0.28491 | val_0_rmse: 0.63037 | val_1_rmse: 0.68186 |  0:00:10s
epoch 22 | loss: 0.28389 | val_0_rmse: 0.62257 | val_1_rmse: 0.67979 |  0:00:10s
epoch 23 | loss: 0.2731  | val_0_rmse: 0.63509 | val_1_rmse: 0.70076 |  0:00:11s
epoch 24 | loss: 0.27202 | val_0_rmse: 0.64163 | val_1_rmse: 0.71104 |  0:00:11s
epoch 25 | loss: 0.26667 | val_0_rmse: 0.62249 | val_1_rmse: 0.68615 |  0:00:11s
epoch 26 | loss: 0.2505  | val_0_rmse: 0.62489 | val_1_rmse: 0.68519 |  0:00:12s
epoch 27 | loss: 0.25578 | val_0_rmse: 0.62712 | val_1_rmse: 0.67779 |  0:00:12s
epoch 28 | loss: 0.25618 | val_0_rmse: 0.61182 | val_1_rmse: 0.66944 |  0:00:13s
epoch 29 | loss: 0.24904 | val_0_rmse: 0.623   | val_1_rmse: 0.69169 |  0:00:13s
epoch 30 | loss: 0.25329 | val_0_rmse: 0.60964 | val_1_rmse: 0.66549 |  0:00:14s
epoch 31 | loss: 0.24856 | val_0_rmse: 0.6027  | val_1_rmse: 0.66865 |  0:00:14s
epoch 32 | loss: 0.24382 | val_0_rmse: 0.61869 | val_1_rmse: 0.68094 |  0:00:15s
epoch 33 | loss: 0.24675 | val_0_rmse: 0.60494 | val_1_rmse: 0.67076 |  0:00:15s
epoch 34 | loss: 0.23432 | val_0_rmse: 0.60398 | val_1_rmse: 0.66289 |  0:00:16s
epoch 35 | loss: 0.24041 | val_0_rmse: 0.59979 | val_1_rmse: 0.66096 |  0:00:16s
epoch 36 | loss: 0.24232 | val_0_rmse: 0.59835 | val_1_rmse: 0.66015 |  0:00:16s
epoch 37 | loss: 0.24309 | val_0_rmse: 0.6097  | val_1_rmse: 0.67924 |  0:00:17s
epoch 38 | loss: 0.23437 | val_0_rmse: 0.58883 | val_1_rmse: 0.66685 |  0:00:17s
epoch 39 | loss: 0.23633 | val_0_rmse: 0.58889 | val_1_rmse: 0.65459 |  0:00:18s
epoch 40 | loss: 0.23616 | val_0_rmse: 0.5914  | val_1_rmse: 0.65587 |  0:00:18s
epoch 41 | loss: 0.23989 | val_0_rmse: 0.58732 | val_1_rmse: 0.64985 |  0:00:19s
epoch 42 | loss: 0.22937 | val_0_rmse: 0.58104 | val_1_rmse: 0.65209 |  0:00:19s
epoch 43 | loss: 0.226   | val_0_rmse: 0.5803  | val_1_rmse: 0.65982 |  0:00:20s
epoch 44 | loss: 0.22596 | val_0_rmse: 0.59662 | val_1_rmse: 0.65558 |  0:00:20s
epoch 45 | loss: 0.23052 | val_0_rmse: 0.57988 | val_1_rmse: 0.64368 |  0:00:21s
epoch 46 | loss: 0.22208 | val_0_rmse: 0.58401 | val_1_rmse: 0.65163 |  0:00:21s
epoch 47 | loss: 0.22311 | val_0_rmse: 0.57445 | val_1_rmse: 0.64625 |  0:00:22s
epoch 48 | loss: 0.2246  | val_0_rmse: 0.57909 | val_1_rmse: 0.64921 |  0:00:22s
epoch 49 | loss: 0.22469 | val_0_rmse: 0.5653  | val_1_rmse: 0.6445  |  0:00:22s
epoch 50 | loss: 0.23273 | val_0_rmse: 0.57758 | val_1_rmse: 0.64358 |  0:00:23s
epoch 51 | loss: 0.21887 | val_0_rmse: 0.55672 | val_1_rmse: 0.6417  |  0:00:23s
epoch 52 | loss: 0.22187 | val_0_rmse: 0.56906 | val_1_rmse: 0.64753 |  0:00:24s
epoch 53 | loss: 0.21593 | val_0_rmse: 0.5554  | val_1_rmse: 0.64751 |  0:00:24s
epoch 54 | loss: 0.21228 | val_0_rmse: 0.56599 | val_1_rmse: 0.64011 |  0:00:25s
epoch 55 | loss: 0.21945 | val_0_rmse: 0.55502 | val_1_rmse: 0.64685 |  0:00:25s
epoch 56 | loss: 0.21286 | val_0_rmse: 0.55969 | val_1_rmse: 0.6337  |  0:00:26s
epoch 57 | loss: 0.21492 | val_0_rmse: 0.5516  | val_1_rmse: 0.63936 |  0:00:26s
epoch 58 | loss: 0.20899 | val_0_rmse: 0.54284 | val_1_rmse: 0.63651 |  0:00:26s
epoch 59 | loss: 0.21405 | val_0_rmse: 0.55461 | val_1_rmse: 0.63088 |  0:00:27s
epoch 60 | loss: 0.21667 | val_0_rmse: 0.53815 | val_1_rmse: 0.6328  |  0:00:27s
epoch 61 | loss: 0.21167 | val_0_rmse: 0.53965 | val_1_rmse: 0.62386 |  0:00:28s
epoch 62 | loss: 0.20651 | val_0_rmse: 0.53957 | val_1_rmse: 0.62861 |  0:00:28s
epoch 63 | loss: 0.206   | val_0_rmse: 0.53765 | val_1_rmse: 0.63817 |  0:00:29s
epoch 64 | loss: 0.20647 | val_0_rmse: 0.53582 | val_1_rmse: 0.64222 |  0:00:29s
epoch 65 | loss: 0.21364 | val_0_rmse: 0.54074 | val_1_rmse: 0.64144 |  0:00:30s
epoch 66 | loss: 0.21055 | val_0_rmse: 0.52224 | val_1_rmse: 0.63786 |  0:00:30s
epoch 67 | loss: 0.20587 | val_0_rmse: 0.51916 | val_1_rmse: 0.6148  |  0:00:31s
epoch 68 | loss: 0.21748 | val_0_rmse: 0.52481 | val_1_rmse: 0.60731 |  0:00:31s
epoch 69 | loss: 0.21419 | val_0_rmse: 0.51843 | val_1_rmse: 0.60941 |  0:00:31s
epoch 70 | loss: 0.21452 | val_0_rmse: 0.52812 | val_1_rmse: 0.61525 |  0:00:32s
epoch 71 | loss: 0.21113 | val_0_rmse: 0.52263 | val_1_rmse: 0.62308 |  0:00:32s
epoch 72 | loss: 0.20893 | val_0_rmse: 0.52148 | val_1_rmse: 0.61933 |  0:00:33s
epoch 73 | loss: 0.19678 | val_0_rmse: 0.51217 | val_1_rmse: 0.61505 |  0:00:33s
epoch 74 | loss: 0.20071 | val_0_rmse: 0.5087  | val_1_rmse: 0.62111 |  0:00:34s
epoch 75 | loss: 0.20316 | val_0_rmse: 0.51134 | val_1_rmse: 0.62655 |  0:00:34s
epoch 76 | loss: 0.20404 | val_0_rmse: 0.50929 | val_1_rmse: 0.6142  |  0:00:35s
epoch 77 | loss: 0.20583 | val_0_rmse: 0.50655 | val_1_rmse: 0.60927 |  0:00:35s
epoch 78 | loss: 0.19498 | val_0_rmse: 0.50223 | val_1_rmse: 0.60938 |  0:00:36s
epoch 79 | loss: 0.19517 | val_0_rmse: 0.49495 | val_1_rmse: 0.5993  |  0:00:36s
epoch 80 | loss: 0.19599 | val_0_rmse: 0.5024  | val_1_rmse: 0.60145 |  0:00:36s
epoch 81 | loss: 0.19771 | val_0_rmse: 0.495   | val_1_rmse: 0.60206 |  0:00:37s
epoch 82 | loss: 0.19136 | val_0_rmse: 0.48749 | val_1_rmse: 0.59342 |  0:00:37s
epoch 83 | loss: 0.1885  | val_0_rmse: 0.48314 | val_1_rmse: 0.59245 |  0:00:38s
epoch 84 | loss: 0.18769 | val_0_rmse: 0.47695 | val_1_rmse: 0.59562 |  0:00:38s
epoch 85 | loss: 0.19269 | val_0_rmse: 0.48572 | val_1_rmse: 0.59146 |  0:00:39s
epoch 86 | loss: 0.1887  | val_0_rmse: 0.46841 | val_1_rmse: 0.58314 |  0:00:39s
epoch 87 | loss: 0.18821 | val_0_rmse: 0.47609 | val_1_rmse: 0.58201 |  0:00:40s
epoch 88 | loss: 0.19023 | val_0_rmse: 0.47648 | val_1_rmse: 0.59223 |  0:00:40s
epoch 89 | loss: 0.19144 | val_0_rmse: 0.47981 | val_1_rmse: 0.59289 |  0:00:41s
epoch 90 | loss: 0.19057 | val_0_rmse: 0.47445 | val_1_rmse: 0.58915 |  0:00:41s
epoch 91 | loss: 0.19648 | val_0_rmse: 0.48652 | val_1_rmse: 0.58744 |  0:00:41s
epoch 92 | loss: 0.19298 | val_0_rmse: 0.47674 | val_1_rmse: 0.58777 |  0:00:42s
epoch 93 | loss: 0.19472 | val_0_rmse: 0.46261 | val_1_rmse: 0.58667 |  0:00:42s
epoch 94 | loss: 0.20397 | val_0_rmse: 0.48266 | val_1_rmse: 0.58522 |  0:00:43s
epoch 95 | loss: 0.20656 | val_0_rmse: 0.46669 | val_1_rmse: 0.58159 |  0:00:43s
epoch 96 | loss: 0.19098 | val_0_rmse: 0.47198 | val_1_rmse: 0.58388 |  0:00:44s
epoch 97 | loss: 0.19815 | val_0_rmse: 0.47119 | val_1_rmse: 0.58422 |  0:00:44s
epoch 98 | loss: 0.1952  | val_0_rmse: 0.45425 | val_1_rmse: 0.58013 |  0:00:45s
epoch 99 | loss: 0.18941 | val_0_rmse: 0.45742 | val_1_rmse: 0.58754 |  0:00:45s
epoch 100| loss: 0.18692 | val_0_rmse: 0.45667 | val_1_rmse: 0.58101 |  0:00:45s
epoch 101| loss: 0.18783 | val_0_rmse: 0.45021 | val_1_rmse: 0.57528 |  0:00:46s
epoch 102| loss: 0.18429 | val_0_rmse: 0.44288 | val_1_rmse: 0.57231 |  0:00:46s
epoch 103| loss: 0.18194 | val_0_rmse: 0.45154 | val_1_rmse: 0.56647 |  0:00:47s
epoch 104| loss: 0.1842  | val_0_rmse: 0.4366  | val_1_rmse: 0.56319 |  0:00:47s
epoch 105| loss: 0.17604 | val_0_rmse: 0.44672 | val_1_rmse: 0.5668  |  0:00:48s
epoch 106| loss: 0.173   | val_0_rmse: 0.43079 | val_1_rmse: 0.56875 |  0:00:48s
epoch 107| loss: 0.17864 | val_0_rmse: 0.43018 | val_1_rmse: 0.56862 |  0:00:49s
epoch 108| loss: 0.17574 | val_0_rmse: 0.44124 | val_1_rmse: 0.58323 |  0:00:49s
epoch 109| loss: 0.17803 | val_0_rmse: 0.43146 | val_1_rmse: 0.57256 |  0:00:50s
epoch 110| loss: 0.18113 | val_0_rmse: 0.42488 | val_1_rmse: 0.56041 |  0:00:50s
epoch 111| loss: 0.17557 | val_0_rmse: 0.43056 | val_1_rmse: 0.55639 |  0:00:51s
epoch 112| loss: 0.16809 | val_0_rmse: 0.41184 | val_1_rmse: 0.56239 |  0:00:51s
epoch 113| loss: 0.17284 | val_0_rmse: 0.42663 | val_1_rmse: 0.55873 |  0:00:51s
epoch 114| loss: 0.17397 | val_0_rmse: 0.40808 | val_1_rmse: 0.57113 |  0:00:52s
epoch 115| loss: 0.17621 | val_0_rmse: 0.42122 | val_1_rmse: 0.55882 |  0:00:52s
epoch 116| loss: 0.17798 | val_0_rmse: 0.41819 | val_1_rmse: 0.55469 |  0:00:53s
epoch 117| loss: 0.17228 | val_0_rmse: 0.41223 | val_1_rmse: 0.56483 |  0:00:53s
epoch 118| loss: 0.17162 | val_0_rmse: 0.41368 | val_1_rmse: 0.55866 |  0:00:54s
epoch 119| loss: 0.17683 | val_0_rmse: 0.40413 | val_1_rmse: 0.55539 |  0:00:54s
epoch 120| loss: 0.16611 | val_0_rmse: 0.40634 | val_1_rmse: 0.5575  |  0:00:55s
epoch 121| loss: 0.17028 | val_0_rmse: 0.40379 | val_1_rmse: 0.56109 |  0:00:55s
epoch 122| loss: 0.1703  | val_0_rmse: 0.40562 | val_1_rmse: 0.55415 |  0:00:56s
epoch 123| loss: 0.16893 | val_0_rmse: 0.39942 | val_1_rmse: 0.56189 |  0:00:56s
epoch 124| loss: 0.17832 | val_0_rmse: 0.404   | val_1_rmse: 0.55372 |  0:00:56s
epoch 125| loss: 0.17044 | val_0_rmse: 0.40025 | val_1_rmse: 0.55096 |  0:00:57s
epoch 126| loss: 0.15979 | val_0_rmse: 0.39465 | val_1_rmse: 0.56092 |  0:00:57s
epoch 127| loss: 0.16546 | val_0_rmse: 0.39213 | val_1_rmse: 0.54419 |  0:00:58s
epoch 128| loss: 0.16707 | val_0_rmse: 0.39299 | val_1_rmse: 0.54437 |  0:00:58s
epoch 129| loss: 0.15922 | val_0_rmse: 0.38778 | val_1_rmse: 0.53892 |  0:00:59s
epoch 130| loss: 0.15937 | val_0_rmse: 0.39045 | val_1_rmse: 0.54744 |  0:00:59s
epoch 131| loss: 0.16037 | val_0_rmse: 0.38772 | val_1_rmse: 0.54778 |  0:01:00s
epoch 132| loss: 0.15818 | val_0_rmse: 0.3838  | val_1_rmse: 0.54162 |  0:01:00s
epoch 133| loss: 0.15329 | val_0_rmse: 0.38531 | val_1_rmse: 0.56206 |  0:01:01s
epoch 134| loss: 0.15882 | val_0_rmse: 0.39576 | val_1_rmse: 0.55417 |  0:01:01s
epoch 135| loss: 0.15627 | val_0_rmse: 0.38814 | val_1_rmse: 0.56793 |  0:01:02s
epoch 136| loss: 0.15937 | val_0_rmse: 0.39183 | val_1_rmse: 0.55369 |  0:01:02s
epoch 137| loss: 0.15825 | val_0_rmse: 0.38293 | val_1_rmse: 0.56    |  0:01:02s
epoch 138| loss: 0.15686 | val_0_rmse: 0.38486 | val_1_rmse: 0.55001 |  0:01:03s
epoch 139| loss: 0.15477 | val_0_rmse: 0.37516 | val_1_rmse: 0.54632 |  0:01:03s
epoch 140| loss: 0.15469 | val_0_rmse: 0.38141 | val_1_rmse: 0.54882 |  0:01:04s
epoch 141| loss: 0.15637 | val_0_rmse: 0.40549 | val_1_rmse: 0.56477 |  0:01:04s
epoch 142| loss: 0.16047 | val_0_rmse: 0.38326 | val_1_rmse: 0.55486 |  0:01:05s
epoch 143| loss: 0.1651  | val_0_rmse: 0.38376 | val_1_rmse: 0.55101 |  0:01:05s
epoch 144| loss: 0.15655 | val_0_rmse: 0.37402 | val_1_rmse: 0.54595 |  0:01:06s
epoch 145| loss: 0.15394 | val_0_rmse: 0.37996 | val_1_rmse: 0.54748 |  0:01:06s
epoch 146| loss: 0.15724 | val_0_rmse: 0.37755 | val_1_rmse: 0.55502 |  0:01:07s
epoch 147| loss: 0.15253 | val_0_rmse: 0.36809 | val_1_rmse: 0.5621  |  0:01:07s
epoch 148| loss: 0.15489 | val_0_rmse: 0.36997 | val_1_rmse: 0.56114 |  0:01:08s
epoch 149| loss: 0.15551 | val_0_rmse: 0.36231 | val_1_rmse: 0.54247 |  0:01:08s
Stop training because you reached max_epochs = 150 with best_epoch = 129 and best_val_1_rmse = 0.53892
Best weights from best epoch are automatically used!
ended training at: 08:27:58
Feature importance:
Mean squared error is of 3152062694.6459274
Mean absolute error:36045.0031528838
MAPE:0.28328589614988003
R2 score:0.6511636831649821
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 8
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:27:58
epoch 0  | loss: 1.41982 | val_0_rmse: 0.99034 | val_1_rmse: 1.02433 |  0:00:00s
epoch 1  | loss: 1.07274 | val_0_rmse: 0.99139 | val_1_rmse: 1.02709 |  0:00:00s
epoch 2  | loss: 0.96567 | val_0_rmse: 0.98208 | val_1_rmse: 1.01653 |  0:00:01s
epoch 3  | loss: 0.8927  | val_0_rmse: 0.95685 | val_1_rmse: 0.98891 |  0:00:01s
epoch 4  | loss: 0.76959 | val_0_rmse: 0.95003 | val_1_rmse: 0.96738 |  0:00:02s
epoch 5  | loss: 0.64399 | val_0_rmse: 0.96112 | val_1_rmse: 0.97159 |  0:00:02s
epoch 6  | loss: 0.58564 | val_0_rmse: 0.84656 | val_1_rmse: 0.85659 |  0:00:03s
epoch 7  | loss: 0.50968 | val_0_rmse: 0.88442 | val_1_rmse: 0.89809 |  0:00:03s
epoch 8  | loss: 0.46156 | val_0_rmse: 0.82925 | val_1_rmse: 0.84591 |  0:00:04s
epoch 9  | loss: 0.44336 | val_0_rmse: 0.92332 | val_1_rmse: 0.90942 |  0:00:04s
epoch 10 | loss: 0.40922 | val_0_rmse: 0.96425 | val_1_rmse: 0.94799 |  0:00:05s
epoch 11 | loss: 0.39229 | val_0_rmse: 0.85904 | val_1_rmse: 0.84135 |  0:00:05s
epoch 12 | loss: 0.38706 | val_0_rmse: 0.79386 | val_1_rmse: 0.77824 |  0:00:06s
epoch 13 | loss: 0.37148 | val_0_rmse: 0.69404 | val_1_rmse: 0.68597 |  0:00:06s
epoch 14 | loss: 0.35493 | val_0_rmse: 0.71401 | val_1_rmse: 0.70457 |  0:00:06s
epoch 15 | loss: 0.33159 | val_0_rmse: 0.71136 | val_1_rmse: 0.69998 |  0:00:07s
epoch 16 | loss: 0.32173 | val_0_rmse: 0.68211 | val_1_rmse: 0.68999 |  0:00:07s
epoch 17 | loss: 0.32257 | val_0_rmse: 0.68219 | val_1_rmse: 0.68334 |  0:00:08s
epoch 18 | loss: 0.33026 | val_0_rmse: 0.6972  | val_1_rmse: 0.69188 |  0:00:08s
epoch 19 | loss: 0.30853 | val_0_rmse: 0.72154 | val_1_rmse: 0.70569 |  0:00:09s
epoch 20 | loss: 0.31082 | val_0_rmse: 0.67975 | val_1_rmse: 0.66815 |  0:00:09s
epoch 21 | loss: 0.30389 | val_0_rmse: 0.6753  | val_1_rmse: 0.66793 |  0:00:10s
epoch 22 | loss: 0.29928 | val_0_rmse: 0.65736 | val_1_rmse: 0.6604  |  0:00:10s
epoch 23 | loss: 0.2916  | val_0_rmse: 0.66152 | val_1_rmse: 0.66778 |  0:00:11s
epoch 24 | loss: 0.30084 | val_0_rmse: 0.73025 | val_1_rmse: 0.71131 |  0:00:11s
epoch 25 | loss: 0.29208 | val_0_rmse: 0.74157 | val_1_rmse: 0.72069 |  0:00:12s
epoch 26 | loss: 0.31269 | val_0_rmse: 0.69101 | val_1_rmse: 0.6728  |  0:00:12s
epoch 27 | loss: 0.29895 | val_0_rmse: 0.64015 | val_1_rmse: 0.64039 |  0:00:12s
epoch 28 | loss: 0.29293 | val_0_rmse: 0.63512 | val_1_rmse: 0.64559 |  0:00:13s
epoch 29 | loss: 0.28929 | val_0_rmse: 0.6282  | val_1_rmse: 0.63533 |  0:00:13s
epoch 30 | loss: 0.28798 | val_0_rmse: 0.63471 | val_1_rmse: 0.64092 |  0:00:14s
epoch 31 | loss: 0.28208 | val_0_rmse: 0.6449  | val_1_rmse: 0.6568  |  0:00:14s
epoch 32 | loss: 0.28471 | val_0_rmse: 0.63437 | val_1_rmse: 0.64448 |  0:00:15s
epoch 33 | loss: 0.28387 | val_0_rmse: 0.63546 | val_1_rmse: 0.64324 |  0:00:15s
epoch 34 | loss: 0.28929 | val_0_rmse: 0.65217 | val_1_rmse: 0.65919 |  0:00:16s
epoch 35 | loss: 0.28173 | val_0_rmse: 0.62481 | val_1_rmse: 0.62179 |  0:00:16s
epoch 36 | loss: 0.27328 | val_0_rmse: 0.60709 | val_1_rmse: 0.60542 |  0:00:17s
epoch 37 | loss: 0.27883 | val_0_rmse: 0.60209 | val_1_rmse: 0.60781 |  0:00:17s
epoch 38 | loss: 0.28375 | val_0_rmse: 0.61755 | val_1_rmse: 0.62837 |  0:00:18s
epoch 39 | loss: 0.2755  | val_0_rmse: 0.61265 | val_1_rmse: 0.62126 |  0:00:18s
epoch 40 | loss: 0.28376 | val_0_rmse: 0.59881 | val_1_rmse: 0.60497 |  0:00:18s
epoch 41 | loss: 0.27516 | val_0_rmse: 0.58973 | val_1_rmse: 0.60334 |  0:00:19s
epoch 42 | loss: 0.27109 | val_0_rmse: 0.61232 | val_1_rmse: 0.6337  |  0:00:19s
epoch 43 | loss: 0.27426 | val_0_rmse: 0.59094 | val_1_rmse: 0.60399 |  0:00:20s
epoch 44 | loss: 0.26629 | val_0_rmse: 0.5838  | val_1_rmse: 0.59432 |  0:00:20s
epoch 45 | loss: 0.26531 | val_0_rmse: 0.58063 | val_1_rmse: 0.58959 |  0:00:21s
epoch 46 | loss: 0.26149 | val_0_rmse: 0.59775 | val_1_rmse: 0.61337 |  0:00:21s
epoch 47 | loss: 0.25513 | val_0_rmse: 0.60057 | val_1_rmse: 0.61458 |  0:00:22s
epoch 48 | loss: 0.26372 | val_0_rmse: 0.5945  | val_1_rmse: 0.60977 |  0:00:22s
epoch 49 | loss: 0.25557 | val_0_rmse: 0.57276 | val_1_rmse: 0.58006 |  0:00:23s
epoch 50 | loss: 0.25295 | val_0_rmse: 0.58886 | val_1_rmse: 0.60827 |  0:00:23s
epoch 51 | loss: 0.2505  | val_0_rmse: 0.59124 | val_1_rmse: 0.60573 |  0:00:24s
epoch 52 | loss: 0.25491 | val_0_rmse: 0.58815 | val_1_rmse: 0.60607 |  0:00:24s
epoch 53 | loss: 0.26662 | val_0_rmse: 0.59159 | val_1_rmse: 0.60704 |  0:00:25s
epoch 54 | loss: 0.2721  | val_0_rmse: 0.58866 | val_1_rmse: 0.60157 |  0:00:25s
epoch 55 | loss: 0.26661 | val_0_rmse: 0.59945 | val_1_rmse: 0.62165 |  0:00:25s
epoch 56 | loss: 0.2529  | val_0_rmse: 0.58069 | val_1_rmse: 0.59787 |  0:00:26s
epoch 57 | loss: 0.26719 | val_0_rmse: 0.58807 | val_1_rmse: 0.60668 |  0:00:26s
epoch 58 | loss: 0.25486 | val_0_rmse: 0.61745 | val_1_rmse: 0.63575 |  0:00:27s
epoch 59 | loss: 0.24723 | val_0_rmse: 0.58221 | val_1_rmse: 0.5998  |  0:00:27s
epoch 60 | loss: 0.25604 | val_0_rmse: 0.57897 | val_1_rmse: 0.59833 |  0:00:28s
epoch 61 | loss: 0.25002 | val_0_rmse: 0.57594 | val_1_rmse: 0.59552 |  0:00:28s
epoch 62 | loss: 0.25546 | val_0_rmse: 0.56897 | val_1_rmse: 0.58406 |  0:00:29s
epoch 63 | loss: 0.24794 | val_0_rmse: 0.57414 | val_1_rmse: 0.59575 |  0:00:29s
epoch 64 | loss: 0.23998 | val_0_rmse: 0.57253 | val_1_rmse: 0.59562 |  0:00:30s
epoch 65 | loss: 0.2544  | val_0_rmse: 0.55101 | val_1_rmse: 0.57494 |  0:00:30s
epoch 66 | loss: 0.23963 | val_0_rmse: 0.54857 | val_1_rmse: 0.57287 |  0:00:30s
epoch 67 | loss: 0.24062 | val_0_rmse: 0.57761 | val_1_rmse: 0.6144  |  0:00:31s
epoch 68 | loss: 0.24626 | val_0_rmse: 0.56931 | val_1_rmse: 0.60529 |  0:00:31s
epoch 69 | loss: 0.24085 | val_0_rmse: 0.53103 | val_1_rmse: 0.56534 |  0:00:32s
epoch 70 | loss: 0.23199 | val_0_rmse: 0.5375  | val_1_rmse: 0.57613 |  0:00:32s
epoch 71 | loss: 0.23611 | val_0_rmse: 0.54632 | val_1_rmse: 0.58933 |  0:00:33s
epoch 72 | loss: 0.22933 | val_0_rmse: 0.53167 | val_1_rmse: 0.57485 |  0:00:33s
epoch 73 | loss: 0.23302 | val_0_rmse: 0.55563 | val_1_rmse: 0.60075 |  0:00:34s
epoch 74 | loss: 0.23032 | val_0_rmse: 0.52463 | val_1_rmse: 0.56208 |  0:00:34s
epoch 75 | loss: 0.22622 | val_0_rmse: 0.5492  | val_1_rmse: 0.59347 |  0:00:35s
epoch 76 | loss: 0.22631 | val_0_rmse: 0.5384  | val_1_rmse: 0.58656 |  0:00:35s
epoch 77 | loss: 0.22934 | val_0_rmse: 0.51875 | val_1_rmse: 0.56546 |  0:00:35s
epoch 78 | loss: 0.23053 | val_0_rmse: 0.53772 | val_1_rmse: 0.59093 |  0:00:36s
epoch 79 | loss: 0.24101 | val_0_rmse: 0.52399 | val_1_rmse: 0.57483 |  0:00:36s
epoch 80 | loss: 0.22266 | val_0_rmse: 0.54361 | val_1_rmse: 0.59402 |  0:00:37s
epoch 81 | loss: 0.22874 | val_0_rmse: 0.53018 | val_1_rmse: 0.58295 |  0:00:37s
epoch 82 | loss: 0.23214 | val_0_rmse: 0.57337 | val_1_rmse: 0.63    |  0:00:38s
epoch 83 | loss: 0.22104 | val_0_rmse: 0.50961 | val_1_rmse: 0.57596 |  0:00:38s
epoch 84 | loss: 0.22001 | val_0_rmse: 0.52016 | val_1_rmse: 0.58207 |  0:00:39s
epoch 85 | loss: 0.22874 | val_0_rmse: 0.50149 | val_1_rmse: 0.57154 |  0:00:39s
epoch 86 | loss: 0.2176  | val_0_rmse: 0.49964 | val_1_rmse: 0.57314 |  0:00:40s
epoch 87 | loss: 0.22938 | val_0_rmse: 0.53507 | val_1_rmse: 0.60491 |  0:00:40s
epoch 88 | loss: 0.22319 | val_0_rmse: 0.48939 | val_1_rmse: 0.56928 |  0:00:40s
epoch 89 | loss: 0.21137 | val_0_rmse: 0.51589 | val_1_rmse: 0.5878  |  0:00:41s
epoch 90 | loss: 0.21214 | val_0_rmse: 0.50548 | val_1_rmse: 0.57743 |  0:00:41s
epoch 91 | loss: 0.21726 | val_0_rmse: 0.50198 | val_1_rmse: 0.5757  |  0:00:42s
epoch 92 | loss: 0.21699 | val_0_rmse: 0.49621 | val_1_rmse: 0.5697  |  0:00:42s
epoch 93 | loss: 0.21962 | val_0_rmse: 0.496   | val_1_rmse: 0.57121 |  0:00:43s
epoch 94 | loss: 0.2111  | val_0_rmse: 0.49836 | val_1_rmse: 0.58054 |  0:00:43s
epoch 95 | loss: 0.21585 | val_0_rmse: 0.47975 | val_1_rmse: 0.5678  |  0:00:44s
epoch 96 | loss: 0.21861 | val_0_rmse: 0.47592 | val_1_rmse: 0.55799 |  0:00:44s
epoch 97 | loss: 0.2117  | val_0_rmse: 0.48099 | val_1_rmse: 0.55846 |  0:00:45s
epoch 98 | loss: 0.21944 | val_0_rmse: 0.46835 | val_1_rmse: 0.55207 |  0:00:45s
epoch 99 | loss: 0.21133 | val_0_rmse: 0.4807  | val_1_rmse: 0.55254 |  0:00:45s
epoch 100| loss: 0.21873 | val_0_rmse: 0.48079 | val_1_rmse: 0.56264 |  0:00:46s
epoch 101| loss: 0.21489 | val_0_rmse: 0.46567 | val_1_rmse: 0.54968 |  0:00:46s
epoch 102| loss: 0.20289 | val_0_rmse: 0.46543 | val_1_rmse: 0.54493 |  0:00:47s
epoch 103| loss: 0.20634 | val_0_rmse: 0.45933 | val_1_rmse: 0.5401  |  0:00:47s
epoch 104| loss: 0.20349 | val_0_rmse: 0.47489 | val_1_rmse: 0.55655 |  0:00:48s
epoch 105| loss: 0.21167 | val_0_rmse: 0.46524 | val_1_rmse: 0.55187 |  0:00:48s
epoch 106| loss: 0.20509 | val_0_rmse: 0.45873 | val_1_rmse: 0.54715 |  0:00:49s
epoch 107| loss: 0.20143 | val_0_rmse: 0.45654 | val_1_rmse: 0.54917 |  0:00:49s
epoch 108| loss: 0.20654 | val_0_rmse: 0.45719 | val_1_rmse: 0.55209 |  0:00:50s
epoch 109| loss: 0.205   | val_0_rmse: 0.46504 | val_1_rmse: 0.5813  |  0:00:50s
epoch 110| loss: 0.20968 | val_0_rmse: 0.46007 | val_1_rmse: 0.55449 |  0:00:50s
epoch 111| loss: 0.20773 | val_0_rmse: 0.44821 | val_1_rmse: 0.54618 |  0:00:51s
epoch 112| loss: 0.20031 | val_0_rmse: 0.45382 | val_1_rmse: 0.54835 |  0:00:51s
epoch 113| loss: 0.20384 | val_0_rmse: 0.4524  | val_1_rmse: 0.54144 |  0:00:52s
epoch 114| loss: 0.21559 | val_0_rmse: 0.45948 | val_1_rmse: 0.5494  |  0:00:52s
epoch 115| loss: 0.20961 | val_0_rmse: 0.4581  | val_1_rmse: 0.55118 |  0:00:53s
epoch 116| loss: 0.20785 | val_0_rmse: 0.45426 | val_1_rmse: 0.5392  |  0:00:53s
epoch 117| loss: 0.21916 | val_0_rmse: 0.45055 | val_1_rmse: 0.5312  |  0:00:54s
epoch 118| loss: 0.20483 | val_0_rmse: 0.45318 | val_1_rmse: 0.54611 |  0:00:54s
epoch 119| loss: 0.22069 | val_0_rmse: 0.44786 | val_1_rmse: 0.53966 |  0:00:54s
epoch 120| loss: 0.2     | val_0_rmse: 0.43521 | val_1_rmse: 0.5373  |  0:00:55s
epoch 121| loss: 0.20253 | val_0_rmse: 0.43984 | val_1_rmse: 0.54933 |  0:00:55s
epoch 122| loss: 0.18659 | val_0_rmse: 0.43446 | val_1_rmse: 0.5327  |  0:00:56s
epoch 123| loss: 0.20166 | val_0_rmse: 0.44258 | val_1_rmse: 0.5522  |  0:00:56s
epoch 124| loss: 0.20032 | val_0_rmse: 0.43311 | val_1_rmse: 0.54026 |  0:00:57s
epoch 125| loss: 0.19764 | val_0_rmse: 0.45087 | val_1_rmse: 0.54344 |  0:00:57s
epoch 126| loss: 0.19424 | val_0_rmse: 0.45245 | val_1_rmse: 0.55367 |  0:00:58s
epoch 127| loss: 0.19673 | val_0_rmse: 0.43194 | val_1_rmse: 0.53663 |  0:00:58s
epoch 128| loss: 0.20171 | val_0_rmse: 0.45215 | val_1_rmse: 0.55591 |  0:00:59s
epoch 129| loss: 0.19343 | val_0_rmse: 0.42093 | val_1_rmse: 0.54039 |  0:00:59s
epoch 130| loss: 0.19484 | val_0_rmse: 0.42001 | val_1_rmse: 0.54083 |  0:01:00s
epoch 131| loss: 0.19391 | val_0_rmse: 0.4157  | val_1_rmse: 0.54267 |  0:01:00s
epoch 132| loss: 0.19886 | val_0_rmse: 0.41847 | val_1_rmse: 0.53983 |  0:01:00s
epoch 133| loss: 0.18285 | val_0_rmse: 0.4113  | val_1_rmse: 0.53958 |  0:01:01s
epoch 134| loss: 0.18527 | val_0_rmse: 0.41736 | val_1_rmse: 0.54083 |  0:01:01s
epoch 135| loss: 0.1925  | val_0_rmse: 0.41299 | val_1_rmse: 0.53436 |  0:01:02s
epoch 136| loss: 0.19159 | val_0_rmse: 0.42968 | val_1_rmse: 0.55914 |  0:01:02s
epoch 137| loss: 0.20099 | val_0_rmse: 0.41285 | val_1_rmse: 0.54215 |  0:01:03s
epoch 138| loss: 0.18653 | val_0_rmse: 0.4543  | val_1_rmse: 0.58051 |  0:01:03s
epoch 139| loss: 0.1962  | val_0_rmse: 0.42933 | val_1_rmse: 0.56775 |  0:01:04s
epoch 140| loss: 0.18973 | val_0_rmse: 0.42305 | val_1_rmse: 0.55708 |  0:01:04s
epoch 141| loss: 0.18581 | val_0_rmse: 0.44643 | val_1_rmse: 0.55237 |  0:01:05s
epoch 142| loss: 0.18409 | val_0_rmse: 0.3991  | val_1_rmse: 0.53302 |  0:01:05s
epoch 143| loss: 0.18214 | val_0_rmse: 0.39772 | val_1_rmse: 0.53132 |  0:01:06s
epoch 144| loss: 0.17863 | val_0_rmse: 0.4156  | val_1_rmse: 0.54078 |  0:01:06s
epoch 145| loss: 0.17566 | val_0_rmse: 0.41452 | val_1_rmse: 0.53839 |  0:01:06s
epoch 146| loss: 0.18    | val_0_rmse: 0.41897 | val_1_rmse: 0.54739 |  0:01:07s
epoch 147| loss: 0.18856 | val_0_rmse: 0.43755 | val_1_rmse: 0.56611 |  0:01:07s

Early stopping occured at epoch 147 with best_epoch = 117 and best_val_1_rmse = 0.5312
Best weights from best epoch are automatically used!
ended training at: 08:29:06
Feature importance:
Mean squared error is of 2336914319.217195
Mean absolute error:32708.14837906528
MAPE:0.24596789158888685
R2 score:0.726176852407561
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: uy properties.csv
Using seed = 9
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:29:06
epoch 0  | loss: 1.44342 | val_0_rmse: 0.99993 | val_1_rmse: 1.02112 |  0:00:00s
epoch 1  | loss: 0.97417 | val_0_rmse: 0.99619 | val_1_rmse: 1.01592 |  0:00:00s
epoch 2  | loss: 0.90861 | val_0_rmse: 0.98432 | val_1_rmse: 1.0056  |  0:00:01s
epoch 3  | loss: 0.83217 | val_0_rmse: 0.92885 | val_1_rmse: 0.93953 |  0:00:01s
epoch 4  | loss: 0.75359 | val_0_rmse: 0.88488 | val_1_rmse: 0.88012 |  0:00:02s
epoch 5  | loss: 0.60846 | val_0_rmse: 0.81962 | val_1_rmse: 0.80542 |  0:00:02s
epoch 6  | loss: 0.52052 | val_0_rmse: 0.77652 | val_1_rmse: 0.78155 |  0:00:03s
epoch 7  | loss: 0.45367 | val_0_rmse: 0.80204 | val_1_rmse: 0.79507 |  0:00:03s
epoch 8  | loss: 0.40332 | val_0_rmse: 0.83374 | val_1_rmse: 0.82953 |  0:00:04s
epoch 9  | loss: 0.38527 | val_0_rmse: 0.76417 | val_1_rmse: 0.75888 |  0:00:04s
epoch 10 | loss: 0.37022 | val_0_rmse: 0.75379 | val_1_rmse: 0.75198 |  0:00:05s
epoch 11 | loss: 0.34016 | val_0_rmse: 0.71407 | val_1_rmse: 0.7291  |  0:00:05s
epoch 12 | loss: 0.33612 | val_0_rmse: 0.73091 | val_1_rmse: 0.7383  |  0:00:06s
epoch 13 | loss: 0.32163 | val_0_rmse: 0.71408 | val_1_rmse: 0.71599 |  0:00:06s
epoch 14 | loss: 0.31631 | val_0_rmse: 0.67845 | val_1_rmse: 0.68979 |  0:00:06s
epoch 15 | loss: 0.31028 | val_0_rmse: 0.65593 | val_1_rmse: 0.67661 |  0:00:07s
epoch 16 | loss: 0.3029  | val_0_rmse: 0.66393 | val_1_rmse: 0.68587 |  0:00:07s
epoch 17 | loss: 0.29335 | val_0_rmse: 0.65458 | val_1_rmse: 0.6802  |  0:00:08s
epoch 18 | loss: 0.29359 | val_0_rmse: 0.6617  | val_1_rmse: 0.67615 |  0:00:08s
epoch 19 | loss: 0.29911 | val_0_rmse: 0.65053 | val_1_rmse: 0.66863 |  0:00:09s
epoch 20 | loss: 0.29145 | val_0_rmse: 0.64991 | val_1_rmse: 0.67367 |  0:00:09s
epoch 21 | loss: 0.27901 | val_0_rmse: 0.64174 | val_1_rmse: 0.66925 |  0:00:10s
epoch 22 | loss: 0.27782 | val_0_rmse: 0.64465 | val_1_rmse: 0.67081 |  0:00:10s
epoch 23 | loss: 0.28119 | val_0_rmse: 0.65076 | val_1_rmse: 0.67202 |  0:00:11s
epoch 24 | loss: 0.28136 | val_0_rmse: 0.64751 | val_1_rmse: 0.67245 |  0:00:11s
epoch 25 | loss: 0.28276 | val_0_rmse: 0.65962 | val_1_rmse: 0.67319 |  0:00:12s
epoch 26 | loss: 0.27869 | val_0_rmse: 0.71291 | val_1_rmse: 0.72583 |  0:00:12s
epoch 27 | loss: 0.28979 | val_0_rmse: 0.6503  | val_1_rmse: 0.67423 |  0:00:13s
epoch 28 | loss: 0.28713 | val_0_rmse: 0.72411 | val_1_rmse: 0.72557 |  0:00:13s
epoch 29 | loss: 0.28969 | val_0_rmse: 0.67635 | val_1_rmse: 0.69749 |  0:00:13s
epoch 30 | loss: 0.2861  | val_0_rmse: 0.69969 | val_1_rmse: 0.71945 |  0:00:14s
epoch 31 | loss: 0.27668 | val_0_rmse: 0.68842 | val_1_rmse: 0.71638 |  0:00:14s
epoch 32 | loss: 0.27602 | val_0_rmse: 0.68508 | val_1_rmse: 0.71257 |  0:00:15s
epoch 33 | loss: 0.27385 | val_0_rmse: 0.64446 | val_1_rmse: 0.67183 |  0:00:15s
epoch 34 | loss: 0.26186 | val_0_rmse: 0.61837 | val_1_rmse: 0.65047 |  0:00:16s
epoch 35 | loss: 0.26312 | val_0_rmse: 0.61078 | val_1_rmse: 0.64795 |  0:00:16s
epoch 36 | loss: 0.26411 | val_0_rmse: 0.62037 | val_1_rmse: 0.64906 |  0:00:17s
epoch 37 | loss: 0.25577 | val_0_rmse: 0.62806 | val_1_rmse: 0.65704 |  0:00:17s
epoch 38 | loss: 0.25924 | val_0_rmse: 0.6022  | val_1_rmse: 0.64599 |  0:00:18s
epoch 39 | loss: 0.25978 | val_0_rmse: 0.60561 | val_1_rmse: 0.64482 |  0:00:18s
epoch 40 | loss: 0.2628  | val_0_rmse: 0.6041  | val_1_rmse: 0.64565 |  0:00:19s
epoch 41 | loss: 0.27323 | val_0_rmse: 0.61645 | val_1_rmse: 0.65542 |  0:00:19s
epoch 42 | loss: 0.25661 | val_0_rmse: 0.59606 | val_1_rmse: 0.64701 |  0:00:19s
epoch 43 | loss: 0.25579 | val_0_rmse: 0.59242 | val_1_rmse: 0.63679 |  0:00:20s
epoch 44 | loss: 0.25358 | val_0_rmse: 0.58677 | val_1_rmse: 0.62406 |  0:00:20s
epoch 45 | loss: 0.24785 | val_0_rmse: 0.62008 | val_1_rmse: 0.65384 |  0:00:21s
epoch 46 | loss: 0.25909 | val_0_rmse: 0.58065 | val_1_rmse: 0.62462 |  0:00:21s
epoch 47 | loss: 0.24956 | val_0_rmse: 0.60129 | val_1_rmse: 0.62104 |  0:00:22s
epoch 48 | loss: 0.24502 | val_0_rmse: 0.59186 | val_1_rmse: 0.62677 |  0:00:22s
epoch 49 | loss: 0.25185 | val_0_rmse: 0.6009  | val_1_rmse: 0.6444  |  0:00:23s
epoch 50 | loss: 0.24801 | val_0_rmse: 0.59196 | val_1_rmse: 0.62684 |  0:00:23s
epoch 51 | loss: 0.24065 | val_0_rmse: 0.60039 | val_1_rmse: 0.63089 |  0:00:23s
epoch 52 | loss: 0.24778 | val_0_rmse: 0.56285 | val_1_rmse: 0.62187 |  0:00:24s
epoch 53 | loss: 0.23912 | val_0_rmse: 0.57591 | val_1_rmse: 0.62451 |  0:00:24s
epoch 54 | loss: 0.24565 | val_0_rmse: 0.5527  | val_1_rmse: 0.61751 |  0:00:25s
epoch 55 | loss: 0.24907 | val_0_rmse: 0.55687 | val_1_rmse: 0.61287 |  0:00:25s
epoch 56 | loss: 0.23833 | val_0_rmse: 0.55589 | val_1_rmse: 0.61168 |  0:00:26s
epoch 57 | loss: 0.23563 | val_0_rmse: 0.5497  | val_1_rmse: 0.61183 |  0:00:26s
epoch 58 | loss: 0.23781 | val_0_rmse: 0.564   | val_1_rmse: 0.6077  |  0:00:27s
epoch 59 | loss: 0.23582 | val_0_rmse: 0.57757 | val_1_rmse: 0.60655 |  0:00:27s
epoch 60 | loss: 0.23909 | val_0_rmse: 0.56029 | val_1_rmse: 0.61686 |  0:00:28s
epoch 61 | loss: 0.23664 | val_0_rmse: 0.54901 | val_1_rmse: 0.61252 |  0:00:28s
epoch 62 | loss: 0.24431 | val_0_rmse: 0.56534 | val_1_rmse: 0.60731 |  0:00:29s
epoch 63 | loss: 0.23302 | val_0_rmse: 0.56538 | val_1_rmse: 0.60667 |  0:00:29s
epoch 64 | loss: 0.22721 | val_0_rmse: 0.54706 | val_1_rmse: 0.59853 |  0:00:30s
epoch 65 | loss: 0.23288 | val_0_rmse: 0.54261 | val_1_rmse: 0.60136 |  0:00:30s
epoch 66 | loss: 0.22671 | val_0_rmse: 0.55034 | val_1_rmse: 0.59799 |  0:00:30s
epoch 67 | loss: 0.23065 | val_0_rmse: 0.54311 | val_1_rmse: 0.60619 |  0:00:31s
epoch 68 | loss: 0.23378 | val_0_rmse: 0.53942 | val_1_rmse: 0.6041  |  0:00:31s
epoch 69 | loss: 0.22962 | val_0_rmse: 0.53714 | val_1_rmse: 0.60003 |  0:00:32s
epoch 70 | loss: 0.23578 | val_0_rmse: 0.5251  | val_1_rmse: 0.59109 |  0:00:32s
epoch 71 | loss: 0.21604 | val_0_rmse: 0.51932 | val_1_rmse: 0.58884 |  0:00:33s
epoch 72 | loss: 0.21749 | val_0_rmse: 0.53424 | val_1_rmse: 0.5915  |  0:00:33s
epoch 73 | loss: 0.21399 | val_0_rmse: 0.52624 | val_1_rmse: 0.58711 |  0:00:34s
epoch 74 | loss: 0.21752 | val_0_rmse: 0.5382  | val_1_rmse: 0.59638 |  0:00:34s
epoch 75 | loss: 0.21643 | val_0_rmse: 0.53984 | val_1_rmse: 0.59787 |  0:00:35s
epoch 76 | loss: 0.21403 | val_0_rmse: 0.51991 | val_1_rmse: 0.59036 |  0:00:35s
epoch 77 | loss: 0.21577 | val_0_rmse: 0.5222  | val_1_rmse: 0.58878 |  0:00:35s
epoch 78 | loss: 0.21152 | val_0_rmse: 0.50227 | val_1_rmse: 0.59048 |  0:00:36s
epoch 79 | loss: 0.21071 | val_0_rmse: 0.5156  | val_1_rmse: 0.59627 |  0:00:36s
epoch 80 | loss: 0.2108  | val_0_rmse: 0.49939 | val_1_rmse: 0.58661 |  0:00:37s
epoch 81 | loss: 0.21307 | val_0_rmse: 0.51346 | val_1_rmse: 0.58317 |  0:00:37s
epoch 82 | loss: 0.21782 | val_0_rmse: 0.50256 | val_1_rmse: 0.58473 |  0:00:38s
epoch 83 | loss: 0.21102 | val_0_rmse: 0.51844 | val_1_rmse: 0.58386 |  0:00:38s
epoch 84 | loss: 0.21466 | val_0_rmse: 0.51176 | val_1_rmse: 0.58907 |  0:00:39s
epoch 85 | loss: 0.21215 | val_0_rmse: 0.50449 | val_1_rmse: 0.59143 |  0:00:39s
epoch 86 | loss: 0.21729 | val_0_rmse: 0.49089 | val_1_rmse: 0.59094 |  0:00:40s
epoch 87 | loss: 0.20579 | val_0_rmse: 0.48409 | val_1_rmse: 0.59393 |  0:00:40s
epoch 88 | loss: 0.21276 | val_0_rmse: 0.47958 | val_1_rmse: 0.59472 |  0:00:40s
epoch 89 | loss: 0.20472 | val_0_rmse: 0.50822 | val_1_rmse: 0.59929 |  0:00:41s
epoch 90 | loss: 0.20197 | val_0_rmse: 0.48046 | val_1_rmse: 0.5918  |  0:00:41s
epoch 91 | loss: 0.20776 | val_0_rmse: 0.4876  | val_1_rmse: 0.58142 |  0:00:42s
epoch 92 | loss: 0.20908 | val_0_rmse: 0.50521 | val_1_rmse: 0.58908 |  0:00:42s
epoch 93 | loss: 0.20527 | val_0_rmse: 0.49122 | val_1_rmse: 0.5821  |  0:00:43s
epoch 94 | loss: 0.20385 | val_0_rmse: 0.4879  | val_1_rmse: 0.58343 |  0:00:43s
epoch 95 | loss: 0.21218 | val_0_rmse: 0.50295 | val_1_rmse: 0.5964  |  0:00:44s
epoch 96 | loss: 0.22486 | val_0_rmse: 0.51823 | val_1_rmse: 0.58995 |  0:00:44s
epoch 97 | loss: 0.23116 | val_0_rmse: 0.5132  | val_1_rmse: 0.58724 |  0:00:45s
epoch 98 | loss: 0.22371 | val_0_rmse: 0.49983 | val_1_rmse: 0.5811  |  0:00:45s
epoch 99 | loss: 0.21231 | val_0_rmse: 0.51139 | val_1_rmse: 0.58654 |  0:00:45s
epoch 100| loss: 0.2143  | val_0_rmse: 0.49243 | val_1_rmse: 0.58467 |  0:00:46s
epoch 101| loss: 0.21041 | val_0_rmse: 0.48075 | val_1_rmse: 0.57812 |  0:00:46s
epoch 102| loss: 0.21042 | val_0_rmse: 0.47863 | val_1_rmse: 0.58568 |  0:00:47s
epoch 103| loss: 0.20758 | val_0_rmse: 0.47573 | val_1_rmse: 0.58883 |  0:00:47s
epoch 104| loss: 0.20859 | val_0_rmse: 0.4715  | val_1_rmse: 0.58525 |  0:00:48s
epoch 105| loss: 0.20481 | val_0_rmse: 0.46603 | val_1_rmse: 0.58041 |  0:00:48s
epoch 106| loss: 0.213   | val_0_rmse: 0.45966 | val_1_rmse: 0.58995 |  0:00:49s
epoch 107| loss: 0.21134 | val_0_rmse: 0.47762 | val_1_rmse: 0.58076 |  0:00:49s
epoch 108| loss: 0.2123  | val_0_rmse: 0.46549 | val_1_rmse: 0.58494 |  0:00:50s
epoch 109| loss: 0.20552 | val_0_rmse: 0.46945 | val_1_rmse: 0.57611 |  0:00:50s
epoch 110| loss: 0.20596 | val_0_rmse: 0.46293 | val_1_rmse: 0.58091 |  0:00:51s
epoch 111| loss: 0.21053 | val_0_rmse: 0.46882 | val_1_rmse: 0.58606 |  0:00:51s
epoch 112| loss: 0.2129  | val_0_rmse: 0.46638 | val_1_rmse: 0.58718 |  0:00:51s
epoch 113| loss: 0.21113 | val_0_rmse: 0.46985 | val_1_rmse: 0.58886 |  0:00:52s
epoch 114| loss: 0.2301  | val_0_rmse: 0.51248 | val_1_rmse: 0.6084  |  0:00:52s
epoch 115| loss: 0.22526 | val_0_rmse: 0.49302 | val_1_rmse: 0.59835 |  0:00:53s
epoch 116| loss: 0.22958 | val_0_rmse: 0.49077 | val_1_rmse: 0.60277 |  0:00:53s
epoch 117| loss: 0.2409  | val_0_rmse: 0.53961 | val_1_rmse: 0.59838 |  0:00:54s
epoch 118| loss: 0.259   | val_0_rmse: 0.55508 | val_1_rmse: 0.66626 |  0:00:54s
epoch 119| loss: 0.23662 | val_0_rmse: 0.52068 | val_1_rmse: 0.64451 |  0:00:55s
epoch 120| loss: 0.23634 | val_0_rmse: 0.48353 | val_1_rmse: 0.60201 |  0:00:55s
epoch 121| loss: 0.23158 | val_0_rmse: 0.49555 | val_1_rmse: 0.60335 |  0:00:56s
epoch 122| loss: 0.22587 | val_0_rmse: 0.4852  | val_1_rmse: 0.58261 |  0:00:56s
epoch 123| loss: 0.22338 | val_0_rmse: 0.48173 | val_1_rmse: 0.58173 |  0:00:56s
epoch 124| loss: 0.22105 | val_0_rmse: 0.47751 | val_1_rmse: 0.57597 |  0:00:57s
epoch 125| loss: 0.21365 | val_0_rmse: 0.47349 | val_1_rmse: 0.56757 |  0:00:57s
epoch 126| loss: 0.21414 | val_0_rmse: 0.48335 | val_1_rmse: 0.57608 |  0:00:58s
epoch 127| loss: 0.22047 | val_0_rmse: 0.50217 | val_1_rmse: 0.59416 |  0:00:58s
epoch 128| loss: 0.22541 | val_0_rmse: 0.4638  | val_1_rmse: 0.58416 |  0:00:59s
epoch 129| loss: 0.22508 | val_0_rmse: 0.45678 | val_1_rmse: 0.58294 |  0:00:59s
epoch 130| loss: 0.22377 | val_0_rmse: 0.4569  | val_1_rmse: 0.57761 |  0:01:00s
epoch 131| loss: 0.21825 | val_0_rmse: 0.44885 | val_1_rmse: 0.5791  |  0:01:00s
epoch 132| loss: 0.20334 | val_0_rmse: 0.44649 | val_1_rmse: 0.57744 |  0:01:01s
epoch 133| loss: 0.20556 | val_0_rmse: 0.44086 | val_1_rmse: 0.58968 |  0:01:01s
epoch 134| loss: 0.20565 | val_0_rmse: 0.43614 | val_1_rmse: 0.58896 |  0:01:01s
epoch 135| loss: 0.20446 | val_0_rmse: 0.43778 | val_1_rmse: 0.60409 |  0:01:02s
epoch 136| loss: 0.19652 | val_0_rmse: 0.43248 | val_1_rmse: 0.58964 |  0:01:02s
epoch 137| loss: 0.20088 | val_0_rmse: 0.43167 | val_1_rmse: 0.58429 |  0:01:03s
epoch 138| loss: 0.20198 | val_0_rmse: 0.43306 | val_1_rmse: 0.57435 |  0:01:03s
epoch 139| loss: 0.19742 | val_0_rmse: 0.42499 | val_1_rmse: 0.57958 |  0:01:04s
epoch 140| loss: 0.19242 | val_0_rmse: 0.43133 | val_1_rmse: 0.58175 |  0:01:04s
epoch 141| loss: 0.19608 | val_0_rmse: 0.43438 | val_1_rmse: 0.57987 |  0:01:05s
epoch 142| loss: 0.19842 | val_0_rmse: 0.42197 | val_1_rmse: 0.59029 |  0:01:05s
epoch 143| loss: 0.19492 | val_0_rmse: 0.42193 | val_1_rmse: 0.58519 |  0:01:06s
epoch 144| loss: 0.19148 | val_0_rmse: 0.42672 | val_1_rmse: 0.58372 |  0:01:06s
epoch 145| loss: 0.18882 | val_0_rmse: 0.42813 | val_1_rmse: 0.57712 |  0:01:07s
epoch 146| loss: 0.18459 | val_0_rmse: 0.41635 | val_1_rmse: 0.58245 |  0:01:07s
epoch 147| loss: 0.1898  | val_0_rmse: 0.41645 | val_1_rmse: 0.58156 |  0:01:07s
epoch 148| loss: 0.18363 | val_0_rmse: 0.41471 | val_1_rmse: 0.58006 |  0:01:08s
epoch 149| loss: 0.18177 | val_0_rmse: 0.41303 | val_1_rmse: 0.59363 |  0:01:08s
Stop training because you reached max_epochs = 150 with best_epoch = 125 and best_val_1_rmse = 0.56757
Best weights from best epoch are automatically used!
ended training at: 08:30:15
Feature importance:
Mean squared error is of 2400047652.839199
Mean absolute error:32551.060372949134
MAPE:0.2481836650726464
R2 score:0.7103991338278721
------------------------------------------------------------------
Normalization used is StandardScaler
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 0
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:30:17
epoch 0  | loss: 0.63024 | val_0_rmse: 0.64578 | val_1_rmse: 0.64682 |  0:00:15s
epoch 1  | loss: 0.31174 | val_0_rmse: 0.59783 | val_1_rmse: 0.59953 |  0:00:31s
epoch 2  | loss: 0.28447 | val_0_rmse: 0.54363 | val_1_rmse: 0.54671 |  0:00:47s
epoch 3  | loss: 0.27176 | val_0_rmse: 0.5247  | val_1_rmse: 0.5291  |  0:01:03s
epoch 4  | loss: 0.26675 | val_0_rmse: 0.50763 | val_1_rmse: 0.51723 |  0:01:19s
epoch 5  | loss: 0.26396 | val_0_rmse: 0.48988 | val_1_rmse: 0.50173 |  0:01:34s
epoch 6  | loss: 0.25708 | val_0_rmse: 0.49455 | val_1_rmse: 0.50681 |  0:01:50s
epoch 7  | loss: 0.25279 | val_0_rmse: 0.49247 | val_1_rmse: 0.50597 |  0:02:06s
epoch 8  | loss: 0.25172 | val_0_rmse: 0.48827 | val_1_rmse: 0.50456 |  0:02:22s
epoch 9  | loss: 0.24767 | val_0_rmse: 0.50906 | val_1_rmse: 0.49843 |  0:02:38s
epoch 10 | loss: 0.24842 | val_0_rmse: 0.58585 | val_1_rmse: 0.80749 |  0:02:53s
epoch 11 | loss: 0.24573 | val_0_rmse: 0.51206 | val_1_rmse: 0.51357 |  0:03:09s
epoch 12 | loss: 0.24156 | val_0_rmse: 0.4944  | val_1_rmse: 0.51404 |  0:03:25s
epoch 13 | loss: 0.2431  | val_0_rmse: 0.49454 | val_1_rmse: 0.50221 |  0:03:41s
epoch 14 | loss: 0.24237 | val_0_rmse: 0.50778 | val_1_rmse: 0.53234 |  0:03:56s
epoch 15 | loss: 0.23862 | val_0_rmse: 0.4778  | val_1_rmse: 0.49941 |  0:04:12s
epoch 16 | loss: 0.23809 | val_0_rmse: 0.4771  | val_1_rmse: 0.50104 |  0:04:28s
epoch 17 | loss: 0.23992 | val_0_rmse: 0.48448 | val_1_rmse: 0.50692 |  0:04:43s
epoch 18 | loss: 0.23699 | val_0_rmse: 0.47329 | val_1_rmse: 0.49819 |  0:04:59s
epoch 19 | loss: 0.237   | val_0_rmse: 0.49088 | val_1_rmse: 0.51444 |  0:05:15s
epoch 20 | loss: 0.23641 | val_0_rmse: 0.4748  | val_1_rmse: 0.50077 |  0:05:30s
epoch 21 | loss: 0.2367  | val_0_rmse: 0.48069 | val_1_rmse: 0.50828 |  0:05:46s
epoch 22 | loss: 0.23593 | val_0_rmse: 0.47869 | val_1_rmse: 0.50702 |  0:06:02s
epoch 23 | loss: 0.23263 | val_0_rmse: 0.47736 | val_1_rmse: 0.50424 |  0:06:17s
epoch 24 | loss: 0.23138 | val_0_rmse: 0.49642 | val_1_rmse: 0.52048 |  0:06:33s
epoch 25 | loss: 0.23239 | val_0_rmse: 0.46974 | val_1_rmse: 0.50262 |  0:06:49s
epoch 26 | loss: 0.2331  | val_0_rmse: 0.48198 | val_1_rmse: 0.51266 |  0:07:05s
epoch 27 | loss: 0.23108 | val_0_rmse: 0.4706  | val_1_rmse: 0.50157 |  0:07:21s
epoch 28 | loss: 0.2297  | val_0_rmse: 0.47544 | val_1_rmse: 0.5027  |  0:07:37s
epoch 29 | loss: 0.23073 | val_0_rmse: 0.48809 | val_1_rmse: 0.51576 |  0:07:53s
epoch 30 | loss: 0.22918 | val_0_rmse: 0.48864 | val_1_rmse: 0.53131 |  0:08:09s
epoch 31 | loss: 0.2273  | val_0_rmse: 0.47589 | val_1_rmse: 0.50686 |  0:08:25s
epoch 32 | loss: 0.22849 | val_0_rmse: 0.4791  | val_1_rmse: 0.50762 |  0:08:41s
epoch 33 | loss: 0.22728 | val_0_rmse: 0.4816  | val_1_rmse: 0.51719 |  0:08:57s
epoch 34 | loss: 0.22434 | val_0_rmse: 0.4709  | val_1_rmse: 0.5029  |  0:09:12s
epoch 35 | loss: 0.22589 | val_0_rmse: 0.47689 | val_1_rmse: 0.50747 |  0:09:28s
epoch 36 | loss: 0.22437 | val_0_rmse: 0.4665  | val_1_rmse: 0.49893 |  0:09:44s
epoch 37 | loss: 0.22511 | val_0_rmse: 0.48071 | val_1_rmse: 0.51033 |  0:10:00s
epoch 38 | loss: 0.22303 | val_0_rmse: 0.4718  | val_1_rmse: 0.50683 |  0:10:15s
epoch 39 | loss: 0.22433 | val_0_rmse: 0.50357 | val_1_rmse: 0.53645 |  0:10:31s
epoch 40 | loss: 0.22544 | val_0_rmse: 0.53462 | val_1_rmse: 0.56489 |  0:10:47s
epoch 41 | loss: 0.22361 | val_0_rmse: 0.50684 | val_1_rmse: 0.53348 |  0:11:03s
epoch 42 | loss: 0.22322 | val_0_rmse: 0.50558 | val_1_rmse: 0.54159 |  0:11:19s
epoch 43 | loss: 0.22375 | val_0_rmse: 0.45983 | val_1_rmse: 0.49702 |  0:11:34s
epoch 44 | loss: 0.22085 | val_0_rmse: 0.50395 | val_1_rmse: 0.54106 |  0:11:50s
epoch 45 | loss: 0.22154 | val_0_rmse: 0.50845 | val_1_rmse: 0.54591 |  0:12:06s
epoch 46 | loss: 0.2208  | val_0_rmse: 0.46454 | val_1_rmse: 0.49973 |  0:12:21s
epoch 47 | loss: 0.21932 | val_0_rmse: 0.45911 | val_1_rmse: 0.49652 |  0:12:37s
epoch 48 | loss: 0.22061 | val_0_rmse: 0.45989 | val_1_rmse: 0.49585 |  0:12:53s
epoch 49 | loss: 0.2203  | val_0_rmse: 0.46366 | val_1_rmse: 0.50397 |  0:13:08s
epoch 50 | loss: 0.22044 | val_0_rmse: 0.45942 | val_1_rmse: 0.50128 |  0:13:24s
epoch 51 | loss: 0.21761 | val_0_rmse: 0.46275 | val_1_rmse: 0.50226 |  0:13:40s
epoch 52 | loss: 0.21805 | val_0_rmse: 0.45775 | val_1_rmse: 0.49916 |  0:13:55s
epoch 53 | loss: 0.21877 | val_0_rmse: 0.46838 | val_1_rmse: 0.51031 |  0:14:11s
epoch 54 | loss: 0.21898 | val_0_rmse: 0.47915 | val_1_rmse: 0.52092 |  0:14:27s
epoch 55 | loss: 0.21895 | val_0_rmse: 0.4595  | val_1_rmse: 0.50237 |  0:14:42s
epoch 56 | loss: 0.21698 | val_0_rmse: 0.472   | val_1_rmse: 0.50591 |  0:14:58s
epoch 57 | loss: 0.21799 | val_0_rmse: 0.46354 | val_1_rmse: 0.5001  |  0:15:14s
epoch 58 | loss: 0.21501 | val_0_rmse: 0.46933 | val_1_rmse: 0.50797 |  0:15:29s
epoch 59 | loss: 0.21436 | val_0_rmse: 0.45902 | val_1_rmse: 0.50026 |  0:15:45s
epoch 60 | loss: 0.21855 | val_0_rmse: 0.64399 | val_1_rmse: 0.52496 |  0:16:01s
epoch 61 | loss: 0.22619 | val_0_rmse: 0.50418 | val_1_rmse: 0.52476 |  0:16:16s
epoch 62 | loss: 0.23019 | val_0_rmse: 0.7481  | val_1_rmse: 0.76747 |  0:16:32s
epoch 63 | loss: 0.24625 | val_0_rmse: 0.47254 | val_1_rmse: 0.50344 |  0:16:48s
epoch 64 | loss: 0.22937 | val_0_rmse: 0.48221 | val_1_rmse: 0.51675 |  0:17:03s
epoch 65 | loss: 0.22416 | val_0_rmse: 0.4777  | val_1_rmse: 0.51025 |  0:17:19s
epoch 66 | loss: 0.22205 | val_0_rmse: 0.48318 | val_1_rmse: 0.52202 |  0:17:35s
epoch 67 | loss: 0.22075 | val_0_rmse: 0.50384 | val_1_rmse: 0.53446 |  0:17:50s
epoch 68 | loss: 0.2201  | val_0_rmse: 0.48652 | val_1_rmse: 0.51067 |  0:18:06s
epoch 69 | loss: 0.21958 | val_0_rmse: 0.47567 | val_1_rmse: 0.51224 |  0:18:22s
epoch 70 | loss: 0.21931 | val_0_rmse: 0.47249 | val_1_rmse: 0.51568 |  0:18:37s
epoch 71 | loss: 0.21973 | val_0_rmse: 0.46169 | val_1_rmse: 0.50207 |  0:18:53s
epoch 72 | loss: 0.21811 | val_0_rmse: 0.4601  | val_1_rmse: 0.50701 |  0:19:09s
epoch 73 | loss: 0.21799 | val_0_rmse: 0.55157 | val_1_rmse: 0.56366 |  0:19:24s
epoch 74 | loss: 0.21683 | val_0_rmse: 0.4576  | val_1_rmse: 0.50049 |  0:19:40s
epoch 75 | loss: 0.21865 | val_0_rmse: 0.46589 | val_1_rmse: 0.50971 |  0:19:56s
epoch 76 | loss: 0.21533 | val_0_rmse: 0.46363 | val_1_rmse: 0.50515 |  0:20:11s
epoch 77 | loss: 0.21458 | val_0_rmse: 0.45716 | val_1_rmse: 0.50862 |  0:20:27s
epoch 78 | loss: 0.21482 | val_0_rmse: 0.45284 | val_1_rmse: 0.49825 |  0:20:43s

Early stopping occured at epoch 78 with best_epoch = 48 and best_val_1_rmse = 0.49585
Best weights from best epoch are automatically used!
ended training at: 08:51:07
Feature importance:
Mean squared error is of 1625778698.407112
Mean absolute error:28474.325942091647
MAPE:0.27571728982185156
R2 score:0.7557288496426829
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 1
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 08:51:10
epoch 0  | loss: 0.60623 | val_0_rmse: 0.69574 | val_1_rmse: 0.6949  |  0:00:15s
epoch 1  | loss: 0.33513 | val_0_rmse: 0.60867 | val_1_rmse: 0.61136 |  0:00:31s
epoch 2  | loss: 0.30487 | val_0_rmse: 0.56822 | val_1_rmse: 0.57086 |  0:00:47s
epoch 3  | loss: 0.28732 | val_0_rmse: 0.52629 | val_1_rmse: 0.53245 |  0:01:02s
epoch 4  | loss: 0.28007 | val_0_rmse: 0.51583 | val_1_rmse: 0.52407 |  0:01:18s
epoch 5  | loss: 0.27919 | val_0_rmse: 0.52779 | val_1_rmse: 0.53758 |  0:01:34s
epoch 6  | loss: 0.27064 | val_0_rmse: 0.50689 | val_1_rmse: 0.51226 |  0:01:49s
epoch 7  | loss: 0.2659  | val_0_rmse: 0.49478 | val_1_rmse: 0.50884 |  0:02:05s
epoch 8  | loss: 0.26872 | val_0_rmse: 0.50895 | val_1_rmse: 0.52106 |  0:02:21s
epoch 9  | loss: 0.26434 | val_0_rmse: 0.51276 | val_1_rmse: 0.52772 |  0:02:37s
epoch 10 | loss: 0.25614 | val_0_rmse: 0.52652 | val_1_rmse: 0.52355 |  0:02:52s
epoch 11 | loss: 0.25521 | val_0_rmse: 0.49949 | val_1_rmse: 0.52035 |  0:03:08s
epoch 12 | loss: 0.25333 | val_0_rmse: 0.49862 | val_1_rmse: 0.51601 |  0:03:23s
epoch 13 | loss: 0.25063 | val_0_rmse: 0.49694 | val_1_rmse: 0.5146  |  0:03:39s
epoch 14 | loss: 0.25071 | val_0_rmse: 0.48588 | val_1_rmse: 0.50535 |  0:03:55s
epoch 15 | loss: 0.2469  | val_0_rmse: 0.4903  | val_1_rmse: 0.50801 |  0:04:10s
epoch 16 | loss: 0.24789 | val_0_rmse: 0.50562 | val_1_rmse: 0.51803 |  0:04:26s
epoch 17 | loss: 0.24711 | val_0_rmse: 0.50145 | val_1_rmse: 0.50584 |  0:04:42s
epoch 18 | loss: 0.24631 | val_0_rmse: 0.48315 | val_1_rmse: 0.50456 |  0:04:57s
epoch 19 | loss: 0.24532 | val_0_rmse: 0.49917 | val_1_rmse: 0.5176  |  0:05:13s
epoch 20 | loss: 0.24128 | val_0_rmse: 0.49487 | val_1_rmse: 0.51612 |  0:05:29s
epoch 21 | loss: 0.24151 | val_0_rmse: 0.48721 | val_1_rmse: 0.50653 |  0:05:44s
epoch 22 | loss: 0.24093 | val_0_rmse: 0.48652 | val_1_rmse: 0.50783 |  0:06:00s
epoch 23 | loss: 0.24036 | val_0_rmse: 0.47842 | val_1_rmse: 0.50628 |  0:06:15s
epoch 24 | loss: 0.23934 | val_0_rmse: 0.48832 | val_1_rmse: 0.50349 |  0:06:31s
epoch 25 | loss: 0.23956 | val_0_rmse: 0.49236 | val_1_rmse: 0.50823 |  0:06:47s
epoch 26 | loss: 0.23853 | val_0_rmse: 0.48817 | val_1_rmse: 0.51307 |  0:07:02s
epoch 27 | loss: 0.23918 | val_0_rmse: 0.48275 | val_1_rmse: 0.51166 |  0:07:18s
epoch 28 | loss: 0.23713 | val_0_rmse: 0.47859 | val_1_rmse: 0.50718 |  0:07:33s
epoch 29 | loss: 0.23619 | val_0_rmse: 0.59718 | val_1_rmse: 0.50502 |  0:07:49s
epoch 30 | loss: 0.23246 | val_0_rmse: 0.48324 | val_1_rmse: 0.51096 |  0:08:05s
epoch 31 | loss: 0.2335  | val_0_rmse: 0.66414 | val_1_rmse: 0.69578 |  0:08:20s
epoch 32 | loss: 0.23422 | val_0_rmse: 0.49076 | val_1_rmse: 0.5211  |  0:08:36s
epoch 33 | loss: 0.23221 | val_0_rmse: 0.48825 | val_1_rmse: 0.51916 |  0:08:52s
epoch 34 | loss: 0.23076 | val_0_rmse: 0.4889  | val_1_rmse: 0.52129 |  0:09:07s
epoch 35 | loss: 0.23154 | val_0_rmse: 0.47557 | val_1_rmse: 0.50717 |  0:09:23s
epoch 36 | loss: 0.23183 | val_0_rmse: 0.48385 | val_1_rmse: 0.50522 |  0:09:39s
epoch 37 | loss: 0.23007 | val_0_rmse: 0.47359 | val_1_rmse: 0.50394 |  0:09:54s
epoch 38 | loss: 0.22959 | val_0_rmse: 0.49676 | val_1_rmse: 0.49811 |  0:10:10s
epoch 39 | loss: 0.2319  | val_0_rmse: 0.52291 | val_1_rmse: 0.50585 |  0:10:26s
epoch 40 | loss: 0.23161 | val_0_rmse: 0.47203 | val_1_rmse: 0.50579 |  0:10:42s
epoch 41 | loss: 0.24873 | val_0_rmse: 0.53363 | val_1_rmse: 0.5029  |  0:10:57s
epoch 42 | loss: 0.23363 | val_0_rmse: 0.49366 | val_1_rmse: 0.49856 |  0:11:13s
epoch 43 | loss: 0.22971 | val_0_rmse: 0.49413 | val_1_rmse: 0.50837 |  0:11:29s
epoch 44 | loss: 0.22785 | val_0_rmse: 0.52073 | val_1_rmse: 0.52203 |  0:11:44s
epoch 45 | loss: 0.22736 | val_0_rmse: 0.49095 | val_1_rmse: 0.50224 |  0:12:00s
epoch 46 | loss: 0.22725 | val_0_rmse: 0.4954  | val_1_rmse: 0.50688 |  0:12:16s
epoch 47 | loss: 0.2269  | val_0_rmse: 0.50399 | val_1_rmse: 0.50684 |  0:12:32s
epoch 48 | loss: 0.22681 | val_0_rmse: 0.4995  | val_1_rmse: 0.50851 |  0:12:47s
epoch 49 | loss: 0.22471 | val_0_rmse: 0.4994  | val_1_rmse: 0.5078  |  0:13:03s
epoch 50 | loss: 0.22642 | val_0_rmse: 0.49826 | val_1_rmse: 0.506   |  0:13:18s
epoch 51 | loss: 0.22554 | val_0_rmse: 0.49338 | val_1_rmse: 0.50338 |  0:13:34s
epoch 52 | loss: 0.2251  | val_0_rmse: 0.50621 | val_1_rmse: 0.52518 |  0:13:50s
epoch 53 | loss: 0.225   | val_0_rmse: 0.48646 | val_1_rmse: 0.50165 |  0:14:06s
epoch 54 | loss: 0.22344 | val_0_rmse: 0.50375 | val_1_rmse: 0.52512 |  0:14:21s
epoch 55 | loss: 0.22402 | val_0_rmse: 0.47747 | val_1_rmse: 0.51048 |  0:14:37s
epoch 56 | loss: 0.22389 | val_0_rmse: 0.49202 | val_1_rmse: 0.5049  |  0:14:53s
epoch 57 | loss: 0.22309 | val_0_rmse: 0.50646 | val_1_rmse: 0.52569 |  0:15:09s
epoch 58 | loss: 0.22293 | val_0_rmse: 0.50362 | val_1_rmse: 0.53998 |  0:15:24s
epoch 59 | loss: 0.22179 | val_0_rmse: 0.46159 | val_1_rmse: 0.5014  |  0:15:40s
epoch 60 | loss: 0.22223 | val_0_rmse: 0.47319 | val_1_rmse: 0.49871 |  0:15:56s
epoch 61 | loss: 0.22207 | val_0_rmse: 0.50068 | val_1_rmse: 0.54057 |  0:16:12s
epoch 62 | loss: 0.22095 | val_0_rmse: 0.48141 | val_1_rmse: 0.52107 |  0:16:28s
epoch 63 | loss: 0.22162 | val_0_rmse: 0.46431 | val_1_rmse: 0.50192 |  0:16:43s
epoch 64 | loss: 0.21958 | val_0_rmse: 0.47464 | val_1_rmse: 0.50429 |  0:16:59s
epoch 65 | loss: 0.21973 | val_0_rmse: 0.47722 | val_1_rmse: 0.51161 |  0:17:15s
epoch 66 | loss: 0.22023 | val_0_rmse: 0.53454 | val_1_rmse: 0.5094  |  0:17:31s
epoch 67 | loss: 0.21921 | val_0_rmse: 0.56627 | val_1_rmse: 0.57698 |  0:17:46s
epoch 68 | loss: 0.22129 | val_0_rmse: 0.51527 | val_1_rmse: 0.53212 |  0:18:02s

Early stopping occured at epoch 68 with best_epoch = 38 and best_val_1_rmse = 0.49811
Best weights from best epoch are automatically used!
ended training at: 09:09:19
Feature importance:
Mean squared error is of 1831476076.7037206
Mean absolute error:28361.566242834975
MAPE:0.2792642374387959
R2 score:0.7213396507656339
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 2
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 09:09:22
epoch 0  | loss: 0.57893 | val_0_rmse: 0.69004 | val_1_rmse: 0.68178 |  0:00:15s
epoch 1  | loss: 0.30813 | val_0_rmse: 0.60373 | val_1_rmse: 0.60091 |  0:00:31s
epoch 2  | loss: 0.28653 | val_0_rmse: 0.5543  | val_1_rmse: 0.54958 |  0:00:47s
epoch 3  | loss: 0.27591 | val_0_rmse: 0.52342 | val_1_rmse: 0.51892 |  0:01:03s
epoch 4  | loss: 0.26697 | val_0_rmse: 0.50059 | val_1_rmse: 0.49706 |  0:01:18s
epoch 5  | loss: 0.26071 | val_0_rmse: 0.5035  | val_1_rmse: 0.50386 |  0:01:34s
epoch 6  | loss: 0.2593  | val_0_rmse: 0.49779 | val_1_rmse: 0.50388 |  0:01:50s
epoch 7  | loss: 0.25497 | val_0_rmse: 0.49322 | val_1_rmse: 0.50044 |  0:02:06s
epoch 8  | loss: 0.25406 | val_0_rmse: 0.4987  | val_1_rmse: 0.5082  |  0:02:21s
epoch 9  | loss: 0.25214 | val_0_rmse: 0.49235 | val_1_rmse: 0.50172 |  0:02:37s
epoch 10 | loss: 0.2545  | val_0_rmse: 0.4898  | val_1_rmse: 0.4982  |  0:02:53s
epoch 11 | loss: 0.24974 | val_0_rmse: 0.54235 | val_1_rmse: 0.55441 |  0:03:08s
epoch 12 | loss: 0.24671 | val_0_rmse: 0.48796 | val_1_rmse: 0.49519 |  0:03:24s
epoch 13 | loss: 0.24622 | val_0_rmse: 0.49882 | val_1_rmse: 0.50329 |  0:03:40s
epoch 14 | loss: 0.24377 | val_0_rmse: 0.48685 | val_1_rmse: 0.49687 |  0:03:56s
epoch 15 | loss: 0.2436  | val_0_rmse: 0.49284 | val_1_rmse: 0.49587 |  0:04:11s
epoch 16 | loss: 0.24275 | val_0_rmse: 0.49663 | val_1_rmse: 0.5315  |  0:04:27s
epoch 17 | loss: 0.24296 | val_0_rmse: 0.49416 | val_1_rmse: 0.50821 |  0:04:43s
epoch 18 | loss: 0.24407 | val_0_rmse: 0.51653 | val_1_rmse: 0.53316 |  0:04:59s
epoch 19 | loss: 0.23955 | val_0_rmse: 0.48472 | val_1_rmse: 0.49003 |  0:05:15s
epoch 20 | loss: 0.23955 | val_0_rmse: 0.4842  | val_1_rmse: 0.50013 |  0:05:31s
epoch 21 | loss: 0.23785 | val_0_rmse: 0.50647 | val_1_rmse: 0.52425 |  0:05:46s
epoch 22 | loss: 0.23702 | val_0_rmse: 0.51365 | val_1_rmse: 0.53565 |  0:06:02s
epoch 23 | loss: 0.23849 | val_0_rmse: 0.47625 | val_1_rmse: 0.49083 |  0:06:18s
epoch 24 | loss: 0.23737 | val_0_rmse: 0.48672 | val_1_rmse: 0.4998  |  0:06:34s
epoch 25 | loss: 0.23624 | val_0_rmse: 0.48001 | val_1_rmse: 0.49355 |  0:06:49s
epoch 26 | loss: 0.23742 | val_0_rmse: 0.51687 | val_1_rmse: 0.526   |  0:07:05s
epoch 27 | loss: 0.23485 | val_0_rmse: 0.47321 | val_1_rmse: 0.49248 |  0:07:21s
epoch 28 | loss: 0.23464 | val_0_rmse: 0.47493 | val_1_rmse: 0.49274 |  0:07:37s
epoch 29 | loss: 0.23315 | val_0_rmse: 0.62793 | val_1_rmse: 0.49154 |  0:07:53s
epoch 30 | loss: 0.23487 | val_0_rmse: 0.47327 | val_1_rmse: 0.49371 |  0:08:09s
epoch 31 | loss: 0.2338  | val_0_rmse: 0.47365 | val_1_rmse: 0.496   |  0:08:24s
epoch 32 | loss: 0.23232 | val_0_rmse: 0.52675 | val_1_rmse: 0.53649 |  0:08:40s
epoch 33 | loss: 0.2349  | val_0_rmse: 0.47197 | val_1_rmse: 0.49356 |  0:08:56s
epoch 34 | loss: 0.23216 | val_0_rmse: 0.4718  | val_1_rmse: 0.499   |  0:09:12s
epoch 35 | loss: 0.23154 | val_0_rmse: 0.47726 | val_1_rmse: 0.49669 |  0:09:27s
epoch 36 | loss: 0.22942 | val_0_rmse: 0.4706  | val_1_rmse: 0.49476 |  0:09:43s
epoch 37 | loss: 0.22855 | val_0_rmse: 0.46994 | val_1_rmse: 0.49593 |  0:09:59s
epoch 38 | loss: 0.2282  | val_0_rmse: 0.48601 | val_1_rmse: 0.51724 |  0:10:15s
epoch 39 | loss: 0.22563 | val_0_rmse: 0.4659  | val_1_rmse: 0.49147 |  0:10:31s
epoch 40 | loss: 0.22622 | val_0_rmse: 0.46768 | val_1_rmse: 0.49077 |  0:10:46s
epoch 41 | loss: 0.22586 | val_0_rmse: 0.48121 | val_1_rmse: 0.50981 |  0:11:02s
epoch 42 | loss: 0.22483 | val_0_rmse: 0.46868 | val_1_rmse: 0.4997  |  0:11:18s
epoch 43 | loss: 0.22494 | val_0_rmse: 0.48685 | val_1_rmse: 0.5185  |  0:11:34s
epoch 44 | loss: 0.22663 | val_0_rmse: 0.50286 | val_1_rmse: 0.51968 |  0:11:50s
epoch 45 | loss: 0.22587 | val_0_rmse: 0.47013 | val_1_rmse: 0.50338 |  0:12:06s
epoch 46 | loss: 0.22501 | val_0_rmse: 0.4651  | val_1_rmse: 0.49799 |  0:12:21s
epoch 47 | loss: 0.22457 | val_0_rmse: 0.47812 | val_1_rmse: 0.5102  |  0:12:37s
epoch 48 | loss: 0.22352 | val_0_rmse: 0.46633 | val_1_rmse: 0.5     |  0:12:53s
epoch 49 | loss: 0.22378 | val_0_rmse: 0.45863 | val_1_rmse: 0.48908 |  0:13:08s
epoch 50 | loss: 0.22341 | val_0_rmse: 0.46314 | val_1_rmse: 0.49647 |  0:13:24s
epoch 51 | loss: 0.22231 | val_0_rmse: 0.46281 | val_1_rmse: 0.49481 |  0:13:40s
epoch 52 | loss: 0.22161 | val_0_rmse: 0.47362 | val_1_rmse: 0.51275 |  0:13:56s
epoch 53 | loss: 0.22204 | val_0_rmse: 0.46233 | val_1_rmse: 0.4976  |  0:14:12s
epoch 54 | loss: 0.25681 | val_0_rmse: 0.63646 | val_1_rmse: 0.68485 |  0:14:27s
epoch 55 | loss: 0.25337 | val_0_rmse: 0.48687 | val_1_rmse: 0.50394 |  0:14:43s
epoch 56 | loss: 0.23786 | val_0_rmse: 0.47997 | val_1_rmse: 0.49827 |  0:14:59s
epoch 57 | loss: 0.2322  | val_0_rmse: 0.47894 | val_1_rmse: 0.50203 |  0:15:15s
epoch 58 | loss: 0.2313  | val_0_rmse: 0.47045 | val_1_rmse: 0.49707 |  0:15:31s
epoch 59 | loss: 0.22784 | val_0_rmse: 0.47543 | val_1_rmse: 0.51108 |  0:15:46s
epoch 60 | loss: 0.22626 | val_0_rmse: 0.48069 | val_1_rmse: 0.51051 |  0:16:02s
epoch 61 | loss: 0.2424  | val_0_rmse: 0.50222 | val_1_rmse: 0.52331 |  0:16:18s
epoch 62 | loss: 0.23805 | val_0_rmse: 0.47055 | val_1_rmse: 0.49415 |  0:16:34s
epoch 63 | loss: 0.22966 | val_0_rmse: 0.47339 | val_1_rmse: 0.49687 |  0:16:49s
epoch 64 | loss: 0.22855 | val_0_rmse: 0.47023 | val_1_rmse: 0.49509 |  0:17:05s
epoch 65 | loss: 0.22701 | val_0_rmse: 0.46729 | val_1_rmse: 0.49251 |  0:17:21s
epoch 66 | loss: 0.22481 | val_0_rmse: 0.46089 | val_1_rmse: 0.4906  |  0:17:37s
epoch 67 | loss: 0.22459 | val_0_rmse: 0.46582 | val_1_rmse: 0.49903 |  0:17:53s
epoch 68 | loss: 0.22359 | val_0_rmse: 0.52879 | val_1_rmse: 0.5626  |  0:18:09s
epoch 69 | loss: 0.22236 | val_0_rmse: 0.462   | val_1_rmse: 0.49248 |  0:18:25s
epoch 70 | loss: 0.2228  | val_0_rmse: 0.46074 | val_1_rmse: 0.49151 |  0:18:41s
epoch 71 | loss: 0.22237 | val_0_rmse: 0.45835 | val_1_rmse: 0.49313 |  0:18:56s
epoch 72 | loss: 0.22138 | val_0_rmse: 0.46583 | val_1_rmse: 0.50226 |  0:19:12s
epoch 73 | loss: 0.22216 | val_0_rmse: 0.45748 | val_1_rmse: 0.49101 |  0:19:28s
epoch 74 | loss: 0.22181 | val_0_rmse: 0.47911 | val_1_rmse: 0.50415 |  0:19:44s
epoch 75 | loss: 0.22042 | val_0_rmse: 0.47638 | val_1_rmse: 0.50268 |  0:20:00s
epoch 76 | loss: 0.22097 | val_0_rmse: 0.47166 | val_1_rmse: 0.50526 |  0:20:16s
epoch 77 | loss: 0.22101 | val_0_rmse: 0.45875 | val_1_rmse: 0.49612 |  0:20:32s
epoch 78 | loss: 0.22086 | val_0_rmse: 0.47885 | val_1_rmse: 0.50589 |  0:20:48s
epoch 79 | loss: 0.21939 | val_0_rmse: 0.46113 | val_1_rmse: 0.49231 |  0:21:04s

Early stopping occured at epoch 79 with best_epoch = 49 and best_val_1_rmse = 0.48908
Best weights from best epoch are automatically used!
ended training at: 09:30:32
Feature importance:
Mean squared error is of 1591933879.4449356
Mean absolute error:27944.565236196002
MAPE:0.26710229690341886
R2 score:0.7599355794881759
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 3
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 09:30:35
epoch 0  | loss: 0.65838 | val_0_rmse: 0.72431 | val_1_rmse: 0.7261  |  0:00:15s
epoch 1  | loss: 0.34251 | val_0_rmse: 0.61072 | val_1_rmse: 0.61447 |  0:00:31s
epoch 2  | loss: 0.29853 | val_0_rmse: 0.57551 | val_1_rmse: 0.57644 |  0:00:47s
epoch 3  | loss: 0.28406 | val_0_rmse: 0.53496 | val_1_rmse: 0.53763 |  0:01:03s
epoch 4  | loss: 0.27272 | val_0_rmse: 0.51405 | val_1_rmse: 0.51707 |  0:01:19s
epoch 5  | loss: 0.26935 | val_0_rmse: 0.53059 | val_1_rmse: 0.53409 |  0:01:34s
epoch 6  | loss: 0.26206 | val_0_rmse: 0.49684 | val_1_rmse: 0.50781 |  0:01:50s
epoch 7  | loss: 0.26061 | val_0_rmse: 0.50853 | val_1_rmse: 0.52158 |  0:02:06s
epoch 8  | loss: 0.25823 | val_0_rmse: 0.53553 | val_1_rmse: 0.54528 |  0:02:22s
epoch 9  | loss: 0.25685 | val_0_rmse: 0.49035 | val_1_rmse: 0.50653 |  0:02:38s
epoch 10 | loss: 0.25218 | val_0_rmse: 0.4858  | val_1_rmse: 0.49954 |  0:02:53s
epoch 11 | loss: 0.2491  | val_0_rmse: 0.49299 | val_1_rmse: 0.50616 |  0:03:09s
epoch 12 | loss: 0.24913 | val_0_rmse: 0.54038 | val_1_rmse: 0.53337 |  0:03:25s
epoch 13 | loss: 0.24569 | val_0_rmse: 0.49514 | val_1_rmse: 0.52951 |  0:03:40s
epoch 14 | loss: 0.24585 | val_0_rmse: 0.49269 | val_1_rmse: 0.50736 |  0:03:56s
epoch 15 | loss: 0.24441 | val_0_rmse: 0.48841 | val_1_rmse: 0.50481 |  0:04:12s
epoch 16 | loss: 0.24419 | val_0_rmse: 0.48784 | val_1_rmse: 0.58725 |  0:04:28s
epoch 17 | loss: 0.24241 | val_0_rmse: 0.4958  | val_1_rmse: 0.49848 |  0:04:43s
epoch 18 | loss: 0.24062 | val_0_rmse: 0.47998 | val_1_rmse: 0.49931 |  0:04:59s
epoch 19 | loss: 0.24029 | val_0_rmse: 0.51498 | val_1_rmse: 0.52087 |  0:05:15s
epoch 20 | loss: 0.2402  | val_0_rmse: 0.47662 | val_1_rmse: 0.53443 |  0:05:31s
epoch 21 | loss: 0.23907 | val_0_rmse: 0.47552 | val_1_rmse: 0.49951 |  0:05:47s
epoch 22 | loss: 0.23752 | val_0_rmse: 0.48755 | val_1_rmse: 0.74421 |  0:06:02s
epoch 23 | loss: 0.23801 | val_0_rmse: 0.496   | val_1_rmse: 0.67967 |  0:06:18s
epoch 24 | loss: 0.23592 | val_0_rmse: 0.47476 | val_1_rmse: 0.71851 |  0:06:34s
epoch 25 | loss: 0.23607 | val_0_rmse: 0.48155 | val_1_rmse: 0.67804 |  0:06:50s
epoch 26 | loss: 0.23534 | val_0_rmse: 0.47106 | val_1_rmse: 0.49588 |  0:07:05s
epoch 27 | loss: 0.2334  | val_0_rmse: 0.47805 | val_1_rmse: 0.5049  |  0:07:21s
epoch 28 | loss: 0.23387 | val_0_rmse: 0.47593 | val_1_rmse: 0.50377 |  0:07:37s
epoch 29 | loss: 0.23336 | val_0_rmse: 0.47856 | val_1_rmse: 0.50622 |  0:07:53s
epoch 30 | loss: 0.23274 | val_0_rmse: 0.47255 | val_1_rmse: 0.50044 |  0:08:08s
epoch 31 | loss: 0.23235 | val_0_rmse: 0.47664 | val_1_rmse: 0.49995 |  0:08:24s
epoch 32 | loss: 0.23027 | val_0_rmse: 0.46839 | val_1_rmse: 0.49389 |  0:08:40s
epoch 33 | loss: 0.23095 | val_0_rmse: 0.47232 | val_1_rmse: 0.50204 |  0:08:56s
epoch 34 | loss: 0.22909 | val_0_rmse: 0.49025 | val_1_rmse: 0.51254 |  0:09:11s
epoch 35 | loss: 0.23046 | val_0_rmse: 0.46973 | val_1_rmse: 0.49842 |  0:09:27s
epoch 36 | loss: 0.22843 | val_0_rmse: 0.4871  | val_1_rmse: 0.51021 |  0:09:43s
epoch 37 | loss: 0.22889 | val_0_rmse: 0.46951 | val_1_rmse: 0.49796 |  0:09:59s
epoch 38 | loss: 0.2276  | val_0_rmse: 0.49307 | val_1_rmse: 0.50146 |  0:10:14s
epoch 39 | loss: 0.22905 | val_0_rmse: 0.47032 | val_1_rmse: 0.50443 |  0:10:30s
epoch 40 | loss: 0.22643 | val_0_rmse: 0.49937 | val_1_rmse: 0.52043 |  0:10:46s
epoch 41 | loss: 0.2271  | val_0_rmse: 0.46653 | val_1_rmse: 0.49858 |  0:11:02s
epoch 42 | loss: 0.22815 | val_0_rmse: 0.46497 | val_1_rmse: 0.49547 |  0:11:17s
epoch 43 | loss: 0.22777 | val_0_rmse: 0.46163 | val_1_rmse: 0.49086 |  0:11:33s
epoch 44 | loss: 0.22635 | val_0_rmse: 0.49399 | val_1_rmse: 0.51305 |  0:11:49s
epoch 45 | loss: 0.22487 | val_0_rmse: 0.5084  | val_1_rmse: 0.53016 |  0:12:04s
epoch 46 | loss: 0.225   | val_0_rmse: 0.48889 | val_1_rmse: 0.52279 |  0:12:20s
epoch 47 | loss: 0.22707 | val_0_rmse: 0.47904 | val_1_rmse: 0.51543 |  0:12:36s
epoch 48 | loss: 0.22403 | val_0_rmse: 0.47855 | val_1_rmse: 0.5142  |  0:12:51s
epoch 49 | loss: 0.22358 | val_0_rmse: 0.47289 | val_1_rmse: 0.50254 |  0:13:07s
epoch 50 | loss: 0.22257 | val_0_rmse: 0.47357 | val_1_rmse: 0.50206 |  0:13:23s
epoch 51 | loss: 0.2223  | val_0_rmse: 0.45826 | val_1_rmse: 0.49306 |  0:13:39s
epoch 52 | loss: 0.22393 | val_0_rmse: 0.46891 | val_1_rmse: 0.50652 |  0:13:54s
epoch 53 | loss: 0.22432 | val_0_rmse: 0.5423  | val_1_rmse: 0.51753 |  0:14:10s
epoch 54 | loss: 0.22439 | val_0_rmse: 0.48445 | val_1_rmse: 0.50699 |  0:14:26s
epoch 55 | loss: 0.222   | val_0_rmse: 0.47821 | val_1_rmse: 0.49474 |  0:14:41s
epoch 56 | loss: 0.22265 | val_0_rmse: 0.51106 | val_1_rmse: 0.53278 |  0:14:57s
epoch 57 | loss: 0.22104 | val_0_rmse: 0.47459 | val_1_rmse: 0.51235 |  0:15:13s
epoch 58 | loss: 0.22082 | val_0_rmse: 0.47799 | val_1_rmse: 0.50827 |  0:15:28s
epoch 59 | loss: 0.22036 | val_0_rmse: 0.48382 | val_1_rmse: 0.50556 |  0:15:44s
epoch 60 | loss: 0.22085 | val_0_rmse: 0.46637 | val_1_rmse: 0.49275 |  0:16:00s
epoch 61 | loss: 0.22088 | val_0_rmse: 0.4622  | val_1_rmse: 0.49894 |  0:16:16s
epoch 62 | loss: 0.21886 | val_0_rmse: 0.46254 | val_1_rmse: 0.50307 |  0:16:31s
epoch 63 | loss: 0.22074 | val_0_rmse: 0.48159 | val_1_rmse: 0.50144 |  0:16:47s
epoch 64 | loss: 0.21839 | val_0_rmse: 0.51094 | val_1_rmse: 0.49909 |  0:17:03s
epoch 65 | loss: 0.21973 | val_0_rmse: 0.46224 | val_1_rmse: 0.49863 |  0:17:18s
epoch 66 | loss: 0.22711 | val_0_rmse: 0.88312 | val_1_rmse: 0.5665  |  0:17:34s
epoch 67 | loss: 0.22596 | val_0_rmse: 0.67538 | val_1_rmse: 0.56068 |  0:17:50s
epoch 68 | loss: 0.21983 | val_0_rmse: 0.46355 | val_1_rmse: 0.52047 |  0:18:05s
epoch 69 | loss: 0.22005 | val_0_rmse: 0.46103 | val_1_rmse: 0.49716 |  0:18:21s
epoch 70 | loss: 0.21702 | val_0_rmse: 0.45507 | val_1_rmse: 0.49796 |  0:18:37s
epoch 71 | loss: 0.21574 | val_0_rmse: 0.48861 | val_1_rmse: 0.54894 |  0:18:53s
epoch 72 | loss: 0.21871 | val_0_rmse: 0.45725 | val_1_rmse: 0.50598 |  0:19:08s
epoch 73 | loss: 0.2171  | val_0_rmse: 0.47733 | val_1_rmse: 0.50259 |  0:19:24s

Early stopping occured at epoch 73 with best_epoch = 43 and best_val_1_rmse = 0.49086
Best weights from best epoch are automatically used!
ended training at: 09:50:06
Feature importance:
Mean squared error is of 1554797958.1433182
Mean absolute error:28114.56695153863
MAPE:0.27600613527348433
R2 score:0.7646008080638362
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 4
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 09:50:09
epoch 0  | loss: 0.62554 | val_0_rmse: 0.67744 | val_1_rmse: 0.67741 |  0:00:15s
epoch 1  | loss: 0.30787 | val_0_rmse: 0.60724 | val_1_rmse: 0.6048  |  0:00:31s
epoch 2  | loss: 0.28608 | val_0_rmse: 0.55823 | val_1_rmse: 0.55758 |  0:00:47s
epoch 3  | loss: 0.27222 | val_0_rmse: 0.52097 | val_1_rmse: 0.52069 |  0:01:02s
epoch 4  | loss: 0.26729 | val_0_rmse: 0.50009 | val_1_rmse: 0.50096 |  0:01:18s
epoch 5  | loss: 0.26305 | val_0_rmse: 0.50153 | val_1_rmse: 0.50647 |  0:01:34s
epoch 6  | loss: 0.2593  | val_0_rmse: 0.48994 | val_1_rmse: 0.49305 |  0:01:49s
epoch 7  | loss: 0.25513 | val_0_rmse: 0.50318 | val_1_rmse: 0.50416 |  0:02:05s
epoch 8  | loss: 0.25217 | val_0_rmse: 0.52415 | val_1_rmse: 0.52244 |  0:02:21s
epoch 9  | loss: 0.25095 | val_0_rmse: 0.49534 | val_1_rmse: 0.50269 |  0:02:36s
epoch 10 | loss: 0.24921 | val_0_rmse: 0.48695 | val_1_rmse: 0.49567 |  0:02:52s
epoch 11 | loss: 0.24911 | val_0_rmse: 0.48732 | val_1_rmse: 0.49697 |  0:03:08s
epoch 12 | loss: 0.24757 | val_0_rmse: 0.49328 | val_1_rmse: 0.49347 |  0:03:23s
epoch 13 | loss: 0.24706 | val_0_rmse: 0.48542 | val_1_rmse: 0.49354 |  0:03:39s
epoch 14 | loss: 0.24439 | val_0_rmse: 0.48531 | val_1_rmse: 0.49813 |  0:03:55s
epoch 15 | loss: 0.24352 | val_0_rmse: 0.4921  | val_1_rmse: 0.50118 |  0:04:10s
epoch 16 | loss: 0.24344 | val_0_rmse: 0.52076 | val_1_rmse: 0.53424 |  0:04:26s
epoch 17 | loss: 0.24251 | val_0_rmse: 0.49575 | val_1_rmse: 0.50396 |  0:04:42s
epoch 18 | loss: 0.24025 | val_0_rmse: 0.4982  | val_1_rmse: 0.51703 |  0:04:58s
epoch 19 | loss: 0.24341 | val_0_rmse: 0.48156 | val_1_rmse: 0.49506 |  0:05:13s
epoch 20 | loss: 0.24225 | val_0_rmse: 0.48654 | val_1_rmse: 0.49512 |  0:05:29s
epoch 21 | loss: 0.23901 | val_0_rmse: 0.4946  | val_1_rmse: 0.50371 |  0:05:44s
epoch 22 | loss: 0.23938 | val_0_rmse: 0.4828  | val_1_rmse: 0.5005  |  0:06:00s
epoch 23 | loss: 0.2397  | val_0_rmse: 0.47699 | val_1_rmse: 0.49082 |  0:06:16s
epoch 24 | loss: 0.23696 | val_0_rmse: 0.48923 | val_1_rmse: 0.49773 |  0:06:32s
epoch 25 | loss: 0.23631 | val_0_rmse: 0.4724  | val_1_rmse: 0.49479 |  0:06:47s
epoch 26 | loss: 0.23666 | val_0_rmse: 0.50821 | val_1_rmse: 0.51481 |  0:07:03s
epoch 27 | loss: 0.23451 | val_0_rmse: 0.5032  | val_1_rmse: 0.52821 |  0:07:19s
epoch 28 | loss: 0.23503 | val_0_rmse: 0.47427 | val_1_rmse: 0.49155 |  0:07:34s
epoch 29 | loss: 0.23513 | val_0_rmse: 0.47107 | val_1_rmse: 0.4935  |  0:07:50s
epoch 30 | loss: 0.23209 | val_0_rmse: 0.47083 | val_1_rmse: 0.48919 |  0:08:06s
epoch 31 | loss: 0.23198 | val_0_rmse: 0.49189 | val_1_rmse: 0.5022  |  0:08:21s
epoch 32 | loss: 0.23113 | val_0_rmse: 0.49515 | val_1_rmse: 0.52438 |  0:08:37s
epoch 33 | loss: 0.23187 | val_0_rmse: 0.47981 | val_1_rmse: 0.58078 |  0:08:53s
epoch 34 | loss: 0.23182 | val_0_rmse: 0.49146 | val_1_rmse: 0.58372 |  0:09:08s
epoch 35 | loss: 0.23004 | val_0_rmse: 0.46507 | val_1_rmse: 0.49106 |  0:09:24s
epoch 36 | loss: 0.23155 | val_0_rmse: 0.46783 | val_1_rmse: 0.4896  |  0:09:40s
epoch 37 | loss: 0.22891 | val_0_rmse: 0.47191 | val_1_rmse: 0.49451 |  0:09:55s
epoch 38 | loss: 0.22925 | val_0_rmse: 0.46844 | val_1_rmse: 0.49219 |  0:10:11s
epoch 39 | loss: 0.2285  | val_0_rmse: 0.50038 | val_1_rmse: 0.49632 |  0:10:27s
epoch 40 | loss: 0.22726 | val_0_rmse: 0.48383 | val_1_rmse: 0.50419 |  0:10:42s
epoch 41 | loss: 0.22717 | val_0_rmse: 0.46642 | val_1_rmse: 0.49171 |  0:10:58s
epoch 42 | loss: 0.22855 | val_0_rmse: 0.46461 | val_1_rmse: 0.49605 |  0:11:13s
epoch 43 | loss: 0.22516 | val_0_rmse: 0.49192 | val_1_rmse: 0.73661 |  0:11:29s
epoch 44 | loss: 0.22959 | val_0_rmse: 0.48288 | val_1_rmse: 0.50416 |  0:11:45s
epoch 45 | loss: 0.22697 | val_0_rmse: 0.46377 | val_1_rmse: 0.49048 |  0:12:01s
epoch 46 | loss: 0.22496 | val_0_rmse: 0.4627  | val_1_rmse: 0.49094 |  0:12:16s
epoch 47 | loss: 0.22564 | val_0_rmse: 0.46578 | val_1_rmse: 0.49659 |  0:12:32s
epoch 48 | loss: 0.22483 | val_0_rmse: 0.47577 | val_1_rmse: 0.5061  |  0:12:48s
epoch 49 | loss: 0.22448 | val_0_rmse: 0.46495 | val_1_rmse: 0.49677 |  0:13:03s
epoch 50 | loss: 0.24257 | val_0_rmse: 0.49921 | val_1_rmse: 1.43871 |  0:13:19s
epoch 51 | loss: 0.2312  | val_0_rmse: 0.47658 | val_1_rmse: 0.49789 |  0:13:35s
epoch 52 | loss: 0.22995 | val_0_rmse: 0.47484 | val_1_rmse: 0.50553 |  0:13:50s
epoch 53 | loss: 0.22775 | val_0_rmse: 0.46768 | val_1_rmse: 0.5     |  0:14:06s
epoch 54 | loss: 0.22524 | val_0_rmse: 0.4688  | val_1_rmse: 0.49326 |  0:14:22s
epoch 55 | loss: 0.22422 | val_0_rmse: 0.49586 | val_1_rmse: 0.53282 |  0:14:38s
epoch 56 | loss: 0.2247  | val_0_rmse: 0.48824 | val_1_rmse: 0.49856 |  0:14:53s
epoch 57 | loss: 0.22374 | val_0_rmse: 0.46933 | val_1_rmse: 0.50263 |  0:15:09s
epoch 58 | loss: 0.22356 | val_0_rmse: 0.46284 | val_1_rmse: 0.49232 |  0:15:25s
epoch 59 | loss: 0.22409 | val_0_rmse: 0.48411 | val_1_rmse: 0.49502 |  0:15:40s
epoch 60 | loss: 0.2229  | val_0_rmse: 0.45687 | val_1_rmse: 0.48882 |  0:15:56s
epoch 61 | loss: 0.22178 | val_0_rmse: 0.46113 | val_1_rmse: 0.49737 |  0:16:12s
epoch 62 | loss: 0.21922 | val_0_rmse: 0.46063 | val_1_rmse: 0.49724 |  0:16:27s
epoch 63 | loss: 0.22058 | val_0_rmse: 0.46741 | val_1_rmse: 0.50272 |  0:16:43s
epoch 64 | loss: 0.22084 | val_0_rmse: 0.46785 | val_1_rmse: 0.49565 |  0:16:59s
epoch 65 | loss: 0.22296 | val_0_rmse: 0.45952 | val_1_rmse: 0.49697 |  0:17:15s
epoch 66 | loss: 0.21987 | val_0_rmse: 0.461   | val_1_rmse: 0.49232 |  0:17:31s
epoch 67 | loss: 0.21906 | val_0_rmse: 0.46084 | val_1_rmse: 0.48903 |  0:17:47s
epoch 68 | loss: 0.22036 | val_0_rmse: 0.4818  | val_1_rmse: 0.51863 |  0:18:02s
epoch 69 | loss: 0.21971 | val_0_rmse: 0.47177 | val_1_rmse: 0.49068 |  0:18:18s
epoch 70 | loss: 0.21927 | val_0_rmse: 0.78905 | val_1_rmse: 0.48778 |  0:18:34s
epoch 71 | loss: 0.21843 | val_0_rmse: 0.47021 | val_1_rmse: 0.50027 |  0:18:50s
epoch 72 | loss: 0.21767 | val_0_rmse: 0.60825 | val_1_rmse: 0.50371 |  0:19:05s
epoch 73 | loss: 0.21859 | val_0_rmse: 0.45664 | val_1_rmse: 0.49469 |  0:19:21s
epoch 74 | loss: 0.2192  | val_0_rmse: 0.56682 | val_1_rmse: 0.49168 |  0:19:36s
epoch 75 | loss: 0.21859 | val_0_rmse: 0.47218 | val_1_rmse: 0.50035 |  0:19:52s
epoch 76 | loss: 0.21743 | val_0_rmse: 0.48988 | val_1_rmse: 0.52433 |  0:20:08s
epoch 77 | loss: 0.21776 | val_0_rmse: 1.32889 | val_1_rmse: 1.81766 |  0:20:24s
epoch 78 | loss: 0.21663 | val_0_rmse: 0.51556 | val_1_rmse: 0.49221 |  0:20:39s
epoch 79 | loss: 0.21551 | val_0_rmse: 0.50937 | val_1_rmse: 0.4981  |  0:20:55s
epoch 80 | loss: 0.2171  | val_0_rmse: 0.45628 | val_1_rmse: 0.49096 |  0:21:11s
epoch 81 | loss: 0.21622 | val_0_rmse: 0.48612 | val_1_rmse: 0.49947 |  0:21:26s
epoch 82 | loss: 0.21585 | val_0_rmse: 0.50059 | val_1_rmse: 0.52156 |  0:21:42s
epoch 83 | loss: 0.21581 | val_0_rmse: 0.49404 | val_1_rmse: 0.49647 |  0:21:58s
epoch 84 | loss: 0.21608 | val_0_rmse: 0.47736 | val_1_rmse: 0.52199 |  0:22:13s
epoch 85 | loss: 0.21539 | val_0_rmse: 0.46669 | val_1_rmse: 0.50168 |  0:22:29s
epoch 86 | loss: 0.21516 | val_0_rmse: 0.46423 | val_1_rmse: 0.50093 |  0:22:45s
epoch 87 | loss: 0.21682 | val_0_rmse: 0.4601  | val_1_rmse: 0.49602 |  0:23:00s
epoch 88 | loss: 0.21529 | val_0_rmse: 0.54359 | val_1_rmse: 0.55704 |  0:23:16s
epoch 89 | loss: 0.21674 | val_0_rmse: 0.48122 | val_1_rmse: 0.50863 |  0:23:32s
epoch 90 | loss: 0.21538 | val_0_rmse: 0.4611  | val_1_rmse: 0.50346 |  0:23:48s
epoch 91 | loss: 0.2145  | val_0_rmse: 0.45227 | val_1_rmse: 0.49151 |  0:24:03s
epoch 92 | loss: 0.21369 | val_0_rmse: 0.57021 | val_1_rmse: 0.61295 |  0:24:19s
epoch 93 | loss: 0.21587 | val_0_rmse: 0.4753  | val_1_rmse: 0.49665 |  0:24:35s
epoch 94 | loss: 0.21468 | val_0_rmse: 0.45808 | val_1_rmse: 0.49215 |  0:24:50s
epoch 95 | loss: 0.21262 | val_0_rmse: 0.46558 | val_1_rmse: 0.49995 |  0:25:06s
epoch 96 | loss: 0.21314 | val_0_rmse: 0.45427 | val_1_rmse: 0.53527 |  0:25:22s
epoch 97 | loss: 0.21248 | val_0_rmse: 0.528   | val_1_rmse: 0.54076 |  0:25:38s
epoch 98 | loss: 0.21248 | val_0_rmse: 0.46192 | val_1_rmse: 0.49998 |  0:25:54s
epoch 99 | loss: 0.21413 | val_0_rmse: 0.52664 | val_1_rmse: 0.73442 |  0:26:09s
epoch 100| loss: 0.21367 | val_0_rmse: 0.45213 | val_1_rmse: 0.71987 |  0:26:25s

Early stopping occured at epoch 100 with best_epoch = 70 and best_val_1_rmse = 0.48778
Best weights from best epoch are automatically used!
ended training at: 10:16:40
Feature importance:
Mean squared error is of 1650324323.193865
Mean absolute error:28449.699610089174
MAPE:0.277029500168088
R2 score:0.7485866795544279
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 5
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 10:16:43
epoch 0  | loss: 0.64038 | val_0_rmse: 0.72297 | val_1_rmse: 0.71822 |  0:00:15s
epoch 1  | loss: 0.31949 | val_0_rmse: 0.61758 | val_1_rmse: 0.61755 |  0:00:31s
epoch 2  | loss: 0.28706 | val_0_rmse: 0.56866 | val_1_rmse: 0.56958 |  0:00:47s
epoch 3  | loss: 0.27413 | val_0_rmse: 0.53087 | val_1_rmse: 0.53447 |  0:01:03s
epoch 4  | loss: 0.2662  | val_0_rmse: 0.51583 | val_1_rmse: 0.52118 |  0:01:18s
epoch 5  | loss: 0.2618  | val_0_rmse: 0.49541 | val_1_rmse: 0.50234 |  0:01:34s
epoch 6  | loss: 0.25712 | val_0_rmse: 0.48773 | val_1_rmse: 0.49875 |  0:01:50s
epoch 7  | loss: 0.2542  | val_0_rmse: 0.49188 | val_1_rmse: 0.5043  |  0:02:06s
epoch 8  | loss: 0.25092 | val_0_rmse: 0.48607 | val_1_rmse: 0.49996 |  0:02:21s
epoch 9  | loss: 0.2498  | val_0_rmse: 0.52833 | val_1_rmse: 0.5433  |  0:02:37s
epoch 10 | loss: 0.2468  | val_0_rmse: 0.49443 | val_1_rmse: 1.13745 |  0:02:53s
epoch 11 | loss: 0.24651 | val_0_rmse: 0.4823  | val_1_rmse: 0.49846 |  0:03:08s
epoch 12 | loss: 0.24283 | val_0_rmse: 0.52915 | val_1_rmse: 0.5506  |  0:03:24s
epoch 13 | loss: 0.24229 | val_0_rmse: 0.4856  | val_1_rmse: 1.17316 |  0:03:40s
epoch 14 | loss: 0.24225 | val_0_rmse: 0.5084  | val_1_rmse: 0.5289  |  0:03:55s
epoch 15 | loss: 0.23967 | val_0_rmse: 0.48064 | val_1_rmse: 0.49863 |  0:04:11s
epoch 16 | loss: 0.24297 | val_0_rmse: 0.5226  | val_1_rmse: 0.5412  |  0:04:27s
epoch 17 | loss: 0.23938 | val_0_rmse: 0.47794 | val_1_rmse: 0.49596 |  0:04:42s
epoch 18 | loss: 0.23778 | val_0_rmse: 0.49967 | val_1_rmse: 0.51873 |  0:04:58s
epoch 19 | loss: 0.23715 | val_0_rmse: 0.48867 | val_1_rmse: 0.51467 |  0:05:14s
epoch 20 | loss: 0.2527  | val_0_rmse: 0.54297 | val_1_rmse: 0.55989 |  0:05:30s
epoch 21 | loss: 0.24484 | val_0_rmse: 0.64796 | val_1_rmse: 0.53096 |  0:05:45s
epoch 22 | loss: 0.23834 | val_0_rmse: 0.49898 | val_1_rmse: 0.52194 |  0:06:01s
epoch 23 | loss: 0.23733 | val_0_rmse: 0.47987 | val_1_rmse: 0.5024  |  0:06:17s
epoch 24 | loss: 0.2347  | val_0_rmse: 0.49827 | val_1_rmse: 0.49863 |  0:06:33s
epoch 25 | loss: 0.23327 | val_0_rmse: 0.48967 | val_1_rmse: 0.51174 |  0:06:49s
epoch 26 | loss: 0.23255 | val_0_rmse: 0.49064 | val_1_rmse: 0.50481 |  0:07:04s
epoch 27 | loss: 0.23343 | val_0_rmse: 0.4711  | val_1_rmse: 0.4959  |  0:07:20s
epoch 28 | loss: 0.23074 | val_0_rmse: 0.47268 | val_1_rmse: 0.49825 |  0:07:36s
epoch 29 | loss: 0.23172 | val_0_rmse: 0.47007 | val_1_rmse: 0.49819 |  0:07:52s
epoch 30 | loss: 0.23086 | val_0_rmse: 0.4723  | val_1_rmse: 0.50027 |  0:08:07s
epoch 31 | loss: 0.23059 | val_0_rmse: 0.47821 | val_1_rmse: 0.49848 |  0:08:23s
epoch 32 | loss: 0.23119 | val_0_rmse: 0.47663 | val_1_rmse: 0.504   |  0:08:39s
epoch 33 | loss: 0.22903 | val_0_rmse: 0.50971 | val_1_rmse: 0.54071 |  0:08:54s
epoch 34 | loss: 0.22904 | val_0_rmse: 0.47354 | val_1_rmse: 0.49923 |  0:09:10s
epoch 35 | loss: 0.22949 | val_0_rmse: 0.47489 | val_1_rmse: 0.49993 |  0:09:26s
epoch 36 | loss: 0.22714 | val_0_rmse: 0.47176 | val_1_rmse: 0.50071 |  0:09:41s
epoch 37 | loss: 0.2258  | val_0_rmse: 0.47831 | val_1_rmse: 0.50647 |  0:09:57s
epoch 38 | loss: 0.22704 | val_0_rmse: 0.47447 | val_1_rmse: 0.50586 |  0:10:13s
epoch 39 | loss: 0.22774 | val_0_rmse: 0.53803 | val_1_rmse: 0.56044 |  0:10:29s
epoch 40 | loss: 0.22738 | val_0_rmse: 0.48005 | val_1_rmse: 0.51637 |  0:10:45s
epoch 41 | loss: 0.22582 | val_0_rmse: 0.4645  | val_1_rmse: 0.5029  |  0:11:00s
epoch 42 | loss: 0.22628 | val_0_rmse: 0.54446 | val_1_rmse: 0.57157 |  0:11:16s
epoch 43 | loss: 0.22653 | val_0_rmse: 0.49545 | val_1_rmse: 0.53652 |  0:11:32s
epoch 44 | loss: 0.22408 | val_0_rmse: 0.46978 | val_1_rmse: 0.50322 |  0:11:48s
epoch 45 | loss: 0.22496 | val_0_rmse: 0.49421 | val_1_rmse: 0.52932 |  0:12:04s
epoch 46 | loss: 0.22429 | val_0_rmse: 0.47389 | val_1_rmse: 0.51982 |  0:12:19s
epoch 47 | loss: 0.22236 | val_0_rmse: 0.46731 | val_1_rmse: 0.5003  |  0:12:35s
epoch 48 | loss: 0.22379 | val_0_rmse: 0.48507 | val_1_rmse: 0.52591 |  0:12:51s
epoch 49 | loss: 0.22274 | val_0_rmse: 0.47081 | val_1_rmse: 0.50398 |  0:13:06s
epoch 50 | loss: 0.22128 | val_0_rmse: 0.46286 | val_1_rmse: 0.49927 |  0:13:22s
epoch 51 | loss: 0.22243 | val_0_rmse: 0.49087 | val_1_rmse: 0.5206  |  0:13:38s
epoch 52 | loss: 0.22237 | val_0_rmse: 0.48235 | val_1_rmse: 0.52958 |  0:13:54s
epoch 53 | loss: 0.22178 | val_0_rmse: 0.50461 | val_1_rmse: 0.55087 |  0:14:09s
epoch 54 | loss: 0.22106 | val_0_rmse: 0.46288 | val_1_rmse: 0.50086 |  0:14:25s
epoch 55 | loss: 0.2201  | val_0_rmse: 0.47063 | val_1_rmse: 0.52579 |  0:14:41s
epoch 56 | loss: 0.22052 | val_0_rmse: 0.47415 | val_1_rmse: 0.50907 |  0:14:57s
epoch 57 | loss: 0.2202  | val_0_rmse: 0.47917 | val_1_rmse: 0.52598 |  0:15:12s

Early stopping occured at epoch 57 with best_epoch = 27 and best_val_1_rmse = 0.4959
Best weights from best epoch are automatically used!
ended training at: 10:32:02
Feature importance:
Mean squared error is of 1625946876.9222593
Mean absolute error:28284.98262665915
MAPE:0.2676976838039037
R2 score:0.7560352713470933
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 6
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 10:32:05
epoch 0  | loss: 0.59047 | val_0_rmse: 0.69552 | val_1_rmse: 0.69639 |  0:00:15s
epoch 1  | loss: 0.31679 | val_0_rmse: 0.61849 | val_1_rmse: 0.62025 |  0:00:31s
epoch 2  | loss: 0.29062 | val_0_rmse: 0.55708 | val_1_rmse: 0.55999 |  0:00:47s
epoch 3  | loss: 0.27743 | val_0_rmse: 0.53073 | val_1_rmse: 0.53446 |  0:01:03s
epoch 4  | loss: 0.26671 | val_0_rmse: 0.50303 | val_1_rmse: 0.50811 |  0:01:19s
epoch 5  | loss: 0.2601  | val_0_rmse: 0.50029 | val_1_rmse: 0.50777 |  0:01:34s
epoch 6  | loss: 0.25938 | val_0_rmse: 0.4994  | val_1_rmse: 0.50895 |  0:01:50s
epoch 7  | loss: 0.25371 | val_0_rmse: 0.51058 | val_1_rmse: 0.52039 |  0:02:06s
epoch 8  | loss: 0.2505  | val_0_rmse: 0.50132 | val_1_rmse: 0.51479 |  0:02:21s
epoch 9  | loss: 0.25019 | val_0_rmse: 0.49611 | val_1_rmse: 0.51051 |  0:02:37s
epoch 10 | loss: 0.24786 | val_0_rmse: 0.53327 | val_1_rmse: 0.59017 |  0:02:53s
epoch 11 | loss: 0.24664 | val_0_rmse: 0.48949 | val_1_rmse: 0.50523 |  0:03:09s
epoch 12 | loss: 0.24443 | val_0_rmse: 0.49056 | val_1_rmse: 0.50348 |  0:03:25s
epoch 13 | loss: 0.24372 | val_0_rmse: 0.50146 | val_1_rmse: 0.51313 |  0:03:40s
epoch 14 | loss: 0.24334 | val_0_rmse: 0.49643 | val_1_rmse: 0.5137  |  0:03:56s
epoch 15 | loss: 0.24037 | val_0_rmse: 0.485   | val_1_rmse: 0.50116 |  0:04:12s
epoch 16 | loss: 0.23969 | val_0_rmse: 0.48083 | val_1_rmse: 0.49956 |  0:04:27s
epoch 17 | loss: 0.23885 | val_0_rmse: 0.49159 | val_1_rmse: 0.50677 |  0:04:43s
epoch 18 | loss: 0.23679 | val_0_rmse: 0.5057  | val_1_rmse: 0.50206 |  0:04:59s
epoch 19 | loss: 0.23744 | val_0_rmse: 0.48066 | val_1_rmse: 0.49891 |  0:05:15s
epoch 20 | loss: 0.2358  | val_0_rmse: 0.50213 | val_1_rmse: 0.51909 |  0:05:30s
epoch 21 | loss: 0.23565 | val_0_rmse: 0.48527 | val_1_rmse: 0.49996 |  0:05:46s
epoch 22 | loss: 0.23361 | val_0_rmse: 0.6059  | val_1_rmse: 0.62345 |  0:06:02s
epoch 23 | loss: 0.23468 | val_0_rmse: 0.47596 | val_1_rmse: 0.49835 |  0:06:18s
epoch 24 | loss: 0.23256 | val_0_rmse: 0.48833 | val_1_rmse: 0.51707 |  0:06:33s
epoch 25 | loss: 0.23187 | val_0_rmse: 0.47413 | val_1_rmse: 0.49942 |  0:06:49s
epoch 26 | loss: 0.23127 | val_0_rmse: 0.49767 | val_1_rmse: 0.54077 |  0:07:05s
epoch 27 | loss: 0.23195 | val_0_rmse: 0.51209 | val_1_rmse: 0.54042 |  0:07:21s
epoch 28 | loss: 0.22852 | val_0_rmse: 0.49038 | val_1_rmse: 0.52593 |  0:07:37s
epoch 29 | loss: 0.22913 | val_0_rmse: 0.50284 | val_1_rmse: 0.54964 |  0:07:52s
epoch 30 | loss: 0.22789 | val_0_rmse: 0.50676 | val_1_rmse: 0.56594 |  0:08:08s
epoch 31 | loss: 0.22852 | val_0_rmse: 0.52401 | val_1_rmse: 0.5955  |  0:08:24s
epoch 32 | loss: 0.22661 | val_0_rmse: 0.53694 | val_1_rmse: 0.60343 |  0:08:40s
epoch 33 | loss: 0.22685 | val_0_rmse: 0.71952 | val_1_rmse: 0.83115 |  0:08:56s
epoch 34 | loss: 0.22591 | val_0_rmse: 0.4672  | val_1_rmse: 0.49911 |  0:09:11s
epoch 35 | loss: 0.22618 | val_0_rmse: 0.47272 | val_1_rmse: 0.50164 |  0:09:27s
epoch 36 | loss: 0.2242  | val_0_rmse: 0.57732 | val_1_rmse: 0.68403 |  0:09:43s
epoch 37 | loss: 0.22327 | val_0_rmse: 0.53966 | val_1_rmse: 0.62433 |  0:09:59s
epoch 38 | loss: 0.22355 | val_0_rmse: 0.46904 | val_1_rmse: 0.50293 |  0:10:14s
epoch 39 | loss: 0.22295 | val_0_rmse: 0.46721 | val_1_rmse: 0.49846 |  0:10:30s
epoch 40 | loss: 0.22228 | val_0_rmse: 0.46842 | val_1_rmse: 0.50193 |  0:10:46s
epoch 41 | loss: 0.22369 | val_0_rmse: 0.51886 | val_1_rmse: 0.54296 |  0:11:02s
epoch 42 | loss: 0.25355 | val_0_rmse: 0.49231 | val_1_rmse: 0.51537 |  0:11:17s
epoch 43 | loss: 0.23841 | val_0_rmse: 0.47708 | val_1_rmse: 0.50245 |  0:11:33s
epoch 44 | loss: 0.22914 | val_0_rmse: 0.47735 | val_1_rmse: 0.50738 |  0:11:49s
epoch 45 | loss: 0.22631 | val_0_rmse: 0.47171 | val_1_rmse: 0.5017  |  0:12:05s
epoch 46 | loss: 0.2251  | val_0_rmse: 0.46618 | val_1_rmse: 0.49506 |  0:12:20s
epoch 47 | loss: 0.22473 | val_0_rmse: 0.4692  | val_1_rmse: 0.50123 |  0:12:36s
epoch 48 | loss: 0.22241 | val_0_rmse: 0.4824  | val_1_rmse: 0.5181  |  0:12:52s
epoch 49 | loss: 0.22168 | val_0_rmse: 0.46515 | val_1_rmse: 0.49936 |  0:13:08s
epoch 50 | loss: 0.22222 | val_0_rmse: 0.46927 | val_1_rmse: 0.50393 |  0:13:23s
epoch 51 | loss: 0.22123 | val_0_rmse: 0.46325 | val_1_rmse: 0.49898 |  0:13:39s
epoch 52 | loss: 0.22107 | val_0_rmse: 0.46819 | val_1_rmse: 0.49865 |  0:13:55s
epoch 53 | loss: 0.22013 | val_0_rmse: 0.46884 | val_1_rmse: 0.50662 |  0:14:11s
epoch 54 | loss: 0.2183  | val_0_rmse: 0.4689  | val_1_rmse: 0.5068  |  0:14:27s
epoch 55 | loss: 0.21756 | val_0_rmse: 0.51488 | val_1_rmse: 0.53558 |  0:14:42s
epoch 56 | loss: 0.21882 | val_0_rmse: 0.47168 | val_1_rmse: 0.49969 |  0:14:58s
epoch 57 | loss: 0.22059 | val_0_rmse: 0.46682 | val_1_rmse: 0.50225 |  0:15:14s
epoch 58 | loss: 0.21963 | val_0_rmse: 0.46027 | val_1_rmse: 0.4992  |  0:15:30s
epoch 59 | loss: 0.21699 | val_0_rmse: 0.46024 | val_1_rmse: 0.50167 |  0:15:45s
epoch 60 | loss: 0.21683 | val_0_rmse: 0.46564 | val_1_rmse: 0.50556 |  0:16:01s
epoch 61 | loss: 0.21591 | val_0_rmse: 0.47022 | val_1_rmse: 0.50861 |  0:16:17s
epoch 62 | loss: 0.21667 | val_0_rmse: 0.46582 | val_1_rmse: 0.50739 |  0:16:33s
epoch 63 | loss: 0.21664 | val_0_rmse: 0.47383 | val_1_rmse: 0.51349 |  0:16:49s
epoch 64 | loss: 0.21742 | val_0_rmse: 0.46029 | val_1_rmse: 0.50051 |  0:17:04s
epoch 65 | loss: 0.21603 | val_0_rmse: 0.47108 | val_1_rmse: 0.51321 |  0:17:20s
epoch 66 | loss: 0.215   | val_0_rmse: 0.53816 | val_1_rmse: 0.61134 |  0:17:36s
epoch 67 | loss: 0.21653 | val_0_rmse: 0.47572 | val_1_rmse: 0.51939 |  0:17:52s
epoch 68 | loss: 0.21648 | val_0_rmse: 0.48146 | val_1_rmse: 0.52362 |  0:18:08s
epoch 69 | loss: 0.2249  | val_0_rmse: 0.5031  | val_1_rmse: 0.54188 |  0:18:23s
epoch 70 | loss: 0.22179 | val_0_rmse: 0.49724 | val_1_rmse: 0.52738 |  0:18:39s
epoch 71 | loss: 0.21905 | val_0_rmse: 0.4745  | val_1_rmse: 0.51143 |  0:18:55s
epoch 72 | loss: 0.21727 | val_0_rmse: 0.53509 | val_1_rmse: 0.57376 |  0:19:11s
epoch 73 | loss: 0.21872 | val_0_rmse: 0.47877 | val_1_rmse: 0.50854 |  0:19:27s
epoch 74 | loss: 0.21674 | val_0_rmse: 0.48849 | val_1_rmse: 0.52479 |  0:19:43s
epoch 75 | loss: 0.21777 | val_0_rmse: 0.49062 | val_1_rmse: 0.52148 |  0:19:58s
epoch 76 | loss: 0.2254  | val_0_rmse: 0.47479 | val_1_rmse: 0.50678 |  0:20:14s

Early stopping occured at epoch 76 with best_epoch = 46 and best_val_1_rmse = 0.49506
Best weights from best epoch are automatically used!
ended training at: 10:52:26
Feature importance:
Mean squared error is of 1618021186.4602246
Mean absolute error:28256.905584174332
MAPE:0.2751346082219904
R2 score:0.7556183526122762
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 7
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 10:52:29
epoch 0  | loss: 0.57431 | val_0_rmse: 0.67045 | val_1_rmse: 0.67019 |  0:00:15s
epoch 1  | loss: 0.30758 | val_0_rmse: 0.61185 | val_1_rmse: 0.60866 |  0:00:31s
epoch 2  | loss: 0.28383 | val_0_rmse: 0.54883 | val_1_rmse: 0.5507  |  0:00:47s
epoch 3  | loss: 0.27331 | val_0_rmse: 0.52966 | val_1_rmse: 0.53526 |  0:01:02s
epoch 4  | loss: 0.26619 | val_0_rmse: 0.5238  | val_1_rmse: 0.5318  |  0:01:18s
epoch 5  | loss: 0.2606  | val_0_rmse: 0.49309 | val_1_rmse: 0.50416 |  0:01:34s
epoch 6  | loss: 0.25639 | val_0_rmse: 0.48769 | val_1_rmse: 0.50018 |  0:01:50s
epoch 7  | loss: 0.25246 | val_0_rmse: 0.48766 | val_1_rmse: 0.50128 |  0:02:06s
epoch 8  | loss: 0.25133 | val_0_rmse: 0.50678 | val_1_rmse: 0.52193 |  0:02:21s
epoch 9  | loss: 0.24975 | val_0_rmse: 0.50806 | val_1_rmse: 0.52336 |  0:02:37s
epoch 10 | loss: 0.2486  | val_0_rmse: 0.48691 | val_1_rmse: 0.5042  |  0:02:53s
epoch 11 | loss: 0.24542 | val_0_rmse: 0.49712 | val_1_rmse: 0.50924 |  0:03:09s
epoch 12 | loss: 0.24355 | val_0_rmse: 0.49249 | val_1_rmse: 0.50902 |  0:03:24s
epoch 13 | loss: 0.24602 | val_0_rmse: 0.48532 | val_1_rmse: 0.50457 |  0:03:40s
epoch 14 | loss: 0.24351 | val_0_rmse: 0.5161  | val_1_rmse: 0.53695 |  0:03:56s
epoch 15 | loss: 0.24283 | val_0_rmse: 0.5079  | val_1_rmse: 0.52721 |  0:04:12s
epoch 16 | loss: 0.24024 | val_0_rmse: 0.47916 | val_1_rmse: 0.5024  |  0:04:27s
epoch 17 | loss: 0.23903 | val_0_rmse: 0.48257 | val_1_rmse: 0.50419 |  0:04:43s
epoch 18 | loss: 0.23704 | val_0_rmse: 0.49549 | val_1_rmse: 0.51685 |  0:04:59s
epoch 19 | loss: 0.23583 | val_0_rmse: 0.5047  | val_1_rmse: 0.52751 |  0:05:15s
epoch 20 | loss: 0.23499 | val_0_rmse: 0.47486 | val_1_rmse: 0.50019 |  0:05:31s
epoch 21 | loss: 0.23514 | val_0_rmse: 0.50474 | val_1_rmse: 0.52869 |  0:05:46s
epoch 22 | loss: 0.23288 | val_0_rmse: 0.4711  | val_1_rmse: 0.49746 |  0:06:02s
epoch 23 | loss: 0.23324 | val_0_rmse: 0.47818 | val_1_rmse: 0.50238 |  0:06:18s
epoch 24 | loss: 0.23216 | val_0_rmse: 0.5228  | val_1_rmse: 0.54734 |  0:06:34s
epoch 25 | loss: 0.23137 | val_0_rmse: 0.47238 | val_1_rmse: 0.4992  |  0:06:50s
epoch 26 | loss: 0.23219 | val_0_rmse: 0.47538 | val_1_rmse: 0.50327 |  0:07:05s
epoch 27 | loss: 0.22989 | val_0_rmse: 0.47912 | val_1_rmse: 0.50598 |  0:07:21s
epoch 28 | loss: 0.22938 | val_0_rmse: 0.48168 | val_1_rmse: 0.50924 |  0:07:37s
epoch 29 | loss: 0.2316  | val_0_rmse: 0.47192 | val_1_rmse: 0.50006 |  0:07:53s
epoch 30 | loss: 0.22777 | val_0_rmse: 0.48255 | val_1_rmse: 0.51229 |  0:08:09s
epoch 31 | loss: 0.22778 | val_0_rmse: 0.47656 | val_1_rmse: 0.50971 |  0:08:24s
epoch 32 | loss: 0.22681 | val_0_rmse: 0.54504 | val_1_rmse: 0.55273 |  0:08:40s
epoch 33 | loss: 0.22571 | val_0_rmse: 0.47803 | val_1_rmse: 0.50956 |  0:08:56s
epoch 34 | loss: 0.22528 | val_0_rmse: 0.47323 | val_1_rmse: 0.5067  |  0:09:12s
epoch 35 | loss: 0.22634 | val_0_rmse: 0.4741  | val_1_rmse: 0.50309 |  0:09:28s
epoch 36 | loss: 0.22522 | val_0_rmse: 0.46617 | val_1_rmse: 0.49912 |  0:09:43s
epoch 37 | loss: 0.22543 | val_0_rmse: 0.47112 | val_1_rmse: 0.50309 |  0:09:59s
epoch 38 | loss: 0.22308 | val_0_rmse: 0.47236 | val_1_rmse: 0.50698 |  0:10:15s
epoch 39 | loss: 0.2234  | val_0_rmse: 0.48817 | val_1_rmse: 0.52374 |  0:10:30s
epoch 40 | loss: 0.22296 | val_0_rmse: 0.47171 | val_1_rmse: 0.50816 |  0:10:46s
epoch 41 | loss: 0.22262 | val_0_rmse: 0.47351 | val_1_rmse: 0.50604 |  0:11:02s
epoch 42 | loss: 0.22424 | val_0_rmse: 0.48281 | val_1_rmse: 0.51446 |  0:11:17s
epoch 43 | loss: 0.22165 | val_0_rmse: 0.46645 | val_1_rmse: 0.50381 |  0:11:33s
epoch 44 | loss: 0.22321 | val_0_rmse: 0.46734 | val_1_rmse: 0.50448 |  0:11:49s
epoch 45 | loss: 0.22327 | val_0_rmse: 0.49926 | val_1_rmse: 0.52987 |  0:12:05s
epoch 46 | loss: 0.22304 | val_0_rmse: 0.465   | val_1_rmse: 0.50227 |  0:12:20s
epoch 47 | loss: 0.22302 | val_0_rmse: 0.73668 | val_1_rmse: 0.74382 |  0:12:36s
epoch 48 | loss: 0.22107 | val_0_rmse: 0.50072 | val_1_rmse: 0.54105 |  0:12:52s
epoch 49 | loss: 0.21996 | val_0_rmse: 0.46252 | val_1_rmse: 0.50435 |  0:13:08s
epoch 50 | loss: 0.21788 | val_0_rmse: 0.50197 | val_1_rmse: 0.53374 |  0:13:24s
epoch 51 | loss: 0.2206  | val_0_rmse: 0.48252 | val_1_rmse: 0.50154 |  0:13:39s
epoch 52 | loss: 0.22048 | val_0_rmse: 0.47118 | val_1_rmse: 0.51139 |  0:13:55s

Early stopping occured at epoch 52 with best_epoch = 22 and best_val_1_rmse = 0.49746
Best weights from best epoch are automatically used!
ended training at: 11:06:31
Feature importance:
Mean squared error is of 1642759501.9230971
Mean absolute error:28318.00076967275
MAPE:0.26823071136034393
R2 score:0.748320431882004
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 8
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 11:06:34
epoch 0  | loss: 0.64839 | val_0_rmse: 0.65337 | val_1_rmse: 0.65445 |  0:00:15s
epoch 1  | loss: 0.31018 | val_0_rmse: 0.61786 | val_1_rmse: 0.6212  |  0:00:31s
epoch 2  | loss: 0.28205 | val_0_rmse: 0.58854 | val_1_rmse: 0.59603 |  0:00:47s
epoch 3  | loss: 0.27004 | val_0_rmse: 0.52591 | val_1_rmse: 0.53377 |  0:01:03s
epoch 4  | loss: 0.26356 | val_0_rmse: 0.53336 | val_1_rmse: 0.54388 |  0:01:19s
epoch 5  | loss: 0.26744 | val_0_rmse: 0.53273 | val_1_rmse: 0.54597 |  0:01:34s
epoch 6  | loss: 0.25733 | val_0_rmse: 0.49105 | val_1_rmse: 0.50795 |  0:01:50s
epoch 7  | loss: 0.25565 | val_0_rmse: 0.50452 | val_1_rmse: 0.5203  |  0:02:06s
epoch 8  | loss: 0.2498  | val_0_rmse: 0.48432 | val_1_rmse: 0.50606 |  0:02:22s
epoch 9  | loss: 0.24873 | val_0_rmse: 0.49751 | val_1_rmse: 0.51932 |  0:02:37s
epoch 10 | loss: 0.2478  | val_0_rmse: 0.49492 | val_1_rmse: 0.51658 |  0:02:53s
epoch 11 | loss: 0.24554 | val_0_rmse: 0.48941 | val_1_rmse: 0.51074 |  0:03:09s
epoch 12 | loss: 0.24439 | val_0_rmse: 0.48495 | val_1_rmse: 0.50702 |  0:03:25s
epoch 13 | loss: 0.2457  | val_0_rmse: 0.4908  | val_1_rmse: 0.51085 |  0:03:40s
epoch 14 | loss: 0.24372 | val_0_rmse: 0.53974 | val_1_rmse: 0.56015 |  0:03:56s
epoch 15 | loss: 0.24112 | val_0_rmse: 0.48769 | val_1_rmse: 0.51396 |  0:04:12s
epoch 16 | loss: 0.24022 | val_0_rmse: 0.52051 | val_1_rmse: 0.55217 |  0:04:28s
epoch 17 | loss: 0.23925 | val_0_rmse: 0.47892 | val_1_rmse: 0.50481 |  0:04:43s
epoch 18 | loss: 0.23813 | val_0_rmse: 0.47716 | val_1_rmse: 0.50167 |  0:04:59s
epoch 19 | loss: 0.23835 | val_0_rmse: 0.47581 | val_1_rmse: 0.50204 |  0:05:15s
epoch 20 | loss: 0.2379  | val_0_rmse: 0.47755 | val_1_rmse: 0.50552 |  0:05:31s
epoch 21 | loss: 0.23793 | val_0_rmse: 0.47979 | val_1_rmse: 0.50772 |  0:05:46s
epoch 22 | loss: 0.23538 | val_0_rmse: 0.6638  | val_1_rmse: 0.67794 |  0:06:02s
epoch 23 | loss: 0.23611 | val_0_rmse: 0.48149 | val_1_rmse: 0.51485 |  0:06:18s
epoch 24 | loss: 0.23606 | val_0_rmse: 0.47536 | val_1_rmse: 0.51045 |  0:06:34s
epoch 25 | loss: 0.23299 | val_0_rmse: 0.47302 | val_1_rmse: 0.50822 |  0:06:49s
epoch 26 | loss: 0.23391 | val_0_rmse: 0.47318 | val_1_rmse: 0.51159 |  0:07:05s
epoch 27 | loss: 0.23255 | val_0_rmse: 0.48479 | val_1_rmse: 0.51784 |  0:07:21s
epoch 28 | loss: 0.23433 | val_0_rmse: 0.47972 | val_1_rmse: 0.51305 |  0:07:37s
epoch 29 | loss: 0.23222 | val_0_rmse: 0.47708 | val_1_rmse: 0.51357 |  0:07:52s
epoch 30 | loss: 0.23163 | val_0_rmse: 0.48632 | val_1_rmse: 0.51671 |  0:08:08s
epoch 31 | loss: 0.23361 | val_0_rmse: 0.47702 | val_1_rmse: 0.50968 |  0:08:24s
epoch 32 | loss: 0.23005 | val_0_rmse: 0.48996 | val_1_rmse: 0.49913 |  0:08:40s
epoch 33 | loss: 0.22851 | val_0_rmse: 0.46983 | val_1_rmse: 0.50513 |  0:08:56s
epoch 34 | loss: 0.22996 | val_0_rmse: 0.47442 | val_1_rmse: 0.50068 |  0:09:11s
epoch 35 | loss: 0.22717 | val_0_rmse: 0.46612 | val_1_rmse: 0.49888 |  0:09:27s
epoch 36 | loss: 0.2263  | val_0_rmse: 0.46404 | val_1_rmse: 0.49949 |  0:09:43s
epoch 37 | loss: 0.22664 | val_0_rmse: 0.50476 | val_1_rmse: 0.53984 |  0:09:59s
epoch 38 | loss: 0.22817 | val_0_rmse: 0.48349 | val_1_rmse: 0.51145 |  0:10:15s
epoch 39 | loss: 0.22619 | val_0_rmse: 0.48678 | val_1_rmse: 0.50317 |  0:10:31s
epoch 40 | loss: 0.22732 | val_0_rmse: 0.48713 | val_1_rmse: 0.52369 |  0:10:46s
epoch 41 | loss: 0.22535 | val_0_rmse: 0.53648 | val_1_rmse: 0.53388 |  0:11:02s
epoch 42 | loss: 0.22643 | val_0_rmse: 0.47957 | val_1_rmse: 0.51666 |  0:11:18s
epoch 43 | loss: 0.22527 | val_0_rmse: 0.5139  | val_1_rmse: 0.55141 |  0:11:34s
epoch 44 | loss: 0.22396 | val_0_rmse: 0.47414 | val_1_rmse: 0.50947 |  0:11:49s
epoch 45 | loss: 0.22498 | val_0_rmse: 0.48613 | val_1_rmse: 0.52563 |  0:12:05s
epoch 46 | loss: 0.22644 | val_0_rmse: 0.477   | val_1_rmse: 0.5164  |  0:12:21s
epoch 47 | loss: 0.22355 | val_0_rmse: 0.50294 | val_1_rmse: 0.54332 |  0:12:37s
epoch 48 | loss: 0.22278 | val_0_rmse: 0.46796 | val_1_rmse: 0.50635 |  0:12:52s
epoch 49 | loss: 0.22103 | val_0_rmse: 0.47586 | val_1_rmse: 0.52038 |  0:13:08s
epoch 50 | loss: 0.22255 | val_0_rmse: 0.50465 | val_1_rmse: 0.54581 |  0:13:24s
epoch 51 | loss: 0.22161 | val_0_rmse: 0.46319 | val_1_rmse: 0.50451 |  0:13:40s
epoch 52 | loss: 0.22194 | val_0_rmse: 0.47715 | val_1_rmse: 0.52225 |  0:13:55s
epoch 53 | loss: 0.21964 | val_0_rmse: 0.46451 | val_1_rmse: 0.5058  |  0:14:11s
epoch 54 | loss: 0.22031 | val_0_rmse: 0.50142 | val_1_rmse: 0.53566 |  0:14:27s
epoch 55 | loss: 0.2206  | val_0_rmse: 0.47001 | val_1_rmse: 0.51754 |  0:14:43s
epoch 56 | loss: 0.22106 | val_0_rmse: 0.46109 | val_1_rmse: 0.50248 |  0:14:58s
epoch 57 | loss: 0.22114 | val_0_rmse: 0.46488 | val_1_rmse: 0.50797 |  0:15:14s
epoch 58 | loss: 0.2196  | val_0_rmse: 0.47955 | val_1_rmse: 0.51671 |  0:15:30s
epoch 59 | loss: 0.22091 | val_0_rmse: 0.50482 | val_1_rmse: 0.54766 |  0:15:45s
epoch 60 | loss: 0.21982 | val_0_rmse: 0.45837 | val_1_rmse: 0.50196 |  0:16:01s
epoch 61 | loss: 0.22006 | val_0_rmse: 0.47767 | val_1_rmse: 0.52488 |  0:16:17s
epoch 62 | loss: 0.22043 | val_0_rmse: 0.49789 | val_1_rmse: 0.54342 |  0:16:33s
epoch 63 | loss: 0.22072 | val_0_rmse: 0.49274 | val_1_rmse: 0.50702 |  0:16:49s
epoch 64 | loss: 0.22046 | val_0_rmse: 0.4607  | val_1_rmse: 0.50589 |  0:17:04s
epoch 65 | loss: 0.21873 | val_0_rmse: 0.46838 | val_1_rmse: 0.60867 |  0:17:20s

Early stopping occured at epoch 65 with best_epoch = 35 and best_val_1_rmse = 0.49888
Best weights from best epoch are automatically used!
ended training at: 11:24:01
Feature importance:
Mean squared error is of 1609798093.3721304
Mean absolute error:28385.792267846744
MAPE:0.28288332203689226
R2 score:0.7526858692711322
------------------------------------------------------------------
------------------------------------------------------------------
Using the dataset: all_datasets
Using seed = 9
Train/val/test division is 64/18/18
Device used : cuda
Random Forest params:

{'cat_dims': [], 'cat_emb_dim': 1, 'cat_idxs': [], 'clip_value': 1, 'device_name': 'auto', 'epsilon': 1e-15, 'gamma': 1.3, 'input_dim': None, 'lambda_sparse': 0.001, 'mask_type': 'sparsemax', 'momentum': 0.02, 'n_a': 12, 'n_d': 12, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.05}, 'output_dim': None, 'scheduler_fn': None, 'scheduler_params': {}, 'seed': 0, 'verbose': 1}
started training at: 11:24:03
epoch 0  | loss: 0.5629  | val_0_rmse: 0.66211 | val_1_rmse: 0.65925 |  0:00:15s
epoch 1  | loss: 0.29314 | val_0_rmse: 0.57338 | val_1_rmse: 0.57356 |  0:00:31s
epoch 2  | loss: 0.2746  | val_0_rmse: 0.53947 | val_1_rmse: 0.54226 |  0:00:47s
epoch 3  | loss: 0.2692  | val_0_rmse: 0.56794 | val_1_rmse: 0.57802 |  0:01:02s
epoch 4  | loss: 0.2608  | val_0_rmse: 0.54027 | val_1_rmse: 0.55127 |  0:01:18s
epoch 5  | loss: 0.2558  | val_0_rmse: 0.48746 | val_1_rmse: 0.50236 |  0:01:34s
epoch 6  | loss: 0.25394 | val_0_rmse: 0.48426 | val_1_rmse: 0.50085 |  0:01:50s
epoch 7  | loss: 0.25036 | val_0_rmse: 0.48315 | val_1_rmse: 0.50263 |  0:02:05s
epoch 8  | loss: 0.24762 | val_0_rmse: 0.48514 | val_1_rmse: 0.50521 |  0:02:21s
epoch 9  | loss: 0.24731 | val_0_rmse: 0.53257 | val_1_rmse: 0.56177 |  0:02:37s
epoch 10 | loss: 0.24503 | val_0_rmse: 0.49999 | val_1_rmse: 0.54367 |  0:02:52s
epoch 11 | loss: 0.2444  | val_0_rmse: 0.48127 | val_1_rmse: 0.51147 |  0:03:08s
epoch 12 | loss: 0.24309 | val_0_rmse: 0.51029 | val_1_rmse: 0.56175 |  0:03:24s
epoch 13 | loss: 0.24323 | val_0_rmse: 0.51085 | val_1_rmse: 0.53377 |  0:03:40s
epoch 14 | loss: 0.2407  | val_0_rmse: 0.51225 | val_1_rmse: 0.50879 |  0:03:55s
epoch 15 | loss: 0.24021 | val_0_rmse: 0.50752 | val_1_rmse: 0.5227  |  0:04:11s
epoch 16 | loss: 0.23902 | val_0_rmse: 0.47505 | val_1_rmse: 0.51974 |  0:04:27s
epoch 17 | loss: 0.23789 | val_0_rmse: 0.47524 | val_1_rmse: 0.49969 |  0:04:43s
epoch 18 | loss: 0.23614 | val_0_rmse: 0.47653 | val_1_rmse: 0.50368 |  0:04:58s
epoch 19 | loss: 0.23774 | val_0_rmse: 0.47791 | val_1_rmse: 0.50103 |  0:05:14s
epoch 20 | loss: 0.23682 | val_0_rmse: 0.48022 | val_1_rmse: 0.50006 |  0:05:30s
epoch 21 | loss: 0.23426 | val_0_rmse: 0.69207 | val_1_rmse: 0.76322 |  0:05:45s
epoch 22 | loss: 0.23342 | val_0_rmse: 0.5546  | val_1_rmse: 0.60443 |  0:06:01s
epoch 23 | loss: 0.2329  | val_0_rmse: 0.6483  | val_1_rmse: 0.70209 |  0:06:17s
epoch 24 | loss: 0.23184 | val_0_rmse: 0.47484 | val_1_rmse: 0.54745 |  0:06:32s
epoch 25 | loss: 0.23009 | val_0_rmse: 0.59548 | val_1_rmse: 0.6136  |  0:06:48s
epoch 26 | loss: 0.23256 | val_0_rmse: 0.75672 | val_1_rmse: 0.83909 |  0:07:04s
epoch 27 | loss: 0.23225 | val_0_rmse: 0.48101 | val_1_rmse: 0.51628 |  0:07:19s
epoch 28 | loss: 0.23116 | val_0_rmse: 0.47049 | val_1_rmse: 0.50218 |  0:07:35s
epoch 29 | loss: 0.22868 | val_0_rmse: 0.46802 | val_1_rmse: 0.50193 |  0:07:51s
epoch 30 | loss: 0.22875 | val_0_rmse: 0.56109 | val_1_rmse: 0.5813  |  0:08:07s
epoch 31 | loss: 0.22586 | val_0_rmse: 0.46421 | val_1_rmse: 0.50085 |  0:08:22s
epoch 32 | loss: 0.2257  | val_0_rmse: 0.47964 | val_1_rmse: 0.50688 |  0:08:38s
epoch 33 | loss: 0.22669 | val_0_rmse: 0.46791 | val_1_rmse: 0.50483 |  0:08:54s
epoch 34 | loss: 0.22515 | val_0_rmse: 0.52662 | val_1_rmse: 0.5536  |  0:09:10s
epoch 35 | loss: 0.2241  | val_0_rmse: 0.48411 | val_1_rmse: 0.51279 |  0:09:25s
epoch 36 | loss: 0.2249  | val_0_rmse: 0.58636 | val_1_rmse: 0.626   |  0:09:41s
epoch 37 | loss: 0.2226  | val_0_rmse: 0.55431 | val_1_rmse: 0.59087 |  0:09:57s
epoch 38 | loss: 0.22452 | val_0_rmse: 0.47227 | val_1_rmse: 0.50097 |  0:10:12s
epoch 39 | loss: 0.22214 | val_0_rmse: 0.54836 | val_1_rmse: 0.57867 |  0:10:28s
epoch 40 | loss: 0.2203  | val_0_rmse: 0.46114 | val_1_rmse: 0.50198 |  0:10:44s
epoch 41 | loss: 0.22018 | val_0_rmse: 0.46385 | val_1_rmse: 0.50263 |  0:11:00s
epoch 42 | loss: 0.22136 | val_0_rmse: 0.45719 | val_1_rmse: 0.49688 |  0:11:15s
epoch 43 | loss: 0.22005 | val_0_rmse: 0.48633 | val_1_rmse: 0.53427 |  0:11:31s
epoch 44 | loss: 0.22074 | val_0_rmse: 0.53411 | val_1_rmse: 0.56289 |  0:11:47s
epoch 45 | loss: 0.21915 | val_0_rmse: 0.46738 | val_1_rmse: 0.51419 |  0:12:02s
epoch 46 | loss: 0.21739 | val_0_rmse: 0.45893 | val_1_rmse: 0.50202 |  0:12:18s
epoch 47 | loss: 0.21734 | val_0_rmse: 0.4774  | val_1_rmse: 0.51895 |  0:12:34s
epoch 48 | loss: 0.21752 | val_0_rmse: 0.46356 | val_1_rmse: 0.50568 |  0:12:50s
epoch 49 | loss: 0.21638 | val_0_rmse: 0.46517 | val_1_rmse: 0.50456 |  0:13:05s
epoch 50 | loss: 0.21545 | val_0_rmse: 0.46507 | val_1_rmse: 0.50331 |  0:13:21s
epoch 51 | loss: 0.21693 | val_0_rmse: 0.46456 | val_1_rmse: 0.51477 |  0:13:37s
epoch 52 | loss: 0.2169  | val_0_rmse: 0.47074 | val_1_rmse: 0.50758 |  0:13:53s
epoch 53 | loss: 0.21648 | val_0_rmse: 0.46225 | val_1_rmse: 0.50766 |  0:14:08s
epoch 54 | loss: 0.21548 | val_0_rmse: 0.48687 | val_1_rmse: 0.55055 |  0:14:24s
epoch 55 | loss: 0.21505 | val_0_rmse: 0.46726 | val_1_rmse: 0.50403 |  0:14:40s
epoch 56 | loss: 0.2171  | val_0_rmse: 0.46028 | val_1_rmse: 0.50654 |  0:14:55s
epoch 57 | loss: 0.21413 | val_0_rmse: 0.47079 | val_1_rmse: 0.52054 |  0:15:11s
epoch 58 | loss: 0.21395 | val_0_rmse: 0.45936 | val_1_rmse: 0.50106 |  0:15:27s
epoch 59 | loss: 0.21159 | val_0_rmse: 0.45604 | val_1_rmse: 0.50146 |  0:15:43s
epoch 60 | loss: 0.2127  | val_0_rmse: 0.45326 | val_1_rmse: 0.49741 |  0:15:59s
epoch 61 | loss: 0.21328 | val_0_rmse: 0.45741 | val_1_rmse: 0.5086  |  0:16:14s
epoch 62 | loss: 0.2128  | val_0_rmse: 0.47705 | val_1_rmse: 0.53145 |  0:16:30s
epoch 63 | loss: 0.21167 | val_0_rmse: 0.46923 | val_1_rmse: 0.51042 |  0:16:46s
epoch 64 | loss: 0.21469 | val_0_rmse: 0.4596  | val_1_rmse: 0.54517 |  0:17:02s
epoch 65 | loss: 0.21284 | val_0_rmse: 0.45389 | val_1_rmse: 0.50201 |  0:17:17s
epoch 66 | loss: 0.21322 | val_0_rmse: 0.45469 | val_1_rmse: 0.49928 |  0:17:33s
epoch 67 | loss: 0.21189 | val_0_rmse: 0.45394 | val_1_rmse: 0.50175 |  0:17:49s
epoch 68 | loss: 0.21474 | val_0_rmse: 0.46412 | val_1_rmse: 0.50996 |  0:18:04s
epoch 69 | loss: 0.2175  | val_0_rmse: 0.47763 | val_1_rmse: 0.51655 |  0:18:20s
epoch 70 | loss: 0.21376 | val_0_rmse: 0.48714 | val_1_rmse: 0.54136 |  0:18:36s
epoch 71 | loss: 0.21482 | val_0_rmse: 0.48568 | val_1_rmse: 0.52466 |  0:18:52s
epoch 72 | loss: 0.2121  | val_0_rmse: 0.46309 | val_1_rmse: 0.50381 |  0:19:08s

Early stopping occured at epoch 72 with best_epoch = 42 and best_val_1_rmse = 0.49688
Best weights from best epoch are automatically used!
ended training at: 11:43:18
Feature importance:
Mean squared error is of 1615678758.933834
Mean absolute error:27954.22770226399
MAPE:0.26800320979867387
R2 score:0.756515641004162
------------------------------------------------------------------
